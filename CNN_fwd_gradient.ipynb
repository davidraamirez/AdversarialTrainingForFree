{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/CNN_fwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Without Backpropagation"
      ],
      "metadata": {
        "id": "qkzEBdcD3BRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm\n",
        "import torch.distributions as distr"
      ],
      "metadata": {
        "id": "dM-jay923zDH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "2DoBHL2Tz2s3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "from torchvision import transforms as T"
      ],
      "metadata": {
        "id": "h5aLBvC5z3kK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the dataset"
      ],
      "metadata": {
        "id": "w_w7gA2P5bQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "YNmPBpfS3FYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This loads data with both data conversion.\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, transform=T.ToTensor())"
      ],
      "metadata": {
        "id": "SLtrWriJ07-S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaders are used to shuffle, batch, and possibly sample the elements of the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "L9a4PEGN0SUD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "print(xb.shape)\n",
        "print(yb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkrrE4f0f7K",
        "outputId": "df9b9295-7ca1-4586-ea44-5d9a8fe42062"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 28, 28])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data is similar, but (a) we do not apply data augmentation,\n",
        "# and (b) we do not shuffle when building the mini-batches.\n",
        "test_data = torchvision.datasets.KMNIST('./data', train=False, transform=T.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "-acBNiYh1KxY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Convolutional Neural Network Class"
      ],
      "metadata": {
        "id": "T55GS3b95kKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "M0UQB1abkxvi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b,):\n",
        "        super().__init__()\n",
        "        input_size = 1\n",
        "        self.conv1 = nn.Conv2d(input_size, 8, 3, padding=1)\n",
        "        self.conv1.weight = torch.nn.Parameter(conv1w)\n",
        "        self.conv1.bias = torch.nn.Parameter(conv1b)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "        self.conv2.weight = torch.nn.Parameter(conv2w)\n",
        "        self.conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3.weight = torch.nn.Parameter(conv3w)\n",
        "        self.conv3.bias = torch.nn.Parameter(conv3b)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4.weight = torch.nn.Parameter(conv4w)\n",
        "        self.conv4.bias = torch.nn.Parameter(conv4b)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
        "        self.fc1.weight = torch.nn.Parameter(fc1w)\n",
        "        self.fc1.bias = torch.nn.Parameter(fc1b)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "        self.fc2.weight = torch.nn.Parameter(fc2w)\n",
        "        self.fc2.bias = torch.nn.Parameter(fc2b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.reshape((-1, 64*7*7))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "ssgUZF_S8gmM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ9BguV01cPi",
        "outputId": "6cf7e3c0-843d-409d-e51e-3cbeb96b4620"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the parameters"
      ],
      "metadata": {
        "id": "jgPnXQqq54pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "conv1w = torch.randn((8, 1, 3, 3), requires_grad=False)\n",
        "conv1b = torch.randn(8, requires_grad=False)\n",
        "conv2w = torch.randn((16, 8, 3, 3), requires_grad=False)\n",
        "conv2b = torch.randn(16, requires_grad=False)\n",
        "conv3w = torch.randn((32, 16, 3, 3), requires_grad=False)\n",
        "conv3b = torch.randn(32, requires_grad=False)\n",
        "conv4w = torch.randn((64, 32, 3, 3), requires_grad=False)\n",
        "conv4b = torch.randn(64, requires_grad=False)\n",
        "fc1w = torch.randn((1024, 3136), requires_grad=False)\n",
        "fc1b = torch.randn(1024, requires_grad=False)\n",
        "fc2w = torch.randn((10, 1024), requires_grad=False)\n",
        "fc2b = torch.randn(10, requires_grad=False)\n",
        "cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)"
      ],
      "metadata": {
        "id": "Exuz9TVC3ReH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we also need to move data when asking for a prediction\n",
        "cnn(xb.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBOLO2Ee3ZwE",
        "outputId": "52f8d7d6-613a-477b-d143-32a0993915e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate the network with forward gradient"
      ],
      "metadata": {
        "id": "TIaVzpBW5th5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(net, loader, device):\n",
        "  # A function that aggregates the accuracy over all mini-batches in the loader.\n",
        "  # See here for a quick-start on torchmetrics: https://torchmetrics.readthedocs.io/en/stable/pages/quickstart.html.\n",
        "  #acc = torchmetrics.Accuracy().to(device)\n",
        "  acc = torchmetrics.Accuracy('multiclass', num_classes=10).to(device)\n",
        "  for xb, yb in loader:\n",
        "      xb, yb = xb.to(device), yb.to(device)\n",
        "      ypred = cnn(xb)\n",
        "      _ = acc(ypred, yb)\n",
        "  return acc.compute()"
      ],
      "metadata": {
        "id": "oY45ByC93hg7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 10% (random guessing).\n",
        "accuracy(cnn, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNh5yF2Q53Tv",
        "outputId": "6ba27eeb-a21a-4572-c684-7a1d55153161"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0891, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CROSS_ENTROPY"
      ],
      "metadata": {
        "id": "fxOipAfLLhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: it is important to move the CNN to the device before initializing the optimizer,\n",
        "# since the optimizer also has a state that must be moved to the GPU.\n",
        "loss = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "17Sb5kRR550I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beale_function(x):\n",
        "  return (torch.pow(torch.tensor([1.5])-x[0]+x[0]*x[1],2) + torch.pow(torch.tensor([2.25])-x[0]+x[0]*torch.pow(x[1],2),2)+torch.pow(torch.tensor([2.625])-x[0]+x[0]*torch.pow(x[1],3),2))"
      ],
      "metadata": {
        "id": "1WtQ6zyjX6wD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock_function(x):\n",
        "  sum=0\n",
        "  for p in x.size():\n",
        "    for i in range (x.size(1)-1):\n",
        "      sum += (100*torch.pow(x[i+1] - torch.pow(x[i], 2), 2) + torch.pow(x[i]-1, 2))\n",
        "  return sum"
      ],
      "metadata": {
        "id": "KsZbhrFnAoK5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functorch import jvp"
      ],
      "metadata": {
        "id": "9oIHpG0dvhhj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fwd_gradient(x, y):\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  l_rate0 = 0.025\n",
        "  f = rosenbrock_function\n",
        "\n",
        "  #Parameters\n",
        "  conv1w = torch.randn((8, 1, 3, 3), requires_grad=False)\n",
        "  conv1b = torch.randn(8, requires_grad=False)\n",
        "  conv2w = torch.randn((16, 8, 3, 3), requires_grad=False)\n",
        "  conv2b = torch.randn(16, requires_grad=False)\n",
        "  conv3w = torch.randn((32, 16, 3, 3), requires_grad=False)\n",
        "  conv3b = torch.randn(32, requires_grad=False)\n",
        "  conv4w = torch.randn((64, 32, 3, 3), requires_grad=False)\n",
        "  conv4b = torch.randn(64, requires_grad=False)\n",
        "  fc1w = torch.randn((1024, 3136), requires_grad=False)\n",
        "  fc1b = torch.randn(1024, requires_grad=False)\n",
        "  fc2w = torch.randn((1, 1024), requires_grad=False)\n",
        "  fc2b = torch.randn(1, requires_grad=False) \n",
        "\n",
        "  conv1w1 = conv1w.reshape(-1)\n",
        "  conv2w1 = conv2w.reshape(-1)\n",
        "  conv3w1 = conv3w.reshape(-1)\n",
        "  conv4w1 = conv4w.reshape(-1)\n",
        "  fc1w1 = fc1w.reshape(-1)\n",
        "  fc2w1 = fc2w.reshape(-1)\n",
        "\n",
        "  cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "  error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  t=torch.tensor([0])\n",
        "\n",
        "  while (error>1e-3) :\n",
        "\n",
        "    t=t+1\n",
        "\n",
        "    vconv1w1=torch.diagonal(torch.normal(torch.zeros_like(conv1w1),torch.eye(conv1w1.shape[0])))\n",
        "    vconv1b=torch.diagonal(torch.normal(torch.zeros_like(conv1b),torch.eye(conv1b.shape[0])))\n",
        "    vconv2w1=torch.diagonal(torch.normal(torch.zeros_like(conv2w1),torch.eye(conv2w1.shape[0])))\n",
        "    vconv2b=torch.diagonal(torch.normal(torch.zeros_like(conv2b),torch.eye(conv2b.shape[0])))\n",
        "    vconv3w1=torch.diagonal(torch.normal(torch.zeros_like(conv3w1),torch.eye(conv3w1.shape[0])))\n",
        "    vconv3b=torch.diagonal(torch.normal(torch.zeros_like(conv3b),torch.eye(conv3b.shape[0])))\n",
        "    vconv4w1=torch.diagonal(torch.normal(torch.zeros_like(conv4w1),torch.eye(conv4w1.shape[0])))\n",
        "    vconv4b=torch.diagonal(torch.normal(torch.zeros_like(conv4b),torch.eye(conv4b.shape[0])))\n",
        "    vfc1w1=torch.diagonal(torch.normal(torch.zeros_like(fc1w1),torch.eye(fc1w1.shape[0])))\n",
        "    vfc1b=torch.diagonal(torch.normal(torch.zeros_like(fc1b),torch.eye(fc1b.shape[0])))\n",
        "    vfc2w1=torch.diagonal(torch.normal(torch.zeros_like(fc2w1),torch.eye(fc2w1.shape[0])))\n",
        "    vfc2b=torch.diagonal(torch.normal(torch.zeros_like(fc2b),torch.eye(fc2b.shape[0])))\n",
        "\n",
        "    ftconv1w1=f(conv1w1)\n",
        "    ftconv1b=f(conv1b)\n",
        "    ftconv2w1=f(conv2w1)\n",
        "    ftconv2b=f(conv2b)\n",
        "    ftconv3w1=f(conv3w1)\n",
        "    ftconv3b=f(conv3b)\n",
        "    ftconv4w1=f(conv4w1)\n",
        "    ftconv4b=f(conv4b)\n",
        "    ftfc1w1=f(fc1w1)\n",
        "    ftfc1b=f(fc1b)\n",
        "    ftfc2w1=f(fc2w1)\n",
        "    ftfc2b=f(fc2b)\n",
        "\n",
        "    dtconv1w1=torch.tensor(jvp(f,(conv1w1, ), (vconv1w1, ))[1])\n",
        "    dtconv1b=torch.tensor(jvp(f,(conv1b, ), (vconv1b, ))[1])\n",
        "    dtconv2w1=torch.tensor(jvp(f,(conv2w1, ), (vconv2w1, ))[1])\n",
        "    dtconv2b=torch.tensor(jvp(f,(conv2b, ), (vconv2b, ))[1])\n",
        "    dtconv3w1=torch.tensor(jvp(f,(conv3w1, ), (vconv3w1, ))[1])\n",
        "    dtconv3b=torch.tensor(jvp(f,(conv3b, ), (vconv3b, ))[1])\n",
        "    dtconv4w1=torch.tensor(jvp(f,(conv4w1, ), (vconv4w1, ))[1])\n",
        "    dtconv4b=torch.tensor(jvp(f,(conv4b, ), (vconv4b, ))[1])\n",
        "    dtfc1w1=torch.tensor(jvp(f,(fc1w1, ), (vfc1w1, ))[1])\n",
        "    dtfc1b=torch.tensor(jvp(f,(fc1b, ), (vfc1b, ))[1])\n",
        "    dtfc2w1=torch.tensor(jvp(f,(fc2w1, ), (vfc2w1, ))[1])\n",
        "    dtfc2b=torch.tensor(jvp(f,(fc2b, ), (vfc2b, ))[1])\n",
        "\n",
        "    gtconv1w1 = vconv1w1*dtconv1w1\n",
        "    gtconv1b = vconv1b*dtconv1b\n",
        "    gtconv2w1 = vconv2w1*dtconv2w1\n",
        "    gtconv2b = vconv2b*dtconv2b\n",
        "    gtconv3w1 = vconv3w1*dtconv3w1\n",
        "    gtconv3b = vconv3b*dtconv3b\n",
        "    gtconv4w1 = vconv4w1*dtconv4w1\n",
        "    gtconv4b = vconv4b*dtconv4b\n",
        "    gtfc1w1 = vfc1w1*dtfc1w1\n",
        "    gtfc1b = vfc1b*dtfc1b\n",
        "    gtfc2w1 = vfc2w1*dtfc2w1\n",
        "    gtfc2b = vfc2b*dtfc2b\n",
        "\n",
        "    conv1w1 -= l_rate0*gtconv1w1\n",
        "    conv1b -= l_rate0*gtconv1b\n",
        "    conv2w1 -= l_rate0*gtconv2w1\n",
        "    conv2b -= l_rate0*gtconv2b\n",
        "    conv3w1 -= l_rate0*gtconv3w1\n",
        "    conv3b -= l_rate0*gtconv3w1\n",
        "    conv4w1 -= l_rate0*gtconv4w1\n",
        "    conv4b -= l_rate0*gtconv4b\n",
        "    fc1w1 -= l_rate0*gtfc1w1\n",
        "    fc1b -= l_rate0*gtfc1b\n",
        "    fc2w1 -= l_rate0*gtfc2w1\n",
        "    fc2b -= l_rate0*gtfc2b\n",
        "\n",
        "    conv1w = conv1w1.reshape(-1, 1, 3, 3)\n",
        "    conv2w = conv2w1.reshape(-1, 8, 3, 3)\n",
        "    conv3w = conv3w1.reshape(-1, 16, 3, 3)\n",
        "    conv4w = conv4w1.reshape(-1, 32, 3, 3)\n",
        "    fc1w = fc1w1.reshape(-1, 3136)\n",
        "    fc2w = fc2w1.reshape(-1, 1024)\n",
        "\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "    error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  return conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b "
      ],
      "metadata": {
        "id": "1xtc8O-2D8YJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "\n",
        "  cnn.train()\n",
        "  for i in range(1):\n",
        "    xb, yb = next(iter(train_loader))\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "\n",
        "    conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b = train_fwd_gradient(xb, yb)\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "\n",
        "    #Update cnn parameters\n",
        "    #Recalculate ypred and loss\n",
        "    #MIRAR NN_LAB_LOGISITC_REGRESSION\n",
        "    #CALCULAR G(THETA) QUE ES EL GRADIENTE Y APLICARLO A LOS PARAMETROS DEL CNN, LOS WEIGHTS"
      ],
      "metadata": {
        "id": "V3k3eeKL_TPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}