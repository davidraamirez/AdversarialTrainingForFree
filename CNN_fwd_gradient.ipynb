{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/CNN_fwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Without Backpropagation"
      ],
      "metadata": {
        "id": "qkzEBdcD3BRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm\n",
        "import torch.distributions as distr"
      ],
      "metadata": {
        "id": "dM-jay923zDH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "2DoBHL2Tz2s3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "h5aLBvC5z3kK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the dataset"
      ],
      "metadata": {
        "id": "w_w7gA2P5bQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "YNmPBpfS3FYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This loads data with both data conversion.\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, transform=T.ToTensor())\n",
        "plt.imshow(train_data.data[0])\n",
        "print(train_data.targets[0])"
      ],
      "metadata": {
        "id": "SLtrWriJ07-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0786e4c5-a33f-46db-b402-9789b560d3e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaders are used to shuffle, batch, and possibly sample the elements of the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "L9a4PEGN0SUD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "xb=xb/255"
      ],
      "metadata": {
        "id": "0HkrrE4f0f7K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data is similar, but (a) we do not apply data augmentation,\n",
        "# and (b) we do not shuffle when building the mini-batches.\n",
        "test_data = torchvision.datasets.KMNIST('./data', train=False, transform=T.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "-acBNiYh1KxY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Convolutional Neural Network Class"
      ],
      "metadata": {
        "id": "T55GS3b95kKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "M0UQB1abkxvi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b,):\n",
        "        super().__init__()\n",
        "        input_size = 1\n",
        "        self.conv1 = nn.Conv2d(input_size, 8, 3, padding=1)\n",
        "        self.conv1.weight = torch.nn.Parameter(conv1w)\n",
        "        self.conv1.bias = torch.nn.Parameter(conv1b)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "        self.conv2.weight = torch.nn.Parameter(conv2w)\n",
        "        self.conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3.weight = torch.nn.Parameter(conv3w)\n",
        "        self.conv3.bias = torch.nn.Parameter(conv3b)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4.weight = torch.nn.Parameter(conv4w)\n",
        "        self.conv4.bias = torch.nn.Parameter(conv4b)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
        "        self.fc1.weight = torch.nn.Parameter(fc1w)\n",
        "        self.fc1.bias = torch.nn.Parameter(fc1b)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "        self.fc2.weight = torch.nn.Parameter(fc2w)\n",
        "        self.fc2.bias = torch.nn.Parameter(fc2b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.reshape((-1, 64*7*7))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "ssgUZF_S8gmM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ9BguV01cPi",
        "outputId": "ef506c05-0917-4c6e-e3df-aff64dcbbf83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the parameters"
      ],
      "metadata": {
        "id": "jgPnXQqq54pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "conv1w = torch.FloatTensor(8, 1, 3, 3).uniform_(-1, 1)\n",
        "print(conv1w)\n",
        "conv1b = torch.randint(-1, 1, (8, ), dtype=torch.float32, requires_grad=False)\n",
        "conv2w = torch.randint(-1, 1, (16, 8, 3, 3), dtype=torch.float32, requires_grad=False)\n",
        "conv2b = torch.randint(-1, 1, (16, ), dtype=torch.float32, requires_grad=False)\n",
        "conv3w = torch.randint(-1, 1, (32, 16, 3, 3), dtype=torch.float32, requires_grad=False)\n",
        "conv3b = torch.randint(-1, 1, (32, ), dtype=torch.float32, requires_grad=False)\n",
        "conv4w = torch.randint(-1, 1, (64, 32, 3, 3), dtype=torch.float32, requires_grad=False)\n",
        "conv4b = torch.randint(-1, 1, (64, ), dtype=torch.float32, requires_grad=False)\n",
        "fc1w = torch.randint(-1, 1, (1024, 3136), dtype=torch.float32, requires_grad=False)\n",
        "fc1b = torch.randint(-1, 1, (1024, ), dtype=torch.float32, requires_grad=False)\n",
        "fc2w = torch.randint(-1, 1, (10, 1024), dtype=torch.float32, requires_grad=False)\n",
        "fc2b = torch.randint(-1, 1, (10, ), dtype=torch.float32, requires_grad=False)\n",
        "cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)"
      ],
      "metadata": {
        "id": "Exuz9TVC3ReH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "63d74739-dd25-4c3c-9821-7e0d9da37e75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d949bf4a444d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We initialize the parameters randomly and the model with an input size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconv1w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv1b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv2w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (tuple, requires_grad=bool), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: requires_grad\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we also need to move data when asking for a prediction\n",
        "print(cnn(xb.to(device))[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBOLO2Ee3ZwE",
        "outputId": "1a742094-32cf-4b83-d6f9-49c764ce58bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-465518.6875,  570140.6250, -489208.9375,  151515.0469,  106204.8906,\n",
            "         365368.9375, -297497.2812, -262074.3906,  -21101.6289, -514078.8750],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate the network with forward gradient"
      ],
      "metadata": {
        "id": "TIaVzpBW5th5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(net, loader, device):\n",
        "  # A function that aggregates the accuracy over all mini-batches in the loader.\n",
        "  # See here for a quick-start on torchmetrics: https://torchmetrics.readthedocs.io/en/stable/pages/quickstart.html.\n",
        "  #acc = torchmetrics.Accuracy().to(device)\n",
        "  acc = torchmetrics.Accuracy('multiclass', num_classes=10).to(device)\n",
        "  for xb, yb in loader:\n",
        "      xb, yb = xb.to(device), yb.to(device)\n",
        "      ypred = cnn(xb)\n",
        "      _ = acc(ypred, yb)\n",
        "  return acc.compute()"
      ],
      "metadata": {
        "id": "oY45ByC93hg7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 10% (random guessing).\n",
        "accuracy(cnn, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNh5yF2Q53Tv",
        "outputId": "158cee9a-1297-415a-bf3d-a46a7bb3a27c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0611, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CROSS_ENTROPY"
      ],
      "metadata": {
        "id": "fxOipAfLLhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: it is important to move the CNN to the device before initializing the optimizer,\n",
        "# since the optimizer also has a state that must be moved to the GPU.\n",
        "loss = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "17Sb5kRR550I"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beale_function(x):\n",
        "  return (torch.pow(torch.tensor([1.5])-x[0]+x[0]*x[1],2) + torch.pow(torch.tensor([2.25])-x[0]+x[0]*torch.pow(x[1],2),2)+torch.pow(torch.tensor([2.625])-x[0]+x[0]*torch.pow(x[1],3),2))"
      ],
      "metadata": {
        "id": "1WtQ6zyjX6wD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock_function(x):\n",
        "  sum=0\n",
        "  for p in x.size():\n",
        "    for i in range (x.size(1)-1):\n",
        "      sum += (100*torch.pow(x[i+1] - torch.pow(x[i], 2), 2) + torch.pow(x[i]-1, 2))\n",
        "  return sum"
      ],
      "metadata": {
        "id": "KsZbhrFnAoK5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functorch import jvp"
      ],
      "metadata": {
        "id": "9oIHpG0dvhhj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fwd_gradient(x, y):\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  x = x / 255\n",
        "\n",
        "  l_rate0 = 0.025\n",
        "  f = rosenbrock_function\n",
        "\n",
        "  #Parameters\n",
        "  conv1w = torch.randn((8, 1, 3, 3), requires_grad=False)\n",
        "  conv1b = torch.randn(8, requires_grad=False)\n",
        "  conv2w = torch.randn((16, 8, 3, 3), requires_grad=False)\n",
        "  conv2b = torch.randn(16, requires_grad=False)\n",
        "  conv3w = torch.randn((32, 16, 3, 3), requires_grad=False)\n",
        "  conv3b = torch.randn(32, requires_grad=False)\n",
        "  conv4w = torch.randn((64, 32, 3, 3), requires_grad=False)\n",
        "  conv4b = torch.randn(64, requires_grad=False)\n",
        "  fc1w = torch.randn((1024, 3136), requires_grad=False)\n",
        "  fc1b = torch.randn(1024, requires_grad=False)\n",
        "  fc2w = torch.randn((1, 1024), requires_grad=False)\n",
        "  fc2b = torch.randn(1, requires_grad=False) \n",
        "\n",
        "  conv1w1 = conv1w.reshape(-1)\n",
        "  conv2w1 = conv2w.reshape(-1)\n",
        "  conv3w1 = conv3w.reshape(-1)\n",
        "  conv4w1 = conv4w.reshape(-1)\n",
        "  fc1w1 = fc1w.reshape(-1)\n",
        "  fc2w1 = fc2w.reshape(-1)\n",
        "\n",
        "  cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "  error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  t=torch.tensor([0])\n",
        "\n",
        "  while (error>1e-3) :\n",
        "\n",
        "    t=t+1\n",
        "\n",
        "    vconv1w1=torch.diagonal(torch.normal(torch.zeros_like(conv1w1),torch.eye(conv1w1.shape[0])))\n",
        "    vconv1b=torch.diagonal(torch.normal(torch.zeros_like(conv1b),torch.eye(conv1b.shape[0])))\n",
        "    vconv2w1=torch.diagonal(torch.normal(torch.zeros_like(conv2w1),torch.eye(conv2w1.shape[0])))\n",
        "    vconv2b=torch.diagonal(torch.normal(torch.zeros_like(conv2b),torch.eye(conv2b.shape[0])))\n",
        "    vconv3w1=torch.diagonal(torch.normal(torch.zeros_like(conv3w1),torch.eye(conv3w1.shape[0])))\n",
        "    vconv3b=torch.diagonal(torch.normal(torch.zeros_like(conv3b),torch.eye(conv3b.shape[0])))\n",
        "    vconv4w1=torch.diagonal(torch.normal(torch.zeros_like(conv4w1),torch.eye(conv4w1.shape[0])))\n",
        "    vconv4b=torch.diagonal(torch.normal(torch.zeros_like(conv4b),torch.eye(conv4b.shape[0])))\n",
        "    vfc1w1=torch.diagonal(torch.normal(torch.zeros_like(fc1w1),torch.eye(fc1w1.shape[0])))\n",
        "    vfc1b=torch.diagonal(torch.normal(torch.zeros_like(fc1b),torch.eye(fc1b.shape[0])))\n",
        "    vfc2w1=torch.diagonal(torch.normal(torch.zeros_like(fc2w1),torch.eye(fc2w1.shape[0])))\n",
        "    vfc2b=torch.diagonal(torch.normal(torch.zeros_like(fc2b),torch.eye(fc2b.shape[0])))\n",
        "\n",
        "    ftconv1w1=f(conv1w1)\n",
        "    ftconv1b=f(conv1b)\n",
        "    ftconv2w1=f(conv2w1)\n",
        "    ftconv2b=f(conv2b)\n",
        "    ftconv3w1=f(conv3w1)\n",
        "    ftconv3b=f(conv3b)\n",
        "    ftconv4w1=f(conv4w1)\n",
        "    ftconv4b=f(conv4b)\n",
        "    ftfc1w1=f(fc1w1)\n",
        "    ftfc1b=f(fc1b)\n",
        "    ftfc2w1=f(fc2w1)\n",
        "    ftfc2b=f(fc2b)\n",
        "\n",
        "    dtconv1w1=torch.tensor(jvp(f,(conv1w1, ), (vconv1w1, ))[1])\n",
        "    dtconv1b=torch.tensor(jvp(f,(conv1b, ), (vconv1b, ))[1])\n",
        "    dtconv2w1=torch.tensor(jvp(f,(conv2w1, ), (vconv2w1, ))[1])\n",
        "    dtconv2b=torch.tensor(jvp(f,(conv2b, ), (vconv2b, ))[1])\n",
        "    dtconv3w1=torch.tensor(jvp(f,(conv3w1, ), (vconv3w1, ))[1])\n",
        "    dtconv3b=torch.tensor(jvp(f,(conv3b, ), (vconv3b, ))[1])\n",
        "    dtconv4w1=torch.tensor(jvp(f,(conv4w1, ), (vconv4w1, ))[1])\n",
        "    dtconv4b=torch.tensor(jvp(f,(conv4b, ), (vconv4b, ))[1])\n",
        "    dtfc1w1=torch.tensor(jvp(f,(fc1w1, ), (vfc1w1, ))[1])\n",
        "    dtfc1b=torch.tensor(jvp(f,(fc1b, ), (vfc1b, ))[1])\n",
        "    dtfc2w1=torch.tensor(jvp(f,(fc2w1, ), (vfc2w1, ))[1])\n",
        "    dtfc2b=torch.tensor(jvp(f,(fc2b, ), (vfc2b, ))[1])\n",
        "\n",
        "    gtconv1w1 = vconv1w1*dtconv1w1\n",
        "    gtconv1b = vconv1b*dtconv1b\n",
        "    gtconv2w1 = vconv2w1*dtconv2w1\n",
        "    gtconv2b = vconv2b*dtconv2b\n",
        "    gtconv3w1 = vconv3w1*dtconv3w1\n",
        "    gtconv3b = vconv3b*dtconv3b\n",
        "    gtconv4w1 = vconv4w1*dtconv4w1\n",
        "    gtconv4b = vconv4b*dtconv4b\n",
        "    gtfc1w1 = vfc1w1*dtfc1w1\n",
        "    gtfc1b = vfc1b*dtfc1b\n",
        "    gtfc2w1 = vfc2w1*dtfc2w1\n",
        "    gtfc2b = vfc2b*dtfc2b\n",
        "\n",
        "    conv1w1 -= l_rate0*gtconv1w1\n",
        "    conv1b -= l_rate0*gtconv1b\n",
        "    conv2w1 -= l_rate0*gtconv2w1\n",
        "    conv2b -= l_rate0*gtconv2b\n",
        "    conv3w1 -= l_rate0*gtconv3w1\n",
        "    conv3b -= l_rate0*gtconv3w1\n",
        "    conv4w1 -= l_rate0*gtconv4w1\n",
        "    conv4b -= l_rate0*gtconv4b\n",
        "    fc1w1 -= l_rate0*gtfc1w1\n",
        "    fc1b -= l_rate0*gtfc1b\n",
        "    fc2w1 -= l_rate0*gtfc2w1\n",
        "    fc2b -= l_rate0*gtfc2b\n",
        "\n",
        "    conv1w = conv1w1.reshape(-1, 1, 3, 3)\n",
        "    conv2w = conv2w1.reshape(-1, 8, 3, 3)\n",
        "    conv3w = conv3w1.reshape(-1, 16, 3, 3)\n",
        "    conv4w = conv4w1.reshape(-1, 32, 3, 3)\n",
        "    fc1w = fc1w1.reshape(-1, 3136)\n",
        "    fc2w = fc2w1.reshape(-1, 1024)\n",
        "\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "    error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  return conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b "
      ],
      "metadata": {
        "id": "1xtc8O-2D8YJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "\n",
        "  cnn.train()\n",
        "  for i in range(1):\n",
        "    xb, yb = next(iter(train_loader))\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "\n",
        "    conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b = train_fwd_gradient(xb, yb)\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "\n",
        "    #Update cnn parameters\n",
        "    #Recalculate ypred and loss\n",
        "    #MIRAR NN_LAB_LOGISITC_REGRESSION\n",
        "    #CALCULAR G(THETA) QUE ES EL GRADIENTE Y APLICARLO A LOS PARAMETROS DEL CNN, LOS WEIGHTS"
      ],
      "metadata": {
        "id": "V3k3eeKL_TPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}