{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/CNN_fwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Without Backpropagation"
      ],
      "metadata": {
        "id": "qkzEBdcD3BRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm\n",
        "import torch.distributions as distr"
      ],
      "metadata": {
        "id": "dM-jay923zDH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "2DoBHL2Tz2s3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "h5aLBvC5z3kK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the dataset"
      ],
      "metadata": {
        "id": "w_w7gA2P5bQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "YNmPBpfS3FYq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This loads data with both data conversion.\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, transform=T.ToTensor())"
      ],
      "metadata": {
        "id": "SLtrWriJ07-S"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaders are used to shuffle, batch, and possibly sample the elements of the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True)"
      ],
      "metadata": {
        "id": "L9a4PEGN0SUD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.randn(500, 1, 1, 28, 28)\n",
        "ytrain = torch.randn(500, 1)\n",
        "for i in range(500):\n",
        "  xb, yb = next(iter(train_loader))\n",
        "  Xtrain[i] = xb\n",
        "  ytrain[i] = yb\n",
        "\n",
        "print(Xtrain.shape)\n",
        "print(ytrain.shape)"
      ],
      "metadata": {
        "id": "0HkrrE4f0f7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b838532b-440d-44a7-a3bc-782dba093f9b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 1, 1, 28, 28])\n",
            "torch.Size([500, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data is similar, but (a) we do not apply data augmentation,\n",
        "# and (b) we do not shuffle when building the mini-batches.\n",
        "test_data = torchvision.datasets.KMNIST('./data', train=False, transform=T.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False)"
      ],
      "metadata": {
        "id": "-acBNiYh1KxY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest = torch.randn(50, 1, 1, 28, 28)\n",
        "ytest = torch.randn(50, 1)\n",
        "for i in range(50):\n",
        "  xb, yb = next(iter(test_loader))\n",
        "  Xtest[i] = xb\n",
        "  ytest[i] = yb\n",
        "\n",
        "print(Xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwZXzD1SHc80",
        "outputId": "dde4f9a5-5104-4f3a-cee1-46e9afaeaca8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1, 1, 28, 28])\n",
            "torch.Size([50, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Convolutional Neural Network Class"
      ],
      "metadata": {
        "id": "T55GS3b95kKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "M0UQB1abkxvi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size, conv1w, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b,):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_size, 2, 3, padding=1)\n",
        "        self.conv1.weight = torch.nn.Parameter(conv1w)\n",
        "        self.conv1.bias = torch.nn.Parameter(conv1b)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "        self.conv2.weight = torch.nn.Parameter(conv2w)\n",
        "        self.conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.w1 = torch.nn.Parameter(fc1w)\n",
        "        self.b1 = torch.nn.Parameter(fc1b)\n",
        "\n",
        "        self.w2 = torch.nn.Parameter(fc2w)\n",
        "        self.b2 = torch.nn.Parameter(fc2b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.reshape((-1, 4*14*14))\n",
        "        x = F.relu(x@self.w1 + self.b1)\n",
        "        x = x@self.w2 + self.b2\n",
        "        return torch.softmax(x,1)"
      ],
      "metadata": {
        "id": "ssgUZF_S8gmM"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ9BguV01cPi",
        "outputId": "174a6ba0-eeff-45a2-db94-3c532f7a9abc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the parameters"
      ],
      "metadata": {
        "id": "jgPnXQqq54pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "conv1w = torch.FloatTensor(2, 1, 3, 3).uniform_(-1, 1)\n",
        "conv1b = torch.FloatTensor(2).uniform_(-1, 1)\n",
        "conv2w = torch.FloatTensor(4, 2, 3, 3).uniform_(-1, 1)\n",
        "conv2b = torch.FloatTensor(4).uniform_(-1, 1)\n",
        "\n",
        "fc1w = torch.FloatTensor(4*14*14,8).uniform_(-1,1)\n",
        "fc1b = torch.FloatTensor(8).uniform_(-1, 1)\n",
        "fc2w = torch.FloatTensor(8,10).uniform_(-1, 1)\n",
        "fc2b = torch.FloatTensor(10).uniform_(-1, 1)\n",
        "cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b).to(device)"
      ],
      "metadata": {
        "id": "Exuz9TVC3ReH"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we also need to move data when asking for a prediction\n",
        "print(cnn(xb.to(device)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBOLO2Ee3ZwE",
        "outputId": "374a6c63-8d61-4468-f41b-ca027abd5601"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropycw1(conv1w, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  print(ypred.shape)\n",
        "  print(ytrue.shape)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()\n"
      ],
      "metadata": {
        "id": "1iYdouzmxI8F"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropycb1(conv1b, conv1w, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "IiGnOrHszB5-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropycw2(conv2w, conv1b, conv1w, conv2b, fc1w, fc1b, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "EBqCOZoBzGIk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropycb2(conv2b, conv1b, conv2w, conv1w, fc1w, fc1b, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "R91OW2Jn3LK2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropyfcw1(fc1w, conv1b, conv2w, conv2b, conv1w, fc1b, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "XNmvJCi23ZF7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropyfcb1(fc1b, conv1b, conv2w, conv2b, fc1w, conv1w, fc2w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "qPi9yulD3gDk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropyfcw2(fc2w, conv1b, conv2w, conv2b, fc1w, fc1b, conv1w, fc2b, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "HEZInDl_3yGK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropyfcb2(fc2b, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, conv1w, ytrue, x):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  ypred=torch.randn((ytrue.shape[0],10))\n",
        "  for j in range (ytrue.shape[0]):\n",
        "    xj =x[j]\n",
        "    conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
        "    conv1.weight = torch.nn.Parameter(conv1w)\n",
        "    conv1.bias = torch.nn.Parameter(conv1b)\n",
        "    conv2 = nn.Conv2d(2, 4, 3, padding=1)\n",
        "    conv2.weight = torch.nn.Parameter(conv2w)\n",
        "    conv2.bias = torch.nn.Parameter(conv2b)\n",
        "\n",
        "    xj = F.relu(conv1(xj))\n",
        "    xj = F.relu(conv2(xj))\n",
        "    xj = nn.MaxPool2d(2)(xj)\n",
        "    xj = xj.reshape((-1, 4*14*14))\n",
        "    xj = F.relu(xj@fc1w + fc1b)\n",
        "    xj = xj@fc2w + fc2b\n",
        "    ypred[j]=torch.softmax(xj,1)\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "sldvM_RZ4BdI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cross_entropycw1(conv1w, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b,ytrain, Xtrain))\n",
        "print(cross_entropycb1(conv1b, conv1w, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b,yb,xb))\n",
        "print(cross_entropycw2(conv2w, conv1b, conv1w, conv2b, fc1w, fc1b, fc2w, fc2b,yb,xb))\n",
        "print(cross_entropycb2(conv2b, conv1b, conv2w, conv1w, fc1w, fc1b, fc2w, fc2b,yb,xb))\n",
        "print(cross_entropyfcw1(fc1w, conv1b, conv2w, conv2b, conv1w, fc1b, fc2w, fc2b,yb,xb))\n",
        "print(cross_entropyfcb1(fc1b, conv1b, conv2w, conv2b, fc1w, conv1w, fc2w, fc2b,yb,xb))\n",
        "print(cross_entropyfcw2(fc2w, conv1b, conv2w, conv2b, fc1w, fc1b, conv1w, fc2b,yb,xb))\n",
        "print(cross_entropyfcb2(fc2b, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, conv1w,yb,xb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "CZ04qJvNzWm2",
        "outputId": "4368c885-168c-442b-d0cf-4e601d6f8a31"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 10])\n",
            "torch.Size([500, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-d8cc5ee16adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropycw1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropycb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropycw2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropycb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropyfcw1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-dc4de6f18414>\u001b[0m in \u001b[0;36mcross_entropycw1\u001b[0;34m(conv1w, conv1b, conv2w, conv2b, fc1w, fc1b, fc2w, fc2b, ytrue, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate the network with forward gradient"
      ],
      "metadata": {
        "id": "TIaVzpBW5th5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "oY45ByC93hg7"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 10% (random guessing).\n",
        "print(yb)\n",
        "print(cnn(xb.to(device)))\n",
        "accuracy(yb.to(device), cnn(xb.to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNh5yF2Q53Tv",
        "outputId": "89f191db-f338-4a52-995d-77cff6152b95"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0])\n",
            "tensor([[4.9879e-01, 8.5248e-07, 9.2412e-06, 2.2820e-08, 3.3297e-05, 4.4109e-03,\n",
            "         4.8422e-01, 1.2538e-02, 5.7235e-07, 1.4758e-06]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CROSS_ENTROPY"
      ],
      "metadata": {
        "id": "fxOipAfLLhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: it is important to move the CNN to the device before initializing the optimizer,\n",
        "# since the optimizer also has a state that must be moved to the GPU.\n",
        "loss = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "17Sb5kRR550I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beale_function(x):\n",
        "  return (torch.pow(torch.tensor([1.5])-x[0]+x[0]*x[1],2) + torch.pow(torch.tensor([2.25])-x[0]+x[0]*torch.pow(x[1],2),2)+torch.pow(torch.tensor([2.625])-x[0]+x[0]*torch.pow(x[1],3),2))"
      ],
      "metadata": {
        "id": "1WtQ6zyjX6wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock_function(x):\n",
        "  sum=0\n",
        "  for p in x.size():\n",
        "    for i in range (x.size(1)-1):\n",
        "      sum += (100*torch.pow(x[i+1] - torch.pow(x[i], 2), 2) + torch.pow(x[i]-1, 2))\n",
        "  return sum"
      ],
      "metadata": {
        "id": "KsZbhrFnAoK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functorch import jvp"
      ],
      "metadata": {
        "id": "9oIHpG0dvhhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fwd_gradient(x, y):\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  x = x / 255\n",
        "\n",
        "  l_rate0 = 0.025\n",
        "  f = rosenbrock_function\n",
        "\n",
        "  #Parameters\n",
        "  conv1w = torch.randn((8, 1, 3, 3), requires_grad=False)\n",
        "  conv1b = torch.randn(8, requires_grad=False)\n",
        "  conv2w = torch.randn((16, 8, 3, 3), requires_grad=False)\n",
        "  conv2b = torch.randn(16, requires_grad=False)\n",
        "  conv3w = torch.randn((32, 16, 3, 3), requires_grad=False)\n",
        "  conv3b = torch.randn(32, requires_grad=False)\n",
        "  conv4w = torch.randn((64, 32, 3, 3), requires_grad=False)\n",
        "  conv4b = torch.randn(64, requires_grad=False)\n",
        "  fc1w = torch.randn((1024, 3136), requires_grad=False)\n",
        "  fc1b = torch.randn(1024, requires_grad=False)\n",
        "  fc2w = torch.randn((1, 1024), requires_grad=False)\n",
        "  fc2b = torch.randn(1, requires_grad=False) \n",
        "\n",
        "  conv1w1 = conv1w.reshape(-1)\n",
        "  conv2w1 = conv2w.reshape(-1)\n",
        "  conv3w1 = conv3w.reshape(-1)\n",
        "  conv4w1 = conv4w.reshape(-1)\n",
        "  fc1w1 = fc1w.reshape(-1)\n",
        "  fc2w1 = fc2w.reshape(-1)\n",
        "\n",
        "  cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "  error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  t=torch.tensor([0])\n",
        "\n",
        "  while (error>1e-3) :\n",
        "\n",
        "    t=t+1\n",
        "\n",
        "    vconv1w1=torch.diagonal(torch.normal(torch.zeros_like(conv1w1),torch.eye(conv1w1.shape[0])))\n",
        "    vconv1b=torch.diagonal(torch.normal(torch.zeros_like(conv1b),torch.eye(conv1b.shape[0])))\n",
        "    vconv2w1=torch.diagonal(torch.normal(torch.zeros_like(conv2w1),torch.eye(conv2w1.shape[0])))\n",
        "    vconv2b=torch.diagonal(torch.normal(torch.zeros_like(conv2b),torch.eye(conv2b.shape[0])))\n",
        "    vconv3w1=torch.diagonal(torch.normal(torch.zeros_like(conv3w1),torch.eye(conv3w1.shape[0])))\n",
        "    vconv3b=torch.diagonal(torch.normal(torch.zeros_like(conv3b),torch.eye(conv3b.shape[0])))\n",
        "    vconv4w1=torch.diagonal(torch.normal(torch.zeros_like(conv4w1),torch.eye(conv4w1.shape[0])))\n",
        "    vconv4b=torch.diagonal(torch.normal(torch.zeros_like(conv4b),torch.eye(conv4b.shape[0])))\n",
        "    vfc1w1=torch.diagonal(torch.normal(torch.zeros_like(fc1w1),torch.eye(fc1w1.shape[0])))\n",
        "    vfc1b=torch.diagonal(torch.normal(torch.zeros_like(fc1b),torch.eye(fc1b.shape[0])))\n",
        "    vfc2w1=torch.diagonal(torch.normal(torch.zeros_like(fc2w1),torch.eye(fc2w1.shape[0])))\n",
        "    vfc2b=torch.diagonal(torch.normal(torch.zeros_like(fc2b),torch.eye(fc2b.shape[0])))\n",
        "\n",
        "    ftconv1w1=f(conv1w1)\n",
        "    ftconv1b=f(conv1b)\n",
        "    ftconv2w1=f(conv2w1)\n",
        "    ftconv2b=f(conv2b)\n",
        "    ftconv3w1=f(conv3w1)\n",
        "    ftconv3b=f(conv3b)\n",
        "    ftconv4w1=f(conv4w1)\n",
        "    ftconv4b=f(conv4b)\n",
        "    ftfc1w1=f(fc1w1)\n",
        "    ftfc1b=f(fc1b)\n",
        "    ftfc2w1=f(fc2w1)\n",
        "    ftfc2b=f(fc2b)\n",
        "\n",
        "    dtconv1w1=torch.tensor(jvp(f,(conv1w1, ), (vconv1w1, ))[1])\n",
        "    dtconv1b=torch.tensor(jvp(f,(conv1b, ), (vconv1b, ))[1])\n",
        "    dtconv2w1=torch.tensor(jvp(f,(conv2w1, ), (vconv2w1, ))[1])\n",
        "    dtconv2b=torch.tensor(jvp(f,(conv2b, ), (vconv2b, ))[1])\n",
        "    dtconv3w1=torch.tensor(jvp(f,(conv3w1, ), (vconv3w1, ))[1])\n",
        "    dtconv3b=torch.tensor(jvp(f,(conv3b, ), (vconv3b, ))[1])\n",
        "    dtconv4w1=torch.tensor(jvp(f,(conv4w1, ), (vconv4w1, ))[1])\n",
        "    dtconv4b=torch.tensor(jvp(f,(conv4b, ), (vconv4b, ))[1])\n",
        "    dtfc1w1=torch.tensor(jvp(f,(fc1w1, ), (vfc1w1, ))[1])\n",
        "    dtfc1b=torch.tensor(jvp(f,(fc1b, ), (vfc1b, ))[1])\n",
        "    dtfc2w1=torch.tensor(jvp(f,(fc2w1, ), (vfc2w1, ))[1])\n",
        "    dtfc2b=torch.tensor(jvp(f,(fc2b, ), (vfc2b, ))[1])\n",
        "\n",
        "    gtconv1w1 = vconv1w1*dtconv1w1\n",
        "    gtconv1b = vconv1b*dtconv1b\n",
        "    gtconv2w1 = vconv2w1*dtconv2w1\n",
        "    gtconv2b = vconv2b*dtconv2b\n",
        "    gtconv3w1 = vconv3w1*dtconv3w1\n",
        "    gtconv3b = vconv3b*dtconv3b\n",
        "    gtconv4w1 = vconv4w1*dtconv4w1\n",
        "    gtconv4b = vconv4b*dtconv4b\n",
        "    gtfc1w1 = vfc1w1*dtfc1w1\n",
        "    gtfc1b = vfc1b*dtfc1b\n",
        "    gtfc2w1 = vfc2w1*dtfc2w1\n",
        "    gtfc2b = vfc2b*dtfc2b\n",
        "\n",
        "    conv1w1 -= l_rate0*gtconv1w1\n",
        "    conv1b -= l_rate0*gtconv1b\n",
        "    conv2w1 -= l_rate0*gtconv2w1\n",
        "    conv2b -= l_rate0*gtconv2b\n",
        "    conv3w1 -= l_rate0*gtconv3w1\n",
        "    conv3b -= l_rate0*gtconv3w1\n",
        "    conv4w1 -= l_rate0*gtconv4w1\n",
        "    conv4b -= l_rate0*gtconv4b\n",
        "    fc1w1 -= l_rate0*gtfc1w1\n",
        "    fc1b -= l_rate0*gtfc1b\n",
        "    fc2w1 -= l_rate0*gtfc2w1\n",
        "    fc2b -= l_rate0*gtfc2b\n",
        "\n",
        "    conv1w = conv1w1.reshape(-1, 1, 3, 3)\n",
        "    conv2w = conv2w1.reshape(-1, 8, 3, 3)\n",
        "    conv3w = conv3w1.reshape(-1, 16, 3, 3)\n",
        "    conv4w = conv4w1.reshape(-1, 32, 3, 3)\n",
        "    fc1w = fc1w1.reshape(-1, 3136)\n",
        "    fc2w = fc2w1.reshape(-1, 1024)\n",
        "\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "    error = torch.norm(cnn(x)-y, 2)\n",
        "\n",
        "  return conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b "
      ],
      "metadata": {
        "id": "1xtc8O-2D8YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "\n",
        "  cnn.train()\n",
        "  for i in range(1):\n",
        "    xb, yb = next(iter(train_loader))\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "\n",
        "    conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b = train_fwd_gradient(xb, yb)\n",
        "    cnn = SimpleCNN(1, conv1w, conv1b, conv2w, conv2b, conv3w, conv3b, conv4w, conv4b, fc1w, fc1b, fc2w, fc2b).to(device)\n",
        "\n",
        "    #Update cnn parameters\n",
        "    #Recalculate ypred and loss\n",
        "    #MIRAR NN_LAB_LOGISITC_REGRESSION\n",
        "    #CALCULAR G(THETA) QUE ES EL GRADIENTE Y APLICARLO A LOS PARAMETROS DEL CNN, LOS WEIGHTS"
      ],
      "metadata": {
        "id": "V3k3eeKL_TPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}