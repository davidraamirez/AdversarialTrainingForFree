{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq77Nj/G5LrdzOf8oMkBAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/LogisticRegression_bwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the necessary packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "x7iZpPFrGWhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rkQFFcg0HXnN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "PZ648ILgHfn2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "ShzuBabDHhVe"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "A61m0FPpGijm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "ZHyH8jgfGmnf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "14D3LUb1KU8z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and preprocessing the data**"
      ],
      "metadata": {
        "id": "G-a43m8xGoJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "penguins = tfds.load('penguins', as_supervised=True, split='train')"
      ],
      "metadata": {
        "id": "ml7IdhKkHjfC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = penguins.batch(500).get_single_element()\n",
        "X, y = X.numpy(), y.numpy()"
      ],
      "metadata": {
        "id": "c2BMFvK7HoFd"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "metadata": {
        "id": "bDM9PTN0HrKa"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "Xtest = torch.from_numpy(Xtest).float()"
      ],
      "metadata": {
        "id": "JLGZsa5pHtTD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "pubjWXD8Hvva"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Logistic Regression**"
      ],
      "metadata": {
        "id": "9y_Sd0mlG27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, w, b):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(w)\n",
        "    self.bias = nn.Parameter(b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(1, -1)\n",
        "    return torch.softmax(x@self.weight + self.bias, 1)"
      ],
      "metadata": {
        "id": "YjCVZwwrH3ah"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pv1yTiJH7JV",
        "outputId": "89546ede-6040-4f30-f2e1-3fece73c5db9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize the parameters**"
      ],
      "metadata": {
        "id": "dUvft9uYG_Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "w = torch.randn((4, 3), requires_grad=True)\n",
        "b = torch.randn((3, ), requires_grad=True)\n",
        "LG = SimpleLogisticRegression(4, w, b).to(device)"
      ],
      "metadata": {
        "id": "l2X3STJaH9aY"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We try our model with the first example\n",
        "print(LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbykYgnuIAWE",
        "outputId": "1e065c9f-64a4-45ea-bc2a-7cd7af36ef32"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5353, 0.4229, 0.0418]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate predictions"
      ],
      "metadata": {
        "id": "-nxjcQ7-HQh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(x,w,b):\n",
        "  ypred=torch.randn((x.shape[0],3))\n",
        "  for j in range (x.shape[0]):\n",
        "    xj = x[j].reshape(1, -1)\n",
        "    ypred[j]=torch.softmax(xj@w+b,1)\n",
        "  return ypred"
      ],
      "metadata": {
        "id": "2OCd-kbfLV5h"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=pred(Xtrain,w,b)"
      ],
      "metadata": {
        "id": "SzBH4FuVNabv"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define accuracy**"
      ],
      "metadata": {
        "id": "1g51kfRQHWSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "_LQ7YyETIB7n"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 33% (random guessing).\n",
        "accuracy(ytrain.to(device),ypred.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bGfj-mfIFwZ",
        "outputId": "c71a5413-4405-4c4f-c8cd-28cc8629882c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0840)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define cross entropy**"
      ],
      "metadata": {
        "id": "hiEzUJ_GHmQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(ytrue,ypred):\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "1MVXQ3PTILFk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cross_entropy(ytrain,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDzjWsUK6YG",
        "outputId": "09afbe36-8b53-49dc-c744-8196da74d00a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0693, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and evaluate the network**"
      ],
      "metadata": {
        "id": "sCrAi6M2H3wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bwd_gradient(x,y):\n",
        "\n",
        "  x,y=x.to(device),y.to(device)\n",
        "\n",
        "  losses = [] # Vector with the cross entropy values of test set\n",
        "  accuracies = [] # Vector with the accuracy values of test set\n",
        "  errors=[] # Vector with the number of misclassification of the test set\n",
        "\n",
        "  l_rate0 = 0.2 # Learning rate used \n",
        "\n",
        "  # Initialize the parameters\n",
        "  w = torch.randn((4, 3), requires_grad=True)\n",
        "  b = torch.randn((3, ), requires_grad=True)\n",
        "\n",
        "  ypred=pred(x,w,b)\n",
        "\n",
        "  loss = cross_entropy(ytrain,ypred) # Loss function\n",
        "\n",
        "  # Calculate the start time \n",
        "  t=0\n",
        "  t0=time.time()\n",
        "  print('Time', t, 'loss', loss)\n",
        "\n",
        "  while (loss>0.3): \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Apply gradients \n",
        "      w -= 0.01*w.grad\n",
        "      b -= 0.01*b.grad\n",
        "\n",
        "      # Gradients are accumulated: we need to zero them out before the next iteration.\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "    \n",
        "    # We calculate the number of misclassification of the test set with the updated model and we add to the errors vector\n",
        "    LG = SimpleLogisticRegression(4, w, b)\n",
        "    ypredT=torch.randn(Xtest.size(0),3)\n",
        "    error=0\n",
        "    for i in range (Xtest.size(0)):\n",
        "      ypredT[i]=LG(Xtest[i])\n",
        "      if (LG(Xtest[i]).argmax(1)- ytest[i])!=0:\n",
        "        error = error+ 1\n",
        "    errors.append(error)\n",
        "\n",
        "    ypred=pred(x,w,b)\n",
        "    \n",
        "    # We calculate the accuracy of the test set with the updated model and we add to the accuracy vector\n",
        "    accuracies.append(accuracy(ytest,ypredT).item())\n",
        "\n",
        "    # We calculate the cross_entropy of the test set with the updated model and we add to the accuracy vector\n",
        "    loss = cross_entropy(ytrain,ypred)\n",
        "    lossT = cross_entropy(ytest,ypredT)\n",
        "    losses.append(lossT.detach().item())\n",
        "\n",
        "    #We add the execution time of the iteration\n",
        "    t1=time.time()\n",
        "    t+=t1-t0\n",
        "    t0=t1\n",
        "    print('Time', t, 'loss', loss)\n",
        "  \n",
        "  return w,b,errors,losses,accuracies\n"
      ],
      "metadata": {
        "id": "cBld3TwvLDl6"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b,errors,losses,accuracies = train_bwd_gradient(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXOhaZSOPSCa",
        "outputId": "fc31ba70-68f3-42fc-b737-7bfae60e8dae"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Time 107.07836937904358 loss tensor(0.5333, grad_fn=<NegBackward0>)\n",
            "Time 107.11759686470032 loss tensor(0.5332, grad_fn=<NegBackward0>)\n",
            "Time 107.15836548805237 loss tensor(0.5331, grad_fn=<NegBackward0>)\n",
            "Time 107.20437932014465 loss tensor(0.5331, grad_fn=<NegBackward0>)\n",
            "Time 107.26481199264526 loss tensor(0.5330, grad_fn=<NegBackward0>)\n",
            "Time 107.3237829208374 loss tensor(0.5329, grad_fn=<NegBackward0>)\n",
            "Time 107.36668705940247 loss tensor(0.5328, grad_fn=<NegBackward0>)\n",
            "Time 107.41058015823364 loss tensor(0.5327, grad_fn=<NegBackward0>)\n",
            "Time 107.44921684265137 loss tensor(0.5326, grad_fn=<NegBackward0>)\n",
            "Time 107.49478125572205 loss tensor(0.5325, grad_fn=<NegBackward0>)\n",
            "Time 107.5339252948761 loss tensor(0.5324, grad_fn=<NegBackward0>)\n",
            "Time 107.57471680641174 loss tensor(0.5323, grad_fn=<NegBackward0>)\n",
            "Time 107.61468553543091 loss tensor(0.5322, grad_fn=<NegBackward0>)\n",
            "Time 107.656574010849 loss tensor(0.5321, grad_fn=<NegBackward0>)\n",
            "Time 107.69612216949463 loss tensor(0.5320, grad_fn=<NegBackward0>)\n",
            "Time 107.75178909301758 loss tensor(0.5319, grad_fn=<NegBackward0>)\n",
            "Time 107.79146265983582 loss tensor(0.5318, grad_fn=<NegBackward0>)\n",
            "Time 107.82963728904724 loss tensor(0.5318, grad_fn=<NegBackward0>)\n",
            "Time 107.86888217926025 loss tensor(0.5317, grad_fn=<NegBackward0>)\n",
            "Time 107.91378855705261 loss tensor(0.5316, grad_fn=<NegBackward0>)\n",
            "Time 107.95392179489136 loss tensor(0.5315, grad_fn=<NegBackward0>)\n",
            "Time 107.99346947669983 loss tensor(0.5314, grad_fn=<NegBackward0>)\n",
            "Time 108.03167080879211 loss tensor(0.5313, grad_fn=<NegBackward0>)\n",
            "Time 108.0696668624878 loss tensor(0.5312, grad_fn=<NegBackward0>)\n",
            "Time 108.10813808441162 loss tensor(0.5311, grad_fn=<NegBackward0>)\n",
            "Time 108.15558218955994 loss tensor(0.5310, grad_fn=<NegBackward0>)\n",
            "Time 108.20253086090088 loss tensor(0.5309, grad_fn=<NegBackward0>)\n",
            "Time 108.24233031272888 loss tensor(0.5308, grad_fn=<NegBackward0>)\n",
            "Time 108.28260445594788 loss tensor(0.5307, grad_fn=<NegBackward0>)\n",
            "Time 108.32161951065063 loss tensor(0.5306, grad_fn=<NegBackward0>)\n",
            "Time 108.365225315094 loss tensor(0.5305, grad_fn=<NegBackward0>)\n",
            "Time 108.40493726730347 loss tensor(0.5305, grad_fn=<NegBackward0>)\n",
            "Time 108.44438028335571 loss tensor(0.5304, grad_fn=<NegBackward0>)\n",
            "Time 108.4833312034607 loss tensor(0.5303, grad_fn=<NegBackward0>)\n",
            "Time 108.52113509178162 loss tensor(0.5302, grad_fn=<NegBackward0>)\n",
            "Time 108.55981636047363 loss tensor(0.5301, grad_fn=<NegBackward0>)\n",
            "Time 108.6059181690216 loss tensor(0.5300, grad_fn=<NegBackward0>)\n",
            "Time 108.65114426612854 loss tensor(0.5299, grad_fn=<NegBackward0>)\n",
            "Time 108.68928909301758 loss tensor(0.5298, grad_fn=<NegBackward0>)\n",
            "Time 108.72828197479248 loss tensor(0.5297, grad_fn=<NegBackward0>)\n",
            "Time 108.77433514595032 loss tensor(0.5296, grad_fn=<NegBackward0>)\n",
            "Time 108.81772184371948 loss tensor(0.5295, grad_fn=<NegBackward0>)\n",
            "Time 108.85856795310974 loss tensor(0.5294, grad_fn=<NegBackward0>)\n",
            "Time 108.89823079109192 loss tensor(0.5294, grad_fn=<NegBackward0>)\n",
            "Time 108.93698287010193 loss tensor(0.5293, grad_fn=<NegBackward0>)\n",
            "Time 108.97501683235168 loss tensor(0.5292, grad_fn=<NegBackward0>)\n",
            "Time 109.01264095306396 loss tensor(0.5291, grad_fn=<NegBackward0>)\n",
            "Time 109.0645079612732 loss tensor(0.5290, grad_fn=<NegBackward0>)\n",
            "Time 109.10411596298218 loss tensor(0.5289, grad_fn=<NegBackward0>)\n",
            "Time 109.14756631851196 loss tensor(0.5288, grad_fn=<NegBackward0>)\n",
            "Time 109.18653893470764 loss tensor(0.5287, grad_fn=<NegBackward0>)\n",
            "Time 109.22601413726807 loss tensor(0.5286, grad_fn=<NegBackward0>)\n",
            "Time 109.26778769493103 loss tensor(0.5285, grad_fn=<NegBackward0>)\n",
            "Time 109.30887532234192 loss tensor(0.5284, grad_fn=<NegBackward0>)\n",
            "Time 109.34779739379883 loss tensor(0.5283, grad_fn=<NegBackward0>)\n",
            "Time 109.39288473129272 loss tensor(0.5283, grad_fn=<NegBackward0>)\n",
            "Time 109.43969798088074 loss tensor(0.5282, grad_fn=<NegBackward0>)\n",
            "Time 109.4846875667572 loss tensor(0.5281, grad_fn=<NegBackward0>)\n",
            "Time 109.5233507156372 loss tensor(0.5280, grad_fn=<NegBackward0>)\n",
            "Time 109.56160140037537 loss tensor(0.5279, grad_fn=<NegBackward0>)\n",
            "Time 109.60298681259155 loss tensor(0.5278, grad_fn=<NegBackward0>)\n",
            "Time 109.6438057422638 loss tensor(0.5277, grad_fn=<NegBackward0>)\n",
            "Time 109.68317580223083 loss tensor(0.5276, grad_fn=<NegBackward0>)\n",
            "Time 109.73427152633667 loss tensor(0.5275, grad_fn=<NegBackward0>)\n",
            "Time 109.77319073677063 loss tensor(0.5274, grad_fn=<NegBackward0>)\n",
            "Time 109.81985569000244 loss tensor(0.5273, grad_fn=<NegBackward0>)\n",
            "Time 109.85889720916748 loss tensor(0.5272, grad_fn=<NegBackward0>)\n",
            "Time 109.90402936935425 loss tensor(0.5272, grad_fn=<NegBackward0>)\n",
            "Time 109.94343137741089 loss tensor(0.5271, grad_fn=<NegBackward0>)\n",
            "Time 109.98560094833374 loss tensor(0.5270, grad_fn=<NegBackward0>)\n",
            "Time 110.02578592300415 loss tensor(0.5269, grad_fn=<NegBackward0>)\n",
            "Time 110.06529974937439 loss tensor(0.5268, grad_fn=<NegBackward0>)\n",
            "Time 110.1041350364685 loss tensor(0.5267, grad_fn=<NegBackward0>)\n",
            "Time 110.15531063079834 loss tensor(0.5266, grad_fn=<NegBackward0>)\n",
            "Time 110.195472240448 loss tensor(0.5265, grad_fn=<NegBackward0>)\n",
            "Time 110.238436460495 loss tensor(0.5264, grad_fn=<NegBackward0>)\n",
            "Time 110.28258275985718 loss tensor(0.5263, grad_fn=<NegBackward0>)\n",
            "Time 110.32812333106995 loss tensor(0.5263, grad_fn=<NegBackward0>)\n",
            "Time 110.37454319000244 loss tensor(0.5262, grad_fn=<NegBackward0>)\n",
            "Time 110.41335582733154 loss tensor(0.5261, grad_fn=<NegBackward0>)\n",
            "Time 110.45158267021179 loss tensor(0.5260, grad_fn=<NegBackward0>)\n",
            "Time 110.49023866653442 loss tensor(0.5259, grad_fn=<NegBackward0>)\n",
            "Time 110.52828526496887 loss tensor(0.5258, grad_fn=<NegBackward0>)\n",
            "Time 110.56671786308289 loss tensor(0.5257, grad_fn=<NegBackward0>)\n",
            "Time 110.61350512504578 loss tensor(0.5256, grad_fn=<NegBackward0>)\n",
            "Time 110.65490007400513 loss tensor(0.5255, grad_fn=<NegBackward0>)\n",
            "Time 110.69971632957458 loss tensor(0.5254, grad_fn=<NegBackward0>)\n",
            "Time 110.7392840385437 loss tensor(0.5253, grad_fn=<NegBackward0>)\n",
            "Time 110.77759194374084 loss tensor(0.5253, grad_fn=<NegBackward0>)\n",
            "Time 110.84062218666077 loss tensor(0.5252, grad_fn=<NegBackward0>)\n",
            "Time 110.88091444969177 loss tensor(0.5251, grad_fn=<NegBackward0>)\n",
            "Time 110.92205739021301 loss tensor(0.5250, grad_fn=<NegBackward0>)\n",
            "Time 110.96106219291687 loss tensor(0.5249, grad_fn=<NegBackward0>)\n",
            "Time 111.00167608261108 loss tensor(0.5248, grad_fn=<NegBackward0>)\n",
            "Time 111.04352331161499 loss tensor(0.5247, grad_fn=<NegBackward0>)\n",
            "Time 111.09449505805969 loss tensor(0.5246, grad_fn=<NegBackward0>)\n",
            "Time 111.13396120071411 loss tensor(0.5245, grad_fn=<NegBackward0>)\n",
            "Time 111.17309713363647 loss tensor(0.5244, grad_fn=<NegBackward0>)\n",
            "Time 111.21413898468018 loss tensor(0.5244, grad_fn=<NegBackward0>)\n",
            "Time 111.2625081539154 loss tensor(0.5243, grad_fn=<NegBackward0>)\n",
            "Time 111.30124235153198 loss tensor(0.5242, grad_fn=<NegBackward0>)\n",
            "Time 111.34571528434753 loss tensor(0.5241, grad_fn=<NegBackward0>)\n",
            "Time 111.38394355773926 loss tensor(0.5240, grad_fn=<NegBackward0>)\n",
            "Time 111.42200303077698 loss tensor(0.5239, grad_fn=<NegBackward0>)\n",
            "Time 111.4605131149292 loss tensor(0.5238, grad_fn=<NegBackward0>)\n",
            "Time 111.50550103187561 loss tensor(0.5237, grad_fn=<NegBackward0>)\n",
            "Time 111.54401779174805 loss tensor(0.5236, grad_fn=<NegBackward0>)\n",
            "Time 111.58225440979004 loss tensor(0.5236, grad_fn=<NegBackward0>)\n",
            "Time 111.62506675720215 loss tensor(0.5235, grad_fn=<NegBackward0>)\n",
            "Time 111.66868352890015 loss tensor(0.5234, grad_fn=<NegBackward0>)\n",
            "Time 111.71504378318787 loss tensor(0.5233, grad_fn=<NegBackward0>)\n",
            "Time 111.75355172157288 loss tensor(0.5232, grad_fn=<NegBackward0>)\n",
            "Time 111.79248332977295 loss tensor(0.5231, grad_fn=<NegBackward0>)\n",
            "Time 111.85783410072327 loss tensor(0.5230, grad_fn=<NegBackward0>)\n",
            "Time 111.89922881126404 loss tensor(0.5229, grad_fn=<NegBackward0>)\n",
            "Time 111.94825148582458 loss tensor(0.5228, grad_fn=<NegBackward0>)\n",
            "Time 111.98874092102051 loss tensor(0.5227, grad_fn=<NegBackward0>)\n",
            "Time 112.02985286712646 loss tensor(0.5227, grad_fn=<NegBackward0>)\n",
            "Time 112.06996703147888 loss tensor(0.5226, grad_fn=<NegBackward0>)\n",
            "Time 112.12583136558533 loss tensor(0.5225, grad_fn=<NegBackward0>)\n",
            "Time 112.17228412628174 loss tensor(0.5224, grad_fn=<NegBackward0>)\n",
            "Time 112.23103547096252 loss tensor(0.5223, grad_fn=<NegBackward0>)\n",
            "Time 112.2733006477356 loss tensor(0.5222, grad_fn=<NegBackward0>)\n",
            "Time 112.31346368789673 loss tensor(0.5221, grad_fn=<NegBackward0>)\n",
            "Time 112.35350942611694 loss tensor(0.5220, grad_fn=<NegBackward0>)\n",
            "Time 112.40111374855042 loss tensor(0.5219, grad_fn=<NegBackward0>)\n",
            "Time 112.44181942939758 loss tensor(0.5219, grad_fn=<NegBackward0>)\n",
            "Time 112.4819164276123 loss tensor(0.5218, grad_fn=<NegBackward0>)\n",
            "Time 112.52082562446594 loss tensor(0.5217, grad_fn=<NegBackward0>)\n",
            "Time 112.56004238128662 loss tensor(0.5216, grad_fn=<NegBackward0>)\n",
            "Time 112.6055817604065 loss tensor(0.5215, grad_fn=<NegBackward0>)\n",
            "Time 112.65151858329773 loss tensor(0.5214, grad_fn=<NegBackward0>)\n",
            "Time 112.69087409973145 loss tensor(0.5213, grad_fn=<NegBackward0>)\n",
            "Time 112.7305679321289 loss tensor(0.5212, grad_fn=<NegBackward0>)\n",
            "Time 112.76937532424927 loss tensor(0.5211, grad_fn=<NegBackward0>)\n",
            "Time 112.80817651748657 loss tensor(0.5211, grad_fn=<NegBackward0>)\n",
            "Time 112.85160160064697 loss tensor(0.5210, grad_fn=<NegBackward0>)\n",
            "Time 112.90439629554749 loss tensor(0.5209, grad_fn=<NegBackward0>)\n",
            "Time 112.94358038902283 loss tensor(0.5208, grad_fn=<NegBackward0>)\n",
            "Time 112.9820396900177 loss tensor(0.5207, grad_fn=<NegBackward0>)\n",
            "Time 113.03648591041565 loss tensor(0.5206, grad_fn=<NegBackward0>)\n",
            "Time 113.07482171058655 loss tensor(0.5205, grad_fn=<NegBackward0>)\n",
            "Time 113.11359357833862 loss tensor(0.5204, grad_fn=<NegBackward0>)\n",
            "Time 113.15245223045349 loss tensor(0.5204, grad_fn=<NegBackward0>)\n",
            "Time 113.19157886505127 loss tensor(0.5203, grad_fn=<NegBackward0>)\n",
            "Time 113.23093605041504 loss tensor(0.5202, grad_fn=<NegBackward0>)\n",
            "Time 113.27863454818726 loss tensor(0.5201, grad_fn=<NegBackward0>)\n",
            "Time 113.31897044181824 loss tensor(0.5200, grad_fn=<NegBackward0>)\n",
            "Time 113.35936641693115 loss tensor(0.5199, grad_fn=<NegBackward0>)\n",
            "Time 113.39840793609619 loss tensor(0.5198, grad_fn=<NegBackward0>)\n",
            "Time 113.43689751625061 loss tensor(0.5197, grad_fn=<NegBackward0>)\n",
            "Time 113.47504305839539 loss tensor(0.5196, grad_fn=<NegBackward0>)\n",
            "Time 113.51852703094482 loss tensor(0.5196, grad_fn=<NegBackward0>)\n",
            "Time 113.55667638778687 loss tensor(0.5195, grad_fn=<NegBackward0>)\n",
            "Time 113.59496140480042 loss tensor(0.5194, grad_fn=<NegBackward0>)\n",
            "Time 113.6386661529541 loss tensor(0.5193, grad_fn=<NegBackward0>)\n",
            "Time 113.67706418037415 loss tensor(0.5192, grad_fn=<NegBackward0>)\n",
            "Time 113.7156012058258 loss tensor(0.5191, grad_fn=<NegBackward0>)\n",
            "Time 113.75918054580688 loss tensor(0.5190, grad_fn=<NegBackward0>)\n",
            "Time 113.7976484298706 loss tensor(0.5189, grad_fn=<NegBackward0>)\n",
            "Time 113.83604049682617 loss tensor(0.5189, grad_fn=<NegBackward0>)\n",
            "Time 113.87442445755005 loss tensor(0.5188, grad_fn=<NegBackward0>)\n",
            "Time 113.92963552474976 loss tensor(0.5187, grad_fn=<NegBackward0>)\n",
            "Time 113.97296166419983 loss tensor(0.5186, grad_fn=<NegBackward0>)\n",
            "Time 114.01328611373901 loss tensor(0.5185, grad_fn=<NegBackward0>)\n",
            "Time 114.05152344703674 loss tensor(0.5184, grad_fn=<NegBackward0>)\n",
            "Time 114.09016871452332 loss tensor(0.5183, grad_fn=<NegBackward0>)\n",
            "Time 114.12913918495178 loss tensor(0.5182, grad_fn=<NegBackward0>)\n",
            "Time 114.16760849952698 loss tensor(0.5182, grad_fn=<NegBackward0>)\n",
            "Time 114.21764707565308 loss tensor(0.5181, grad_fn=<NegBackward0>)\n",
            "Time 114.26174187660217 loss tensor(0.5180, grad_fn=<NegBackward0>)\n",
            "Time 114.30140352249146 loss tensor(0.5179, grad_fn=<NegBackward0>)\n",
            "Time 114.33958458900452 loss tensor(0.5178, grad_fn=<NegBackward0>)\n",
            "Time 114.39423251152039 loss tensor(0.5177, grad_fn=<NegBackward0>)\n",
            "Time 114.44593572616577 loss tensor(0.5176, grad_fn=<NegBackward0>)\n",
            "Time 114.48367142677307 loss tensor(0.5175, grad_fn=<NegBackward0>)\n",
            "Time 114.52630734443665 loss tensor(0.5175, grad_fn=<NegBackward0>)\n",
            "Time 114.56496381759644 loss tensor(0.5174, grad_fn=<NegBackward0>)\n",
            "Time 114.60477447509766 loss tensor(0.5173, grad_fn=<NegBackward0>)\n",
            "Time 114.64612007141113 loss tensor(0.5172, grad_fn=<NegBackward0>)\n",
            "Time 114.69137573242188 loss tensor(0.5171, grad_fn=<NegBackward0>)\n",
            "Time 114.73008894920349 loss tensor(0.5170, grad_fn=<NegBackward0>)\n",
            "Time 114.76888298988342 loss tensor(0.5169, grad_fn=<NegBackward0>)\n",
            "Time 114.81269335746765 loss tensor(0.5169, grad_fn=<NegBackward0>)\n",
            "Time 114.85279679298401 loss tensor(0.5168, grad_fn=<NegBackward0>)\n",
            "Time 114.89809131622314 loss tensor(0.5167, grad_fn=<NegBackward0>)\n",
            "Time 114.9601378440857 loss tensor(0.5166, grad_fn=<NegBackward0>)\n",
            "Time 115.0232937335968 loss tensor(0.5165, grad_fn=<NegBackward0>)\n",
            "Time 115.08337330818176 loss tensor(0.5164, grad_fn=<NegBackward0>)\n",
            "Time 115.15575432777405 loss tensor(0.5163, grad_fn=<NegBackward0>)\n",
            "Time 115.21965384483337 loss tensor(0.5162, grad_fn=<NegBackward0>)\n",
            "Time 115.27952265739441 loss tensor(0.5162, grad_fn=<NegBackward0>)\n",
            "Time 115.33844661712646 loss tensor(0.5161, grad_fn=<NegBackward0>)\n",
            "Time 115.40525794029236 loss tensor(0.5160, grad_fn=<NegBackward0>)\n",
            "Time 115.46748185157776 loss tensor(0.5159, grad_fn=<NegBackward0>)\n",
            "Time 115.54565334320068 loss tensor(0.5158, grad_fn=<NegBackward0>)\n",
            "Time 115.60459494590759 loss tensor(0.5157, grad_fn=<NegBackward0>)\n",
            "Time 115.67237663269043 loss tensor(0.5156, grad_fn=<NegBackward0>)\n",
            "Time 115.73061466217041 loss tensor(0.5156, grad_fn=<NegBackward0>)\n",
            "Time 115.78856778144836 loss tensor(0.5155, grad_fn=<NegBackward0>)\n",
            "Time 115.84615445137024 loss tensor(0.5154, grad_fn=<NegBackward0>)\n",
            "Time 115.91318845748901 loss tensor(0.5153, grad_fn=<NegBackward0>)\n",
            "Time 115.98010087013245 loss tensor(0.5152, grad_fn=<NegBackward0>)\n",
            "Time 116.04096555709839 loss tensor(0.5151, grad_fn=<NegBackward0>)\n",
            "Time 116.10668325424194 loss tensor(0.5150, grad_fn=<NegBackward0>)\n",
            "Time 116.18349099159241 loss tensor(0.5150, grad_fn=<NegBackward0>)\n",
            "Time 116.2457025051117 loss tensor(0.5149, grad_fn=<NegBackward0>)\n",
            "Time 116.30791401863098 loss tensor(0.5148, grad_fn=<NegBackward0>)\n",
            "Time 116.36936354637146 loss tensor(0.5147, grad_fn=<NegBackward0>)\n",
            "Time 116.43180632591248 loss tensor(0.5146, grad_fn=<NegBackward0>)\n",
            "Time 116.4901762008667 loss tensor(0.5145, grad_fn=<NegBackward0>)\n",
            "Time 116.54902744293213 loss tensor(0.5144, grad_fn=<NegBackward0>)\n",
            "Time 116.61498379707336 loss tensor(0.5144, grad_fn=<NegBackward0>)\n",
            "Time 116.68275094032288 loss tensor(0.5143, grad_fn=<NegBackward0>)\n",
            "Time 116.74027729034424 loss tensor(0.5142, grad_fn=<NegBackward0>)\n",
            "Time 116.79588174819946 loss tensor(0.5141, grad_fn=<NegBackward0>)\n",
            "Time 116.85365319252014 loss tensor(0.5140, grad_fn=<NegBackward0>)\n",
            "Time 116.92452359199524 loss tensor(0.5139, grad_fn=<NegBackward0>)\n",
            "Time 116.99188113212585 loss tensor(0.5138, grad_fn=<NegBackward0>)\n",
            "Time 117.05517435073853 loss tensor(0.5138, grad_fn=<NegBackward0>)\n",
            "Time 117.11484861373901 loss tensor(0.5137, grad_fn=<NegBackward0>)\n",
            "Time 117.18276357650757 loss tensor(0.5136, grad_fn=<NegBackward0>)\n",
            "Time 117.24418544769287 loss tensor(0.5135, grad_fn=<NegBackward0>)\n",
            "Time 117.30489039421082 loss tensor(0.5134, grad_fn=<NegBackward0>)\n",
            "Time 117.36565089225769 loss tensor(0.5133, grad_fn=<NegBackward0>)\n",
            "Time 117.43648433685303 loss tensor(0.5132, grad_fn=<NegBackward0>)\n",
            "Time 117.51298379898071 loss tensor(0.5132, grad_fn=<NegBackward0>)\n",
            "Time 117.58562207221985 loss tensor(0.5131, grad_fn=<NegBackward0>)\n",
            "Time 117.63255739212036 loss tensor(0.5130, grad_fn=<NegBackward0>)\n",
            "Time 117.67962336540222 loss tensor(0.5129, grad_fn=<NegBackward0>)\n",
            "Time 117.71897840499878 loss tensor(0.5128, grad_fn=<NegBackward0>)\n",
            "Time 117.75818133354187 loss tensor(0.5127, grad_fn=<NegBackward0>)\n",
            "Time 117.79668474197388 loss tensor(0.5126, grad_fn=<NegBackward0>)\n",
            "Time 117.83530688285828 loss tensor(0.5126, grad_fn=<NegBackward0>)\n",
            "Time 117.87358903884888 loss tensor(0.5125, grad_fn=<NegBackward0>)\n",
            "Time 117.92161989212036 loss tensor(0.5124, grad_fn=<NegBackward0>)\n",
            "Time 117.96059465408325 loss tensor(0.5123, grad_fn=<NegBackward0>)\n",
            "Time 117.99915409088135 loss tensor(0.5122, grad_fn=<NegBackward0>)\n",
            "Time 118.04549407958984 loss tensor(0.5121, grad_fn=<NegBackward0>)\n",
            "Time 118.08422231674194 loss tensor(0.5120, grad_fn=<NegBackward0>)\n",
            "Time 118.12356424331665 loss tensor(0.5120, grad_fn=<NegBackward0>)\n",
            "Time 118.1747260093689 loss tensor(0.5119, grad_fn=<NegBackward0>)\n",
            "Time 118.21380972862244 loss tensor(0.5118, grad_fn=<NegBackward0>)\n",
            "Time 118.25204682350159 loss tensor(0.5117, grad_fn=<NegBackward0>)\n",
            "Time 118.29312038421631 loss tensor(0.5116, grad_fn=<NegBackward0>)\n",
            "Time 118.33550024032593 loss tensor(0.5115, grad_fn=<NegBackward0>)\n",
            "Time 118.38038444519043 loss tensor(0.5115, grad_fn=<NegBackward0>)\n",
            "Time 118.42777013778687 loss tensor(0.5114, grad_fn=<NegBackward0>)\n",
            "Time 118.46756768226624 loss tensor(0.5113, grad_fn=<NegBackward0>)\n",
            "Time 118.50653290748596 loss tensor(0.5112, grad_fn=<NegBackward0>)\n",
            "Time 118.54981184005737 loss tensor(0.5111, grad_fn=<NegBackward0>)\n",
            "Time 118.58818340301514 loss tensor(0.5110, grad_fn=<NegBackward0>)\n",
            "Time 118.62912154197693 loss tensor(0.5109, grad_fn=<NegBackward0>)\n",
            "Time 118.67018795013428 loss tensor(0.5109, grad_fn=<NegBackward0>)\n",
            "Time 118.70941853523254 loss tensor(0.5108, grad_fn=<NegBackward0>)\n",
            "Time 118.74821949005127 loss tensor(0.5107, grad_fn=<NegBackward0>)\n",
            "Time 118.79797220230103 loss tensor(0.5106, grad_fn=<NegBackward0>)\n",
            "Time 118.83714866638184 loss tensor(0.5105, grad_fn=<NegBackward0>)\n",
            "Time 118.87493205070496 loss tensor(0.5104, grad_fn=<NegBackward0>)\n",
            "Time 118.9149522781372 loss tensor(0.5104, grad_fn=<NegBackward0>)\n",
            "Time 118.95413947105408 loss tensor(0.5103, grad_fn=<NegBackward0>)\n",
            "Time 118.9948959350586 loss tensor(0.5102, grad_fn=<NegBackward0>)\n",
            "Time 119.03993654251099 loss tensor(0.5101, grad_fn=<NegBackward0>)\n",
            "Time 119.08717393875122 loss tensor(0.5100, grad_fn=<NegBackward0>)\n",
            "Time 119.12598443031311 loss tensor(0.5099, grad_fn=<NegBackward0>)\n",
            "Time 119.16916012763977 loss tensor(0.5099, grad_fn=<NegBackward0>)\n",
            "Time 119.20848417282104 loss tensor(0.5098, grad_fn=<NegBackward0>)\n",
            "Time 119.25429201126099 loss tensor(0.5097, grad_fn=<NegBackward0>)\n",
            "Time 119.29436898231506 loss tensor(0.5096, grad_fn=<NegBackward0>)\n",
            "Time 119.3347647190094 loss tensor(0.5095, grad_fn=<NegBackward0>)\n",
            "Time 119.37494158744812 loss tensor(0.5094, grad_fn=<NegBackward0>)\n",
            "Time 119.41360116004944 loss tensor(0.5093, grad_fn=<NegBackward0>)\n",
            "Time 119.45281720161438 loss tensor(0.5093, grad_fn=<NegBackward0>)\n",
            "Time 119.49875330924988 loss tensor(0.5092, grad_fn=<NegBackward0>)\n",
            "Time 119.53739857673645 loss tensor(0.5091, grad_fn=<NegBackward0>)\n",
            "Time 119.57599139213562 loss tensor(0.5090, grad_fn=<NegBackward0>)\n",
            "Time 119.61543297767639 loss tensor(0.5089, grad_fn=<NegBackward0>)\n",
            "Time 119.66102242469788 loss tensor(0.5088, grad_fn=<NegBackward0>)\n",
            "Time 119.7051568031311 loss tensor(0.5088, grad_fn=<NegBackward0>)\n",
            "Time 119.74471545219421 loss tensor(0.5087, grad_fn=<NegBackward0>)\n",
            "Time 119.78289699554443 loss tensor(0.5086, grad_fn=<NegBackward0>)\n",
            "Time 119.82136702537537 loss tensor(0.5085, grad_fn=<NegBackward0>)\n",
            "Time 119.86008214950562 loss tensor(0.5084, grad_fn=<NegBackward0>)\n",
            "Time 119.9039535522461 loss tensor(0.5083, grad_fn=<NegBackward0>)\n",
            "Time 119.9495804309845 loss tensor(0.5083, grad_fn=<NegBackward0>)\n",
            "Time 119.98795127868652 loss tensor(0.5082, grad_fn=<NegBackward0>)\n",
            "Time 120.02887511253357 loss tensor(0.5081, grad_fn=<NegBackward0>)\n",
            "Time 120.06905722618103 loss tensor(0.5080, grad_fn=<NegBackward0>)\n",
            "Time 120.1211142539978 loss tensor(0.5079, grad_fn=<NegBackward0>)\n",
            "Time 120.16551566123962 loss tensor(0.5078, grad_fn=<NegBackward0>)\n",
            "Time 120.20473313331604 loss tensor(0.5078, grad_fn=<NegBackward0>)\n",
            "Time 120.24563837051392 loss tensor(0.5077, grad_fn=<NegBackward0>)\n",
            "Time 120.28733110427856 loss tensor(0.5076, grad_fn=<NegBackward0>)\n",
            "Time 120.32994174957275 loss tensor(0.5075, grad_fn=<NegBackward0>)\n",
            "Time 120.36906313896179 loss tensor(0.5074, grad_fn=<NegBackward0>)\n",
            "Time 120.40694546699524 loss tensor(0.5073, grad_fn=<NegBackward0>)\n",
            "Time 120.44556832313538 loss tensor(0.5073, grad_fn=<NegBackward0>)\n",
            "Time 120.48496794700623 loss tensor(0.5072, grad_fn=<NegBackward0>)\n",
            "Time 120.52405118942261 loss tensor(0.5071, grad_fn=<NegBackward0>)\n",
            "Time 120.56944584846497 loss tensor(0.5070, grad_fn=<NegBackward0>)\n",
            "Time 120.60900473594666 loss tensor(0.5069, grad_fn=<NegBackward0>)\n",
            "Time 120.6496844291687 loss tensor(0.5068, grad_fn=<NegBackward0>)\n",
            "Time 120.69017767906189 loss tensor(0.5068, grad_fn=<NegBackward0>)\n",
            "Time 120.72852182388306 loss tensor(0.5067, grad_fn=<NegBackward0>)\n",
            "Time 120.77659845352173 loss tensor(0.5066, grad_fn=<NegBackward0>)\n",
            "Time 120.81655836105347 loss tensor(0.5065, grad_fn=<NegBackward0>)\n",
            "Time 120.85503625869751 loss tensor(0.5064, grad_fn=<NegBackward0>)\n",
            "Time 120.89686274528503 loss tensor(0.5063, grad_fn=<NegBackward0>)\n",
            "Time 120.93740248680115 loss tensor(0.5063, grad_fn=<NegBackward0>)\n",
            "Time 120.97559785842896 loss tensor(0.5062, grad_fn=<NegBackward0>)\n",
            "Time 121.02105474472046 loss tensor(0.5061, grad_fn=<NegBackward0>)\n",
            "Time 121.06414103507996 loss tensor(0.5060, grad_fn=<NegBackward0>)\n",
            "Time 121.11260199546814 loss tensor(0.5059, grad_fn=<NegBackward0>)\n",
            "Time 121.15235137939453 loss tensor(0.5059, grad_fn=<NegBackward0>)\n",
            "Time 121.19243717193604 loss tensor(0.5058, grad_fn=<NegBackward0>)\n",
            "Time 121.23638606071472 loss tensor(0.5057, grad_fn=<NegBackward0>)\n",
            "Time 121.28161907196045 loss tensor(0.5056, grad_fn=<NegBackward0>)\n",
            "Time 121.32092881202698 loss tensor(0.5055, grad_fn=<NegBackward0>)\n",
            "Time 121.36010575294495 loss tensor(0.5054, grad_fn=<NegBackward0>)\n",
            "Time 121.39804196357727 loss tensor(0.5054, grad_fn=<NegBackward0>)\n",
            "Time 121.439692735672 loss tensor(0.5053, grad_fn=<NegBackward0>)\n",
            "Time 121.48495268821716 loss tensor(0.5052, grad_fn=<NegBackward0>)\n",
            "Time 121.52370095252991 loss tensor(0.5051, grad_fn=<NegBackward0>)\n",
            "Time 121.56719946861267 loss tensor(0.5050, grad_fn=<NegBackward0>)\n",
            "Time 121.60579633712769 loss tensor(0.5049, grad_fn=<NegBackward0>)\n",
            "Time 121.6475338935852 loss tensor(0.5049, grad_fn=<NegBackward0>)\n",
            "Time 121.69079303741455 loss tensor(0.5048, grad_fn=<NegBackward0>)\n",
            "Time 121.73024678230286 loss tensor(0.5047, grad_fn=<NegBackward0>)\n",
            "Time 121.76943635940552 loss tensor(0.5046, grad_fn=<NegBackward0>)\n",
            "Time 121.80795812606812 loss tensor(0.5045, grad_fn=<NegBackward0>)\n",
            "Time 121.8467526435852 loss tensor(0.5045, grad_fn=<NegBackward0>)\n",
            "Time 121.89014530181885 loss tensor(0.5044, grad_fn=<NegBackward0>)\n",
            "Time 121.93014526367188 loss tensor(0.5043, grad_fn=<NegBackward0>)\n",
            "Time 121.96916389465332 loss tensor(0.5042, grad_fn=<NegBackward0>)\n",
            "Time 122.0141372680664 loss tensor(0.5041, grad_fn=<NegBackward0>)\n",
            "Time 122.05270838737488 loss tensor(0.5040, grad_fn=<NegBackward0>)\n",
            "Time 122.09231758117676 loss tensor(0.5040, grad_fn=<NegBackward0>)\n",
            "Time 122.14368152618408 loss tensor(0.5039, grad_fn=<NegBackward0>)\n",
            "Time 122.18240332603455 loss tensor(0.5038, grad_fn=<NegBackward0>)\n",
            "Time 122.2215268611908 loss tensor(0.5037, grad_fn=<NegBackward0>)\n",
            "Time 122.2629075050354 loss tensor(0.5036, grad_fn=<NegBackward0>)\n",
            "Time 122.30680561065674 loss tensor(0.5036, grad_fn=<NegBackward0>)\n",
            "Time 122.3485758304596 loss tensor(0.5035, grad_fn=<NegBackward0>)\n",
            "Time 122.3904218673706 loss tensor(0.5034, grad_fn=<NegBackward0>)\n",
            "Time 122.44195246696472 loss tensor(0.5033, grad_fn=<NegBackward0>)\n",
            "Time 122.48585319519043 loss tensor(0.5032, grad_fn=<NegBackward0>)\n",
            "Time 122.53105092048645 loss tensor(0.5031, grad_fn=<NegBackward0>)\n",
            "Time 122.56991219520569 loss tensor(0.5031, grad_fn=<NegBackward0>)\n",
            "Time 122.60861825942993 loss tensor(0.5030, grad_fn=<NegBackward0>)\n",
            "Time 122.65007591247559 loss tensor(0.5029, grad_fn=<NegBackward0>)\n",
            "Time 122.69227337837219 loss tensor(0.5028, grad_fn=<NegBackward0>)\n",
            "Time 122.73155570030212 loss tensor(0.5027, grad_fn=<NegBackward0>)\n",
            "Time 122.77463412284851 loss tensor(0.5027, grad_fn=<NegBackward0>)\n",
            "Time 122.81271624565125 loss tensor(0.5026, grad_fn=<NegBackward0>)\n",
            "Time 122.85152649879456 loss tensor(0.5025, grad_fn=<NegBackward0>)\n",
            "Time 122.88978338241577 loss tensor(0.5024, grad_fn=<NegBackward0>)\n",
            "Time 122.93020296096802 loss tensor(0.5023, grad_fn=<NegBackward0>)\n",
            "Time 122.97478699684143 loss tensor(0.5023, grad_fn=<NegBackward0>)\n",
            "Time 123.01511740684509 loss tensor(0.5022, grad_fn=<NegBackward0>)\n",
            "Time 123.05400609970093 loss tensor(0.5021, grad_fn=<NegBackward0>)\n",
            "Time 123.09300804138184 loss tensor(0.5020, grad_fn=<NegBackward0>)\n",
            "Time 123.1425416469574 loss tensor(0.5019, grad_fn=<NegBackward0>)\n",
            "Time 123.18592810630798 loss tensor(0.5018, grad_fn=<NegBackward0>)\n",
            "Time 123.23012042045593 loss tensor(0.5018, grad_fn=<NegBackward0>)\n",
            "Time 123.27238750457764 loss tensor(0.5017, grad_fn=<NegBackward0>)\n",
            "Time 123.31116366386414 loss tensor(0.5016, grad_fn=<NegBackward0>)\n",
            "Time 123.34922552108765 loss tensor(0.5015, grad_fn=<NegBackward0>)\n",
            "Time 123.3858494758606 loss tensor(0.5014, grad_fn=<NegBackward0>)\n",
            "Time 123.43394613265991 loss tensor(0.5014, grad_fn=<NegBackward0>)\n",
            "Time 123.47241187095642 loss tensor(0.5013, grad_fn=<NegBackward0>)\n",
            "Time 123.51041984558105 loss tensor(0.5012, grad_fn=<NegBackward0>)\n",
            "Time 123.54853820800781 loss tensor(0.5011, grad_fn=<NegBackward0>)\n",
            "Time 123.5867428779602 loss tensor(0.5010, grad_fn=<NegBackward0>)\n",
            "Time 123.63663792610168 loss tensor(0.5010, grad_fn=<NegBackward0>)\n",
            "Time 123.67974615097046 loss tensor(0.5009, grad_fn=<NegBackward0>)\n",
            "Time 123.7217767238617 loss tensor(0.5008, grad_fn=<NegBackward0>)\n",
            "Time 123.76331210136414 loss tensor(0.5007, grad_fn=<NegBackward0>)\n",
            "Time 123.81014013290405 loss tensor(0.5006, grad_fn=<NegBackward0>)\n",
            "Time 123.85541319847107 loss tensor(0.5006, grad_fn=<NegBackward0>)\n",
            "Time 123.8940019607544 loss tensor(0.5005, grad_fn=<NegBackward0>)\n",
            "Time 123.93454623222351 loss tensor(0.5004, grad_fn=<NegBackward0>)\n",
            "Time 123.9735472202301 loss tensor(0.5003, grad_fn=<NegBackward0>)\n",
            "Time 124.01226782798767 loss tensor(0.5002, grad_fn=<NegBackward0>)\n",
            "Time 124.0640640258789 loss tensor(0.5002, grad_fn=<NegBackward0>)\n",
            "Time 124.10454678535461 loss tensor(0.5001, grad_fn=<NegBackward0>)\n",
            "Time 124.14368152618408 loss tensor(0.5000, grad_fn=<NegBackward0>)\n",
            "Time 124.1911084651947 loss tensor(0.4999, grad_fn=<NegBackward0>)\n",
            "Time 124.23340916633606 loss tensor(0.4998, grad_fn=<NegBackward0>)\n",
            "Time 124.27791476249695 loss tensor(0.4998, grad_fn=<NegBackward0>)\n",
            "Time 124.31844186782837 loss tensor(0.4997, grad_fn=<NegBackward0>)\n",
            "Time 124.35825943946838 loss tensor(0.4996, grad_fn=<NegBackward0>)\n",
            "Time 124.39647197723389 loss tensor(0.4995, grad_fn=<NegBackward0>)\n",
            "Time 124.43737649917603 loss tensor(0.4994, grad_fn=<NegBackward0>)\n",
            "Time 124.47699570655823 loss tensor(0.4994, grad_fn=<NegBackward0>)\n",
            "Time 124.52009630203247 loss tensor(0.4993, grad_fn=<NegBackward0>)\n",
            "Time 124.55841636657715 loss tensor(0.4992, grad_fn=<NegBackward0>)\n",
            "Time 124.59590721130371 loss tensor(0.4991, grad_fn=<NegBackward0>)\n",
            "Time 124.63675308227539 loss tensor(0.4990, grad_fn=<NegBackward0>)\n",
            "Time 124.67524600028992 loss tensor(0.4990, grad_fn=<NegBackward0>)\n",
            "Time 124.72198867797852 loss tensor(0.4989, grad_fn=<NegBackward0>)\n",
            "Time 124.76087236404419 loss tensor(0.4988, grad_fn=<NegBackward0>)\n",
            "Time 124.79927372932434 loss tensor(0.4987, grad_fn=<NegBackward0>)\n",
            "Time 124.83857798576355 loss tensor(0.4986, grad_fn=<NegBackward0>)\n",
            "Time 124.87763094902039 loss tensor(0.4986, grad_fn=<NegBackward0>)\n",
            "Time 124.91639852523804 loss tensor(0.4985, grad_fn=<NegBackward0>)\n",
            "Time 124.96657109260559 loss tensor(0.4984, grad_fn=<NegBackward0>)\n",
            "Time 125.00589179992676 loss tensor(0.4983, grad_fn=<NegBackward0>)\n",
            "Time 125.04758167266846 loss tensor(0.4982, grad_fn=<NegBackward0>)\n",
            "Time 125.08717846870422 loss tensor(0.4982, grad_fn=<NegBackward0>)\n",
            "Time 125.12611961364746 loss tensor(0.4981, grad_fn=<NegBackward0>)\n",
            "Time 125.16515707969666 loss tensor(0.4980, grad_fn=<NegBackward0>)\n",
            "Time 125.22069668769836 loss tensor(0.4979, grad_fn=<NegBackward0>)\n",
            "Time 125.2604751586914 loss tensor(0.4978, grad_fn=<NegBackward0>)\n",
            "Time 125.29789972305298 loss tensor(0.4978, grad_fn=<NegBackward0>)\n",
            "Time 125.33906364440918 loss tensor(0.4977, grad_fn=<NegBackward0>)\n",
            "Time 125.39466214179993 loss tensor(0.4976, grad_fn=<NegBackward0>)\n",
            "Time 125.43447279930115 loss tensor(0.4975, grad_fn=<NegBackward0>)\n",
            "Time 125.47350478172302 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 125.51129102706909 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 125.54955005645752 loss tensor(0.4973, grad_fn=<NegBackward0>)\n",
            "Time 125.58793687820435 loss tensor(0.4972, grad_fn=<NegBackward0>)\n",
            "Time 125.63492918014526 loss tensor(0.4971, grad_fn=<NegBackward0>)\n",
            "Time 125.67940354347229 loss tensor(0.4970, grad_fn=<NegBackward0>)\n",
            "Time 125.7204327583313 loss tensor(0.4970, grad_fn=<NegBackward0>)\n",
            "Time 125.75942158699036 loss tensor(0.4969, grad_fn=<NegBackward0>)\n",
            "Time 125.79796409606934 loss tensor(0.4968, grad_fn=<NegBackward0>)\n",
            "Time 125.837890625 loss tensor(0.4967, grad_fn=<NegBackward0>)\n",
            "Time 125.88127398490906 loss tensor(0.4967, grad_fn=<NegBackward0>)\n",
            "Time 125.92034029960632 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 125.96101188659668 loss tensor(0.4965, grad_fn=<NegBackward0>)\n",
            "Time 126.00658917427063 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 126.05155849456787 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 126.09085321426392 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 126.12953495979309 loss tensor(0.4962, grad_fn=<NegBackward0>)\n",
            "Time 126.16835331916809 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 126.21459436416626 loss tensor(0.4960, grad_fn=<NegBackward0>)\n",
            "Time 126.2612373828888 loss tensor(0.4959, grad_fn=<NegBackward0>)\n",
            "Time 126.30500340461731 loss tensor(0.4959, grad_fn=<NegBackward0>)\n",
            "Time 126.34657216072083 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 126.38766384124756 loss tensor(0.4957, grad_fn=<NegBackward0>)\n",
            "Time 126.42570447921753 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 126.4678065776825 loss tensor(0.4955, grad_fn=<NegBackward0>)\n",
            "Time 126.50908660888672 loss tensor(0.4955, grad_fn=<NegBackward0>)\n",
            "Time 126.54910063743591 loss tensor(0.4954, grad_fn=<NegBackward0>)\n",
            "Time 126.58847689628601 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 126.62968134880066 loss tensor(0.4952, grad_fn=<NegBackward0>)\n",
            "Time 126.6705310344696 loss tensor(0.4952, grad_fn=<NegBackward0>)\n",
            "Time 126.88750696182251 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 127.10610389709473 loss tensor(0.4950, grad_fn=<NegBackward0>)\n",
            "Time 127.24922704696655 loss tensor(0.4949, grad_fn=<NegBackward0>)\n",
            "Time 127.38548135757446 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 127.42397904396057 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 127.46309328079224 loss tensor(0.4947, grad_fn=<NegBackward0>)\n",
            "Time 127.50245904922485 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 127.54186463356018 loss tensor(0.4945, grad_fn=<NegBackward0>)\n",
            "Time 127.58136296272278 loss tensor(0.4945, grad_fn=<NegBackward0>)\n",
            "Time 127.64964199066162 loss tensor(0.4944, grad_fn=<NegBackward0>)\n",
            "Time 127.71083736419678 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 127.7699043750763 loss tensor(0.4942, grad_fn=<NegBackward0>)\n",
            "Time 127.82684445381165 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 127.96928858757019 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 128.03972148895264 loss tensor(0.4940, grad_fn=<NegBackward0>)\n",
            "Time 128.2033474445343 loss tensor(0.4939, grad_fn=<NegBackward0>)\n",
            "Time 128.32201194763184 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 128.4691026210785 loss tensor(0.4937, grad_fn=<NegBackward0>)\n",
            "Time 128.6002266407013 loss tensor(0.4937, grad_fn=<NegBackward0>)\n",
            "Time 128.7394778728485 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 128.85813999176025 loss tensor(0.4935, grad_fn=<NegBackward0>)\n",
            "Time 128.97229647636414 loss tensor(0.4934, grad_fn=<NegBackward0>)\n",
            "Time 129.11206817626953 loss tensor(0.4934, grad_fn=<NegBackward0>)\n",
            "Time 129.23349595069885 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 129.48812699317932 loss tensor(0.4932, grad_fn=<NegBackward0>)\n",
            "Time 129.65499758720398 loss tensor(0.4931, grad_fn=<NegBackward0>)\n",
            "Time 129.71888637542725 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 129.80740308761597 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 129.87046909332275 loss tensor(0.4929, grad_fn=<NegBackward0>)\n",
            "Time 129.9354329109192 loss tensor(0.4928, grad_fn=<NegBackward0>)\n",
            "Time 129.9956374168396 loss tensor(0.4927, grad_fn=<NegBackward0>)\n",
            "Time 130.055743932724 loss tensor(0.4927, grad_fn=<NegBackward0>)\n",
            "Time 130.11467957496643 loss tensor(0.4926, grad_fn=<NegBackward0>)\n",
            "Time 130.18482613563538 loss tensor(0.4925, grad_fn=<NegBackward0>)\n",
            "Time 130.24397826194763 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 130.30610585212708 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 130.3720805644989 loss tensor(0.4923, grad_fn=<NegBackward0>)\n",
            "Time 130.44269704818726 loss tensor(0.4922, grad_fn=<NegBackward0>)\n",
            "Time 130.50765538215637 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 130.55985021591187 loss tensor(0.4920, grad_fn=<NegBackward0>)\n",
            "Time 130.5982813835144 loss tensor(0.4920, grad_fn=<NegBackward0>)\n",
            "Time 130.64012837409973 loss tensor(0.4919, grad_fn=<NegBackward0>)\n",
            "Time 130.68508052825928 loss tensor(0.4918, grad_fn=<NegBackward0>)\n",
            "Time 130.72922039031982 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 130.77194094657898 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 130.81132578849792 loss tensor(0.4916, grad_fn=<NegBackward0>)\n",
            "Time 130.85136795043945 loss tensor(0.4915, grad_fn=<NegBackward0>)\n",
            "Time 130.89667320251465 loss tensor(0.4914, grad_fn=<NegBackward0>)\n",
            "Time 130.9380283355713 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 130.98145699501038 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 131.0282850265503 loss tensor(0.4912, grad_fn=<NegBackward0>)\n",
            "Time 131.0692160129547 loss tensor(0.4911, grad_fn=<NegBackward0>)\n",
            "Time 131.11507105827332 loss tensor(0.4910, grad_fn=<NegBackward0>)\n",
            "Time 131.1537697315216 loss tensor(0.4910, grad_fn=<NegBackward0>)\n",
            "Time 131.19222116470337 loss tensor(0.4909, grad_fn=<NegBackward0>)\n",
            "Time 131.23267483711243 loss tensor(0.4908, grad_fn=<NegBackward0>)\n",
            "Time 131.27794981002808 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 131.3187758922577 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 131.39248728752136 loss tensor(0.4906, grad_fn=<NegBackward0>)\n",
            "Time 131.44742822647095 loss tensor(0.4905, grad_fn=<NegBackward0>)\n",
            "Time 131.50180101394653 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 131.55305242538452 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 131.5920329093933 loss tensor(0.4903, grad_fn=<NegBackward0>)\n",
            "Time 131.6330268383026 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 131.67678809165955 loss tensor(0.4901, grad_fn=<NegBackward0>)\n",
            "Time 131.71806716918945 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 131.76469016075134 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 131.80594539642334 loss tensor(0.4899, grad_fn=<NegBackward0>)\n",
            "Time 131.8444390296936 loss tensor(0.4898, grad_fn=<NegBackward0>)\n",
            "Time 131.88336157798767 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 131.92258715629578 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 131.96384644508362 loss tensor(0.4896, grad_fn=<NegBackward0>)\n",
            "Time 132.00939297676086 loss tensor(0.4895, grad_fn=<NegBackward0>)\n",
            "Time 132.05267715454102 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 132.09405541419983 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 132.14067387580872 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 132.19232416152954 loss tensor(0.4892, grad_fn=<NegBackward0>)\n",
            "Time 132.23189163208008 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 132.27372193336487 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 132.3294551372528 loss tensor(0.4890, grad_fn=<NegBackward0>)\n",
            "Time 132.3750021457672 loss tensor(0.4889, grad_fn=<NegBackward0>)\n",
            "Time 132.4207887649536 loss tensor(0.4888, grad_fn=<NegBackward0>)\n",
            "Time 132.45963668823242 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 132.50256180763245 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 132.5420265197754 loss tensor(0.4886, grad_fn=<NegBackward0>)\n",
            "Time 132.58113312721252 loss tensor(0.4885, grad_fn=<NegBackward0>)\n",
            "Time 132.62639260292053 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 132.668288230896 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 132.70718455314636 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 132.74995231628418 loss tensor(0.4882, grad_fn=<NegBackward0>)\n",
            "Time 132.78954577445984 loss tensor(0.4881, grad_fn=<NegBackward0>)\n",
            "Time 132.82825994491577 loss tensor(0.4881, grad_fn=<NegBackward0>)\n",
            "Time 132.87366223335266 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 132.93153047561646 loss tensor(0.4879, grad_fn=<NegBackward0>)\n",
            "Time 132.97200083732605 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 133.01089811325073 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 133.05071902275085 loss tensor(0.4877, grad_fn=<NegBackward0>)\n",
            "Time 133.1020429134369 loss tensor(0.4876, grad_fn=<NegBackward0>)\n",
            "Time 133.14071989059448 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 133.18213486671448 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 133.22330975532532 loss tensor(0.4874, grad_fn=<NegBackward0>)\n",
            "Time 133.26381659507751 loss tensor(0.4873, grad_fn=<NegBackward0>)\n",
            "Time 133.30277514457703 loss tensor(0.4872, grad_fn=<NegBackward0>)\n",
            "Time 133.346195936203 loss tensor(0.4872, grad_fn=<NegBackward0>)\n",
            "Time 133.3887939453125 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 133.43057322502136 loss tensor(0.4870, grad_fn=<NegBackward0>)\n",
            "Time 133.46957516670227 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 133.5077977180481 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 133.55258226394653 loss tensor(0.4868, grad_fn=<NegBackward0>)\n",
            "Time 133.5918412208557 loss tensor(0.4867, grad_fn=<NegBackward0>)\n",
            "Time 133.63376259803772 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 133.6721169948578 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 133.70991110801697 loss tensor(0.4865, grad_fn=<NegBackward0>)\n",
            "Time 133.74823188781738 loss tensor(0.4864, grad_fn=<NegBackward0>)\n",
            "Time 133.79813027381897 loss tensor(0.4863, grad_fn=<NegBackward0>)\n",
            "Time 133.83848333358765 loss tensor(0.4863, grad_fn=<NegBackward0>)\n",
            "Time 133.87779831886292 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 133.91709184646606 loss tensor(0.4861, grad_fn=<NegBackward0>)\n",
            "Time 133.95796990394592 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 133.99779629707336 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 134.0437934398651 loss tensor(0.4859, grad_fn=<NegBackward0>)\n",
            "Time 134.08155035972595 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 134.12028813362122 loss tensor(0.4857, grad_fn=<NegBackward0>)\n",
            "Time 134.15901517868042 loss tensor(0.4857, grad_fn=<NegBackward0>)\n",
            "Time 134.19680857658386 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 134.24176001548767 loss tensor(0.4855, grad_fn=<NegBackward0>)\n",
            "Time 134.2826886177063 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 134.3263063430786 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 134.3671064376831 loss tensor(0.4853, grad_fn=<NegBackward0>)\n",
            "Time 134.41190314292908 loss tensor(0.4852, grad_fn=<NegBackward0>)\n",
            "Time 134.4593186378479 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 134.49832010269165 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 134.53535723686218 loss tensor(0.4850, grad_fn=<NegBackward0>)\n",
            "Time 134.57462215423584 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 134.6204333305359 loss tensor(0.4848, grad_fn=<NegBackward0>)\n",
            "Time 134.6615173816681 loss tensor(0.4848, grad_fn=<NegBackward0>)\n",
            "Time 134.70400667190552 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 134.74218368530273 loss tensor(0.4846, grad_fn=<NegBackward0>)\n",
            "Time 134.78250002861023 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 134.81996870040894 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 134.85866737365723 loss tensor(0.4844, grad_fn=<NegBackward0>)\n",
            "Time 134.90972566604614 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 134.95097994804382 loss tensor(0.4842, grad_fn=<NegBackward0>)\n",
            "Time 134.99045991897583 loss tensor(0.4842, grad_fn=<NegBackward0>)\n",
            "Time 135.02892565727234 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 135.06746697425842 loss tensor(0.4840, grad_fn=<NegBackward0>)\n",
            "Time 135.1058087348938 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 135.1501760482788 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 135.18831062316895 loss tensor(0.4838, grad_fn=<NegBackward0>)\n",
            "Time 135.2329695224762 loss tensor(0.4837, grad_fn=<NegBackward0>)\n",
            "Time 135.27713108062744 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 135.31911969184875 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 135.36400866508484 loss tensor(0.4835, grad_fn=<NegBackward0>)\n",
            "Time 135.40204501152039 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 135.4493863582611 loss tensor(0.4833, grad_fn=<NegBackward0>)\n",
            "Time 135.48823809623718 loss tensor(0.4833, grad_fn=<NegBackward0>)\n",
            "Time 135.52672004699707 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 135.56946444511414 loss tensor(0.4831, grad_fn=<NegBackward0>)\n",
            "Time 135.6118574142456 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 135.6540288925171 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 135.69256114959717 loss tensor(0.4829, grad_fn=<NegBackward0>)\n",
            "Time 135.73089265823364 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 135.7734935283661 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 135.81461024284363 loss tensor(0.4827, grad_fn=<NegBackward0>)\n",
            "Time 135.85232043266296 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 135.89077591896057 loss tensor(0.4825, grad_fn=<NegBackward0>)\n",
            "Time 135.9295392036438 loss tensor(0.4825, grad_fn=<NegBackward0>)\n",
            "Time 135.96957325935364 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 136.01880049705505 loss tensor(0.4823, grad_fn=<NegBackward0>)\n",
            "Time 136.05819416046143 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 136.09591126441956 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 136.13444447517395 loss tensor(0.4821, grad_fn=<NegBackward0>)\n",
            "Time 136.17551159858704 loss tensor(0.4820, grad_fn=<NegBackward0>)\n",
            "Time 136.21480798721313 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 136.26112914085388 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 136.3000888824463 loss tensor(0.4818, grad_fn=<NegBackward0>)\n",
            "Time 136.3450562953949 loss tensor(0.4817, grad_fn=<NegBackward0>)\n",
            "Time 136.38469171524048 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 136.42359828948975 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 136.47585487365723 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 136.51421356201172 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 136.55219435691833 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 136.59088826179504 loss tensor(0.4813, grad_fn=<NegBackward0>)\n",
            "Time 136.64186310768127 loss tensor(0.4812, grad_fn=<NegBackward0>)\n",
            "Time 136.68529963493347 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 136.72816228866577 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 136.76780700683594 loss tensor(0.4810, grad_fn=<NegBackward0>)\n",
            "Time 136.80616283416748 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 136.8448703289032 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 136.8844850063324 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 136.93381547927856 loss tensor(0.4807, grad_fn=<NegBackward0>)\n",
            "Time 136.9748215675354 loss tensor(0.4806, grad_fn=<NegBackward0>)\n",
            "Time 137.01373720169067 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 137.0524561405182 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 137.09142804145813 loss tensor(0.4804, grad_fn=<NegBackward0>)\n",
            "Time 137.13665914535522 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 137.1760537624359 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 137.21578240394592 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 137.25578260421753 loss tensor(0.4801, grad_fn=<NegBackward0>)\n",
            "Time 137.29595398902893 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 137.33517265319824 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 137.38093852996826 loss tensor(0.4799, grad_fn=<NegBackward0>)\n",
            "Time 137.42535185813904 loss tensor(0.4798, grad_fn=<NegBackward0>)\n",
            "Time 137.4692506790161 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 137.51236414909363 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 137.5512113571167 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 137.5955011844635 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 137.6377730369568 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 137.67798352241516 loss tensor(0.4794, grad_fn=<NegBackward0>)\n",
            "Time 137.71723103523254 loss tensor(0.4793, grad_fn=<NegBackward0>)\n",
            "Time 137.75625491142273 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 137.79849362373352 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 137.8426914215088 loss tensor(0.4791, grad_fn=<NegBackward0>)\n",
            "Time 137.88342690467834 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 137.92276644706726 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 137.96377801895142 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 138.01154208183289 loss tensor(0.4788, grad_fn=<NegBackward0>)\n",
            "Time 138.05326533317566 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 138.09223198890686 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 138.13122391700745 loss tensor(0.4786, grad_fn=<NegBackward0>)\n",
            "Time 138.16974401474 loss tensor(0.4785, grad_fn=<NegBackward0>)\n",
            "Time 138.21003890037537 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 138.25779390335083 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 138.30546522140503 loss tensor(0.4783, grad_fn=<NegBackward0>)\n",
            "Time 138.34591937065125 loss tensor(0.4782, grad_fn=<NegBackward0>)\n",
            "Time 138.38515782356262 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 138.42313981056213 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 138.46499180793762 loss tensor(0.4780, grad_fn=<NegBackward0>)\n",
            "Time 138.5149655342102 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 138.55281615257263 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 138.5971565246582 loss tensor(0.4778, grad_fn=<NegBackward0>)\n",
            "Time 138.6394989490509 loss tensor(0.4777, grad_fn=<NegBackward0>)\n",
            "Time 138.68456292152405 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 138.7232804298401 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 138.76204752922058 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 138.803724527359 loss tensor(0.4774, grad_fn=<NegBackward0>)\n",
            "Time 138.8433403968811 loss tensor(0.4774, grad_fn=<NegBackward0>)\n",
            "Time 138.89117765426636 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 138.93354320526123 loss tensor(0.4772, grad_fn=<NegBackward0>)\n",
            "Time 138.97598338127136 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 139.0159034729004 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 139.0549659729004 loss tensor(0.4770, grad_fn=<NegBackward0>)\n",
            "Time 139.0950276851654 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 139.14263343811035 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 139.18973803520203 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 139.2306776046753 loss tensor(0.4767, grad_fn=<NegBackward0>)\n",
            "Time 139.27091598510742 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 139.3158311843872 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 139.35541820526123 loss tensor(0.4765, grad_fn=<NegBackward0>)\n",
            "Time 139.39435601234436 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 139.43337678909302 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 139.47306323051453 loss tensor(0.4763, grad_fn=<NegBackward0>)\n",
            "Time 139.52290654182434 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 139.565856218338 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 139.6054880619049 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 139.64624500274658 loss tensor(0.4760, grad_fn=<NegBackward0>)\n",
            "Time 139.68531847000122 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 139.72419047355652 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 139.7686653137207 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 139.81064820289612 loss tensor(0.4757, grad_fn=<NegBackward0>)\n",
            "Time 139.84919333457947 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 139.89267015457153 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 139.94119834899902 loss tensor(0.4755, grad_fn=<NegBackward0>)\n",
            "Time 139.9862551689148 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 140.02561593055725 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 140.0649185180664 loss tensor(0.4753, grad_fn=<NegBackward0>)\n",
            "Time 140.10435581207275 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 140.14455151557922 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 140.1886625289917 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 140.22794485092163 loss tensor(0.4750, grad_fn=<NegBackward0>)\n",
            "Time 140.26886010169983 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 140.30719590187073 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 140.35086226463318 loss tensor(0.4748, grad_fn=<NegBackward0>)\n",
            "Time 140.4143214225769 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 140.46588897705078 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 140.50528573989868 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 140.56249284744263 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 140.63657569885254 loss tensor(0.4744, grad_fn=<NegBackward0>)\n",
            "Time 140.6986300945282 loss tensor(0.4744, grad_fn=<NegBackward0>)\n",
            "Time 140.75647711753845 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 140.82373690605164 loss tensor(0.4742, grad_fn=<NegBackward0>)\n",
            "Time 140.8843412399292 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 140.94504809379578 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 141.00509309768677 loss tensor(0.4740, grad_fn=<NegBackward0>)\n",
            "Time 141.07254767417908 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 141.13046383857727 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 141.19364166259766 loss tensor(0.4738, grad_fn=<NegBackward0>)\n",
            "Time 141.25655460357666 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 141.31947469711304 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 141.37942504882812 loss tensor(0.4736, grad_fn=<NegBackward0>)\n",
            "Time 141.43726921081543 loss tensor(0.4735, grad_fn=<NegBackward0>)\n",
            "Time 141.4949812889099 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 141.56833720207214 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 141.6374650001526 loss tensor(0.4733, grad_fn=<NegBackward0>)\n",
            "Time 141.6952908039093 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 141.75648498535156 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 141.82027673721313 loss tensor(0.4731, grad_fn=<NegBackward0>)\n",
            "Time 141.87988233566284 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 141.93813848495483 loss tensor(0.4729, grad_fn=<NegBackward0>)\n",
            "Time 141.99852561950684 loss tensor(0.4729, grad_fn=<NegBackward0>)\n",
            "Time 142.06612634658813 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 142.12442278862 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 142.18577122688293 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 142.24738121032715 loss tensor(0.4726, grad_fn=<NegBackward0>)\n",
            "Time 142.3173017501831 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 142.37552762031555 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 142.43171525001526 loss tensor(0.4724, grad_fn=<NegBackward0>)\n",
            "Time 142.48976969718933 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 142.55909705162048 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 142.6285059452057 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 142.68789911270142 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 142.74715542793274 loss tensor(0.4720, grad_fn=<NegBackward0>)\n",
            "Time 142.81402778625488 loss tensor(0.4720, grad_fn=<NegBackward0>)\n",
            "Time 142.8759069442749 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 142.93705558776855 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 142.99549674987793 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 143.06704592704773 loss tensor(0.4717, grad_fn=<NegBackward0>)\n",
            "Time 143.132746219635 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 143.20012664794922 loss tensor(0.4715, grad_fn=<NegBackward0>)\n",
            "Time 143.27793216705322 loss tensor(0.4715, grad_fn=<NegBackward0>)\n",
            "Time 143.31906247138977 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 143.36271500587463 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 143.40436792373657 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 143.44481706619263 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 143.4864706993103 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 143.5257875919342 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 143.5636441707611 loss tensor(0.4710, grad_fn=<NegBackward0>)\n",
            "Time 143.6026735305786 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 143.64855289459229 loss tensor(0.4708, grad_fn=<NegBackward0>)\n",
            "Time 143.7018837928772 loss tensor(0.4708, grad_fn=<NegBackward0>)\n",
            "Time 143.74409341812134 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 143.782644033432 loss tensor(0.4706, grad_fn=<NegBackward0>)\n",
            "Time 143.82246828079224 loss tensor(0.4706, grad_fn=<NegBackward0>)\n",
            "Time 143.86120629310608 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 143.907386302948 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 143.94986605644226 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 143.99192237854004 loss tensor(0.4703, grad_fn=<NegBackward0>)\n",
            "Time 144.03064918518066 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 144.0694351196289 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 144.10985732078552 loss tensor(0.4701, grad_fn=<NegBackward0>)\n",
            "Time 144.15583491325378 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 144.19418144226074 loss tensor(0.4699, grad_fn=<NegBackward0>)\n",
            "Time 144.23215460777283 loss tensor(0.4699, grad_fn=<NegBackward0>)\n",
            "Time 144.27179193496704 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 144.31330847740173 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 144.3628237247467 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 144.41801381111145 loss tensor(0.4696, grad_fn=<NegBackward0>)\n",
            "Time 144.4564323425293 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 144.49454379081726 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 144.5331904888153 loss tensor(0.4694, grad_fn=<NegBackward0>)\n",
            "Time 144.57217621803284 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 144.6157467365265 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 144.6541199684143 loss tensor(0.4692, grad_fn=<NegBackward0>)\n",
            "Time 144.7159070968628 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 144.75787901878357 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 144.81158828735352 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 144.8520793914795 loss tensor(0.4689, grad_fn=<NegBackward0>)\n",
            "Time 144.89102983474731 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 144.93081903457642 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 144.97190356254578 loss tensor(0.4687, grad_fn=<NegBackward0>)\n",
            "Time 145.01173758506775 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 145.0573616027832 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 145.09552192687988 loss tensor(0.4685, grad_fn=<NegBackward0>)\n",
            "Time 145.13455080986023 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 145.17243576049805 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 145.21563839912415 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 145.26784682273865 loss tensor(0.4682, grad_fn=<NegBackward0>)\n",
            "Time 145.3116898536682 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 145.34999442100525 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 145.38866066932678 loss tensor(0.4680, grad_fn=<NegBackward0>)\n",
            "Time 145.4275677204132 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 145.46730089187622 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 145.51261162757874 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 145.56102752685547 loss tensor(0.4677, grad_fn=<NegBackward0>)\n",
            "Time 145.60058999061584 loss tensor(0.4677, grad_fn=<NegBackward0>)\n",
            "Time 145.64203190803528 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 145.6833267211914 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 145.73241710662842 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 145.77312541007996 loss tensor(0.4674, grad_fn=<NegBackward0>)\n",
            "Time 145.81156516075134 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 145.85322308540344 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 145.8967490196228 loss tensor(0.4672, grad_fn=<NegBackward0>)\n",
            "Time 145.9419560432434 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 145.98415064811707 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 146.0247344970703 loss tensor(0.4670, grad_fn=<NegBackward0>)\n",
            "Time 146.0646951198578 loss tensor(0.4669, grad_fn=<NegBackward0>)\n",
            "Time 146.10884809494019 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 146.14796614646912 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 146.192973613739 loss tensor(0.4667, grad_fn=<NegBackward0>)\n",
            "Time 146.23138546943665 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 146.27173233032227 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 146.315425157547 loss tensor(0.4665, grad_fn=<NegBackward0>)\n",
            "Time 146.3592493534088 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 146.40056443214417 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 146.44074058532715 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 146.48536682128906 loss tensor(0.4662, grad_fn=<NegBackward0>)\n",
            "Time 146.53093004226685 loss tensor(0.4662, grad_fn=<NegBackward0>)\n",
            "Time 146.56974744796753 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 146.60868859291077 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 146.65074253082275 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 146.69061946868896 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 146.74589943885803 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 146.79336428642273 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 146.8326153755188 loss tensor(0.4657, grad_fn=<NegBackward0>)\n",
            "Time 146.8709499835968 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 146.9100124835968 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 146.95387482643127 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 146.99464654922485 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 147.03553080558777 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 147.0749156475067 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 147.11685252189636 loss tensor(0.4652, grad_fn=<NegBackward0>)\n",
            "Time 147.1638731956482 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 147.20503950119019 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 147.2430238723755 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 147.28233075141907 loss tensor(0.4649, grad_fn=<NegBackward0>)\n",
            "Time 147.3222472667694 loss tensor(0.4649, grad_fn=<NegBackward0>)\n",
            "Time 147.36205625534058 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 147.40668654441833 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 147.44512581825256 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 147.4825098514557 loss tensor(0.4646, grad_fn=<NegBackward0>)\n",
            "Time 147.52120661735535 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 147.55995869636536 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 147.59782218933105 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 147.64547872543335 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 147.68384337425232 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 147.72201895713806 loss tensor(0.4642, grad_fn=<NegBackward0>)\n",
            "Time 147.77298855781555 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 147.81230854988098 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 147.85804438591003 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 147.8974781036377 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 147.93699169158936 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 147.97975206375122 loss tensor(0.4638, grad_fn=<NegBackward0>)\n",
            "Time 148.01796174049377 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 148.05578804016113 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 148.10565733909607 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 148.1493058204651 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 148.18896865844727 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 148.23537707328796 loss tensor(0.4634, grad_fn=<NegBackward0>)\n",
            "Time 148.2810881137848 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 148.3279333114624 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 148.3671796321869 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 148.4061985015869 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 148.44487500190735 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 148.4892919063568 loss tensor(0.4630, grad_fn=<NegBackward0>)\n",
            "Time 148.53042197227478 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 148.57306599617004 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 148.61264753341675 loss tensor(0.4628, grad_fn=<NegBackward0>)\n",
            "Time 148.65343570709229 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 148.69228744506836 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 148.73077702522278 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 148.78616738319397 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 148.8287444114685 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 148.8704390525818 loss tensor(0.4624, grad_fn=<NegBackward0>)\n",
            "Time 148.9100399017334 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 148.94996809959412 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 148.9938304424286 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 149.03559041023254 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 149.0747013092041 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 149.11471962928772 loss tensor(0.4620, grad_fn=<NegBackward0>)\n",
            "Time 149.15718507766724 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 149.19587111473083 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 149.24561667442322 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 149.28530740737915 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 149.32405281066895 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 149.3640170097351 loss tensor(0.4616, grad_fn=<NegBackward0>)\n",
            "Time 149.4025857448578 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 149.44235038757324 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 149.49007153511047 loss tensor(0.4614, grad_fn=<NegBackward0>)\n",
            "Time 149.5276472568512 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 149.564120054245 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 149.60185432434082 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 149.64319467544556 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 149.6812071800232 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 149.72600030899048 loss tensor(0.4610, grad_fn=<NegBackward0>)\n",
            "Time 149.764976978302 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 149.81238293647766 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 149.8528847694397 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 149.8907630443573 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 149.94398593902588 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 149.98645853996277 loss tensor(0.4606, grad_fn=<NegBackward0>)\n",
            "Time 150.02667832374573 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 150.06620407104492 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 150.10575819015503 loss tensor(0.4604, grad_fn=<NegBackward0>)\n",
            "Time 150.15036702156067 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 150.2067973613739 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 150.24462938308716 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 150.2967655658722 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 150.3365137577057 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 150.38119673728943 loss tensor(0.4600, grad_fn=<NegBackward0>)\n",
            "Time 150.41930270195007 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 150.45809769630432 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 150.49700832366943 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 150.5347490310669 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 150.57779383659363 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 150.62200355529785 loss tensor(0.4596, grad_fn=<NegBackward0>)\n",
            "Time 150.66201734542847 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 150.69991087913513 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 150.73723101615906 loss tensor(0.4594, grad_fn=<NegBackward0>)\n",
            "Time 150.77516412734985 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 150.82086515426636 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 150.87225127220154 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 150.91295456886292 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 150.9533290863037 loss tensor(0.4591, grad_fn=<NegBackward0>)\n",
            "Time 150.9941487312317 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 151.0329134464264 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 151.07117176055908 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 151.11493754386902 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 151.15852904319763 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 151.19852566719055 loss tensor(0.4587, grad_fn=<NegBackward0>)\n",
            "Time 151.23858618736267 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 151.2979998588562 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 151.33830094337463 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 151.37780928611755 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 151.41651940345764 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 151.45630645751953 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 151.5003342628479 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 151.5433533191681 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 151.5820004940033 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 151.6207308769226 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 151.65992093086243 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 151.69774079322815 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 151.7519097328186 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 151.79023456573486 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 151.83639907836914 loss tensor(0.4577, grad_fn=<NegBackward0>)\n",
            "Time 151.87683844566345 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 151.91593647003174 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 151.95985794067383 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 152.00115323066711 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 152.0406355857849 loss tensor(0.4574, grad_fn=<NegBackward0>)\n",
            "Time 152.0790994167328 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 152.1182906627655 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 152.157128572464 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 152.2087664604187 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 152.247652053833 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 152.29738688468933 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 152.3368113040924 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 152.37554836273193 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 152.4198100566864 loss tensor(0.4568, grad_fn=<NegBackward0>)\n",
            "Time 152.45956683158875 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 152.50049352645874 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 152.53868913650513 loss tensor(0.4566, grad_fn=<NegBackward0>)\n",
            "Time 152.5778260231018 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 152.61746907234192 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 152.6710650920868 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 152.709321975708 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 152.747873544693 loss tensor(0.4563, grad_fn=<NegBackward0>)\n",
            "Time 152.78511357307434 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 152.82283759117126 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 152.88283371925354 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 152.9224488735199 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 152.96140027046204 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 153.00157690048218 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 153.04000568389893 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 153.07779335975647 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 153.12297701835632 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 153.16146779060364 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 153.20611000061035 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 153.24912405014038 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 153.29803323745728 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 153.36289286613464 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 153.42247557640076 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 153.4804253578186 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 153.54408240318298 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 153.60818076133728 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 153.6762535572052 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 153.73958945274353 loss tensor(0.4550, grad_fn=<NegBackward0>)\n",
            "Time 153.8015434741974 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 153.86877632141113 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 153.93299174308777 loss tensor(0.4548, grad_fn=<NegBackward0>)\n",
            "Time 153.9942548274994 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 154.05363059043884 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 154.11370277404785 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 154.17263197898865 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 154.2333538532257 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 154.2922704219818 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 154.35892128944397 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 154.4165198802948 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 154.47414875030518 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 154.53565287590027 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 154.59786224365234 loss tensor(0.4541, grad_fn=<NegBackward0>)\n",
            "Time 154.6664752960205 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 154.72442388534546 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 154.78621244430542 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 154.846741437912 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 154.91129779815674 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 154.98282551765442 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 155.04103112220764 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 155.11343693733215 loss tensor(0.4536, grad_fn=<NegBackward0>)\n",
            "Time 155.172110080719 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 155.2303581237793 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 155.2940490245819 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 155.36641931533813 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 155.43225765228271 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 155.49079513549805 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 155.55215525627136 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 155.62801122665405 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 155.68600511550903 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 155.74597215652466 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 155.80369544029236 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 155.87847685813904 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 155.94472193717957 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 156.01280570030212 loss tensor(0.4527, grad_fn=<NegBackward0>)\n",
            "Time 156.06917309761047 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 156.11424350738525 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 156.15337014198303 loss tensor(0.4525, grad_fn=<NegBackward0>)\n",
            "Time 156.191739320755 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 156.22902917861938 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 156.2684609889984 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 156.3064363002777 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 156.3575301170349 loss tensor(0.4522, grad_fn=<NegBackward0>)\n",
            "Time 156.39807868003845 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 156.43674397468567 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 156.47510075569153 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 156.51395344734192 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 156.55280137062073 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 156.59989309310913 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 156.64215350151062 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 156.6809437274933 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 156.71998834609985 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 156.75904893875122 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 156.79770731925964 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 156.84293031692505 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 156.8830211162567 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 156.9246702194214 loss tensor(0.4513, grad_fn=<NegBackward0>)\n",
            "Time 156.96457648277283 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 157.00652194023132 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 157.0598406791687 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 157.0987033843994 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 157.13708400726318 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 157.17468762397766 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 157.2178294658661 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 157.26825428009033 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 157.3109323978424 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 157.3580641746521 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 157.39763045310974 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 157.4358627796173 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 157.47767233848572 loss tensor(0.4505, grad_fn=<NegBackward0>)\n",
            "Time 157.5182385444641 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 157.55620336532593 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 157.59487748146057 loss tensor(0.4503, grad_fn=<NegBackward0>)\n",
            "Time 157.64256072044373 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 157.68382382392883 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 157.730299949646 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 157.769136428833 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 157.8136305809021 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 157.85273814201355 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 157.8929421901703 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 157.94650721549988 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 157.98637413978577 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 158.02524161338806 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 158.0731840133667 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 158.1179666519165 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 158.1597375869751 loss tensor(0.4495, grad_fn=<NegBackward0>)\n",
            "Time 158.20428729057312 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 158.24408555030823 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 158.28403782844543 loss tensor(0.4493, grad_fn=<NegBackward0>)\n",
            "Time 158.3274929523468 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 158.36742639541626 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 158.4061713218689 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 158.4448685646057 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 158.48365998268127 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 158.5213327407837 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 158.57113814353943 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 158.6170516014099 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 158.66016030311584 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 158.69882488250732 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 158.73715209960938 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 158.77884221076965 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 158.8187186717987 loss tensor(0.4485, grad_fn=<NegBackward0>)\n",
            "Time 158.85742235183716 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 158.89643001556396 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 158.93832278251648 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 158.97984075546265 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 159.02856755256653 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 159.07570099830627 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 159.11508297920227 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 159.15385007858276 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 159.19349455833435 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 159.23754382133484 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 159.28193354606628 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 159.32713341712952 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 159.36954545974731 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 159.40983724594116 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 159.45427298545837 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 159.49280190467834 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 159.5315535068512 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 159.56979966163635 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 159.60884189605713 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 159.65083527565002 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 159.69987773895264 loss tensor(0.4472, grad_fn=<NegBackward0>)\n",
            "Time 159.73863124847412 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 159.77734470367432 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 159.8204574584961 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 159.85908389091492 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 159.89776158332825 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 159.94882798194885 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 159.98872184753418 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 160.02934503555298 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 160.06918811798096 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 160.11770582199097 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 160.16577649116516 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 160.20657801628113 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 160.2493245601654 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 160.2938859462738 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 160.33512449264526 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 160.38037395477295 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 160.4225618839264 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 160.47013688087463 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 160.51972436904907 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 160.55870151519775 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 160.60324501991272 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 160.6451380252838 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 160.68445587158203 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 160.72372341156006 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 160.76243710517883 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 160.81598329544067 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 160.8566026687622 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 160.89580392837524 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 160.935884475708 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 160.97476315498352 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 161.01536464691162 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 161.0609085559845 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 161.10927891731262 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 161.15380859375 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 161.19343972206116 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 161.23726439476013 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 161.27726197242737 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 161.31497311592102 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 161.3534278869629 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 161.39129543304443 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 161.42993330955505 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 161.4773814678192 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 161.51501154899597 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 161.55525636672974 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 161.59361934661865 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 161.63535976409912 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 161.67447710037231 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 161.72164154052734 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 161.76166319847107 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 161.79992389678955 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 161.84308767318726 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 161.88314604759216 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 161.92218351364136 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 161.97036981582642 loss tensor(0.4439, grad_fn=<NegBackward0>)\n",
            "Time 162.01265120506287 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 162.05209064483643 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 162.09092473983765 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 162.1409032344818 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 162.18254375457764 loss tensor(0.4436, grad_fn=<NegBackward0>)\n",
            "Time 162.22096729278564 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 162.26184272766113 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 162.30714082717896 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 162.35447788238525 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 162.39185690879822 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 162.43130111694336 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 162.4697334766388 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 162.50765705108643 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 162.54609203338623 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 162.59256768226624 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 162.63811945915222 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 162.67919301986694 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 162.7177813053131 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 162.75705194473267 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 162.79944324493408 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 162.84479880332947 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 162.8852894306183 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 162.92802572250366 loss tensor(0.4425, grad_fn=<NegBackward0>)\n",
            "Time 162.97082448005676 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 163.01838946342468 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 163.0579936504364 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 163.09788060188293 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 163.13979601860046 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 163.18604922294617 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 163.23082423210144 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 163.28647375106812 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 163.3480978012085 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 163.3879358768463 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 163.42687010765076 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 163.4720582962036 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 163.5112223625183 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 163.55028080940247 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 163.58968663215637 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 163.63213896751404 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 163.67155003547668 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 163.71526265144348 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 163.75401425361633 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 163.79414820671082 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 163.83369398117065 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 163.87305355072021 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 163.9179983139038 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 163.9605860710144 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 164.0115807056427 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 164.05347514152527 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 164.09256505966187 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 164.13815569877625 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 164.18761348724365 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 164.2367250919342 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 164.28880786895752 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 164.32796096801758 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 164.3732087612152 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 164.4122953414917 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 164.4510850906372 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 164.49042344093323 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 164.52921676635742 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 164.5678424835205 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 164.61922335624695 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 164.66124081611633 loss tensor(0.4401, grad_fn=<NegBackward0>)\n",
            "Time 164.70023584365845 loss tensor(0.4401, grad_fn=<NegBackward0>)\n",
            "Time 164.73857736587524 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 164.77730679512024 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 164.81537890434265 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 164.8603584766388 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 164.90445470809937 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 164.94431853294373 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 164.98544096946716 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 165.02832317352295 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 165.07315063476562 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 165.1132435798645 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 165.152822971344 loss tensor(0.4394, grad_fn=<NegBackward0>)\n",
            "Time 165.20445036888123 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 165.24664545059204 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 165.29470038414001 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 165.33388376235962 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 165.3751084804535 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 165.41498827934265 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 165.45378232002258 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 165.4920768737793 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 165.54017233848572 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 165.57860231399536 loss tensor(0.4388, grad_fn=<NegBackward0>)\n",
            "Time 165.61770176887512 loss tensor(0.4388, grad_fn=<NegBackward0>)\n",
            "Time 165.65890741348267 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 165.69809317588806 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 165.73690342903137 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 165.78355050086975 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 165.82250142097473 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 165.8608410358429 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 165.89992713928223 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 165.9393789768219 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 165.9814112186432 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 166.02769947052002 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 166.09963726997375 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 166.1650516986847 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 166.23103952407837 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 166.29798555374146 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 166.35649824142456 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 166.41607904434204 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 166.4893398284912 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 166.54734253883362 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 166.60550785064697 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 166.66628003120422 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 166.73743677139282 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 166.79486751556396 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 166.85216569900513 loss tensor(0.4374, grad_fn=<NegBackward0>)\n",
            "Time 166.90986609458923 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 166.98221516609192 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 167.04401326179504 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 167.10774302482605 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 167.17355704307556 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 167.238196849823 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 167.31214880943298 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 167.37069034576416 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 167.43013191223145 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 167.50022745132446 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 167.55890941619873 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 167.6170666217804 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 167.67882680892944 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 167.75204229354858 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 167.8103551864624 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 167.86780524253845 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 167.9255108833313 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 167.98559308052063 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 168.04892301559448 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 168.13397526741028 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 168.20544385910034 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 168.26339411735535 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 168.32697868347168 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 168.38974976539612 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 168.45585465431213 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 168.51354217529297 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 168.58003115653992 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 168.6490454673767 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 168.72752594947815 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 168.79204630851746 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 168.8350658416748 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 168.87397837638855 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 168.91643118858337 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 168.96560335159302 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 169.00836753845215 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 169.04854559898376 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 169.0894124507904 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 169.1293442249298 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 169.1769471168518 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 169.2213258743286 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 169.26237893104553 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 169.30166268348694 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 169.3485016822815 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 169.39346885681152 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 169.43168950080872 loss tensor(0.4348, grad_fn=<NegBackward0>)\n",
            "Time 169.47012948989868 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 169.5084171295166 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 169.55110931396484 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 169.5901436805725 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 169.6388864517212 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 169.67848563194275 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 169.717143535614 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 169.75673985481262 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 169.81244134902954 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 169.86263394355774 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 169.9022810459137 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 169.9414415359497 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 169.98091578483582 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 170.0239703655243 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 170.0663709640503 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 170.11318254470825 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 170.15269684791565 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 170.1995666027069 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 170.2406461238861 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 170.29244875907898 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 170.33617496490479 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 170.39155530929565 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 170.43144416809082 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 170.472229719162 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 170.5245282649994 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 170.56485795974731 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 170.6117742061615 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 170.6537299156189 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 170.69252729415894 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 170.73757982254028 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 170.77802300453186 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 170.81640124320984 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 170.85537028312683 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 170.8967080116272 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 170.9375183582306 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 170.98137617111206 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 171.0282518863678 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 171.0668022632599 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 171.10767102241516 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 171.14995908737183 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 171.19599199295044 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 171.2530038356781 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 171.29200148582458 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 171.33226871490479 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 171.3816647529602 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 171.42829751968384 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 171.46686673164368 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 171.50538611412048 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 171.5444746017456 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 171.58569192886353 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 171.63330674171448 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 171.67243099212646 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 171.71139764785767 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 171.7502887248993 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 171.7889382839203 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 171.83564257621765 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 171.88211941719055 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 171.92219281196594 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 171.96258401870728 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 172.0035674571991 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 172.05350399017334 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 172.09335899353027 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 172.13273739814758 loss tensor(0.4312, grad_fn=<NegBackward0>)\n",
            "Time 172.1801562309265 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 172.22137546539307 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 172.2700116634369 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 172.31257700920105 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 172.35318613052368 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 172.39186429977417 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 172.43982577323914 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 172.48926901817322 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 172.52883982658386 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 172.56801009178162 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 172.60699439048767 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 172.64861178398132 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 172.6868336200714 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 172.7334761619568 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 172.7728226184845 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 172.8114619255066 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 172.85076093673706 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 172.89015674591064 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 172.93016910552979 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 172.9754889011383 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 173.014746427536 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 173.0556390285492 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 173.094624042511 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 173.13852262496948 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 173.18739795684814 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 173.23130893707275 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 173.2711899280548 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 173.3144359588623 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 173.36034274101257 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 173.40672898292542 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 173.454345703125 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 173.49875378608704 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 173.5379023551941 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 173.5763430595398 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 173.62208032608032 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 173.66263556480408 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 173.70064640045166 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 173.73927307128906 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 173.77862572669983 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 173.82213616371155 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 173.8694863319397 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 173.90819358825684 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 173.9483518600464 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 173.98899602890015 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 174.0394492149353 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 174.08183550834656 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 174.1305067539215 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 174.17041301727295 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 174.21194195747375 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 174.25859427452087 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 174.30268788337708 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 174.34231638908386 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 174.38267397880554 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 174.42360663414001 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 174.4792079925537 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 174.51948833465576 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 174.55820608139038 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 174.6081416606903 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 174.65561723709106 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 174.70382142066956 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 174.74492287635803 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 174.78369092941284 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 174.82304072380066 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 174.8624575138092 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 174.90181231498718 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 174.94750666618347 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 174.99346733093262 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 175.03641080856323 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 175.07552218437195 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 175.1145420074463 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 175.16167068481445 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 175.20174622535706 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 175.24232244491577 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 175.2835032939911 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 175.32573580741882 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 175.37190866470337 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 175.41681361198425 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 175.45673370361328 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 175.50331211090088 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 175.5425751209259 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 175.58858633041382 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 175.63116264343262 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 175.67093753814697 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 175.71025800704956 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 175.7533233165741 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 175.7961082458496 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 175.8377537727356 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 175.87665009498596 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 175.91729712486267 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 175.95712971687317 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 175.9970474243164 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 176.05007147789001 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 176.0895974636078 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 176.12899827957153 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 176.16784501075745 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 176.21306371688843 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 176.25890636444092 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 176.3055694103241 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 176.34502387046814 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 176.38377141952515 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 176.4276008605957 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 176.46669960021973 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 176.51346135139465 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 176.55418252944946 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 176.59472179412842 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 176.6413061618805 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 176.67991757392883 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 176.7177596092224 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 176.75584745407104 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 176.7943994998932 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 176.83445000648499 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 176.88398814201355 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 176.92427349090576 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 176.96434950828552 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 177.00309419631958 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 177.04486203193665 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 177.08386778831482 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 177.1310577392578 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 177.16988897323608 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 177.20887303352356 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 177.24775767326355 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 177.28706812858582 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 177.3314836025238 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 177.36991572380066 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 177.4112150669098 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 177.45105290412903 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 177.49166798591614 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 177.5478823184967 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 177.58650279045105 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 177.6278178691864 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 177.6673548221588 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 177.7124044895172 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 177.75492477416992 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 177.79808855056763 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 177.83852076530457 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 177.87789058685303 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 177.91687941551208 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 177.95608162879944 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 178.00488328933716 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 178.05519151687622 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 178.11088943481445 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 178.15515780448914 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 178.19458103179932 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 178.24171829223633 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 178.2829248905182 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 178.32577919960022 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 178.36595177650452 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 178.40455102920532 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 178.4561002254486 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 178.49761819839478 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 178.544447183609 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 178.58287048339844 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 178.6212751865387 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 178.66629266738892 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 178.7115879058838 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 178.75124645233154 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 178.79291105270386 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 178.85314679145813 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 178.9244523048401 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 178.98573470115662 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 179.05050945281982 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 179.11295819282532 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 179.1746346950531 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 179.23723530769348 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 179.29677319526672 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 179.35771417617798 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 179.41863489151 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 179.4766387939453 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 179.53472685813904 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 179.59996104240417 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 179.6679129600525 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 179.72544813156128 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 179.7830445766449 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 179.84066247940063 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 179.90547513961792 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 179.96415448188782 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 180.0267515182495 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 180.08772349357605 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 180.15738677978516 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 180.21645784378052 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 180.2753415107727 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 180.3335611820221 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 180.39688277244568 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 180.46000814437866 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 180.51812601089478 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 180.57499599456787 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 180.6541187763214 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 180.7131826877594 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 180.77152109146118 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 180.83408856391907 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 180.90521216392517 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 180.96385836601257 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 181.0243422985077 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 181.08592987060547 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 181.1517014503479 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 181.21692490577698 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 181.28613996505737 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 181.35628080368042 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 181.42848873138428 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 181.4932084083557 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 181.54597520828247 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 181.5918323993683 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 181.63973116874695 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 181.68693733215332 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 181.7255892753601 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 181.7644236087799 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 181.8096685409546 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 181.84957432746887 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 181.88850617408752 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 181.92899107933044 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 181.96812558174133 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 182.0081980228424 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 182.05600023269653 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 182.0984787940979 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 182.13777136802673 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 182.17691588401794 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 182.22338843345642 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 182.27410745620728 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 182.3150053024292 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 182.35419631004333 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 182.39794445037842 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 182.4376826286316 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 182.47772908210754 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 182.5277156829834 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 182.56683778762817 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 182.60530161857605 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 182.6484501361847 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 182.7022259235382 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 182.74132823944092 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 182.77907943725586 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 182.8212547302246 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 182.8605797290802 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 182.8994734287262 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 182.94484448432922 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 182.9848656654358 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 183.0246605873108 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 183.06445050239563 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 183.10577058792114 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 183.14780068397522 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 183.19580817222595 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 183.23507475852966 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 183.27487921714783 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 183.32006692886353 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 183.36187553405762 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 183.4072985649109 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 183.4492826461792 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 183.49045276641846 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 183.52886772155762 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 183.57052493095398 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 183.61451935768127 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 183.6592447757721 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 183.7095034122467 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 183.7494466304779 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 183.7947132587433 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 183.83533334732056 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 183.87384057044983 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 183.91943049430847 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 183.95953035354614 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 184.00332260131836 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 184.04414653778076 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 184.08643531799316 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 184.14209413528442 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 184.18161821365356 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 184.23043298721313 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 184.27082800865173 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 184.3092761039734 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 184.3508644104004 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 184.39099764823914 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 184.4309709072113 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 184.4764847755432 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 184.52007365226746 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 184.56006908416748 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 184.59894227981567 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 184.6411509513855 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 184.6858413219452 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 184.73416304588318 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 184.77324748039246 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 184.815491437912 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 184.8580584526062 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 184.89984107017517 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 184.93999910354614 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 184.9793405532837 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 185.0260546207428 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 185.07859182357788 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 185.11914801597595 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 185.1655170917511 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 185.20508527755737 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 185.24592638015747 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 185.29742670059204 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 185.33755803108215 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 185.37761545181274 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 185.4168345928192 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 185.45599055290222 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 185.5014181137085 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 185.5487563610077 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 185.5864977836609 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 185.62839198112488 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 185.6689829826355 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 185.73375844955444 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 185.78406691551208 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 185.8241970539093 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 185.8638162612915 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 185.90254139900208 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 185.94404196739197 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 185.9882471561432 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 186.02750372886658 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 186.07294869422913 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 186.11516737937927 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 186.16340923309326 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 186.22487378120422 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 186.26663851737976 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 186.3060417175293 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 186.34601092338562 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 186.39234399795532 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 186.4311261177063 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 186.4700219631195 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 186.5091860294342 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 186.54902029037476 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 186.5879304409027 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 186.63602137565613 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 186.67538785934448 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 186.71404194831848 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 186.7644443511963 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 186.8088457584381 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 186.85357308387756 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 186.89408946037292 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 186.93354654312134 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 186.9718894958496 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 187.010883808136 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 187.05077457427979 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 187.09896683692932 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 187.14257669448853 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 187.18178296089172 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 187.2209689617157 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 187.2631959915161 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 187.30472660064697 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 187.35250782966614 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 187.3934190273285 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 187.43780040740967 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 187.4775731563568 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 187.5214478969574 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 187.56180906295776 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 187.6006624698639 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 187.64340472221375 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 187.68672060966492 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 187.72903394699097 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 187.7780885696411 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 187.8168432712555 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 187.85609126091003 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 187.89473676681519 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 187.94386553764343 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 187.9831621646881 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 188.02229976654053 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 188.0639808177948 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 188.10538125038147 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 188.14460587501526 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 188.19361686706543 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 188.24734449386597 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 188.28984427452087 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 188.32971143722534 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 188.37588334083557 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 188.41560626029968 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 188.45516514778137 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 188.49442958831787 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 188.53366684913635 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 188.5729525089264 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 188.61995315551758 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 188.66105675697327 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 188.7001280784607 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 188.7389430999756 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 188.78301095962524 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 188.83142805099487 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 188.8716790676117 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 188.91016030311584 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 188.94886350631714 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 188.98814058303833 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 189.0501389503479 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 189.09115934371948 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 189.13229036331177 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 189.17157793045044 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 189.21234393119812 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 189.25073337554932 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 189.29674816131592 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 189.33528351783752 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 189.37365865707397 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 189.4166226387024 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 189.45578408241272 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 189.50315308570862 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 189.54202318191528 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 189.5800642967224 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 189.61866402626038 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 189.66000723838806 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 189.69811582565308 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 189.7453293800354 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 189.7941873073578 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 189.84208250045776 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 189.88074374198914 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 189.9185185432434 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 189.9651141166687 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 190.00528597831726 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 190.0454375743866 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 190.08579635620117 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 190.1343765258789 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 190.17948818206787 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 190.21928596496582 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 190.2604341506958 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 190.29908323287964 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 190.33891773223877 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 190.37896704673767 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 190.42529249191284 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 190.4647674560547 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 190.5088369846344 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 190.548752784729 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 190.58784699440002 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 190.6390950679779 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 190.6810154914856 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 190.73305749893188 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 190.77283334732056 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 190.84278392791748 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 190.89430403709412 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 190.93458366394043 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 190.9763960838318 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 191.01575231552124 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 191.06146025657654 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 191.10205721855164 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 191.1434462070465 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 191.1821734905243 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 191.22155213356018 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 191.2669439315796 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 191.31193685531616 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 191.35151982307434 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 191.39094400405884 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 191.43085885047913 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 191.47301316261292 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 191.51888966560364 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 191.57633233070374 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 191.63550424575806 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 191.69294333457947 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 191.7510507106781 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 191.80801916122437 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 191.87427473068237 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 191.93739366531372 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 191.9983947277069 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 192.05730867385864 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 192.12034034729004 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 192.18600583076477 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 192.24681735038757 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 192.30776453018188 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 192.3666853904724 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 192.42739486694336 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 192.48700213432312 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 192.5516390800476 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 192.61030173301697 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 192.67953896522522 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 192.7377827167511 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 192.7996699810028 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 192.85869026184082 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 192.93680119514465 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 192.99436712265015 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 193.0531394481659 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 193.11199355125427 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 193.18492603302002 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 193.24573755264282 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 193.31088542938232 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 193.37210392951965 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 193.43555808067322 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 193.49382495880127 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 193.55181527137756 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 193.61562991142273 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 193.68285608291626 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 193.7406942844391 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 193.8015751838684 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 193.85985207557678 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 193.92679262161255 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 193.99622535705566 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 194.05509448051453 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 194.12658548355103 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 194.20154666900635 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 194.26802515983582 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 194.3223214149475 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 194.37128520011902 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 194.41027402877808 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 194.44946384429932 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 194.4886691570282 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 194.5268576145172 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 194.56534099578857 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 194.61213159561157 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 194.65354180335999 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 194.6976330280304 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 194.73655319213867 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 194.77521443367004 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 194.8128261566162 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 194.8568229675293 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 194.89512968063354 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 194.9338698387146 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 194.9785327911377 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 195.0278296470642 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 195.07306289672852 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 195.11501336097717 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 195.15438151359558 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 195.19751071929932 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 195.24371886253357 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 195.28508067131042 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 195.3294608592987 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 195.36879420280457 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 195.41024804115295 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 195.4541573524475 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 195.4936294555664 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 195.53220319747925 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 195.5710551738739 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 195.63068675994873 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 195.6780822277069 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 195.71659994125366 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 195.75553369522095 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 195.79421973228455 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 195.8324613571167 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 195.87094020843506 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 195.9173264503479 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 195.95638012886047 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 196.00418305397034 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 196.0558319091797 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 196.09741044044495 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 196.1443247795105 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 196.1869192123413 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 196.2277796268463 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 196.26974773406982 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 196.3099443912506 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 196.3562672138214 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 196.4047167301178 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 196.4450969696045 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 196.4846704006195 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 196.52332520484924 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 196.56625938415527 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 196.6083037853241 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 196.65530681610107 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 196.69553875923157 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 196.73522973060608 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 196.77937126159668 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 196.8188180923462 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 196.85822820663452 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 196.89754152297974 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 196.94212007522583 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 196.98474073410034 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 197.03880143165588 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 197.07910633087158 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 197.12093234062195 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 197.16050696372986 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 197.20849609375 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 197.24822807312012 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 197.29200506210327 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 197.3336145877838 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 197.37771344184875 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 197.42432618141174 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 197.46546363830566 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 197.50545406341553 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 197.54503178596497 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 197.58553266525269 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 197.63200974464417 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 197.67508840560913 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 197.7151334285736 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 197.75395226478577 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 197.79243969917297 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 197.83125400543213 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 197.87879300117493 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 197.91874933242798 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 197.95682311058044 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 197.99594020843506 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 198.04935598373413 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 198.0977599620819 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 198.13698720932007 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 198.17863273620605 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 198.21995210647583 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 198.26104187965393 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 198.30272436141968 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 198.3469433784485 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 198.38673615455627 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 198.42586064338684 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 198.46510934829712 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 198.50981378555298 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 198.5561923980713 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 198.59566378593445 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 198.6374158859253 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 198.67740511894226 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 198.71746730804443 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 198.7622036933899 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 198.80570816993713 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 198.84559535980225 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 198.8851466178894 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 198.92475414276123 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 198.96974515914917 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 199.0093162059784 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 199.05212998390198 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 199.09686946868896 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 199.14359545707703 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 199.1883978843689 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 199.22787284851074 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 199.26823377609253 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 199.30904269218445 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 199.35279083251953 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 199.40035843849182 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 199.44152188301086 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 199.48080492019653 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 199.5256326198578 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 199.58176255226135 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 199.62406539916992 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 199.66482734680176 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 199.70456314086914 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 199.74372839927673 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 199.78313779830933 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 199.8279631137848 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 199.86690998077393 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 199.91094183921814 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 199.95075845718384 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 199.99017310142517 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 200.03627395629883 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 200.08156633377075 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 200.12316751480103 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 200.16182041168213 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 200.21115159988403 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 200.25179028511047 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 200.29486083984375 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 200.33615493774414 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 200.37564992904663 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 200.41768097877502 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 200.46843028068542 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 200.50838041305542 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 200.54760241508484 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 200.59304881095886 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 200.64183378219604 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 200.68329119682312 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 200.72188997268677 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 200.76097536087036 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 200.79904556274414 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 200.83739948272705 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 200.88778519630432 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 200.93163442611694 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 200.97099542617798 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 201.0096995830536 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 201.05055212974548 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 201.10279369354248 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 201.14916944503784 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 201.19283938407898 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 201.2359836101532 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 201.28600525856018 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 201.3328037261963 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 201.37702298164368 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 201.41760563850403 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 201.45652103424072 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 201.49619340896606 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 201.53610634803772 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 201.5805697441101 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 201.61934423446655 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 201.66207885742188 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 201.7046995162964 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 201.74327278137207 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 201.7904703617096 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 201.82956910133362 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 201.86899042129517 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 201.90716886520386 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 201.94883561134338 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 201.99628067016602 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 202.0353844165802 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 202.07485604286194 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 202.12195324897766 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 202.161847114563 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 202.2149875164032 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 202.25643467903137 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 202.2971270084381 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 202.33698511123657 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 202.3759639263153 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 202.41972088813782 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 202.46502375602722 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 202.50358486175537 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 202.54175806045532 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 202.57981610298157 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 202.61955308914185 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 202.66565346717834 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 202.7046205997467 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 202.74285078048706 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 202.78939056396484 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 202.82845735549927 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 202.86854600906372 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 202.9162313938141 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 202.95553255081177 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 202.99545121192932 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 203.03541803359985 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 203.07875776290894 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 203.13641929626465 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 203.17827725410461 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 203.22087240219116 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 203.26248598098755 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 203.31107020378113 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 203.35911536216736 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 203.40446424484253 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 203.44492030143738 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 203.48461627960205 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 203.5319685935974 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 203.5728154182434 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 203.61281776428223 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 203.65372896194458 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 203.69320487976074 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 203.74231266975403 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 203.78298354148865 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 203.8223099708557 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 203.8618562221527 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 203.9007761478424 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 203.939523935318 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 203.98710465431213 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 204.0262632369995 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 204.06779289245605 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 204.11432242393494 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 204.1672031879425 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 204.2174735069275 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 204.25854468345642 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 204.30027222633362 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 204.3600993156433 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 204.42029285430908 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 204.49220871925354 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 204.55102133750916 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 204.60874319076538 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 204.67995142936707 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 204.73912405967712 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 204.79773902893066 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 204.85560202598572 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 204.92500710487366 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 204.98343229293823 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 205.04263734817505 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 205.10257697105408 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 205.17555356025696 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 205.2406768798828 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 205.3039367198944 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 205.36261534690857 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 205.4332733154297 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 205.4937207698822 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 205.55351305007935 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 205.61496376991272 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 205.689284324646 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 205.7494933605194 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 205.80693697929382 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 205.86523866653442 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 205.9378936290741 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 205.9960606098175 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 206.05639386177063 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 206.11530566215515 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 206.18902111053467 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 206.26598572731018 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 206.34511971473694 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 206.44642615318298 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 206.53262281417847 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 206.59320974349976 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 206.66461658477783 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 206.72527742385864 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 206.7839527130127 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 206.84184765815735 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 206.90664172172546 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 206.97176241874695 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 207.03678178787231 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 207.1008460521698 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 207.15872287750244 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 207.19879603385925 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 207.23865914344788 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 207.28502702713013 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 207.32795763015747 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 207.3784794807434 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 207.42049717903137 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 207.459397315979 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 207.49840188026428 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 207.53759956359863 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 207.57570052146912 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 207.62140893936157 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 207.67365217208862 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 207.7134575843811 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 207.75257229804993 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 207.79590940475464 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 207.84052181243896 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 207.8827521800995 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 207.92128109931946 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 207.9609410762787 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 208.0005259513855 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 208.04956340789795 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 208.09291291236877 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 208.1336371898651 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 208.17261242866516 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 208.2125744819641 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 208.2584934234619 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 208.30264925956726 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 208.34704303741455 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 208.38597178459167 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 208.43084239959717 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 208.47932481765747 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 208.51908040046692 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 208.55839586257935 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 208.59765100479126 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 208.63987612724304 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 208.68796372413635 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 208.7333106994629 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 208.77207493782043 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 208.82033586502075 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 208.86031556129456 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 208.90549397468567 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 208.94416308403015 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 208.98380041122437 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 209.03100204467773 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 209.0704584121704 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 209.1138744354248 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 209.15584111213684 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 209.20043396949768 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 209.23966717720032 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 209.28510856628418 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 209.3445589542389 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 209.3849093914032 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 209.42427730560303 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 209.4637439250946 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 209.50248646736145 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 209.5415861606598 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 209.58839774131775 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 209.63114070892334 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 209.6779487133026 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 209.7175850868225 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 209.75753688812256 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 209.80197143554688 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 209.84298610687256 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 209.88137936592102 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 209.92017579078674 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 209.96390295028687 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 210.00931477546692 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 210.05170130729675 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 210.0916874408722 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 210.13258862495422 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 210.1726155281067 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 210.21336722373962 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 210.2643904685974 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 210.3046703338623 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 210.3583996295929 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 210.3982048034668 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 210.4449348449707 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 210.48502898216248 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 210.52532935142517 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 210.56392884254456 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 210.6035578250885 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 210.64524698257446 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 210.6955373287201 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 210.7350869178772 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 210.77455973625183 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 210.81374382972717 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 210.853168964386 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 210.8996570110321 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 210.94440698623657 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 210.98368334770203 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 211.02216243743896 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 211.06167888641357 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 211.1014428138733 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 211.1513011455536 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 211.190265417099 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 211.2292652130127 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 211.27193808555603 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 211.31187629699707 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 211.3696005344391 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 211.43184781074524 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 211.474595785141 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 211.52769780158997 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 211.57510709762573 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 211.61467456817627 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 211.66478180885315 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 211.71685338020325 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 211.77016806602478 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 211.80926728248596 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 211.84937238693237 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 211.88737416267395 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 211.92779803276062 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 211.970285654068 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 212.01509833335876 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 212.05480813980103 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 212.09480214118958 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 212.13477277755737 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 212.17474460601807 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 212.2264494895935 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 212.27041172981262 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 212.31102204322815 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 212.35274481773376 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 212.40226674079895 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 212.4451675415039 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 212.48384761810303 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 212.52647519111633 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 212.57003736495972 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 212.61516284942627 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 212.65817093849182 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 212.69691395759583 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 212.73593926429749 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 212.77483224868774 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 212.81659865379333 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 212.86369943618774 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 212.90263104438782 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 212.94109463691711 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 212.97972130775452 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 213.0192527770996 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 213.066015958786 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 213.10972666740417 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 213.15133690834045 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 213.1915888786316 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 213.23267078399658 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 213.27943181991577 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 213.32063508033752 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 213.36091208457947 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 213.4105670452118 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 213.47576308250427 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 213.52417922019958 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 213.56516361236572 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 213.60513639450073 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 213.64709734916687 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 213.68697381019592 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 213.72727036476135 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 213.7714340686798 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 213.81003642082214 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 213.84938287734985 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 213.88758206367493 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 213.92685437202454 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 213.97875332832336 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 214.0172462463379 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 214.0569498538971 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 214.09679198265076 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 214.14051485061646 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 214.1912021636963 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 214.2358522415161 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 214.280109167099 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 214.31934356689453 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 214.35907435417175 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 214.4041383266449 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 214.44818258285522 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 214.4896638393402 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 214.52887630462646 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 214.56836891174316 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 214.6191964149475 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 214.66052842140198 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 214.69997572898865 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 214.74065375328064 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 214.77938771247864 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 214.81738090515137 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 214.86351037025452 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 214.9079785346985 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 214.9474790096283 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 214.98582673072815 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 215.0250322818756 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 215.06479358673096 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 215.11056089401245 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 215.15117120742798 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 215.1972839832306 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 215.2371850013733 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 215.28028845787048 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 215.32713842391968 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 215.36855936050415 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 215.40933918952942 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 215.44871473312378 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 215.5021231174469 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 215.5467381477356 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 215.58704018592834 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 215.6285479068756 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 215.66797947883606 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 215.71127939224243 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 215.75405979156494 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 215.793288230896 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 215.83757829666138 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 215.87697982788086 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 215.91576218605042 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 215.96134448051453 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 215.99974083900452 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 216.0380823612213 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 216.0768129825592 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 216.11639714241028 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 216.1671531200409 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 216.20688438415527 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 216.24757027626038 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 216.2919807434082 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 216.34207582473755 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 216.39050602912903 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 216.42982602119446 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 216.46811890602112 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 216.51547813415527 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 216.55441975593567 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 216.59538793563843 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 216.6425964832306 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 216.68106245994568 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 216.719877243042 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 216.76211786270142 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 216.80572295188904 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 216.86251401901245 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 216.90056490898132 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 216.9394507408142 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 216.97854471206665 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 217.02469730377197 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 217.07140851020813 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 217.11049675941467 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 217.16162252426147 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 217.22390365600586 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 217.29595565795898 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 217.35685276985168 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 217.4161343574524 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 217.48645567893982 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 217.5547616481781 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 217.6146228313446 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 217.67478561401367 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 217.73776078224182 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 217.79655742645264 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 217.85474681854248 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 217.91258239746094 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 217.97416710853577 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 218.03278827667236 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 218.10511994361877 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 218.16566586494446 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 218.22796320915222 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 218.28779244422913 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 218.35075998306274 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 218.41039633750916 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 218.4852318763733 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 218.54661321640015 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 218.61254906654358 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 218.67851066589355 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 218.74023389816284 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 218.79928398132324 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 218.8572657108307 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 218.91467452049255 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 218.9804105758667 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 219.04037308692932 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 219.09807991981506 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 219.15731358528137 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 219.22591972351074 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 219.29094982147217 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 219.3492558002472 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 219.4102439880371 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 219.47627806663513 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 219.534903049469 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 219.59766578674316 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 219.66072535514832 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 219.7317054271698 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 219.7960000038147 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 219.85988235473633 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 219.91443133354187 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 219.96138858795166 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 220.00113606452942 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 220.04039192199707 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 220.08335280418396 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 220.1263382434845 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 220.17175102233887 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 220.21316170692444 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 220.25280332565308 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 220.29246854782104 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 220.33340430259705 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 220.37278056144714 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 220.42935395240784 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 220.46869206428528 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 220.50787448883057 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 220.54730343818665 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 220.5929172039032 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 220.64395427703857 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 220.6832857131958 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 220.72246932983398 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 220.76230883598328 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 220.80766773223877 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 220.84793734550476 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 220.88714623451233 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 220.92639803886414 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 220.96551322937012 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 221.0052616596222 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 221.05300283432007 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 221.09262561798096 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 221.1324987411499 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 221.17362666130066 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 221.21394872665405 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 221.25726675987244 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 221.30273246765137 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 221.34437799453735 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 221.38551115989685 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 221.4267647266388 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 221.47216391563416 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 221.51268601417542 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 221.5520532131195 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 221.59667706489563 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 221.64749574661255 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 221.69292092323303 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 221.7321755886078 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 221.77120184898376 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 221.8103482723236 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 221.84963083267212 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 221.89265084266663 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 221.9388346672058 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 221.97827792167664 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 222.01642203330994 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 222.05643033981323 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 222.09681630134583 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 222.1537070274353 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 222.1987042427063 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 222.23816537857056 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 222.2828071117401 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 222.33404564857483 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 222.37362551689148 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 222.4123969078064 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 222.45652890205383 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 222.49535584449768 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 222.5346667766571 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 222.58129334449768 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 222.62054777145386 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 222.67022395133972 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 222.7099232673645 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 222.7563328742981 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 222.79639315605164 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 222.8348617553711 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 222.87411451339722 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 222.91216659545898 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 222.95081448554993 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 223.01073908805847 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 223.05156993865967 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 223.09089922904968 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 223.13552594184875 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 223.17705368995667 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 223.2210338115692 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 223.26419472694397 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 223.3050980567932 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 223.3488748073578 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 223.39019775390625 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 223.4418921470642 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 223.48142981529236 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 223.5203197002411 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 223.55928206443787 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 223.59788012504578 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 223.63975548744202 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 223.69983792304993 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 223.7391800880432 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 223.77827262878418 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 223.81706976890564 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 223.85559916496277 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 223.89351606369019 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 223.94264149665833 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 223.98378157615662 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 224.02407479286194 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 224.06351351737976 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 224.10545706748962 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 224.14722514152527 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 224.19055724143982 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 224.23465490341187 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 224.27610611915588 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 224.31511807441711 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 224.3625717163086 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 224.40546917915344 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 224.44367957115173 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 224.48679947853088 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 224.52607440948486 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 224.5662534236908 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 224.61008405685425 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 224.65142011642456 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 224.6921148300171 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 224.73854398727417 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 224.78395342826843 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 224.8238492012024 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 224.86842441558838 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 224.90676617622375 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 224.94563674926758 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 224.98480558395386 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 225.0297372341156 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 225.06952381134033 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 225.10881924629211 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 225.1498827934265 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 225.18878936767578 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 225.23575687408447 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 225.2789430618286 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 225.31957602500916 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 225.36065125465393 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 225.40339636802673 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 225.4490203857422 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 225.48758029937744 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 225.5262815952301 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 225.5651707649231 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 225.6033070087433 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 225.64351153373718 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 225.69104862213135 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 225.74310326576233 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 225.78298449516296 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 225.82193779945374 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 225.8613748550415 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 225.9062044620514 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 225.94590258598328 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 225.98526978492737 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 226.02373909950256 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 226.06735396385193 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 226.1071000099182 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 226.1556658744812 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 226.19666504859924 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 226.23807549476624 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 226.27920627593994 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 226.3231246471405 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 226.3694257736206 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 226.4087905883789 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 226.44925117492676 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 226.4890570640564 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 226.5325756072998 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 226.5751075744629 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 226.61465120315552 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 226.65741205215454 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 226.69591736793518 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 226.7438223361969 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 226.7960388660431 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 226.83487701416016 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 226.87464046478271 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 226.91324090957642 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 226.9580008983612 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 226.99946403503418 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 227.04102396965027 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 227.0866138935089 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 227.12612867355347 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 227.1767816543579 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 227.2176868915558 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 227.2586109638214 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 227.29817962646484 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 227.34998989105225 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 227.40509414672852 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 227.44561743736267 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 227.4858100414276 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 227.52911567687988 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 227.58266043663025 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 227.63127946853638 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 227.6717071533203 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 227.71064114570618 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 227.74989223480225 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 227.79745483398438 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 227.83748483657837 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 227.87933135032654 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 227.91716599464417 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 227.95567393302917 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 227.99728322029114 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 228.03633761405945 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 228.08177947998047 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 228.12111353874207 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 228.16098356246948 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 228.19991326332092 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 228.2388277053833 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 228.28302645683289 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 228.33367085456848 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 228.3850667476654 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 228.4375035762787 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 228.47737312316895 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 228.5225350856781 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 228.5610864162445 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 228.6018521785736 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 228.64395213127136 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 228.68346452713013 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 228.72292232513428 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 228.77025508880615 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 228.81770038604736 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 228.86039352416992 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 228.9000313282013 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 228.9456467628479 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 228.9907603263855 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 229.02910542488098 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 229.06819605827332 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 229.10767769813538 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 229.1470386981964 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 229.1991684436798 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 229.2384488582611 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 229.27917075157166 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 229.3175847530365 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 229.36461234092712 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 229.4089949131012 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 229.44802117347717 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 229.48704838752747 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 229.52549076080322 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 229.56517028808594 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 229.61004900932312 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 229.65122628211975 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 229.6900544166565 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 229.7291338443756 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 229.76806640625 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 229.82053303718567 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 229.86394238471985 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 229.90650725364685 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 229.96735215187073 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 230.03198647499084 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 230.0930140018463 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 230.1505584716797 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 230.21114873886108 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 230.27671837806702 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 230.3364930152893 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 230.3986964225769 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 230.45836448669434 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 230.5189471244812 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 230.5773265361786 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 230.63863277435303 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 230.69616103172302 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 230.75705432891846 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 230.81542086601257 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 230.88713192939758 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 230.94436526298523 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 231.00695753097534 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 231.0661289691925 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 231.1234531402588 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 231.1862509250641 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 231.24873518943787 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 231.31308031082153 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 231.37802124023438 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 231.4367184638977 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 231.49709820747375 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 231.55667066574097 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 231.61833715438843 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 231.6840045452118 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 231.7441258430481 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 231.8023989200592 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 231.86094641685486 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 231.92293977737427 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 231.99516558647156 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 232.06097030639648 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 232.12205028533936 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 232.1847083568573 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 232.25700545310974 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 232.31996154785156 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 232.38108229637146 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 232.4408049583435 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 232.50481748580933 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 232.5694818496704 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 232.63917684555054 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 232.71388745307922 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 232.7627944946289 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 232.80410146713257 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 232.8444447517395 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 232.88359332084656 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 232.93761610984802 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 232.98601269721985 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 233.0253825187683 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 233.06429076194763 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 233.10539364814758 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 233.1530361175537 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 233.1996247768402 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 233.24013113975525 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 233.28267073631287 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 233.32228446006775 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 233.37077856063843 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 233.41428899765015 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 233.4542751312256 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 233.49383568763733 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 233.53693652153015 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 233.5824007987976 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 233.62367749214172 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 233.663733959198 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 233.70331478118896 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 233.74260449409485 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 233.78184294700623 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 233.83408308029175 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 233.87396883964539 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 233.9134705066681 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 233.95298647880554 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 234.0089876651764 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 234.0499894618988 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 234.09026861190796 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 234.1299602985382 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 234.17319917678833 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 234.2171950340271 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 234.260755777359 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 234.30335235595703 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 234.34396266937256 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 234.38479900360107 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 234.42995476722717 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 234.47173714637756 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 234.50951504707336 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 234.54829239845276 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 234.58771777153015 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 234.64746403694153 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 234.69122552871704 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 234.73080158233643 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 234.7699511051178 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 234.81014037132263 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 234.85222816467285 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 234.90307235717773 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 234.94535636901855 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 234.98776769638062 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 235.0328495502472 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 235.08037877082825 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 235.11951184272766 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 235.16359734535217 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 235.20633673667908 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 235.24667072296143 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 235.29219460487366 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 235.33145952224731 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 235.37049055099487 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 235.4113028049469 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 235.4506711959839 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 235.49503231048584 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 235.5426549911499 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 235.58192467689514 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 235.62216114997864 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 235.66286849975586 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 235.70728993415833 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 235.7512514591217 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 235.7903025150299 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 235.83533334732056 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 235.8753318786621 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 235.91805720329285 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 235.96278047561646 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 236.00209259986877 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 236.05008172988892 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 236.08954048156738 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 236.13526463508606 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 236.17596912384033 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 236.2144067287445 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 236.25871229171753 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 236.31030249595642 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 236.35914063453674 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 236.40161895751953 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 236.4441044330597 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 236.4836175441742 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 236.52320003509521 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 236.56596636772156 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 236.61037254333496 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 236.65125632286072 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 236.68988966941833 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 236.7292115688324 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 236.76844668388367 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 236.8174180984497 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 236.8618724346161 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 236.90198612213135 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 236.94125032424927 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 236.98637104034424 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 237.03551626205444 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 237.07812976837158 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 237.13319063186646 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 237.17320322990417 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 237.218505859375 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 237.25950264930725 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 237.30779647827148 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 237.34869766235352 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 237.38829278945923 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 237.43667149543762 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 237.47596168518066 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 237.51525115966797 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 237.5543053150177 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 237.59381580352783 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 237.6478476524353 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 237.6889293193817 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 237.72812247276306 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 237.76767563819885 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 237.80814957618713 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 237.8485608100891 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 237.90061736106873 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 237.94536113739014 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 237.98571395874023 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 238.0252501964569 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 238.0802342891693 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 238.11954641342163 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 238.1579566001892 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 238.19831228256226 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 238.26030731201172 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 238.30979466438293 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 238.35722517967224 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 238.39742231369019 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 238.43875980377197 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 238.47802805900574 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 238.52405714988708 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 238.5635142326355 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 238.6025414466858 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 238.6441388130188 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 238.68312764167786 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 238.72225999832153 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 238.76790928840637 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 238.80773401260376 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 238.84780263900757 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 238.8870666027069 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 238.92633175849915 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 238.96543216705322 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 239.01246047019958 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 239.05205965042114 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 239.0992567539215 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 239.13849592208862 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 239.19729161262512 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 239.25350999832153 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 239.29400038719177 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 239.33318066596985 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 239.3725242614746 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 239.4128019809723 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 239.45357966423035 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 239.50232362747192 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 239.54133987426758 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 239.5800120830536 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 239.62609457969666 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 239.66533637046814 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 239.7055881023407 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 239.75215601921082 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 239.7908034324646 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 239.82973074913025 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 239.868243932724 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 239.9070475101471 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 239.95212507247925 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 239.9914140701294 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 240.0315818786621 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 240.07489728927612 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 240.1299650669098 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 240.1716296672821 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 240.21212363243103 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 240.25094366073608 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 240.2907555103302 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 240.33371829986572 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 240.3798348903656 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 240.41924357414246 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 240.46033573150635 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 240.49951076507568 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 240.53853058815002 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 240.58508110046387 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 240.62659764289856 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 240.66557693481445 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 240.70414280891418 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 240.7510006427765 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 240.79475140571594 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 240.83586931228638 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 240.87496066093445 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 240.91460037231445 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 240.95491528511047 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 241.01562023162842 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 241.05963611602783 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 241.0991177558899 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 241.1470444202423 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 241.18800282478333 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 241.23485040664673 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 241.27703332901 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 241.31609177589417 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 241.35550260543823 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 241.39452075958252 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 241.4360921382904 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 241.4875180721283 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 241.52749872207642 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 241.56594705581665 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 241.6060347557068 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 241.6549472808838 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 241.69466519355774 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 241.7338945865631 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 241.77393651008606 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 241.81898164749146 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 241.8627734184265 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 241.90517807006836 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 241.94416284561157 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 241.98311281204224 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 242.02187085151672 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 242.06177735328674 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 242.1096591949463 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 242.16445970535278 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 242.20592737197876 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 242.24481058120728 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 242.28499913215637 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 242.34208369255066 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 242.38747000694275 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 242.42990159988403 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 242.47176265716553 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 242.51081109046936 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 242.55482172966003 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 242.5986454486847 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 242.64008831977844 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 242.67907905578613 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 242.718186378479 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 242.7769260406494 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 242.8388271331787 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 242.89580249786377 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 242.95555782318115 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 243.02276253700256 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 243.0835416316986 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 243.14855885505676 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 243.2107310295105 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 243.27080702781677 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 243.3311836719513 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 243.39205741882324 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 243.45077395439148 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 243.527259349823 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 243.5863528251648 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 243.6459128856659 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 243.70403575897217 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 243.7732572555542 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 243.83251333236694 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 243.89036083221436 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 243.94970750808716 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 244.013587474823 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 244.0725338459015 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 244.13074159622192 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 244.19000267982483 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 244.26188230514526 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 244.3198525905609 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 244.37903714179993 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 244.43665885925293 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 244.5089395046234 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 244.56775736808777 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 244.62727808952332 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 244.6855161190033 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 244.74974131584167 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 244.81268405914307 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 244.87370777130127 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 244.9330096244812 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 245.00254654884338 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 245.06155681610107 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 245.12042474746704 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 245.18072485923767 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 245.24823808670044 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 245.3169572353363 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 245.3805992603302 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 245.44610357284546 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 245.51752638816833 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 245.56524968147278 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 245.6042652130127 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 245.64576888084412 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 245.6920464038849 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 245.73154878616333 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 245.7707004547119 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 245.80959296226501 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 245.8537175655365 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 245.89371418952942 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 245.94761085510254 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 245.98775124549866 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 246.0269558429718 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 246.06627440452576 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 246.11652970314026 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 246.1565670967102 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 246.19697284698486 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 246.23741936683655 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 246.2775113582611 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 246.33361792564392 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 246.37799620628357 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 246.41641807556152 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 246.45434975624084 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 246.4947385787964 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 246.53344678878784 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 246.57982110977173 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 246.61913084983826 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 246.660338640213 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 246.6990683078766 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 246.73827743530273 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 246.78829050064087 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 246.82972407341003 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 246.86889553070068 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 246.90700459480286 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 246.94605112075806 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 246.99270343780518 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 247.03331685066223 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 247.0726773738861 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 247.11185455322266 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 247.1511173248291 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 247.20105481147766 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 247.24311995506287 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 247.2848517894745 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 247.33271384239197 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 247.37265253067017 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 247.41778016090393 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 247.45727729797363 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 247.50330257415771 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 247.54280257225037 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 247.58217597007751 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 247.6231451034546 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 247.67031049728394 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 247.7092523574829 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 247.7477731704712 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 247.78698062896729 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 247.82587480545044 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 247.87385439872742 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 247.9172899723053 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 247.9564197063446 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 247.9960057735443 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 248.03713464736938 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 248.0814356803894 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 248.12614560127258 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 248.16648387908936 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 248.21042156219482 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 248.25082635879517 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 248.3079490661621 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 248.35617232322693 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 248.3956482410431 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 248.43408370018005 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 248.4737672805786 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 248.52185916900635 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 248.5638723373413 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 248.60809969902039 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 248.65046072006226 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 248.68955039978027 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 248.73187232017517 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 248.78089714050293 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 248.82891511917114 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 248.86811542510986 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 248.9075837135315 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 248.9529345035553 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 249.00078082084656 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 249.04712080955505 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 249.08745908737183 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 249.1419231891632 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 249.1900291442871 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 249.2313871383667 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 249.27531671524048 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 249.3225953578949 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 249.37213468551636 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 249.41842317581177 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 249.45730638504028 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 249.49561262130737 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 249.5356888771057 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 249.57478976249695 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 249.613694190979 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 249.66161608695984 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 249.70034670829773 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 249.74184799194336 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 249.7813925743103 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 249.8195869922638 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 249.8589563369751 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 249.90658807754517 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 249.94554781913757 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 249.98450994491577 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 250.0226891040802 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 250.06511425971985 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 250.10502576828003 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 250.1551570892334 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 250.1991696357727 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 250.23901081085205 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 250.2815511226654 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 250.32356452941895 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 250.37714219093323 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 250.4196331501007 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 250.45918130874634 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 250.4979100227356 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 250.5390408039093 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 250.57808423042297 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 250.63052988052368 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 250.66917848587036 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 250.70833563804626 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 250.75295305252075 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 250.79942059516907 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 250.8396279811859 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 250.87909245491028 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 250.91852116584778 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 250.95806193351746 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 250.99723315238953 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 251.04369521141052 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 251.08408570289612 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 251.13016986846924 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 251.17511105537415 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 251.2179479598999 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 251.2640359401703 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 251.3039882183075 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 251.34343576431274 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 251.3824484348297 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 251.43113732337952 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 251.47729873657227 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 251.52334141731262 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 251.5666332244873 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 251.60599946975708 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 251.64762473106384 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 251.6919810771942 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 251.73138451576233 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 251.77086877822876 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 251.80962109565735 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 251.84831285476685 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 251.8876497745514 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 251.93711829185486 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 251.97710800170898 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 252.01681351661682 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 252.05744743347168 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 252.1029462814331 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 252.1467740535736 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 252.18722248077393 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 252.22698163986206 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 252.26824927330017 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 252.30741906166077 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 252.34605193138123 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 252.3965244293213 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 252.445729970932 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 252.49119663238525 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 252.53343558311462 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 252.58027482032776 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 252.62031054496765 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 252.66104912757874 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 252.70105600357056 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 252.7409930229187 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 252.78864455223083 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 252.8316957950592 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 252.87128615379333 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 252.91089153289795 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 252.95081758499146 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 252.99043560028076 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 253.03683233261108 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 253.08116102218628 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 253.12311434745789 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 253.16703009605408 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 253.2135157585144 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 253.25393795967102 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 253.2946801185608 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 253.33482456207275 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 253.37746024131775 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 253.41832399368286 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 253.47291731834412 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 253.5119767189026 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 253.55303263664246 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 253.59291005134583 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 253.63911175727844 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 253.67911887168884 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 253.71749544143677 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 253.75707697868347 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 253.79599595069885 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 253.83501982688904 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 253.8828730583191 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 253.92731070518494 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 253.9669370651245 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 254.00784301757812 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 254.0491921901703 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 254.09968614578247 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 254.1505253314972 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 254.20790696144104 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 254.24785113334656 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 254.28898096084595 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 254.33635067939758 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 254.38116717338562 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 254.4217917919159 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 254.46964263916016 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 254.5096790790558 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 254.5577051639557 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 254.59742331504822 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 254.6392331123352 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 254.68001294136047 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 254.73544573783875 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 254.7887053489685 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 254.8473925590515 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 254.88924193382263 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 254.93826365470886 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 254.98028922080994 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 255.03524732589722 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 255.0764241218567 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 255.11958241462708 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 255.15887212753296 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 255.19769096374512 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 255.2389256954193 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 255.28380370140076 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 255.33103227615356 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 255.3725221157074 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 255.41146397590637 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 255.46189856529236 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 255.53715324401855 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 255.61178374290466 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 255.68890810012817 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 255.74891090393066 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 255.81041383743286 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 255.86869764328003 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 255.93051481246948 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 255.98958563804626 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 256.05062556266785 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 256.1079339981079 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 256.17192459106445 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 256.2331004142761 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 256.2937617301941 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 256.35485005378723 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 256.41819858551025 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 256.47656893730164 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 256.546302318573 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 256.6137845516205 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 256.6843774318695 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 256.7439064979553 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 256.80296754837036 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 256.8613977432251 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 256.9271719455719 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 256.9864478111267 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 257.0471978187561 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 257.1172933578491 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 257.1840205192566 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 257.24671840667725 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 257.3068368434906 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 257.3647782802582 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 257.42747688293457 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 257.4853663444519 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 257.54798698425293 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 257.616290807724 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 257.68294191360474 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 257.74411273002625 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 257.8062617778778 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 257.8662497997284 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 257.92944049835205 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 257.98995876312256 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 258.0556597709656 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 258.1206855773926 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 258.18914341926575 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 258.2434186935425 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 258.2838497161865 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 258.32453203201294 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 258.3643317222595 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 258.4159028530121 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 258.4567070007324 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 258.4995365142822 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 258.54045367240906 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 258.5796802043915 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 258.619713306427 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 258.6742548942566 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 258.7131576538086 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 258.7524070739746 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 258.79177713394165 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 258.8408236503601 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 258.88344168663025 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 258.92335772514343 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 258.9628975391388 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 259.0025591850281 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 259.0419042110443 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 259.0880877971649 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 259.1407570838928 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 259.18775486946106 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 259.2286026477814 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 259.2859661579132 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 259.33656573295593 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 259.37578678131104 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 259.4152066707611 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 259.4538905620575 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 259.4972143173218 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 259.5383427143097 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 259.57924032211304 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 259.6195526123047 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 259.67480993270874 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 259.7218964099884 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 259.7620093822479 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 259.80186700820923 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 259.8412024974823 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 259.88138222694397 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 259.92575216293335 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 259.9729588031769 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 260.01310324668884 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 260.05264711380005 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 260.09139800071716 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 260.1320164203644 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 260.1790699958801 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 260.2222502231598 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 260.2665228843689 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 260.32759976387024 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 260.38851976394653 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 260.4279682636261 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 260.46626925468445 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 260.50630736351013 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 260.5471911430359 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 260.5862262248993 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 260.6343688964844 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 260.67440700531006 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 260.7200367450714 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 260.7596650123596 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 260.799928188324 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 260.8429055213928 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 260.88615894317627 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 260.92717146873474 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 260.9662754535675 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 261.00691533088684 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 261.04650020599365 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 261.0924105644226 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 261.13132095336914 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 261.1721742153168 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 261.2109422683716 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 261.2511029243469 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 261.2994508743286 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 261.33987045288086 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 261.3900487422943 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 261.42896270751953 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 261.47600293159485 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 261.5384747982025 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 261.58042335510254 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 261.6192903518677 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 261.6601777076721 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 261.7026607990265 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 261.75062251091003 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 261.7961769104004 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 261.835333108902 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 261.8746964931488 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 261.9183270931244 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 261.9638161659241 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 262.00525426864624 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 262.0461609363556 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 262.08674454689026 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 262.12634086608887 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 262.16667103767395 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 262.21205496788025 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 262.25908970832825 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 262.30064821243286 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 262.3407232761383 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 262.38492345809937 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 262.42383074760437 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 262.46229338645935 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 262.5005693435669 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 262.5391824245453 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 262.5804946422577 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 262.63509798049927 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 262.6749517917633 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 262.7143659591675 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 262.7597327232361 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 262.7983946800232 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 262.8384861946106 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 262.8816637992859 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 262.92534613609314 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 262.9652576446533 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 263.0044512748718 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 263.04373836517334 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 263.0926969051361 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 263.1320083141327 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 263.1710877418518 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 263.21267557144165 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 263.25477600097656 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 263.2943866252899 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 263.33913826942444 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 263.3775706291199 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 263.4156849384308 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 263.45415711402893 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 263.49755239486694 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 263.544456243515 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 263.58441376686096 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 263.62300753593445 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 263.6617090702057 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 263.7000222206116 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 263.74221873283386 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 263.7911536693573 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 263.8353455066681 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 263.87466764450073 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 263.9133770465851 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 263.9529609680176 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 263.99266958236694 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 264.0397152900696 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 264.0911796092987 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 264.1398129463196 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 264.178165435791 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 264.2291512489319 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 264.2721354961395 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 264.3268024921417 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 264.36670207977295 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 264.40867924690247 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 264.4579484462738 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 264.4976899623871 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 264.5536952018738 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 264.59558725357056 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 264.63899993896484 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 264.6899106502533 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 264.7294764518738 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 264.7695391178131 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 264.81435990333557 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 264.85759711265564 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 264.90072298049927 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 264.9410147666931 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 264.98025393486023 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 265.0231111049652 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 265.0632269382477 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 265.10229325294495 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 265.1554071903229 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 265.194344997406 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 265.2360556125641 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 265.2774107456207 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 265.3260838985443 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 265.36816024780273 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 265.4078469276428 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 265.44707465171814 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 265.4895646572113 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 265.53132009506226 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 265.57786083221436 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 265.6174087524414 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 265.6647319793701 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 265.70395016670227 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 265.7511727809906 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 265.79412937164307 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 265.8392472267151 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 265.87852478027344 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 265.91849088668823 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 265.96376395225525 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 266.007000207901 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 266.04992842674255 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 266.0953149795532 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 266.1378996372223 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 266.183545589447 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 266.22943806648254 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 266.2725160121918 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 266.3130326271057 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 266.352392911911 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 266.4101731777191 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 266.4497811794281 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 266.48874616622925 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 266.5275354385376 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 266.56589102745056 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 266.60715103149414 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 266.65633893013 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 266.6956310272217 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 266.73497247695923 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 266.78195333480835 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 266.8309018611908 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 266.8783781528473 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 266.91870045661926 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 266.9584610462189 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 266.99855160713196 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 267.040167093277 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 267.0803167819977 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 267.1342148780823 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 267.17364716529846 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 267.2133688926697 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 267.2552788257599 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 267.3025851249695 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 267.3426938056946 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 267.3816227912903 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 267.42243814468384 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 267.46333742141724 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 267.51020526885986 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 267.5540249347687 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 267.5947425365448 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 267.63681197166443 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 267.6749141216278 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 267.717316865921 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 267.7606403827667 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 267.79889035224915 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 267.84387278556824 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 267.88377690315247 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 267.9261317253113 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 267.9684519767761 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 268.0112826824188 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 268.05028438568115 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 268.09028720855713 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 268.1310679912567 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 268.17463541030884 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 268.21306252479553 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 268.2760753631592 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 268.34341526031494 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 268.4134991168976 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 268.47608947753906 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 268.535603761673 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 268.5981810092926 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 268.66115641593933 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 268.7209942340851 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 268.7792274951935 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 268.83997678756714 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 268.9048397541046 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 268.96354579925537 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 269.02113604545593 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 269.0926570892334 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 269.1514699459076 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 269.2090458869934 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 269.27250504493713 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 269.34915566444397 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 269.40730905532837 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 269.46692538261414 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 269.53303813934326 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 269.5994620323181 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 269.6596269607544 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 269.7173171043396 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 269.7746593952179 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 269.8424115180969 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 269.9022469520569 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 269.9630103111267 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 270.0220432281494 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 270.1014497280121 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 270.1770977973938 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 270.2362906932831 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 270.319393157959 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 270.3835074901581 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 270.44420194625854 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 270.5060091018677 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 270.5681748390198 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 270.6351857185364 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 270.6968402862549 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 270.75538539886475 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 270.8222506046295 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 270.88669419288635 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 270.953467130661 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 271.02252554893494 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 271.069899559021 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 271.1106655597687 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 271.1487991809845 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 271.18758726119995 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 271.2290256023407 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 271.27727603912354 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 271.3185305595398 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 271.3661046028137 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 271.4057774543762 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 271.45073533058167 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 271.4913809299469 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 271.5304877758026 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 271.57387614250183 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 271.61392402648926 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 271.6609470844269 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 271.70154643058777 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 271.73979926109314 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 271.77914547920227 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 271.81847739219666 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 271.85712218284607 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 271.90353894233704 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 271.9434630870819 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 271.98212695121765 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 272.0326466560364 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 272.0719485282898 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 272.11971974372864 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 272.15936970710754 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 272.19780015945435 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 272.2394962310791 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 272.2956566810608 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 272.34500312805176 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 272.3856990337372 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 272.42472076416016 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 272.46346044540405 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 272.5014476776123 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 272.54023456573486 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 272.5868890285492 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 272.6298270225525 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 272.6682856082916 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 272.7123050689697 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 272.75213050842285 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 272.794061422348 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 272.83643531799316 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 272.8747727870941 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 272.91365003585815 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 272.95245456695557 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 272.99670124053955 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 273.0527319908142 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 273.09260988235474 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 273.13431191444397 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 273.1744432449341 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 273.21866154670715 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 273.26857924461365 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 273.3104302883148 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 273.3498902320862 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 273.38877534866333 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 273.427964925766 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 273.46762228012085 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 273.5224540233612 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 273.56669306755066 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 273.60690474510193 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 273.6497929096222 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 273.6948399543762 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 273.7351658344269 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 273.7746994495392 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 273.8197138309479 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 273.86042618751526 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 273.90343475341797 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 273.94593381881714 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 273.98514199256897 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 274.035640001297 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 274.080534696579 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 274.1319189071655 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 274.1706438064575 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 274.20900201797485 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 274.24948620796204 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 274.28845262527466 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 274.32767844200134 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 274.38588309288025 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 274.42553758621216 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 274.46565198898315 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 274.5054843425751 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 274.5448098182678 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 274.5854434967041 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 274.6365616321564 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 274.67645263671875 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 274.71594524383545 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 274.75561594963074 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 274.7974286079407 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 274.84206771850586 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 274.8814570903778 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 274.92078852653503 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 274.9610023498535 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 274.99968814849854 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 275.0547580718994 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 275.0971746444702 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 275.1424958705902 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 275.1870267391205 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 275.23992705345154 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 275.2830216884613 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 275.32279682159424 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 275.36231803894043 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 275.40162801742554 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 275.4419491291046 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 275.4932334423065 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 275.53321290016174 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 275.574116230011 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 275.6315643787384 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 275.68414068222046 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 275.72334027290344 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 275.7629804611206 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 275.80291199684143 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 275.8513512611389 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 275.8956210613251 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 275.93609142303467 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 275.97611784935 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 276.02310061454773 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 276.0629005432129 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 276.11929535865784 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 276.16152715682983 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 276.20179438591003 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 276.2569954395294 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 276.2976689338684 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 276.3452498912811 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 276.3899757862091 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 276.4300148487091 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 276.469970703125 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 276.5103943347931 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 276.5641655921936 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 276.61643171310425 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 276.6614336967468 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 276.7008545398712 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 276.74523425102234 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 276.7927315235138 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 276.8327293395996 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 276.87283301353455 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 276.91253423690796 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 276.9520251750946 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 276.9913680553436 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 277.0384192466736 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 277.0785539150238 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 277.1270124912262 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 277.1661534309387 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 277.2053327560425 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 277.250853061676 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 277.2940332889557 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 277.3338990211487 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 277.3744122982025 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 277.414941072464 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 277.45986700057983 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 277.5060980319977 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 277.5450129508972 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 277.5841553211212 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 277.62498021125793 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 277.6691737174988 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 277.7143406867981 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 277.753466129303 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 277.79220747947693 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 277.831618309021 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 277.88138699531555 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 277.92500925064087 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 277.9653217792511 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 278.00463223457336 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 278.0451035499573 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 278.0894720554352 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 278.13989996910095 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 278.1795644760132 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 278.2242040634155 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 278.2688133716583 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 278.3158612251282 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 278.35583305358887 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 278.3951196670532 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 278.43360567092896 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 278.47332406044006 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 278.5117530822754 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 278.5578382015228 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 278.6015751361847 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 278.64509320259094 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 278.68463587760925 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 278.7232394218445 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 278.76616287231445 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 278.80986857414246 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 278.849977016449 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 278.889324426651 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 278.9337041378021 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 278.97783756256104 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 279.0208170413971 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 279.0598073005676 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 279.0983326435089 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 279.1466646194458 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 279.1968104839325 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 279.2375500202179 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 279.27833890914917 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 279.3226845264435 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 279.361843585968 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 279.4021954536438 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 279.44435477256775 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 279.48315143585205 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 279.5211429595947 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 279.5595872402191 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 279.5982451438904 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 279.65099453926086 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 279.6901590824127 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 279.7285180091858 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 279.76754212379456 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 279.8064670562744 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 279.8452847003937 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 279.8914017677307 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 279.9472510814667 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 279.9880402088165 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 280.0298366546631 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 280.0707528591156 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 280.11699295043945 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 280.1698706150055 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 280.20907855033875 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 280.24915528297424 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 280.2901611328125 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 280.3378596305847 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 280.37868785858154 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 280.41941595077515 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 280.45843029022217 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 280.4971032142639 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 280.53670954704285 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 280.5866470336914 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 280.62917947769165 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 280.6712734699249 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 280.710657119751 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 280.76606273651123 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 280.8155059814453 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 280.8562617301941 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 280.89545130729675 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 280.94295477867126 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 280.98276829719543 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 281.0440044403076 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 281.11285305023193 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 281.178031206131 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 281.252920627594 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 281.3229296207428 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 281.38171339035034 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 281.4424829483032 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 281.5154118537903 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 281.57452487945557 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 281.63644766807556 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 281.6984894275665 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 281.781124830246 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 281.847128868103 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 281.90532994270325 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 281.9630434513092 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 282.02992606163025 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 282.0888202190399 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 282.15041947364807 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 282.2236759662628 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 282.2915270328522 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 282.35074400901794 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 282.4082713127136 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 282.4666862487793 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 282.52986693382263 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 282.5879907608032 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 282.649395942688 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 282.7095410823822 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 282.77374029159546 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 282.8326413631439 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 282.89114475250244 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 282.9490511417389 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 283.01265048980713 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 283.0727882385254 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 283.1344952583313 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 283.19184398651123 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 283.2643597126007 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 283.32649540901184 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 283.3867573738098 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 283.44987630844116 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 283.51476860046387 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 283.57891297340393 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 283.6464855670929 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 283.71260595321655 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 283.7686457633972 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 283.80715465545654 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 283.84600830078125 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 283.88965034484863 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 283.94190645217896 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 283.98565220832825 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 284.02585792541504 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 284.0804350376129 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 284.1223497390747 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 284.1690580844879 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 284.20847940444946 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 284.2468008995056 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 284.29823064804077 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 284.33901834487915 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 284.383917093277 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 284.42292165756226 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 284.4612822532654 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 284.5002558231354 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 284.53834557533264 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 284.5772144794464 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 284.62583923339844 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 284.6702330112457 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 284.7123062610626 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 284.7513635158539 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 284.790433883667 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 284.8346149921417 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 284.877322435379 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 284.91574573516846 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 284.95502972602844 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 284.9992399215698 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 285.0470790863037 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 285.09022283554077 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 285.13135600090027 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 285.17387533187866 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 285.21528363227844 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 285.2602400779724 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 285.30768156051636 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 285.3508427143097 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 285.3905498981476 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 285.4390571117401 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 285.48637771606445 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 285.5261194705963 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 285.56702947616577 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 285.6062560081482 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 285.64794397354126 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 285.68762278556824 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 285.7351746559143 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 285.77490043640137 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 285.8143253326416 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 285.8579652309418 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 285.897842168808 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 285.94502997398376 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 285.98464703559875 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 286.02404618263245 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 286.06773257255554 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 286.1122040748596 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 286.1570177078247 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 286.1961314678192 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 286.23602056503296 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 286.2777807712555 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 286.31904006004333 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 286.3756146430969 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 286.421044588089 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 286.462557554245 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 286.50208044052124 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 286.5488193035126 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 286.58861804008484 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 286.6312415599823 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 286.67090487480164 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 286.71263456344604 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 286.75269985198975 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 286.7983150482178 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 286.8376111984253 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 286.8773424625397 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 286.9166338443756 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 286.9579243659973 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 287.00637912750244 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 287.0451190471649 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 287.08421325683594 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 287.1235616207123 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 287.1622884273529 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 287.20305275917053 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 287.25355291366577 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 287.2971589565277 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 287.336886882782 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 287.3844735622406 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 287.42328095436096 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 287.46876883506775 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 287.5085744857788 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 287.5516240596771 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 287.5913450717926 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 287.6320171356201 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 287.67206263542175 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 287.7177517414093 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 287.7561786174774 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 287.7941780090332 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 287.8324234485626 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 287.8765273094177 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 287.92475056648254 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 287.9640862941742 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 288.00377893447876 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 288.04174852371216 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 288.082097530365 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 288.12237000465393 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 288.16913294792175 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 288.21102380752563 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 288.2524423599243 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 288.2990036010742 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 288.3384222984314 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 288.4024477005005 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 288.4580497741699 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 288.5127148628235 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 288.5661096572876 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 288.6084814071655 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 288.65444707870483 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 288.694375038147 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 288.73580265045166 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 288.7752923965454 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 288.81502056121826 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 288.86770939826965 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 288.9096488952637 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 288.9493741989136 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 288.9937641620636 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 289.0400321483612 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 289.0805275440216 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 289.12052941322327 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 289.15919852256775 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 289.1981258392334 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 289.23820757865906 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 289.2890796661377 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 289.32836174964905 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 289.36853432655334 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 289.42053151130676 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 289.4603576660156 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 289.5071454048157 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 289.54645586013794 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 289.58532094955444 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 289.62784361839294 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 289.6673719882965 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 289.7063617706299 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 289.75984954833984 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 289.79998540878296 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 289.83917331695557 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 289.87833619117737 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 289.9169445037842 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 289.9645085334778 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 290.0043976306915 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 290.0432345867157 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 290.0819499492645 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 290.1208770275116 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 290.1689999103546 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 290.20963644981384 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 290.24793553352356 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 290.29115319252014 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 290.33521699905396 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 290.3967888355255 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 290.4443199634552 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 290.48806047439575 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 290.53109216690063 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 290.5698518753052 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 290.61604261398315 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 290.657589673996 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 290.6968762874603 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 290.738077878952 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 290.77736043930054 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 290.81634426116943 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 290.86230659484863 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 290.9010202884674 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 290.9393689632416 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 290.9775655269623 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 291.01615595817566 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 291.0685143470764 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 291.10894107818604 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 291.14822912216187 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 291.1965870857239 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 291.23676109313965 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 291.2824110984802 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 291.32247376441956 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 291.3697667121887 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 291.4197916984558 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 291.4766778945923 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 291.52450609207153 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 291.56418347358704 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 291.6038784980774 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 291.64578223228455 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 291.6852626800537 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 291.7276122570038 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 291.77482557296753 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 291.81454586982727 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 291.8542935848236 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 291.893851518631 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 291.9330265522003 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 291.9853255748749 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 292.0240421295166 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 292.0635130405426 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 292.1035418510437 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 292.14554738998413 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 292.19401478767395 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 292.23429250717163 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 292.2757217884064 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 292.31622433662415 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 292.3585743904114 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 292.4050395488739 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 292.4462559223175 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 292.49435591697693 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 292.53338503837585 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 292.57994389533997 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 292.6294412612915 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 292.6693911552429 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 292.7099606990814 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 292.75183939933777 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 292.79864835739136 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 292.8403968811035 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 292.88021326065063 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 292.91954278945923 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 292.9594633579254 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 292.99916911125183 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 293.04605770111084 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 293.08642768859863 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 293.126660823822 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 293.1689398288727 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 293.21575450897217 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 293.25918650627136 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 293.30262446403503 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 293.345596075058 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 293.3848068714142 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 293.4315631389618 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 293.4715094566345 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 293.5193295478821 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 293.5588855743408 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 293.60315585136414 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 293.6524577140808 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 293.69182682037354 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 293.73001408576965 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 293.7821898460388 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 293.84287214279175 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 293.90174412727356 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 293.96079564094543 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 294.02154302597046 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 294.0811266899109 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 294.14517998695374 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 294.20853996276855 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 294.28367280960083 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 294.34203910827637 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 294.40232157707214 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 294.46066188812256 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 294.5250668525696 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 294.59229707717896 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 294.6547532081604 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 294.7134919166565 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 294.77465200424194 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 294.83278465270996 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 294.8918991088867 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 294.94984197616577 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 295.01105785369873 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 295.0708501338959 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 295.1316270828247 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 295.19293904304504 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 295.25890469551086 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 295.3182735443115 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 295.3827440738678 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 295.44654870033264 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 295.50934195518494 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 295.5671660900116 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 295.63731813430786 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 295.6975293159485 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 295.7574405670166 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 295.8181984424591 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 295.8864483833313 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 295.94706773757935 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 296.0067038536072 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 296.07426023483276 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 296.14739775657654 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 296.20865082740784 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 296.2679533958435 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 296.34166622161865 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 296.4133574962616 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 296.47717118263245 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 296.5296788215637 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 296.5685007572174 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 296.608035326004 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 296.6660006046295 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 296.70684242248535 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 296.7476053237915 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 296.7892150878906 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 296.82878255844116 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 296.86919689178467 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 296.9155538082123 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 296.95489740371704 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 296.99415135383606 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 297.0381202697754 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 297.0825436115265 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 297.124849319458 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 297.1641125679016 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 297.20528388023376 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 297.2463004589081 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 297.29223895072937 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 297.3365616798401 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 297.37527418136597 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 297.4192113876343 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 297.45921754837036 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 297.50295877456665 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 297.5435354709625 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 297.58254313468933 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 297.6226558685303 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 297.67211413383484 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 297.7168915271759 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 297.7580645084381 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 297.7990515232086 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 297.83862352371216 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 297.877774477005 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 297.9168839454651 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 297.9674611091614 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 298.00595784187317 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 298.048401594162 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 298.08833622932434 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 298.1279966831207 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 298.1756703853607 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 298.21591782569885 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 298.2573175430298 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 298.3075840473175 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 298.349552154541 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 298.39558386802673 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 298.4383957386017 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 298.4794921875 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 298.5184121131897 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 298.55800795555115 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 298.59753370285034 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 298.6517496109009 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 298.6997730731964 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 298.7389039993286 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 298.7795853614807 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 298.82662892341614 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 298.86576437950134 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 298.90505814552307 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 298.9446578025818 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 298.98375034332275 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 299.0230121612549 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 299.0717740058899 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 299.1175870895386 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 299.15765357017517 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 299.1970725059509 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 299.2365720272064 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 299.28011679649353 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 299.3252589702606 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 299.36694264411926 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 299.4084541797638 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 299.4478554725647 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 299.4903664588928 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 299.53161787986755 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 299.5751852989197 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 299.61479687690735 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 299.6716549396515 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 299.731653213501 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 299.77215576171875 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 299.81046891212463 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 299.8501124382019 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 299.88878774642944 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 299.92835545539856 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 299.9745845794678 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 300.01418137550354 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 300.05302000045776 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 300.0921618938446 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 300.1310067176819 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 300.17018938064575 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 300.21867775917053 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 300.2647969722748 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 300.3047389984131 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 300.3432631492615 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 300.3818037509918 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 300.4411315917969 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 300.481698513031 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 300.52096033096313 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 300.5710778236389 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 300.6204173564911 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 300.66904377937317 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 300.7085053920746 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 300.7566394805908 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 300.797899723053 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 300.84106850624084 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 300.9016537666321 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 300.94145011901855 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 300.9872624874115 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 301.02738308906555 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 301.06618070602417 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 301.1080951690674 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 301.1509234905243 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 301.1907408237457 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 301.23015689849854 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 301.27087807655334 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 301.31196689605713 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 301.3662040233612 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 301.40683007240295 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 301.46541595458984 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 301.5223648548126 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 301.57380270957947 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 301.6135103702545 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 301.66329860687256 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 301.70346188545227 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 301.7492182254791 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 301.79925632476807 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 301.83831667900085 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 301.87788105010986 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 301.9187054634094 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 301.96460223197937 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 302.0050799846649 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 302.0448143482208 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 302.0845277309418 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 302.12790274620056 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 302.1674237251282 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 302.215528011322 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 302.2553870677948 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 302.2952058315277 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 302.33726382255554 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 302.38298296928406 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 302.4237971305847 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 302.4633946418762 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 302.5030734539032 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 302.543251991272 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 302.5832142829895 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 302.63742327690125 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 302.678275346756 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 302.71695613861084 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 302.7643792629242 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 302.81455397605896 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 302.8589391708374 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 302.898229598999 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 302.9454433917999 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 302.9843068122864 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 303.0243630409241 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 303.06804180145264 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 303.11496138572693 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 303.1553964614868 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 303.21062707901 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 303.25546622276306 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 303.3087809085846 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 303.3492546081543 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 303.3881003856659 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 303.43391156196594 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 303.47402811050415 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 303.5191013813019 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 303.56295108795166 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 303.6028287410736 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 303.6450183391571 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 303.68469405174255 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 303.7249958515167 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 303.7702941894531 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 303.8262712955475 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 303.8669970035553 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 303.9064338207245 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 303.9547231197357 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 303.99468302726746 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 304.03345370292664 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 304.0724594593048 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 304.1118366718292 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 304.1510446071625 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 304.19825196266174 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 304.23810720443726 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 304.2795548439026 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 304.3279287815094 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 304.3827486038208 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 304.4346354007721 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 304.47783613204956 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 304.51717591285706 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 304.5660123825073 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 304.60523414611816 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 304.6549141407013 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 304.7026207447052 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 304.7468764781952 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 304.78707003593445 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 304.8371558189392 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 304.8871750831604 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 304.9278244972229 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 304.96816205978394 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 305.0076563358307 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 305.048552274704 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 305.1125240325928 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 305.1517872810364 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 305.1906225681305 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 305.2296543121338 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 305.27608370780945 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 305.3231272697449 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 305.3656520843506 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 305.4061427116394 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 305.44525957107544 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 305.48449325561523 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 305.5233898162842 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 305.57072281837463 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 305.61334347724915 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 305.6556017398834 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 305.6950612068176 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 305.73507738113403 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 305.7796881198883 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 305.8201665878296 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 305.8681654930115 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 305.90690994262695 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 305.9513008594513 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 305.9929323196411 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 306.0337612628937 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 306.07537746429443 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 306.1158254146576 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 306.1560335159302 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 306.2002868652344 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 306.24052715301514 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 306.28240752220154 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 306.324342250824 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 306.3697123527527 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 306.41077065467834 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 306.44960498809814 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 306.4890146255493 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 306.5392711162567 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 306.6036944389343 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 306.66181659698486 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 306.7189302444458 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 306.77937150001526 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 306.85096979141235 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 306.92728424072266 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 306.98676013946533 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 307.04613876342773 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 307.1137034893036 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 307.17795515060425 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 307.23798847198486 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 307.2970654964447 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 307.3701503276825 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 307.4284703731537 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 307.48740458488464 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 307.5451674461365 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 307.61718130111694 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 307.68867540359497 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 307.75744223594666 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 307.8293650150299 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 307.88957595825195 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 307.9561402797699 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 308.0153160095215 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 308.0796539783478 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 308.1382989883423 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 308.1957769393921 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 308.2547583580017 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 308.3287441730499 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 308.3920633792877 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 308.45089983940125 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 308.5089976787567 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 308.57520174980164 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 308.6433901786804 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 308.7026822566986 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 308.76339507102966 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 308.83976221084595 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 308.9009392261505 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 308.95980978012085 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 309.0574095249176 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 309.1235909461975 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 309.19854974746704 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 309.25679302215576 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 309.31102085113525 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 309.35156774520874 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 309.3917338848114 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 309.4313008785248 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 309.4771420955658 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 309.5168571472168 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 309.5559632778168 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 309.59505701065063 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 309.63623571395874 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 309.6750395298004 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 309.7261300086975 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 309.76668310165405 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 309.8057076931 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 309.8466956615448 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 309.8862295150757 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 309.92541885375977 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 309.9736988544464 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 310.02120304107666 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 310.0671455860138 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 310.10761761665344 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 310.15571904182434 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 310.19803380966187 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 310.23797726631165 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 310.2807734012604 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 310.3229308128357 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 310.37019634246826 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 310.410950422287 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 310.4509072303772 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 310.49088859558105 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 310.5305371284485 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 310.5700376033783 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 310.6228322982788 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 310.6638660430908 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 310.70283007621765 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 310.7425048351288 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 310.78486227989197 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 310.82939743995667 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 310.8714551925659 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 310.9104890823364 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 310.9500744342804 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 310.9937262535095 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 311.04316902160645 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 311.08498644828796 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 311.12695693969727 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 311.1660692691803 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 311.21368432044983 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 311.25537943840027 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 311.29446172714233 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 311.33498072624207 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 311.37551856040955 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 311.41578340530396 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 311.46141052246094 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 311.50108337402344 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 311.5402693748474 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 311.57974457740784 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 311.6195080280304 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 311.6609756946564 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 311.72563672065735 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 311.7700216770172 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 311.8089396953583 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 311.8498787879944 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 311.89720034599304 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 311.93635153770447 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 311.9755027294159 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 312.0145320892334 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 312.0650010108948 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 312.1146342754364 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 312.16177320480347 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 312.20193791389465 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 312.24317622184753 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 312.2873513698578 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 312.33584928512573 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 312.37547492980957 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 312.4146292209625 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 312.45397782325745 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 312.49269914627075 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 312.53109860420227 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 312.58018016815186 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 312.6257164478302 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 312.6658456325531 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 312.7050971984863 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 312.7445147037506 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 312.7835907936096 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 312.8287630081177 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 312.8709628582001 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 312.9099335670471 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 312.9499628543854 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 312.9887878894806 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 313.0435724258423 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 313.09273195266724 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 313.13278675079346 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 313.18298053741455 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 313.2240810394287 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 313.2716791629791 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 313.311918258667 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 313.35185384750366 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 313.3911623954773 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 313.4346625804901 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 313.4778549671173 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 313.521235704422 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 313.56868410110474 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 313.6090180873871 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 313.65162897109985 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 313.69858050346375 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 313.73792695999146 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 313.7776277065277 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 313.81637167930603 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 313.8582043647766 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 313.89684414863586 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 313.94583344459534 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 313.98631024360657 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 314.03710746765137 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 314.07829761505127 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 314.1263499259949 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 314.1726622581482 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 314.2117872238159 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 314.2507154941559 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 314.29111075401306 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 314.3334164619446 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 314.3808536529541 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 314.424843788147 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 314.4644548892975 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 314.50308871269226 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 314.5421919822693 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 314.5809941291809 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 314.6286208629608 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 314.66813349723816 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 314.7072274684906 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 314.74636793136597 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 314.78606247901917 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 314.83593249320984 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 314.8784658908844 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 314.92226815223694 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 314.96210289001465 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 315.00296235084534 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 315.04801964759827 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 315.0888149738312 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 315.13783407211304 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 315.17843413352966 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 315.21774435043335 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 315.2676808834076 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 315.30889534950256 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 315.3517150878906 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 315.3971540927887 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 315.4370913505554 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 315.4892704486847 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 315.5288586616516 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 315.5685362815857 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 315.6077015399933 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 315.6488661766052 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 315.69407391548157 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 315.73827147483826 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 315.7778334617615 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 315.81716132164 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 315.85642075538635 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 315.8995773792267 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 315.9427490234375 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 315.98245906829834 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 316.0205979347229 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 316.0661005973816 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 316.13343834877014 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 316.18241572380066 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 316.22339844703674 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 316.26571249961853 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 316.30383563041687 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 316.35170793533325 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 316.398668050766 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 316.43841314315796 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 316.47851848602295 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 316.51745796203613 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 316.5598187446594 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 316.6029713153839 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 316.6445662975311 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 316.6840491294861 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 316.7226707935333 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 316.7617139816284 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 316.81119871139526 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 316.85047340393066 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 316.8919630050659 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 316.93139123916626 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 316.9708204269409 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 317.01807379722595 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 317.0589141845703 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 317.09914565086365 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 317.1390781402588 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 317.1884071826935 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 317.2340188026428 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 317.27957940101624 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 317.3207128047943 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 317.3623011112213 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 317.40287923812866 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 317.44863843917847 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 317.4890856742859 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 317.5278866291046 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 317.56694984436035 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 317.60568046569824 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 317.6484501361847 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 317.69832372665405 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 317.73818016052246 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 317.77744722366333 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 317.8168876171112 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 317.855495929718 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 317.9053201675415 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 317.9443497657776 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 317.98379397392273 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 318.02275800704956 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 318.07889127731323 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 318.1188688278198 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 318.15842270851135 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 318.2072641849518 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 318.24654817581177 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 318.294558763504 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 318.3367249965668 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 318.3759436607361 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 318.41449213027954 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 318.45332288742065 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 318.4920847415924 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 318.5439398288727 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 318.5839030742645 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 318.6224081516266 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 318.6622807979584 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 318.70125365257263 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 318.7399640083313 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 318.7858695983887 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 318.82542514801025 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 318.865394115448 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 318.90685200691223 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 318.95073342323303 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 318.99283266067505 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 319.0379149913788 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 319.0772919654846 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 319.11632561683655 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 319.15708351135254 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 319.213791847229 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 319.2778744697571 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 319.3381164073944 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 319.3986723423004 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 319.4686396121979 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 319.5284204483032 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 319.5970346927643 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 319.66147327423096 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 319.7335934638977 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 319.7925069332123 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 319.85074734687805 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 319.9108200073242 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 319.97995042800903 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 320.0433027744293 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 320.1038887500763 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 320.18660950660706 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 320.26496481895447 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 320.32252621650696 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 320.38820457458496 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 320.4545204639435 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 320.51259088516235 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 320.5706660747528 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 320.6299829483032 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 320.7031238079071 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 320.76116943359375 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 320.81860733032227 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 320.880277633667 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 320.9571409225464 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 321.01944851875305 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 321.0776917934418 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 321.13636350631714 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 321.19999623298645 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 321.26342391967773 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 321.33617186546326 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 321.39455676078796 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 321.46064615249634 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 321.52534794807434 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 321.58425521850586 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 321.64618492126465 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 321.71091771125793 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 321.77598333358765 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 321.8397309780121 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 321.9053864479065 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 321.98063802719116 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 322.02084517478943 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 322.05991315841675 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 322.099817276001 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 322.13902759552 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 322.18059372901917 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 322.2352788448334 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 322.2765552997589 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 322.32564210891724 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 322.3658037185669 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 322.4121823310852 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 322.4518961906433 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 322.49131751060486 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 322.5311634540558 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 322.5700685977936 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 322.60914158821106 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 322.65955543518066 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 322.7024977207184 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 322.74157977104187 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 322.7817029953003 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 322.82022070884705 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 322.8595473766327 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 322.90410685539246 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 322.94574093818665 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 322.98565101623535 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 323.0255198478699 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 323.0658161640167 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 323.11613368988037 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 323.1555631160736 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 323.1973433494568 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 323.23699283599854 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 323.2832770347595 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 323.3394091129303 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 323.3791298866272 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 323.4194839000702 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 323.46083426475525 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 323.50872564315796 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 323.54826378822327 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 323.58844804763794 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 323.6351161003113 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 323.67525362968445 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 323.7255926132202 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 323.7648322582245 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 323.803768157959 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 323.84321880340576 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 323.8829755783081 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 323.924902677536 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 323.97062730789185 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 324.01011514663696 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 324.05343437194824 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 324.094069480896 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 324.14635944366455 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 324.1907980442047 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 324.23119378089905 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 324.27209734916687 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 324.3128125667572 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 324.37311720848083 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 324.4143900871277 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 324.4533236026764 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 324.49243211746216 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 324.5309660434723 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 324.56984996795654 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 324.63599467277527 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 324.67549204826355 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 324.7189166545868 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 324.758181810379 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 324.79799246788025 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 324.837281703949 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 324.882563829422 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 324.9229679107666 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 324.9628641605377 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 325.0022621154785 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 325.0450122356415 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 325.0912685394287 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 325.13476157188416 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 325.18098521232605 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 325.22219800949097 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 325.270099401474 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 325.3099238872528 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 325.3501043319702 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 325.39727783203125 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 325.4364187717438 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 325.4806365966797 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 325.523313999176 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 325.56169509887695 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 325.59999418258667 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 325.6436257362366 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 325.68283557891846 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 325.7294137477875 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 325.77149963378906 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 325.81077694892883 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 325.8496367931366 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 325.88931131362915 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 325.9326403141022 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 325.985454082489 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 326.02873182296753 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 326.0718460083008 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 326.1140217781067 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 326.16272616386414 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 326.2044219970703 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 326.24448919296265 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 326.2867374420166 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 326.32681369781494 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 326.37163376808167 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 326.4322030544281 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 326.4734568595886 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 326.5122866630554 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 326.55156207084656 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 326.60134768486023 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 326.6429350376129 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 326.68228125572205 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 326.7226083278656 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 326.76273345947266 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 326.80300879478455 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 326.8551993370056 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 326.89524006843567 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 326.9361536502838 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 326.9756052494049 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 327.01789951324463 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 327.0621728897095 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 327.10118079185486 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 327.1433765888214 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 327.1835913658142 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 327.22937059402466 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 327.28749895095825 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 327.3281807899475 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 327.3693470954895 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 327.4135847091675 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 327.4689242839813 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 327.50859236717224 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 327.5474216938019 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 327.58613753318787 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 327.6268882751465 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 327.66605496406555 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 327.7128872871399 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 327.7521824836731 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 327.7916736602783 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 327.831401348114 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 327.8702495098114 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 327.90981936454773 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 327.95807456970215 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 327.9985582828522 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 328.03837513923645 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 328.0817642211914 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 328.123416185379 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 328.16799211502075 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 328.21202993392944 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 328.2537591457367 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 328.29358315467834 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 328.33380460739136 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 328.39215755462646 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 328.431453704834 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 328.4747030735016 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 328.5184199810028 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 328.5581612586975 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 328.601181268692 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 328.6456253528595 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 328.68548464775085 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 328.7243432998657 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 328.76557970046997 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 328.8058967590332 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 328.8532793521881 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 328.8929407596588 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 328.93275928497314 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 328.97329664230347 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 329.0164484977722 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 329.060005903244 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 329.10057759284973 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 329.1401653289795 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 329.1855409145355 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 329.2315080165863 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 329.2781512737274 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 329.31724882125854 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 329.3575689792633 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 329.39846777915955 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 329.4426939487457 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 329.48326230049133 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 329.5304732322693 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 329.5687851905823 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 329.61409401893616 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 329.6623227596283 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 329.70344138145447 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 329.74208331108093 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 329.78137707710266 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 329.82017254829407 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 329.8591158390045 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 329.9051744937897 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 329.9466624259949 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 329.98606419563293 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 330.0255434513092 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 330.06627202033997 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 330.10574102401733 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 330.1551992893219 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 330.19579005241394 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 330.2464804649353 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 330.28684425354004 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 330.3341245651245 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 330.3747863769531 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 330.4140479564667 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 330.453027009964 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 330.49239110946655 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 330.54520082473755 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 330.5867643356323 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 330.6275610923767 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 330.6664934158325 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 330.7053804397583 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 330.75898456573486 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 330.7987768650055 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 330.837952375412 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 330.87722611427307 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 330.9166226387024 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 330.95794224739075 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 331.0058128833771 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 331.04630041122437 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 331.0844535827637 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 331.13017320632935 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 331.1696858406067 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 331.2167856693268 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 331.2627971172333 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 331.3025052547455 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 331.3427827358246 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 331.3837933540344 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 331.43291878700256 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 331.47379183769226 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 331.5117983818054 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 331.5598177909851 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 331.599244594574 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 331.6480624675751 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 331.6872055530548 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 331.7308931350708 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 331.7702260017395 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 331.8089039325714 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 331.84753799438477 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 331.8941340446472 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 331.9324700832367 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 331.99215936660767 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 332.05266213417053 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 332.1185874938965 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 332.17789936065674 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 332.2379093170166 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 332.3003327846527 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 332.3693780899048 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 332.42967438697815 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 332.48820304870605 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 332.55357575416565 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 332.63757586479187 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 332.69554471969604 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 332.7537693977356 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 332.8110017776489 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 332.87882685661316 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 332.9415316581726 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 333.0100953578949 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 333.06936597824097 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 333.13594245910645 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 333.19767117500305 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 333.2683730125427 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 333.346182346344 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 333.40844321250916 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 333.46735525131226 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 333.52566480636597 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 333.591979265213 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 333.6653468608856 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 333.7234058380127 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 333.78138422966003 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 333.84652376174927 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 333.9045147895813 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 333.9628002643585 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 334.03942012786865 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 334.1047537326813 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 334.1653411388397 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 334.2421281337738 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 334.3299345970154 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 334.39767026901245 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 334.4561405181885 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 334.52011823654175 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 334.5872633457184 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 334.657333612442 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 334.72338676452637 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 334.7678253650665 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 334.8138566017151 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 334.85368394851685 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 334.8942587375641 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 334.9334309101105 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 334.9729835987091 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 335.01470613479614 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 335.0608060359955 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 335.11141204833984 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 335.16741728782654 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 335.2125632762909 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 335.2609210014343 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 335.3045103549957 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 335.34630966186523 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 335.3859133720398 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 335.42772936820984 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 335.4719150066376 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 335.5121068954468 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 335.55525159835815 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 335.5947790145874 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 335.63700556755066 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 335.6773302555084 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 335.732834815979 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 335.7732484340668 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 335.8117084503174 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 335.8518388271332 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 335.89976692199707 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 335.940621137619 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 335.988254070282 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 336.0306077003479 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 336.07028555870056 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 336.117262840271 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 336.16019892692566 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 336.2078711986542 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 336.249005317688 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 336.28929352760315 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 336.3388478755951 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 336.3868899345398 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 336.4258704185486 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 336.47199845314026 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 336.510538816452 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 336.5569717884064 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 336.5965883731842 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 336.63924288749695 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 336.6782443523407 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 336.7269215583801 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 336.77282309532166 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 336.81220960617065 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 336.8511092662811 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 336.890971660614 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 336.93116092681885 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 336.96997904777527 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 337.020614862442 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 337.0610113143921 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 337.10067319869995 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 337.14505672454834 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 337.1850833892822 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 337.2322449684143 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 337.27790331840515 loss tensor(0.3000, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "XNQaGo06Ta49",
        "outputId": "306bae03-6cf3-43c5-c442-ec871edc38c6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd8767e5190>]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6G3P5f8LTdAY",
        "outputId": "30cbfbdc-3155-4d7b-b0fd-d73b65b62e35"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd876733b80>]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "l0LtcyhPTeh8",
        "outputId": "b82fcb5e-287e-490e-ad80-0896313cfc3b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd8767132b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}