{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrSGkbB8N313DkXAaSw2az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/LogisticRegression_bwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rkQFFcg0HXnN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "PZ648ILgHfn2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "ShzuBabDHhVe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "penguins = tfds.load('penguins', as_supervised=True, split='train')"
      ],
      "metadata": {
        "id": "ml7IdhKkHjfC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = penguins.batch(500).get_single_element()\n",
        "X, y = X.numpy(), y.numpy()"
      ],
      "metadata": {
        "id": "c2BMFvK7HoFd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "metadata": {
        "id": "bDM9PTN0HrKa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "Xtest = torch.from_numpy(Xtest).float()"
      ],
      "metadata": {
        "id": "JLGZsa5pHtTD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "pubjWXD8Hvva"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "pHLbfdzSH0iW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, w, b):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(w)\n",
        "    self.bias = nn.Parameter(b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(1, -1)\n",
        "    return torch.softmax(x@self.weight + self.bias, 1)"
      ],
      "metadata": {
        "id": "YjCVZwwrH3ah"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pv1yTiJH7JV",
        "outputId": "7cf8b83b-5097-41fd-a14d-1297f814779a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn((4, 3), requires_grad=True)\n",
        "b = torch.randn((3, ), requires_grad=True)\n",
        "LG = SimpleLogisticRegression(4, w, b).to(device)"
      ],
      "metadata": {
        "id": "l2X3STJaH9aY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbykYgnuIAWE",
        "outputId": "59ea086b-970b-440a-e3c8-8c8d176d9327"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1089, 0.8515, 0.0396]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(x,w,b):\n",
        "  ypred=torch.randn((x.shape[0],3))\n",
        "  for j in range (x.shape[0]):\n",
        "    xj = x[j].reshape(1, -1)\n",
        "    ypred[j]=torch.softmax(xj@w+b,1)\n",
        "  return ypred\n"
      ],
      "metadata": {
        "id": "2OCd-kbfLV5h"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=pred(Xtrain,w,b)"
      ],
      "metadata": {
        "id": "SzBH4FuVNabv"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "_LQ7YyETIB7n"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bDbFhIPEMjic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 33% (random guessing).\n",
        "accuracy(ytrain.to(device),ypred.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bGfj-mfIFwZ",
        "outputId": "7e9c2dcf-70b6-414a-8b99-b36a380cfc30"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2040)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(ytrue,ypred):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "1MVXQ3PTILFk"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cross_entropy(ytrain,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDzjWsUK6YG",
        "outputId": "cf671bfb-39b9-4967-bbbf-3586b8833680"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2663, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "6WFmibVCP9y5"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bwd_gradient(x,y):\n",
        "\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  errors=[]\n",
        "\n",
        "  l_rate=0.2\n",
        "\n",
        "  w = torch.randn((4, 3), requires_grad=True)\n",
        "  b = torch.randn((3, ), requires_grad=True)\n",
        "\n",
        "  ypred=pred(x,w,b)\n",
        "\n",
        "  loss = cross_entropy(ytrain,ypred)\n",
        "\n",
        "  t=0\n",
        "  t0=time.time()\n",
        "  print('Time', t, 'loss', loss)\n",
        "\n",
        "  while (loss>0.3): \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Apply gradients \n",
        "      w -= 0.01*w.grad\n",
        "      b -= 0.01*b.grad\n",
        "\n",
        "      # Gradients are accumulated: we need to zero them out before the next iteration.\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "    \n",
        "    ypred=pred(x,w,b)\n",
        "\n",
        "    loss = cross_entropy(ytrain,ypred)\n",
        "\n",
        "    LG = SimpleLogisticRegression(4, w, b)\n",
        "    ypredT=torch.randn(Xtest.size(0),3)\n",
        "    error=0\n",
        "    for i in range (Xtest.size(0)):\n",
        "      ypredT[i]=LG(Xtest[i])\n",
        "      if (LG(Xtest[i]).argmax(1)- ytest[i])!=0:\n",
        "        error = error+ 1\n",
        "\n",
        "    errors.append(error)\n",
        "    accuracies.append(accuracy(ytest,ypredT).item())\n",
        "    losses.append(cross_entropy(ytest,ypredT).detach().item())\n",
        "\n",
        "    t1=time.time()\n",
        "    t+=t1-t0\n",
        "    t0=t1\n",
        "    print('Time', t, 'loss', loss)\n",
        "  \n",
        "  return w,b,errors,losses,accuracies\n"
      ],
      "metadata": {
        "id": "cBld3TwvLDl6"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b,errors,losses,accuracies = train_bwd_gradient(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXOhaZSOPSCa",
        "outputId": "2b1efcdf-535c-4209-88c6-e6ff685b3f98"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Time 136.38462018966675 loss tensor(0.4979, grad_fn=<NegBackward0>)\n",
            "Time 136.43344712257385 loss tensor(0.4978, grad_fn=<NegBackward0>)\n",
            "Time 136.47366285324097 loss tensor(0.4977, grad_fn=<NegBackward0>)\n",
            "Time 136.5220251083374 loss tensor(0.4977, grad_fn=<NegBackward0>)\n",
            "Time 136.56283450126648 loss tensor(0.4976, grad_fn=<NegBackward0>)\n",
            "Time 136.60857582092285 loss tensor(0.4975, grad_fn=<NegBackward0>)\n",
            "Time 136.6493067741394 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 136.68961715698242 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 136.73976969718933 loss tensor(0.4973, grad_fn=<NegBackward0>)\n",
            "Time 136.79259538650513 loss tensor(0.4972, grad_fn=<NegBackward0>)\n",
            "Time 136.83340787887573 loss tensor(0.4972, grad_fn=<NegBackward0>)\n",
            "Time 136.874018907547 loss tensor(0.4971, grad_fn=<NegBackward0>)\n",
            "Time 136.93843722343445 loss tensor(0.4970, grad_fn=<NegBackward0>)\n",
            "Time 136.989595413208 loss tensor(0.4969, grad_fn=<NegBackward0>)\n",
            "Time 137.03252625465393 loss tensor(0.4969, grad_fn=<NegBackward0>)\n",
            "Time 137.07230710983276 loss tensor(0.4968, grad_fn=<NegBackward0>)\n",
            "Time 137.1137638092041 loss tensor(0.4967, grad_fn=<NegBackward0>)\n",
            "Time 137.15440011024475 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 137.2002580165863 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 137.24460864067078 loss tensor(0.4965, grad_fn=<NegBackward0>)\n",
            "Time 137.28544163703918 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 137.32845544815063 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 137.37633609771729 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 137.42377185821533 loss tensor(0.4962, grad_fn=<NegBackward0>)\n",
            "Time 137.46429347991943 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 137.50423765182495 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 137.54420614242554 loss tensor(0.4960, grad_fn=<NegBackward0>)\n",
            "Time 137.58425641059875 loss tensor(0.4959, grad_fn=<NegBackward0>)\n",
            "Time 137.62827324867249 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 137.67504239082336 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 137.71752524375916 loss tensor(0.4957, grad_fn=<NegBackward0>)\n",
            "Time 137.76311016082764 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 137.81430006027222 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 137.86560559272766 loss tensor(0.4955, grad_fn=<NegBackward0>)\n",
            "Time 137.90831470489502 loss tensor(0.4954, grad_fn=<NegBackward0>)\n",
            "Time 137.95704007148743 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 138.00843286514282 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 138.05901646614075 loss tensor(0.4952, grad_fn=<NegBackward0>)\n",
            "Time 138.1066255569458 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 138.14939665794373 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 138.1945662498474 loss tensor(0.4950, grad_fn=<NegBackward0>)\n",
            "Time 138.23523783683777 loss tensor(0.4949, grad_fn=<NegBackward0>)\n",
            "Time 138.2759382724762 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 138.3232045173645 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 138.3638837337494 loss tensor(0.4947, grad_fn=<NegBackward0>)\n",
            "Time 138.41241979599 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 138.45276260375977 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 138.4928696155548 loss tensor(0.4945, grad_fn=<NegBackward0>)\n",
            "Time 138.54096221923828 loss tensor(0.4944, grad_fn=<NegBackward0>)\n",
            "Time 138.58240628242493 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 138.6225974559784 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 138.67143511772156 loss tensor(0.4942, grad_fn=<NegBackward0>)\n",
            "Time 138.72109293937683 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 138.7725007534027 loss tensor(0.4940, grad_fn=<NegBackward0>)\n",
            "Time 138.8141326904297 loss tensor(0.4940, grad_fn=<NegBackward0>)\n",
            "Time 138.85502433776855 loss tensor(0.4939, grad_fn=<NegBackward0>)\n",
            "Time 138.8956642150879 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 138.94315433502197 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 138.99224281311035 loss tensor(0.4937, grad_fn=<NegBackward0>)\n",
            "Time 139.03426957130432 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 139.0740602016449 loss tensor(0.4935, grad_fn=<NegBackward0>)\n",
            "Time 139.11463046073914 loss tensor(0.4935, grad_fn=<NegBackward0>)\n",
            "Time 139.16763353347778 loss tensor(0.4934, grad_fn=<NegBackward0>)\n",
            "Time 139.21696615219116 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 139.25719594955444 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 139.29688358306885 loss tensor(0.4932, grad_fn=<NegBackward0>)\n",
            "Time 139.33675074577332 loss tensor(0.4931, grad_fn=<NegBackward0>)\n",
            "Time 139.37651944160461 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 139.4175271987915 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 139.46250009536743 loss tensor(0.4929, grad_fn=<NegBackward0>)\n",
            "Time 139.50774884223938 loss tensor(0.4928, grad_fn=<NegBackward0>)\n",
            "Time 139.54942893981934 loss tensor(0.4928, grad_fn=<NegBackward0>)\n",
            "Time 139.58911609649658 loss tensor(0.4927, grad_fn=<NegBackward0>)\n",
            "Time 139.63255667686462 loss tensor(0.4926, grad_fn=<NegBackward0>)\n",
            "Time 139.6799602508545 loss tensor(0.4925, grad_fn=<NegBackward0>)\n",
            "Time 139.7249255180359 loss tensor(0.4925, grad_fn=<NegBackward0>)\n",
            "Time 139.76899695396423 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 139.81898832321167 loss tensor(0.4923, grad_fn=<NegBackward0>)\n",
            "Time 139.86872172355652 loss tensor(0.4923, grad_fn=<NegBackward0>)\n",
            "Time 139.9078071117401 loss tensor(0.4922, grad_fn=<NegBackward0>)\n",
            "Time 139.94925832748413 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 139.99983644485474 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 140.04270386695862 loss tensor(0.4920, grad_fn=<NegBackward0>)\n",
            "Time 140.09076380729675 loss tensor(0.4919, grad_fn=<NegBackward0>)\n",
            "Time 140.14255571365356 loss tensor(0.4918, grad_fn=<NegBackward0>)\n",
            "Time 140.1837615966797 loss tensor(0.4918, grad_fn=<NegBackward0>)\n",
            "Time 140.22428250312805 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 140.267165184021 loss tensor(0.4916, grad_fn=<NegBackward0>)\n",
            "Time 140.31447982788086 loss tensor(0.4916, grad_fn=<NegBackward0>)\n",
            "Time 140.36446857452393 loss tensor(0.4915, grad_fn=<NegBackward0>)\n",
            "Time 140.40575122833252 loss tensor(0.4914, grad_fn=<NegBackward0>)\n",
            "Time 140.4467577934265 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 140.48697805404663 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 140.5407099723816 loss tensor(0.4912, grad_fn=<NegBackward0>)\n",
            "Time 140.58194994926453 loss tensor(0.4911, grad_fn=<NegBackward0>)\n",
            "Time 140.62731766700745 loss tensor(0.4911, grad_fn=<NegBackward0>)\n",
            "Time 140.67118859291077 loss tensor(0.4910, grad_fn=<NegBackward0>)\n",
            "Time 140.71268033981323 loss tensor(0.4909, grad_fn=<NegBackward0>)\n",
            "Time 140.75836539268494 loss tensor(0.4908, grad_fn=<NegBackward0>)\n",
            "Time 140.8015739917755 loss tensor(0.4908, grad_fn=<NegBackward0>)\n",
            "Time 140.84295320510864 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 140.88823890686035 loss tensor(0.4906, grad_fn=<NegBackward0>)\n",
            "Time 140.92978477478027 loss tensor(0.4906, grad_fn=<NegBackward0>)\n",
            "Time 140.98499393463135 loss tensor(0.4905, grad_fn=<NegBackward0>)\n",
            "Time 141.02935028076172 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 141.0723066329956 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 141.11311149597168 loss tensor(0.4903, grad_fn=<NegBackward0>)\n",
            "Time 141.15467810630798 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 141.20205664634705 loss tensor(0.4901, grad_fn=<NegBackward0>)\n",
            "Time 141.24548649787903 loss tensor(0.4901, grad_fn=<NegBackward0>)\n",
            "Time 141.28561115264893 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 141.32658553123474 loss tensor(0.4899, grad_fn=<NegBackward0>)\n",
            "Time 141.3661036491394 loss tensor(0.4899, grad_fn=<NegBackward0>)\n",
            "Time 141.41016817092896 loss tensor(0.4898, grad_fn=<NegBackward0>)\n",
            "Time 141.45397567749023 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 141.49584436416626 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 141.5462944507599 loss tensor(0.4896, grad_fn=<NegBackward0>)\n",
            "Time 141.58893203735352 loss tensor(0.4895, grad_fn=<NegBackward0>)\n",
            "Time 141.63524174690247 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 141.67547488212585 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 141.71535897254944 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 141.75572395324707 loss tensor(0.4892, grad_fn=<NegBackward0>)\n",
            "Time 141.7972650527954 loss tensor(0.4892, grad_fn=<NegBackward0>)\n",
            "Time 141.8450870513916 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 141.89070177078247 loss tensor(0.4890, grad_fn=<NegBackward0>)\n",
            "Time 141.93303990364075 loss tensor(0.4890, grad_fn=<NegBackward0>)\n",
            "Time 141.9797625541687 loss tensor(0.4889, grad_fn=<NegBackward0>)\n",
            "Time 142.02975034713745 loss tensor(0.4888, grad_fn=<NegBackward0>)\n",
            "Time 142.08385848999023 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 142.13711500167847 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 142.1782259941101 loss tensor(0.4886, grad_fn=<NegBackward0>)\n",
            "Time 142.21816635131836 loss tensor(0.4885, grad_fn=<NegBackward0>)\n",
            "Time 142.25810980796814 loss tensor(0.4885, grad_fn=<NegBackward0>)\n",
            "Time 142.303325176239 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 142.34694504737854 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 142.3867061138153 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 142.42807149887085 loss tensor(0.4882, grad_fn=<NegBackward0>)\n",
            "Time 142.46881294250488 loss tensor(0.4881, grad_fn=<NegBackward0>)\n",
            "Time 142.51367568969727 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 142.55757641792297 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 142.59771990776062 loss tensor(0.4879, grad_fn=<NegBackward0>)\n",
            "Time 142.63736629486084 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 142.6772744655609 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 142.73061609268188 loss tensor(0.4877, grad_fn=<NegBackward0>)\n",
            "Time 142.7739701271057 loss tensor(0.4876, grad_fn=<NegBackward0>)\n",
            "Time 142.81656575202942 loss tensor(0.4876, grad_fn=<NegBackward0>)\n",
            "Time 142.85824275016785 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 142.89963746070862 loss tensor(0.4874, grad_fn=<NegBackward0>)\n",
            "Time 142.95011019706726 loss tensor(0.4874, grad_fn=<NegBackward0>)\n",
            "Time 142.99245762825012 loss tensor(0.4873, grad_fn=<NegBackward0>)\n",
            "Time 143.04553532600403 loss tensor(0.4872, grad_fn=<NegBackward0>)\n",
            "Time 143.0852370262146 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 143.12550234794617 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 143.17553043365479 loss tensor(0.4870, grad_fn=<NegBackward0>)\n",
            "Time 143.2234547138214 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 143.2633340358734 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 143.30636930465698 loss tensor(0.4868, grad_fn=<NegBackward0>)\n",
            "Time 143.3500759601593 loss tensor(0.4867, grad_fn=<NegBackward0>)\n",
            "Time 143.39746713638306 loss tensor(0.4867, grad_fn=<NegBackward0>)\n",
            "Time 143.43788886070251 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 143.4778413772583 loss tensor(0.4865, grad_fn=<NegBackward0>)\n",
            "Time 143.5175187587738 loss tensor(0.4865, grad_fn=<NegBackward0>)\n",
            "Time 143.55774521827698 loss tensor(0.4864, grad_fn=<NegBackward0>)\n",
            "Time 143.59726428985596 loss tensor(0.4863, grad_fn=<NegBackward0>)\n",
            "Time 143.6429147720337 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 143.68863582611084 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 143.7289435863495 loss tensor(0.4861, grad_fn=<NegBackward0>)\n",
            "Time 143.76852178573608 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 143.82033467292786 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 143.8631193637848 loss tensor(0.4859, grad_fn=<NegBackward0>)\n",
            "Time 143.90799713134766 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 143.95116305351257 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 143.99082899093628 loss tensor(0.4857, grad_fn=<NegBackward0>)\n",
            "Time 144.0427107810974 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 144.08850121498108 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 144.12813115119934 loss tensor(0.4855, grad_fn=<NegBackward0>)\n",
            "Time 144.17815709114075 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 144.21849179267883 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 144.26458358764648 loss tensor(0.4853, grad_fn=<NegBackward0>)\n",
            "Time 144.30400323867798 loss tensor(0.4852, grad_fn=<NegBackward0>)\n",
            "Time 144.34405279159546 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 144.3837378025055 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 144.42363929748535 loss tensor(0.4850, grad_fn=<NegBackward0>)\n",
            "Time 144.4636070728302 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 144.51419973373413 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 144.55735111236572 loss tensor(0.4848, grad_fn=<NegBackward0>)\n",
            "Time 144.59896779060364 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 144.64020466804504 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 144.7018644809723 loss tensor(0.4846, grad_fn=<NegBackward0>)\n",
            "Time 144.74580693244934 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 144.78774976730347 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 144.82798719406128 loss tensor(0.4844, grad_fn=<NegBackward0>)\n",
            "Time 144.86847853660583 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 144.92299103736877 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 144.97086644172668 loss tensor(0.4842, grad_fn=<NegBackward0>)\n",
            "Time 145.0142970085144 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 145.0541398525238 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 145.12034344673157 loss tensor(0.4840, grad_fn=<NegBackward0>)\n",
            "Time 145.19090366363525 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 145.25278329849243 loss tensor(0.4838, grad_fn=<NegBackward0>)\n",
            "Time 145.31416940689087 loss tensor(0.4838, grad_fn=<NegBackward0>)\n",
            "Time 145.3738853931427 loss tensor(0.4837, grad_fn=<NegBackward0>)\n",
            "Time 145.44658017158508 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 145.50776863098145 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 145.56761288642883 loss tensor(0.4835, grad_fn=<NegBackward0>)\n",
            "Time 145.62888956069946 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 145.6974265575409 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 145.76018905639648 loss tensor(0.4833, grad_fn=<NegBackward0>)\n",
            "Time 145.82541465759277 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 145.8974757194519 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 145.96919512748718 loss tensor(0.4831, grad_fn=<NegBackward0>)\n",
            "Time 146.03146862983704 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 146.09442973136902 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 146.1610677242279 loss tensor(0.4829, grad_fn=<NegBackward0>)\n",
            "Time 146.222069978714 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 146.2805778980255 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 146.33918619155884 loss tensor(0.4827, grad_fn=<NegBackward0>)\n",
            "Time 146.41083335876465 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 146.47104597091675 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 146.5295534133911 loss tensor(0.4825, grad_fn=<NegBackward0>)\n",
            "Time 146.58737444877625 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 146.6573567390442 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 146.7300043106079 loss tensor(0.4823, grad_fn=<NegBackward0>)\n",
            "Time 146.78863525390625 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 146.84930849075317 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 146.90996170043945 loss tensor(0.4821, grad_fn=<NegBackward0>)\n",
            "Time 146.9697504043579 loss tensor(0.4820, grad_fn=<NegBackward0>)\n",
            "Time 147.02985286712646 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 147.08867692947388 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 147.1526370048523 loss tensor(0.4818, grad_fn=<NegBackward0>)\n",
            "Time 147.22680163383484 loss tensor(0.4817, grad_fn=<NegBackward0>)\n",
            "Time 147.2859227657318 loss tensor(0.4817, grad_fn=<NegBackward0>)\n",
            "Time 147.34418773651123 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 147.40498304367065 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 147.4645812511444 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 147.52316188812256 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 147.58501553535461 loss tensor(0.4813, grad_fn=<NegBackward0>)\n",
            "Time 147.64702677726746 loss tensor(0.4813, grad_fn=<NegBackward0>)\n",
            "Time 147.7061014175415 loss tensor(0.4812, grad_fn=<NegBackward0>)\n",
            "Time 147.76548767089844 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 147.824720621109 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 147.91490197181702 loss tensor(0.4810, grad_fn=<NegBackward0>)\n",
            "Time 147.97783732414246 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 148.0519917011261 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 148.11279487609863 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 148.18516325950623 loss tensor(0.4807, grad_fn=<NegBackward0>)\n",
            "Time 148.25194430351257 loss tensor(0.4807, grad_fn=<NegBackward0>)\n",
            "Time 148.31482982635498 loss tensor(0.4806, grad_fn=<NegBackward0>)\n",
            "Time 148.389310836792 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 148.44845938682556 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 148.51205396652222 loss tensor(0.4804, grad_fn=<NegBackward0>)\n",
            "Time 148.58268904685974 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 148.64817023277283 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 148.71635222434998 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 148.76331901550293 loss tensor(0.4801, grad_fn=<NegBackward0>)\n",
            "Time 148.81437420845032 loss tensor(0.4801, grad_fn=<NegBackward0>)\n",
            "Time 148.85494542121887 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 148.8956813812256 loss tensor(0.4799, grad_fn=<NegBackward0>)\n",
            "Time 148.93792963027954 loss tensor(0.4799, grad_fn=<NegBackward0>)\n",
            "Time 148.97795057296753 loss tensor(0.4798, grad_fn=<NegBackward0>)\n",
            "Time 149.031879901886 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 149.07231497764587 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 149.11596989631653 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 149.16709113121033 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 149.20979285240173 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 149.27626967430115 loss tensor(0.4794, grad_fn=<NegBackward0>)\n",
            "Time 149.3169002532959 loss tensor(0.4793, grad_fn=<NegBackward0>)\n",
            "Time 149.35678100585938 loss tensor(0.4793, grad_fn=<NegBackward0>)\n",
            "Time 149.39619541168213 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 149.43611860275269 loss tensor(0.4791, grad_fn=<NegBackward0>)\n",
            "Time 149.47610712051392 loss tensor(0.4791, grad_fn=<NegBackward0>)\n",
            "Time 149.52158117294312 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 149.56274271011353 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 149.60268211364746 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 149.64333033561707 loss tensor(0.4788, grad_fn=<NegBackward0>)\n",
            "Time 149.6991991996765 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 149.74234676361084 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 149.7829029560089 loss tensor(0.4786, grad_fn=<NegBackward0>)\n",
            "Time 149.83712792396545 loss tensor(0.4785, grad_fn=<NegBackward0>)\n",
            "Time 149.8901731967926 loss tensor(0.4785, grad_fn=<NegBackward0>)\n",
            "Time 149.93867325782776 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 149.9789023399353 loss tensor(0.4783, grad_fn=<NegBackward0>)\n",
            "Time 150.0235116481781 loss tensor(0.4783, grad_fn=<NegBackward0>)\n",
            "Time 150.07264852523804 loss tensor(0.4782, grad_fn=<NegBackward0>)\n",
            "Time 150.11265325546265 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 150.1650583744049 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 150.20793747901917 loss tensor(0.4780, grad_fn=<NegBackward0>)\n",
            "Time 150.24819087982178 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 150.29712915420532 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 150.3377857208252 loss tensor(0.4778, grad_fn=<NegBackward0>)\n",
            "Time 150.3847062587738 loss tensor(0.4777, grad_fn=<NegBackward0>)\n",
            "Time 150.42520141601562 loss tensor(0.4777, grad_fn=<NegBackward0>)\n",
            "Time 150.46798419952393 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 150.50859141349792 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 150.56386709213257 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 150.61261463165283 loss tensor(0.4774, grad_fn=<NegBackward0>)\n",
            "Time 150.65280294418335 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 150.70994663238525 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 150.7520043849945 loss tensor(0.4772, grad_fn=<NegBackward0>)\n",
            "Time 150.7934067249298 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 150.84037137031555 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 150.88122820854187 loss tensor(0.4770, grad_fn=<NegBackward0>)\n",
            "Time 150.92328071594238 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 150.97016668319702 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 151.01224422454834 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 151.06081628799438 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 151.1087465286255 loss tensor(0.4767, grad_fn=<NegBackward0>)\n",
            "Time 151.15190982818604 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 151.35458040237427 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 151.48753190040588 loss tensor(0.4765, grad_fn=<NegBackward0>)\n",
            "Time 151.65969443321228 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 151.85961055755615 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 151.99787521362305 loss tensor(0.4763, grad_fn=<NegBackward0>)\n",
            "Time 152.1626524925232 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 152.38578963279724 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 152.53067994117737 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 152.66984844207764 loss tensor(0.4760, grad_fn=<NegBackward0>)\n",
            "Time 152.75667262077332 loss tensor(0.4760, grad_fn=<NegBackward0>)\n",
            "Time 152.79762148857117 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 152.84241461753845 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 152.89115142822266 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 152.93298292160034 loss tensor(0.4757, grad_fn=<NegBackward0>)\n",
            "Time 152.97481751441956 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 153.0230085849762 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 153.0660376548767 loss tensor(0.4755, grad_fn=<NegBackward0>)\n",
            "Time 153.11661314964294 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 153.1575207710266 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 153.19843077659607 loss tensor(0.4753, grad_fn=<NegBackward0>)\n",
            "Time 153.2410707473755 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 153.28948616981506 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 153.3355975151062 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 153.38293933868408 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 153.42475152015686 loss tensor(0.4750, grad_fn=<NegBackward0>)\n",
            "Time 153.46497535705566 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 153.5069055557251 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 153.55686283111572 loss tensor(0.4748, grad_fn=<NegBackward0>)\n",
            "Time 153.605131149292 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 153.64797139167786 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 153.69017839431763 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 153.73135685920715 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 153.7818567752838 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 153.82405018806458 loss tensor(0.4744, grad_fn=<NegBackward0>)\n",
            "Time 153.86444973945618 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 153.90758085250854 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 153.9517467021942 loss tensor(0.4742, grad_fn=<NegBackward0>)\n",
            "Time 153.99929022789001 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 154.04295301437378 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 154.08785271644592 loss tensor(0.4740, grad_fn=<NegBackward0>)\n",
            "Time 154.13871908187866 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 154.18011808395386 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 154.2295229434967 loss tensor(0.4738, grad_fn=<NegBackward0>)\n",
            "Time 154.27857613563538 loss tensor(0.4738, grad_fn=<NegBackward0>)\n",
            "Time 154.31808042526245 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 154.3582420349121 loss tensor(0.4736, grad_fn=<NegBackward0>)\n",
            "Time 154.41256737709045 loss tensor(0.4736, grad_fn=<NegBackward0>)\n",
            "Time 154.457909822464 loss tensor(0.4735, grad_fn=<NegBackward0>)\n",
            "Time 154.50007510185242 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 154.55406188964844 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 154.5952546596527 loss tensor(0.4733, grad_fn=<NegBackward0>)\n",
            "Time 154.63845658302307 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 154.6844437122345 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 154.72473907470703 loss tensor(0.4731, grad_fn=<NegBackward0>)\n",
            "Time 154.76480269432068 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 154.80746245384216 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 154.85526847839355 loss tensor(0.4729, grad_fn=<NegBackward0>)\n",
            "Time 154.90249156951904 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 154.94705200195312 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 154.998854637146 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 155.04493713378906 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 155.08615446090698 loss tensor(0.4726, grad_fn=<NegBackward0>)\n",
            "Time 155.13128113746643 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 155.17134499549866 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 155.21553659439087 loss tensor(0.4724, grad_fn=<NegBackward0>)\n",
            "Time 155.25926184654236 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 155.30051064491272 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 155.34917068481445 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 155.39789080619812 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 155.44686222076416 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 155.48747897148132 loss tensor(0.4720, grad_fn=<NegBackward0>)\n",
            "Time 155.52916073799133 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 155.57567405700684 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 155.61795902252197 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 155.6630663871765 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 155.70824599266052 loss tensor(0.4717, grad_fn=<NegBackward0>)\n",
            "Time 155.75481009483337 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 155.80303144454956 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 155.84528398513794 loss tensor(0.4715, grad_fn=<NegBackward0>)\n",
            "Time 155.8877112865448 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 155.92852807044983 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 155.97582864761353 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 156.02693676948547 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 156.0685966014862 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 156.1096887588501 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 156.1503300666809 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 156.19033241271973 loss tensor(0.4710, grad_fn=<NegBackward0>)\n",
            "Time 156.2440700531006 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 156.2877721786499 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 156.3275852203369 loss tensor(0.4708, grad_fn=<NegBackward0>)\n",
            "Time 156.38181924819946 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 156.4242582321167 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 156.47928524017334 loss tensor(0.4706, grad_fn=<NegBackward0>)\n",
            "Time 156.52662754058838 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 156.5691261291504 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 156.6113407611847 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 156.66042494773865 loss tensor(0.4703, grad_fn=<NegBackward0>)\n",
            "Time 156.71231055259705 loss tensor(0.4703, grad_fn=<NegBackward0>)\n",
            "Time 156.75281620025635 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 156.79613161087036 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 156.85606360435486 loss tensor(0.4701, grad_fn=<NegBackward0>)\n",
            "Time 156.89845323562622 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 156.94797372817993 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 156.9897644519806 loss tensor(0.4699, grad_fn=<NegBackward0>)\n",
            "Time 157.032776594162 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 157.07486534118652 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 157.12124466896057 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 157.1681432723999 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 157.20990705490112 loss tensor(0.4696, grad_fn=<NegBackward0>)\n",
            "Time 157.2495391368866 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 157.29082703590393 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 157.33024048805237 loss tensor(0.4694, grad_fn=<NegBackward0>)\n",
            "Time 157.37844252586365 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 157.4245855808258 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 157.47539448738098 loss tensor(0.4692, grad_fn=<NegBackward0>)\n",
            "Time 157.51587986946106 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 157.55571675300598 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 157.6044774055481 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 157.64548540115356 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 157.69193410873413 loss tensor(0.4689, grad_fn=<NegBackward0>)\n",
            "Time 157.7347342967987 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 157.77749586105347 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 157.82898688316345 loss tensor(0.4687, grad_fn=<NegBackward0>)\n",
            "Time 157.8715958595276 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 157.9145483970642 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 157.96084570884705 loss tensor(0.4685, grad_fn=<NegBackward0>)\n",
            "Time 158.00176072120667 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 158.04951310157776 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 158.09071803092957 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 158.1310203075409 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 158.17147946357727 loss tensor(0.4682, grad_fn=<NegBackward0>)\n",
            "Time 158.2124707698822 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 158.2673258781433 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 158.3086016178131 loss tensor(0.4680, grad_fn=<NegBackward0>)\n",
            "Time 158.3483407497406 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 158.3895251750946 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 158.43061780929565 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 158.4715347290039 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 158.5300030708313 loss tensor(0.4677, grad_fn=<NegBackward0>)\n",
            "Time 158.5745551586151 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 158.62971091270447 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 158.67153763771057 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 158.72108340263367 loss tensor(0.4674, grad_fn=<NegBackward0>)\n",
            "Time 158.78952932357788 loss tensor(0.4674, grad_fn=<NegBackward0>)\n",
            "Time 158.8561556339264 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 158.9173059463501 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 158.98891258239746 loss tensor(0.4672, grad_fn=<NegBackward0>)\n",
            "Time 159.0548174381256 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 159.11664962768555 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 159.18064785003662 loss tensor(0.4670, grad_fn=<NegBackward0>)\n",
            "Time 159.2540054321289 loss tensor(0.4669, grad_fn=<NegBackward0>)\n",
            "Time 159.31669855117798 loss tensor(0.4669, grad_fn=<NegBackward0>)\n",
            "Time 159.37320470809937 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 159.43166589736938 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 159.51239275932312 loss tensor(0.4667, grad_fn=<NegBackward0>)\n",
            "Time 159.58259391784668 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 159.66364455223083 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 159.73247385025024 loss tensor(0.4665, grad_fn=<NegBackward0>)\n",
            "Time 159.79153680801392 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 159.85188364982605 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 159.91443610191345 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 159.98306274414062 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 160.04880452156067 loss tensor(0.4662, grad_fn=<NegBackward0>)\n",
            "Time 160.1080961227417 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 160.1659333705902 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 160.23563742637634 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 160.29886436462402 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 160.3574619293213 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 160.41597175598145 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 160.47988748550415 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 160.54079246520996 loss tensor(0.4657, grad_fn=<NegBackward0>)\n",
            "Time 160.61294078826904 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 160.6724681854248 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 160.73550415039062 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 160.80195713043213 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 160.86765718460083 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 160.93479919433594 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 161.00978016853333 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 161.06926250457764 loss tensor(0.4652, grad_fn=<NegBackward0>)\n",
            "Time 161.12850141525269 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 161.19789004325867 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 161.2571680545807 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 161.3175745010376 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 161.38412261009216 loss tensor(0.4649, grad_fn=<NegBackward0>)\n",
            "Time 161.45514059066772 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 161.51502132415771 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 161.5819923877716 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 161.64651489257812 loss tensor(0.4646, grad_fn=<NegBackward0>)\n",
            "Time 161.71699810028076 loss tensor(0.4646, grad_fn=<NegBackward0>)\n",
            "Time 161.78280377388 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 161.84575843811035 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 161.91524362564087 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 161.97992515563965 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 162.04272651672363 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 162.10751152038574 loss tensor(0.4642, grad_fn=<NegBackward0>)\n",
            "Time 162.175927400589 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 162.24227499961853 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 162.30919981002808 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 162.35221219062805 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 162.40267753601074 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 162.44383645057678 loss tensor(0.4638, grad_fn=<NegBackward0>)\n",
            "Time 162.48446011543274 loss tensor(0.4638, grad_fn=<NegBackward0>)\n",
            "Time 162.52468466758728 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 162.5647566318512 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 162.6202414035797 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 162.67160201072693 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 162.7128620147705 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 162.75391960144043 loss tensor(0.4634, grad_fn=<NegBackward0>)\n",
            "Time 162.79463648796082 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 162.84243845939636 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 162.8839943408966 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 162.93071746826172 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 162.97551608085632 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 163.02575731277466 loss tensor(0.4630, grad_fn=<NegBackward0>)\n",
            "Time 163.07235312461853 loss tensor(0.4630, grad_fn=<NegBackward0>)\n",
            "Time 163.11328077316284 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 163.15596556663513 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 163.19881105422974 loss tensor(0.4628, grad_fn=<NegBackward0>)\n",
            "Time 163.239515542984 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 163.28802919387817 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 163.3317267894745 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 163.37203359603882 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 163.41339349746704 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 163.45816135406494 loss tensor(0.4624, grad_fn=<NegBackward0>)\n",
            "Time 163.50488352775574 loss tensor(0.4624, grad_fn=<NegBackward0>)\n",
            "Time 163.54834723472595 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 163.59236693382263 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 163.63929319381714 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 163.6924991607666 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 163.73800659179688 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 163.77941799163818 loss tensor(0.4620, grad_fn=<NegBackward0>)\n",
            "Time 163.82793140411377 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 163.86996984481812 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 163.9097216129303 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 163.9585018157959 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 164.00125360488892 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 164.05144882202148 loss tensor(0.4616, grad_fn=<NegBackward0>)\n",
            "Time 164.0984525680542 loss tensor(0.4616, grad_fn=<NegBackward0>)\n",
            "Time 164.13959312438965 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 164.1875286102295 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 164.22770428657532 loss tensor(0.4614, grad_fn=<NegBackward0>)\n",
            "Time 164.2675426006317 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 164.30820417404175 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 164.3516652584076 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 164.396151304245 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 164.437730550766 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 164.47784519195557 loss tensor(0.4610, grad_fn=<NegBackward0>)\n",
            "Time 164.52410745620728 loss tensor(0.4610, grad_fn=<NegBackward0>)\n",
            "Time 164.5652461051941 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 164.6134307384491 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 164.65375018119812 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 164.71757888793945 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 164.75975823402405 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 164.8022599220276 loss tensor(0.4606, grad_fn=<NegBackward0>)\n",
            "Time 164.85147070884705 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 164.89267539978027 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 164.93258595466614 loss tensor(0.4604, grad_fn=<NegBackward0>)\n",
            "Time 164.97351217269897 loss tensor(0.4604, grad_fn=<NegBackward0>)\n",
            "Time 165.0174331665039 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 165.06618309020996 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 165.10730814933777 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 165.14741253852844 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 165.1877338886261 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 165.2324719429016 loss tensor(0.4600, grad_fn=<NegBackward0>)\n",
            "Time 165.2777533531189 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 165.32122445106506 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 165.3699758052826 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 165.41132378578186 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 165.45148730278015 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 165.4997274875641 loss tensor(0.4596, grad_fn=<NegBackward0>)\n",
            "Time 165.5414640903473 loss tensor(0.4596, grad_fn=<NegBackward0>)\n",
            "Time 165.58180785179138 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 165.62496280670166 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 165.66933631896973 loss tensor(0.4594, grad_fn=<NegBackward0>)\n",
            "Time 165.72449493408203 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 165.76864099502563 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 165.80785584449768 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 165.8538122177124 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 165.91024136543274 loss tensor(0.4591, grad_fn=<NegBackward0>)\n",
            "Time 165.9661009311676 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 166.0096640586853 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 166.04915046691895 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 166.09446024894714 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 166.1359519958496 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 166.18373894691467 loss tensor(0.4587, grad_fn=<NegBackward0>)\n",
            "Time 166.22483348846436 loss tensor(0.4587, grad_fn=<NegBackward0>)\n",
            "Time 166.26506233215332 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 166.3050720691681 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 166.34698724746704 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 166.40275478363037 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 166.44341564178467 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 166.48593378067017 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 166.52892065048218 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 166.57263016700745 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 166.62084245681763 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 166.66821360588074 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 166.72201800346375 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 166.7725646495819 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 166.8136179447174 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 166.8660113811493 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 166.90695333480835 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 166.94845843315125 loss tensor(0.4577, grad_fn=<NegBackward0>)\n",
            "Time 167.03127551078796 loss tensor(0.4577, grad_fn=<NegBackward0>)\n",
            "Time 167.08204746246338 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 167.12383651733398 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 167.16388583183289 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 167.2043595314026 loss tensor(0.4574, grad_fn=<NegBackward0>)\n",
            "Time 167.24439930915833 loss tensor(0.4574, grad_fn=<NegBackward0>)\n",
            "Time 167.28422021865845 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 167.33450055122375 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 167.3782844543457 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 167.41944813728333 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 167.45931673049927 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 167.5152976512909 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 167.55579137802124 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 167.59585738182068 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 167.63764429092407 loss tensor(0.4568, grad_fn=<NegBackward0>)\n",
            "Time 167.67796111106873 loss tensor(0.4568, grad_fn=<NegBackward0>)\n",
            "Time 167.7232825756073 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 167.7765736579895 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 167.8178505897522 loss tensor(0.4566, grad_fn=<NegBackward0>)\n",
            "Time 167.85850548744202 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 167.9026288986206 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 167.95236229896545 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 167.99340724945068 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 168.05109691619873 loss tensor(0.4563, grad_fn=<NegBackward0>)\n",
            "Time 168.1104576587677 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 168.15248203277588 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 168.20152640342712 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 168.24983549118042 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 168.2911684513092 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 168.33285188674927 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 168.37982320785522 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 168.42073464393616 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 168.46092319488525 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 168.50134325027466 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 168.5417284965515 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 168.59468984603882 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 168.64139556884766 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 168.68553972244263 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 168.72653913497925 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 168.76642060279846 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 168.82027435302734 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 168.86184763908386 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 168.90491580963135 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 168.9485285282135 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 168.98857355117798 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 169.03948330879211 loss tensor(0.4550, grad_fn=<NegBackward0>)\n",
            "Time 169.08411717414856 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 169.12491583824158 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 169.16520619392395 loss tensor(0.4548, grad_fn=<NegBackward0>)\n",
            "Time 169.20829796791077 loss tensor(0.4548, grad_fn=<NegBackward0>)\n",
            "Time 169.26865601539612 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 169.3100564479828 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 169.35153007507324 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 169.393981218338 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 169.43557357788086 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 169.48423314094543 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 169.5266740322113 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 169.5692422389984 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 169.61732172966003 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 169.65834069252014 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 169.70360827445984 loss tensor(0.4541, grad_fn=<NegBackward0>)\n",
            "Time 169.74311208724976 loss tensor(0.4541, grad_fn=<NegBackward0>)\n",
            "Time 169.7825939655304 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 169.83027172088623 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 169.8733971118927 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 169.9200541973114 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 169.96749782562256 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 170.01582384109497 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 170.06202578544617 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 170.1035087108612 loss tensor(0.4536, grad_fn=<NegBackward0>)\n",
            "Time 170.15058588981628 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 170.19098925590515 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 170.23325562477112 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 170.27413535118103 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 170.3142750263214 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 170.3621518611908 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 170.40449690818787 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 170.44909739494324 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 170.48903512954712 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 170.52861166000366 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 170.57545685768127 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 170.61577486991882 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 170.65548968315125 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 170.69615840911865 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 170.73910784721375 loss tensor(0.4527, grad_fn=<NegBackward0>)\n",
            "Time 170.7929003238678 loss tensor(0.4527, grad_fn=<NegBackward0>)\n",
            "Time 170.85067749023438 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 170.8906672000885 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 170.93141078948975 loss tensor(0.4525, grad_fn=<NegBackward0>)\n",
            "Time 170.97360825538635 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 171.0213656425476 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 171.06379103660583 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 171.10496139526367 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 171.1555051803589 loss tensor(0.4522, grad_fn=<NegBackward0>)\n",
            "Time 171.19562554359436 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 171.25101447105408 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 171.29241824150085 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 171.33211970329285 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 171.37381744384766 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 171.41546034812927 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 171.45870733261108 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 171.50034260749817 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 171.54048252105713 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 171.58046889305115 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 171.6210150718689 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 171.68606185913086 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 171.73230266571045 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 171.7724781036377 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 171.8132152557373 loss tensor(0.4513, grad_fn=<NegBackward0>)\n",
            "Time 171.86332869529724 loss tensor(0.4513, grad_fn=<NegBackward0>)\n",
            "Time 171.91132521629333 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 171.9542796611786 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 171.9962477684021 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 172.04220032691956 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 172.08271837234497 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 172.12983083724976 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 172.16955852508545 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 172.21371006965637 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 172.2542688846588 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 172.2940697669983 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 172.35022521018982 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 172.41409468650818 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 172.47243094444275 loss tensor(0.4505, grad_fn=<NegBackward0>)\n",
            "Time 172.5416922569275 loss tensor(0.4505, grad_fn=<NegBackward0>)\n",
            "Time 172.6172912120819 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 172.68164563179016 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 172.74598288536072 loss tensor(0.4503, grad_fn=<NegBackward0>)\n",
            "Time 172.8105115890503 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 172.88914918899536 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 172.95672821998596 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 173.030207157135 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 173.08982944488525 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 173.16498708724976 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 173.2269196510315 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 173.2944221496582 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 173.36472487449646 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 173.44384694099426 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 173.50784063339233 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 173.58913946151733 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 173.65845108032227 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 173.72562527656555 loss tensor(0.4495, grad_fn=<NegBackward0>)\n",
            "Time 173.786789894104 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 173.85029363632202 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 173.94417023658752 loss tensor(0.4493, grad_fn=<NegBackward0>)\n",
            "Time 174.01794528961182 loss tensor(0.4493, grad_fn=<NegBackward0>)\n",
            "Time 174.0765380859375 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 174.13791704177856 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 174.20322346687317 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 174.26290369033813 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 174.32131481170654 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 174.38659143447876 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 174.4574806690216 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 174.5184986591339 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 174.57662224769592 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 174.6347677707672 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 174.70229077339172 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 174.76325106620789 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 174.8245928287506 loss tensor(0.4485, grad_fn=<NegBackward0>)\n",
            "Time 174.88910841941833 loss tensor(0.4485, grad_fn=<NegBackward0>)\n",
            "Time 174.95268940925598 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 175.01831102371216 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 175.082946062088 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 175.14257287979126 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 175.20747065544128 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 175.26988530158997 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 175.3318154811859 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 175.39431643486023 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 175.46719670295715 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 175.5281527042389 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 175.5910506248474 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 175.64990782737732 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 175.72263026237488 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 175.7891664505005 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 175.85606980323792 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 175.9183156490326 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 175.96717953681946 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 176.01132154464722 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 176.06160020828247 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 176.10331010818481 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 176.14606094360352 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 176.19744610786438 loss tensor(0.4472, grad_fn=<NegBackward0>)\n",
            "Time 176.2527060508728 loss tensor(0.4472, grad_fn=<NegBackward0>)\n",
            "Time 176.29412579536438 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 176.3345878124237 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 176.37726759910583 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 176.42978382110596 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 176.47307753562927 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 176.51410341262817 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 176.55388379096985 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 176.59542059898376 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 176.6430675983429 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 176.68301939964294 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 176.72448182106018 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 176.76990222930908 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 176.81377363204956 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 176.86342525482178 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 176.9040732383728 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 176.94820928573608 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 176.99106550216675 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 177.03500056266785 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 177.09258580207825 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 177.13624715805054 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 177.1835582256317 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 177.22436451911926 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 177.26412987709045 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 177.3149631023407 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 177.35601902008057 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 177.41567468643188 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 177.4894506931305 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 177.56458353996277 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 177.74265933036804 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 177.9449565410614 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 178.1876609325409 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 178.36927270889282 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 178.56298851966858 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 178.6672682762146 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 178.82669305801392 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 178.93346428871155 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 178.97681832313538 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 179.01954102516174 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 179.07726764678955 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 179.12250995635986 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 179.1673138141632 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 179.20854663848877 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 179.24882793426514 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 179.29588055610657 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 179.33678889274597 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 179.37660956382751 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 179.42375111579895 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 179.46353483200073 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 179.51124453544617 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 179.55110001564026 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 179.59189176559448 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 179.63261580467224 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 179.6724407672882 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 179.72446966171265 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 179.7660617828369 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 179.80884671211243 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 179.85687923431396 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 179.90553188323975 loss tensor(0.4439, grad_fn=<NegBackward0>)\n",
            "Time 179.95222234725952 loss tensor(0.4439, grad_fn=<NegBackward0>)\n",
            "Time 180.00046920776367 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 180.04607510566711 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 180.09266185760498 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 180.14294505119324 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 180.19281792640686 loss tensor(0.4436, grad_fn=<NegBackward0>)\n",
            "Time 180.2373456954956 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 180.28186917304993 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 180.32928562164307 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 180.37619590759277 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 180.4298288822174 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 180.47117352485657 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 180.51133704185486 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 180.55280017852783 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 180.5926353931427 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 180.63723015785217 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 180.68562960624695 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 180.72841382026672 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 180.77506852149963 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 180.82569694519043 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 180.87602925300598 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 180.91622734069824 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 180.96174097061157 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 181.00557208061218 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 181.04981350898743 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 181.09699177742004 loss tensor(0.4425, grad_fn=<NegBackward0>)\n",
            "Time 181.137845993042 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 181.19588780403137 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 181.23613381385803 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 181.27864742279053 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 181.33153533935547 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 181.37182140350342 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 181.41292095184326 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 181.454984664917 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 181.49547410011292 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 181.54078650474548 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 181.59439730644226 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 181.6369559764862 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 181.67818975448608 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 181.71979761123657 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 181.77358675003052 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 181.8146619796753 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 181.8606526851654 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 181.90324091911316 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 181.94667530059814 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 181.99881649017334 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 182.04208707809448 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 182.08412742614746 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 182.12570357322693 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 182.17424631118774 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 182.22852611541748 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 182.26847410202026 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 182.3080916404724 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 182.34740924835205 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 182.38730597496033 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 182.42915439605713 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 182.47907638549805 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 182.519305229187 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 182.55928659439087 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 182.59865832328796 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 182.64460444450378 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 182.68730545043945 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 182.72812747955322 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 182.7723035812378 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 182.81760668754578 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 182.86698722839355 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 182.91000032424927 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 182.95224356651306 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 182.9928321838379 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 183.036714553833 loss tensor(0.4401, grad_fn=<NegBackward0>)\n",
            "Time 183.0855462551117 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 183.1299991607666 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 183.17361330986023 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 183.222309589386 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 183.2627923488617 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 183.30998539924622 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 183.35474920272827 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 183.39545845985413 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 183.44119930267334 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 183.4850471019745 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 183.53226613998413 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 183.5730812549591 loss tensor(0.4394, grad_fn=<NegBackward0>)\n",
            "Time 183.61340260505676 loss tensor(0.4394, grad_fn=<NegBackward0>)\n",
            "Time 183.65383315086365 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 183.69830203056335 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 183.74854588508606 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 183.7923400402069 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 183.83327436447144 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 183.87453722953796 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 183.91523122787476 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 183.96401000022888 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 184.01820135116577 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 184.0591230392456 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 184.10074615478516 loss tensor(0.4388, grad_fn=<NegBackward0>)\n",
            "Time 184.14874053001404 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 184.19891023635864 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 184.25480103492737 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 184.2961404323578 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 184.3370704650879 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 184.37698650360107 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 184.42944717407227 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 184.47303414344788 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 184.52578377723694 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 184.57302689552307 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 184.6202793121338 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 184.6693685054779 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 184.7172508239746 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 184.7589418888092 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 184.79950141906738 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 184.83936309814453 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 184.8872354030609 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 184.9285204410553 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 184.97242379188538 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 185.02243733406067 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 185.06244111061096 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 185.11301350593567 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 185.15299320220947 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 185.1933090686798 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 185.2332739830017 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 185.2813000679016 loss tensor(0.4374, grad_fn=<NegBackward0>)\n",
            "Time 185.32916116714478 loss tensor(0.4374, grad_fn=<NegBackward0>)\n",
            "Time 185.37341022491455 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 185.4141492843628 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 185.45652222633362 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 185.49686670303345 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 185.54467964172363 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 185.58656525611877 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 185.6270318031311 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 185.67281579971313 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 185.7133388519287 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 185.76016902923584 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 185.8061559200287 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 185.8486258983612 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 185.89133071899414 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 185.94609451293945 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 186.0124955177307 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 186.0764672756195 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 186.1384072303772 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 186.21009397506714 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 186.29429578781128 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 186.35417008399963 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 186.41404247283936 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 186.48754954338074 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 186.5493574142456 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 186.60871720314026 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 186.67964482307434 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 186.750572681427 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 186.80977416038513 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 186.86997723579407 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 186.94221806526184 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 187.00748920440674 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 187.06611013412476 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 187.1279067993164 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 187.20526933670044 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 187.2647819519043 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 187.32754826545715 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 187.3868498802185 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 187.45805191993713 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 187.5187816619873 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 187.57818484306335 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 187.63948893547058 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 187.71025037765503 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 187.7749195098877 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 187.84046030044556 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 187.90156030654907 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 187.9853482246399 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 188.05078411102295 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 188.12688565254211 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 188.1870846748352 loss tensor(0.4348, grad_fn=<NegBackward0>)\n",
            "Time 188.2650396823883 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 188.32528138160706 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 188.4053134918213 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 188.4776909351349 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 188.54925274848938 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 188.61687850952148 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 188.6853940486908 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 188.7530002593994 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 188.8162715435028 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 188.88052797317505 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 188.9518117904663 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 189.01794958114624 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 189.08097195625305 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 189.14310479164124 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 189.2065668106079 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 189.26796221733093 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 189.33166074752808 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 189.3983027935028 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 189.468989610672 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 189.53864669799805 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 189.59271001815796 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 189.63829517364502 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 189.69547843933105 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 189.73818445205688 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 189.78203797340393 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 189.82365775108337 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 189.86378264427185 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 189.9150915145874 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 189.95804738998413 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 189.99901032447815 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 190.04604482650757 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 190.08902502059937 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 190.13725781440735 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 190.17777299880981 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 190.21817255020142 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 190.25954580307007 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 190.30590319633484 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 190.36382293701172 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 190.40343379974365 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 190.45341205596924 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 190.49664187431335 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 190.5377926826477 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 190.58986592292786 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 190.63361501693726 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 190.67915153503418 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 190.72908782958984 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 190.7711410522461 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 190.8246910572052 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 190.86922430992126 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 190.9128613471985 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 190.96026062965393 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 191.0155439376831 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 191.06657457351685 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 191.11405539512634 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 191.1566081047058 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 191.1968011856079 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 191.237206697464 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 191.28573989868164 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 191.32590317726135 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 191.36574602127075 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 191.4121024608612 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 191.4569091796875 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 191.5088393688202 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 191.55123138427734 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 191.59421014785767 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 191.63489437103271 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 191.68558502197266 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 191.73256874084473 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 191.7734558582306 loss tensor(0.4312, grad_fn=<NegBackward0>)\n",
            "Time 191.8140525817871 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 191.85810470581055 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 191.9029679298401 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 191.95244908332825 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 191.99325013160706 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 192.04282236099243 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 192.0842010974884 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 192.12594294548035 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 192.1736662387848 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 192.21386575698853 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 192.25468039512634 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 192.30030584335327 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 192.34178400039673 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 192.38691425323486 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 192.43141984939575 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 192.4757580757141 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 192.52216124534607 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 192.5674810409546 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 192.61491799354553 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 192.65658855438232 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 192.6973419189453 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 192.74000024795532 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 192.78098106384277 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 192.83479952812195 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 192.88757014274597 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 192.93392181396484 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 192.97562074661255 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 193.01862120628357 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 193.06753373146057 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 193.11112880706787 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 193.1511414051056 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 193.19119334220886 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 193.2310073375702 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 193.27419352531433 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 193.31702661514282 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 193.3569667339325 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 193.39801263809204 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 193.43856382369995 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 193.4803650379181 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 193.54285717010498 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 193.58416152000427 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 193.62804555892944 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 193.67201614379883 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 193.71993708610535 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 193.76231598854065 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 193.80245876312256 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 193.8448145389557 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 193.88702869415283 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 193.93772792816162 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 193.98334527015686 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 194.0255103111267 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 194.06525230407715 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 194.10590839385986 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 194.1582887172699 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 194.19884610176086 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 194.23999977111816 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 194.27971172332764 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 194.31956315040588 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 194.35928773880005 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 194.40848565101624 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 194.4492483139038 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 194.48883438110352 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 194.54560613632202 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 194.5946843624115 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 194.6410038471222 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 194.6819293498993 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 194.72231602668762 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 194.76203060150146 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 194.8125376701355 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 194.85378289222717 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 194.89344596862793 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 194.94148015975952 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 194.98147296905518 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 195.0302221775055 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 195.07757949829102 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 195.1169741153717 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 195.15853428840637 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 195.19918823242188 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 195.24903559684753 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 195.2905719280243 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 195.33068537712097 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 195.37073516845703 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 195.41079545021057 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 195.4542772769928 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 195.49795603752136 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 195.54753923416138 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 195.5922040939331 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 195.63247656822205 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 195.68167924880981 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 195.723548412323 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 195.76579475402832 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 195.8140869140625 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 195.85530066490173 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 195.90706157684326 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 195.9489164352417 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 195.9901909828186 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 196.03323364257812 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 196.07437539100647 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 196.13248538970947 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 196.173513174057 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 196.213534116745 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 196.2538537979126 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 196.29406261444092 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 196.33667516708374 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 196.38650059700012 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 196.42666959762573 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 196.46773290634155 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 196.5079164505005 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 196.55858540534973 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 196.60766005516052 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 196.6512167453766 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 196.69347596168518 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 196.7360327243805 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 196.78276562690735 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 196.82368898391724 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 196.87195563316345 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 196.91933870315552 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 196.96130299568176 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 197.01585292816162 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 197.06259942054749 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 197.10273051261902 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 197.14385986328125 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 197.18440008163452 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 197.2326741218567 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 197.27310633659363 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 197.31314373016357 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 197.35877966880798 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 197.40052127838135 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 197.44547295570374 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 197.48917961120605 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 197.5293426513672 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 197.57176232337952 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 197.62899661064148 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 197.67548370361328 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 197.71710896492004 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 197.75743556022644 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 197.79662942886353 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 197.8393359184265 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 197.8848795890808 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 197.93266773223877 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 197.97878789901733 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 198.02149558067322 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 198.061616897583 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 198.10876178741455 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 198.15005660057068 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 198.19277215003967 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 198.2389018535614 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 198.2798216342926 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 198.32710218429565 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 198.36916255950928 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 198.43271589279175 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 198.47414422035217 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 198.52047300338745 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 198.5707471370697 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 198.61683011054993 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 198.66192531585693 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 198.70212960243225 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 198.7459032535553 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 198.79914450645447 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 198.83962869644165 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 198.87997436523438 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 198.92315316200256 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 198.9648470878601 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 199.01416516304016 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 199.05555200576782 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 199.10047841072083 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 199.14321398735046 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 199.19199395179749 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 199.24964594841003 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 199.2900791168213 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 199.33040857315063 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 199.37039351463318 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 199.41038060188293 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 199.4536166191101 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 199.5031442642212 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 199.5440423488617 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 199.59500098228455 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 199.66520428657532 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 199.73215579986572 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 199.79433012008667 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 199.85325121879578 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 199.93975353240967 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 200.0108404159546 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 200.07013940811157 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 200.1342432498932 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 200.19442653656006 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 200.25443530082703 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 200.31323766708374 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 200.3713893890381 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 200.43200206756592 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 200.49067163467407 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 200.55386400222778 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 200.61653327941895 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 200.68814134597778 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 200.74729919433594 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 200.80620312690735 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 200.86966466903687 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 200.93352508544922 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 200.99158644676208 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 201.05323672294617 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 201.11328673362732 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 201.17447328567505 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 201.2338263988495 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 201.29383754730225 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 201.35298466682434 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 201.41720628738403 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 201.4772171974182 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 201.53642868995667 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 201.5969808101654 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 201.66666722297668 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 201.7358341217041 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 201.80195379257202 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 201.86251878738403 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 201.9282374382019 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 201.98880529403687 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 202.05128622055054 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 202.11058926582336 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 202.18030285835266 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 202.24127197265625 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 202.29986214637756 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 202.35904097557068 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 202.43534088134766 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 202.49388456344604 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 202.5590558052063 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 202.62210988998413 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 202.69483137130737 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 202.7612006664276 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 202.82535886764526 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 202.88475465774536 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 202.95428204536438 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 203.01842951774597 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 203.08272671699524 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 203.14820051193237 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 203.23484253883362 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 203.27815890312195 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 203.31825757026672 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 203.35778903961182 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 203.39756417274475 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 203.43961548805237 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 203.4862926006317 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 203.5325927734375 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 203.57498979568481 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 203.61813735961914 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 203.66614603996277 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 203.71036982536316 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 203.75170421600342 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 203.79164361953735 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 203.84045147895813 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 203.8879771232605 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 203.92983651161194 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 203.9778459072113 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 204.02019119262695 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 204.06055116653442 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 204.10665488243103 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 204.14694571495056 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 204.18700671195984 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 204.23255944252014 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 204.27303957939148 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 204.3194649219513 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 204.36192917823792 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 204.40167260169983 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 204.44232487678528 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 204.4866213798523 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 204.53340792655945 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 204.57414650917053 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 204.61602139472961 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 204.65693426132202 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 204.69693279266357 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 204.75780630111694 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 204.8029625415802 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 204.86693692207336 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 204.90851521492004 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 204.95152044296265 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 205.00272274017334 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 205.04795956611633 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 205.08964323997498 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 205.12978172302246 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 205.1698088645935 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 205.2204031944275 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 205.2623062133789 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 205.3030722141266 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 205.3539011478424 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 205.3953263759613 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 205.44527578353882 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 205.48565196990967 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 205.5254111289978 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 205.56526160240173 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 205.6079878807068 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 205.66153287887573 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 205.70659160614014 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 205.74756264686584 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 205.7875165939331 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 205.82730793952942 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 205.886643409729 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 205.92796516418457 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 205.97002339363098 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 206.01355123519897 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 206.05519938468933 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 206.1042058467865 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 206.14459109306335 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 206.18442392349243 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 206.22457933425903 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 206.26926851272583 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 206.31430411338806 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 206.35754084587097 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 206.4175717830658 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 206.45877504348755 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 206.49877262115479 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 206.54655981063843 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 206.5889811515808 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 206.63295459747314 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 206.67470049858093 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 206.71558165550232 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 206.76157402992249 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 206.80400896072388 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 206.84532976150513 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 206.8960666656494 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 206.94307017326355 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 206.9908082485199 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 207.04058480262756 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 207.0826563835144 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 207.1235203742981 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 207.16465735435486 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 207.2108006477356 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 207.25080966949463 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 207.29141426086426 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 207.3313000202179 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 207.37141513824463 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 207.41515278816223 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 207.4677803516388 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 207.50823855400085 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 207.54896759986877 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 207.589013338089 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 207.63605618476868 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 207.6777844429016 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 207.71844744682312 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 207.75897455215454 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 207.8001103401184 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 207.85119676589966 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 207.90210127830505 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 207.9451403617859 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 207.98559522628784 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 208.02808666229248 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 208.0780143737793 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 208.12309002876282 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 208.1647732257843 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 208.20810341835022 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 208.2531702518463 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 208.30982494354248 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 208.3501501083374 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 208.39075016975403 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 208.43149065971375 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 208.4721496105194 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 208.51375007629395 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 208.55913829803467 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 208.60281562805176 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 208.6460633277893 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 208.68863201141357 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 208.73983097076416 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 208.7882685661316 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 208.83522176742554 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 208.87714505195618 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 208.9329674243927 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 208.98794174194336 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 209.03152179718018 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 209.07557344436646 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 209.12900257110596 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 209.1722285747528 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 209.22460222244263 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 209.26571655273438 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 209.3061625957489 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 209.34642815589905 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 209.38569474220276 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 209.4254813194275 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 209.47206687927246 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 209.51788234710693 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 209.55954837799072 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 209.60148549079895 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 209.65313005447388 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 209.70149040222168 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 209.7430398464203 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 209.78334593772888 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 209.82329487800598 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 209.87120938301086 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 209.91556572914124 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 209.97808051109314 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 210.04258823394775 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 210.0951476097107 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 210.13596391677856 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 210.1762764453888 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 210.2168469429016 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 210.25633811950684 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 210.29921913146973 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 210.34861636161804 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 210.3882236480713 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 210.4287610054016 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 210.46872997283936 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 210.51133847236633 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 210.5553059577942 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 210.59465646743774 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 210.64308166503906 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 210.6836335659027 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 210.73072409629822 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 210.77380108833313 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 210.813574552536 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 210.85627245903015 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 210.8989770412445 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 210.95391988754272 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 211.0082402229309 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 211.04806280136108 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 211.08823466300964 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 211.13292050361633 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 211.1813142299652 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 211.22158122062683 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 211.26583743095398 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 211.30639147758484 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 211.34656143188477 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 211.39016556739807 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 211.43286037445068 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 211.47300672531128 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 211.51305651664734 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 211.556250333786 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 211.6054790019989 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 211.6491231918335 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 211.69138431549072 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 211.7355318069458 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 211.7772352695465 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 211.8311264514923 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 211.8746349811554 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 211.91583514213562 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 211.9586796760559 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 212.02936792373657 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 212.0782573223114 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 212.11975646018982 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 212.16954731941223 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 212.212078332901 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 212.25311374664307 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 212.30149340629578 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 212.34357070922852 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 212.38421320915222 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 212.4260413646698 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 212.47218084335327 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 212.52055263519287 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 212.5629427433014 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 212.60476875305176 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 212.64913058280945 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 212.69052743911743 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 212.7365152835846 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 212.7784445285797 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 212.8245768547058 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 212.8736138343811 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 212.9140841960907 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 212.9648561477661 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 213.0085060596466 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 213.0610704421997 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 213.1014051437378 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 213.14903163909912 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 213.2029914855957 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 213.24403262138367 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 213.306627035141 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 213.37980699539185 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 213.45110940933228 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 213.51611042022705 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 213.57833862304688 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 213.64326858520508 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 213.712055683136 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 213.7730791568756 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 213.8386480808258 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 213.89917087554932 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 213.96590089797974 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 214.02874779701233 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 214.1039593219757 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 214.1632432937622 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 214.22661113739014 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 214.28528213500977 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 214.34382605552673 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 214.40222835540771 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 214.4668252468109 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 214.52768635749817 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 214.5869266986847 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 214.64598393440247 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 214.72345852851868 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 214.78364491462708 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 214.84311890602112 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 214.90463638305664 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 214.97998046875 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 215.04561376571655 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 215.1123242378235 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 215.17905068397522 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 215.25296878814697 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 215.31709337234497 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 215.38046026229858 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 215.44783520698547 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 215.5066421031952 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 215.56566715240479 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 215.632550239563 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 215.70022249221802 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 215.7596366405487 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 215.81828927993774 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 215.88187170028687 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 215.94865226745605 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 216.0126190185547 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 216.07081127166748 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 216.13011169433594 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 216.21186470985413 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 216.27764987945557 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 216.33732342720032 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 216.40470433235168 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 216.47115349769592 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 216.53190350532532 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 216.5906081199646 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 216.65321516990662 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 216.7393560409546 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 216.80726385116577 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 216.87400031089783 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 216.9167354106903 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 216.96564149856567 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 217.0084674358368 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 217.0487186908722 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 217.08908200263977 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 217.12941932678223 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 217.17252230644226 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 217.21945595741272 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 217.27440524101257 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 217.31436133384705 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 217.35453867912292 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 217.40353965759277 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 217.44378662109375 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 217.48871493339539 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 217.52907800674438 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 217.5692582130432 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 217.6116635799408 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 217.6555392742157 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 217.69973587989807 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 217.74580550193787 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 217.78776502609253 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 217.83569741249084 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 217.87658429145813 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 217.92163038253784 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 217.9640874862671 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 218.00968432426453 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 218.05673098564148 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 218.09730529785156 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 218.1449637413025 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 218.18531847000122 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 218.22527647018433 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 218.27965903282166 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 218.32472348213196 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 218.36404180526733 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 218.4040789604187 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 218.44920420646667 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 218.4971888065338 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 218.53725695610046 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 218.57664895057678 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 218.61852955818176 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 218.66393208503723 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 218.71108722686768 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 218.7582995891571 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 218.79717302322388 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 218.83717274665833 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 218.87959098815918 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 218.93091535568237 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 218.9746925830841 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 219.0162787437439 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 219.05959272384644 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 219.10765027999878 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 219.15534663200378 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 219.19491696357727 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 219.23554873466492 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 219.30316066741943 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 219.3442304134369 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 219.39264678955078 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 219.43455719947815 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 219.47918128967285 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 219.5200982093811 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 219.55905199050903 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 219.60429000854492 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 219.6476936340332 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 219.68934416770935 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 219.72908234596252 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 219.7749421596527 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 219.8237500190735 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 219.8682098388672 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 219.9092881679535 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 219.95259428024292 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 219.99331855773926 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 220.04867267608643 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 220.0942897796631 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 220.13797998428345 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 220.18067288398743 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 220.22172141075134 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 220.27509880065918 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 220.32160353660583 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 220.3639953136444 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 220.41186141967773 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 220.45509934425354 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 220.50069046020508 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 220.54136395454407 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 220.58097863197327 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 220.62153387069702 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 220.6616199016571 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 220.7156481742859 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 220.7625699043274 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 220.80430579185486 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 220.84485006332397 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 220.8900043964386 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 220.94126057624817 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 220.9859504699707 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 221.02928757667542 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 221.0691750049591 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 221.1091480255127 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 221.1546003818512 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 221.20048117637634 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 221.24043250083923 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 221.28308773040771 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 221.32709455490112 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 221.38251638412476 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 221.42199397087097 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 221.46227407455444 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 221.50220847129822 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 221.54371094703674 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 221.58879208564758 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 221.63882517814636 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 221.6879689693451 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 221.73010301589966 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 221.77264833450317 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 221.82375478744507 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 221.8659336566925 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 221.90655612945557 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 221.95011711120605 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 221.99359321594238 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 222.045325756073 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 222.0857617855072 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 222.133624792099 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 222.17385601997375 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 222.21508812904358 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 222.26259803771973 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 222.30316591262817 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 222.34288501739502 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 222.39149832725525 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 222.43347883224487 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 222.48347210884094 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 222.5316560268402 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 222.5736424922943 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 222.6140320301056 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 222.65374040603638 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 222.7002592086792 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 222.74026083946228 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 222.78222060203552 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 222.82378220558167 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 222.87023425102234 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 222.918518781662 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 222.96561884880066 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 223.01110124588013 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 223.05077290534973 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 223.09951186180115 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 223.1484649181366 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 223.18959307670593 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 223.23032140731812 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 223.27105569839478 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 223.31159257888794 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 223.35391783714294 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 223.40678596496582 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 223.4524827003479 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 223.492529630661 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 223.53302311897278 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 223.582417011261 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 223.62330317497253 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 223.66369009017944 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 223.7053942680359 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 223.74719548225403 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 223.79695081710815 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 223.8427379131317 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 223.88263773918152 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 223.92518210411072 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 223.96811938285828 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 224.0197036266327 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 224.06000089645386 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 224.10034799575806 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 224.143789768219 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 224.18340730667114 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 224.23124194145203 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 224.2812225818634 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 224.32130694389343 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 224.36062502861023 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 224.40798664093018 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 224.45772576332092 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 224.498797416687 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 224.53767943382263 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 224.5779218673706 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 224.6199324131012 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 224.66807317733765 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 224.7208514213562 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 224.7633500099182 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 224.80283093452454 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 224.84340977668762 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 224.89040899276733 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 224.93301010131836 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 224.97682452201843 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 225.02378034591675 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 225.0647096633911 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 225.11242198944092 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 225.16127181053162 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 225.2016441822052 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 225.24182605743408 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 225.28172159194946 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 225.32760620117188 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 225.36963367462158 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 225.40947318077087 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 225.45817613601685 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 225.49789094924927 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 225.55047273635864 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 225.59661149978638 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 225.63694953918457 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 225.678040266037 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 225.71809887886047 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 225.76715850830078 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 225.8110888004303 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 225.85362601280212 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 225.89952731132507 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 225.94892644882202 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 226.0167360305786 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 226.05792093276978 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 226.09752082824707 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 226.13882613182068 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 226.1792721748352 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 226.22141695022583 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 226.2681303024292 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 226.3085961341858 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 226.34825086593628 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 226.38870477676392 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 226.433260679245 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 226.49049925804138 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 226.53098607063293 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 226.57141208648682 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 226.61112213134766 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 226.6587212085724 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 226.70783162117004 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 226.75040078163147 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 226.79440712928772 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 226.84457278251648 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 226.902006149292 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 226.965350151062 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 227.03204250335693 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 227.09196591377258 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 227.15503549575806 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 227.21839118003845 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 227.28025269508362 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 227.3394660949707 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 227.40304923057556 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 227.4626772403717 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 227.54097652435303 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 227.5991563796997 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 227.6828465461731 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 227.74220538139343 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 227.80330419540405 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 227.87505888938904 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 227.9404594898224 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 228.00124883651733 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 228.06310296058655 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 228.1237256526947 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 228.19926643371582 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 228.25903010368347 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 228.31810188293457 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 228.37905049324036 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 228.44579935073853 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 228.50586009025574 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 228.5780873298645 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 228.63816285133362 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 228.71039462089539 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 228.77062058448792 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 228.8323211669922 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 228.89645051956177 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 228.9665069580078 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 229.02824807167053 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 229.08804845809937 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 229.14801287651062 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 229.22084522247314 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 229.2835717201233 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 229.3439199924469 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 229.40328431129456 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 229.47278761863708 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 229.5344467163086 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 229.59674096107483 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 229.67301177978516 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 229.74549055099487 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 229.81061029434204 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 229.87397503852844 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 229.94672918319702 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 230.01046109199524 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 230.07190990447998 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 230.13832473754883 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 230.19795036315918 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 230.25871801376343 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 230.32293176651 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 230.3898994922638 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 230.46057105064392 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 230.51361656188965 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 230.55373787879944 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 230.59699130058289 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 230.66051483154297 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 230.7152121067047 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 230.76830291748047 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 230.81495809555054 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 230.859699010849 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 230.90227723121643 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 230.94536519050598 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 230.98782062530518 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 231.03780579566956 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 231.07822608947754 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 231.12249875068665 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 231.16200256347656 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 231.20216727256775 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 231.2533082962036 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 231.29934430122375 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 231.34098649024963 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 231.3884482383728 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 231.42970442771912 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 231.476167678833 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 231.51876997947693 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 231.561133146286 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 231.6028687953949 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 231.64315271377563 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 231.69163823127747 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 231.7483468055725 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 231.78790807724 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 231.83119893074036 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 231.87592720985413 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 231.92258739471436 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 231.96353673934937 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 232.00749397277832 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 232.0467984676361 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 232.08677530288696 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 232.13023781776428 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 232.17470407485962 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 232.2140815258026 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 232.25898790359497 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 232.30005049705505 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 232.34892892837524 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 232.3910415172577 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 232.43161916732788 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 232.47114658355713 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 232.51080656051636 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 232.55743718147278 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 232.60427355766296 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 232.64464735984802 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 232.6842815876007 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 232.72963953018188 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 232.78513288497925 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 232.82640099525452 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 232.8736379146576 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 232.91533970832825 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 232.9563593864441 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 233.0074360370636 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 233.0475206375122 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 233.08798098564148 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 233.13125848770142 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 233.17231225967407 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 233.21896982192993 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 233.26411056518555 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 233.3037886619568 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 233.3449890613556 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 233.38525485992432 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 233.43227410316467 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 233.4808075428009 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 233.52409482002258 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 233.5643231868744 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 233.6044464111328 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 233.65571856498718 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 233.69921779632568 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 233.74107718467712 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 233.7981698513031 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 233.84198212623596 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 233.89207315444946 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 233.940012216568 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 233.99133610725403 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 234.03354287147522 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 234.07429838180542 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 234.12984776496887 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 234.17090606689453 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 234.21356177330017 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 234.26020669937134 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 234.3014030456543 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 234.34759759902954 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 234.38863801956177 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 234.4289116859436 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 234.46979999542236 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 234.51460456848145 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 234.56543350219727 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 234.60906887054443 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 234.6496775150299 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 234.6909589767456 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 234.73249197006226 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 234.78998732566833 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 234.8312964439392 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 234.87404251098633 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 234.91679501533508 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 234.96110606193542 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 235.0127465724945 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 235.05447602272034 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 235.09517455101013 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 235.14265394210815 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 235.18754124641418 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 235.2356071472168 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 235.28153944015503 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 235.32319283485413 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 235.3640100955963 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 235.4038622379303 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 235.45834636688232 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 235.50696420669556 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 235.55898880958557 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 235.60490202903748 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 235.64555668830872 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 235.69891095161438 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 235.74197554588318 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 235.78475737571716 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 235.84471583366394 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 235.8869912624359 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 235.93615078926086 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 235.97818732261658 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 236.02043104171753 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 236.06139874458313 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 236.1041021347046 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 236.15195631980896 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 236.19878816604614 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 236.24018716812134 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 236.28056287765503 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 236.32068252563477 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 236.37718105316162 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 236.41959261894226 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 236.4594168663025 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 236.5040578842163 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 236.5534508228302 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 236.6020860671997 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 236.6425542831421 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 236.68796014785767 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 236.7301037311554 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 236.77053451538086 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 236.81893634796143 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 236.87123656272888 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 236.91618537902832 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 236.9635717868805 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 237.010999917984 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 237.06191229820251 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 237.1027374267578 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 237.14394092559814 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 237.1849501132965 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 237.22507619857788 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 237.27233171463013 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 237.32035493850708 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 237.36216974258423 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 237.4021918773651 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 237.4428014755249 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 237.49090766906738 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 237.5313446521759 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 237.57385158538818 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 237.61315751075745 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 237.65614199638367 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 237.70758247375488 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 237.76078915596008 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 237.80204606056213 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 237.84417486190796 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 237.90051889419556 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 237.95332622528076 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 237.99544715881348 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 238.03781390190125 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 238.08439350128174 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 238.12650156021118 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 238.1792962551117 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 238.22196745872498 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 238.2624056339264 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 238.30255007743835 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 238.34452366828918 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 238.40348887443542 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 238.44449090957642 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 238.4845485687256 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 238.5247242450714 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 238.564688205719 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 238.60442185401917 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 238.65953588485718 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 238.70106410980225 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 238.75056838989258 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 238.79374051094055 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 238.84505200386047 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 238.89797925949097 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 238.94013381004333 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 238.98206043243408 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 239.02527713775635 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 239.07247948646545 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 239.11379170417786 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 239.15631079673767 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 239.1984589099884 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 239.2407078742981 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 239.29077053070068 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 239.3341028690338 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 239.37421989440918 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 239.41461515426636 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 239.4598081111908 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 239.5211489200592 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 239.56201601028442 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 239.6130862236023 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 239.6545286178589 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 239.698566198349 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 239.7486708164215 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 239.78927612304688 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 239.8306474685669 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 239.87261128425598 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 239.92019867897034 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 239.9679651260376 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 240.01917958259583 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 240.06818962097168 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 240.10997414588928 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 240.1494734287262 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 240.1999545097351 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 240.23929572105408 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 240.2785997390747 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 240.34032082557678 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 240.38756275177002 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 240.43557381629944 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 240.4758563041687 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 240.5300374031067 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 240.59471344947815 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 240.66383051872253 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 240.72468781471252 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 240.78751754760742 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 240.84854912757874 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 240.92843461036682 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 240.99467968940735 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 241.05516386032104 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 241.1153438091278 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 241.17987656593323 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 241.23836755752563 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 241.29612827301025 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 241.35444164276123 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 241.41748046875 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 241.47592663764954 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 241.53482151031494 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 241.59303450584412 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 241.65713453292847 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 241.7349123954773 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 241.80006003379822 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 241.8645737171173 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 241.9266266822815 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 241.9910261631012 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 242.05446100234985 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 242.11786937713623 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 242.17664289474487 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 242.23491787910461 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 242.29307532310486 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 242.3582694530487 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 242.41650438308716 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 242.47475218772888 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 242.5348663330078 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 242.59808087348938 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 242.66195273399353 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 242.72301769256592 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 242.78363275527954 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 242.84593272209167 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 242.907785654068 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 242.9711320400238 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 243.04196786880493 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 243.11102986335754 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 243.17029547691345 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 243.2291078567505 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 243.2872552871704 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 243.36083602905273 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 243.42044115066528 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 243.48286509513855 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 243.54670429229736 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 243.61291766166687 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 243.67613291740417 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 243.73796272277832 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 243.79827284812927 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 243.86756825447083 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 243.92963218688965 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 243.99284505844116 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 244.0612177848816 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 244.14102792739868 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 244.20912551879883 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 244.26346015930176 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 244.30340051651 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 244.3431441783905 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 244.39179611206055 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 244.43219137191772 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 244.4775779247284 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 244.51779341697693 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 244.5633647441864 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 244.60354328155518 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 244.64358472824097 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 244.68300986289978 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 244.72305989265442 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 244.76283502578735 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 244.81479501724243 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 244.85825657844543 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 244.90155410766602 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 244.94608569145203 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 244.9858832359314 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 245.038170337677 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 245.07877254486084 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 245.12907886505127 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 245.17063283920288 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 245.2104663848877 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 245.27316975593567 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 245.31408166885376 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 245.35446453094482 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 245.39383220672607 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 245.43455839157104 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 245.47454714775085 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 245.52192401885986 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 245.56273007392883 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 245.6084020137787 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 245.64878129959106 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 245.69668412208557 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 245.7391209602356 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 245.7816345691681 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 245.82178497314453 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 245.87887239456177 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 245.93183708190918 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 245.9742431640625 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 246.01874828338623 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 246.05850410461426 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 246.09867238998413 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 246.14703607559204 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 246.19763493537903 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 246.2380337715149 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 246.27760934829712 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 246.31775403022766 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 246.37683486938477 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 246.41794300079346 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 246.45832633972168 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 246.4985728263855 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 246.54624342918396 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 246.59309244155884 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 246.63432788848877 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 246.6855194568634 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 246.72544598579407 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 246.76656198501587 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 246.81431984901428 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 246.85811924934387 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 246.89816403388977 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 246.94143867492676 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 246.98161220550537 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 247.03267216682434 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 247.07596564292908 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 247.11629486083984 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 247.15602469444275 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 247.21345353126526 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 247.26010704040527 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 247.3001720905304 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 247.33994722366333 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 247.37998485565186 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 247.4204978942871 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 247.45988655090332 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 247.51048040390015 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 247.55717849731445 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 247.59667325019836 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 247.636155128479 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 247.6855230331421 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 247.72670793533325 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 247.76744198799133 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 247.81058979034424 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 247.85100674629211 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 247.90404319763184 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 247.94692873954773 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 247.9863314628601 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 248.0293483734131 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 248.06912851333618 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 248.11618542671204 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 248.15743207931519 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 248.2068314552307 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 248.2476589679718 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 248.2870578765869 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 248.33671712875366 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 248.3855459690094 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 248.4266209602356 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 248.4660267829895 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 248.50625896453857 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 248.55340337753296 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 248.59357714653015 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 248.6379199028015 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 248.67627382278442 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 248.7190911769867 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 248.767240524292 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 248.8116147518158 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 248.85223579406738 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 248.89263153076172 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 248.93306636810303 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 248.98410558700562 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 249.02972841262817 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 249.07011938095093 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 249.10970211029053 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 249.14950394630432 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 249.19978952407837 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 249.24798035621643 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 249.2917001247406 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 249.34127497673035 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 249.38177609443665 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 249.42982649803162 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 249.4697675704956 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 249.51095747947693 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 249.55093336105347 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 249.59084296226501 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 249.6445436477661 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 249.68766474723816 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 249.72891306877136 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 249.76946806907654 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 249.81024718284607 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 249.85993933677673 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 249.90384531021118 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 249.9494433403015 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 249.9892578125 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 250.03266763687134 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 250.0786428451538 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 250.11876606941223 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 250.15940952301025 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 250.20605754852295 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 250.25676798820496 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 250.3202245235443 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 250.37815475463867 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 250.4199674129486 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 250.46186470985413 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 250.50221395492554 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 250.55450224876404 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 250.59466409683228 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 250.6504476070404 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 250.6903657913208 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 250.73343443870544 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 250.78229069709778 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 250.8229877948761 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 250.8632504940033 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 250.90441465377808 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 250.94656920433044 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 250.99293112754822 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 251.04471969604492 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 251.08556127548218 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 251.14227175712585 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 251.1980836391449 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 251.24297857284546 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 251.2913920879364 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 251.3313639163971 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 251.37605929374695 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 251.42241954803467 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 251.46235632896423 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 251.5019633769989 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 251.54208040237427 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 251.58213782310486 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 251.62206363677979 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 251.67496514320374 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 251.71722435951233 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 251.76393222808838 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 251.8077037334442 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 251.8553340435028 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 251.89592456817627 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 251.9367437362671 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 251.98100566864014 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 252.0246548652649 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 252.07093238830566 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 252.11336612701416 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 252.15396904945374 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 252.2018551826477 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 252.24262237548828 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 252.30478143692017 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 252.35064387321472 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 252.39326333999634 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 252.4338047504425 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 252.4740698337555 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 252.52184081077576 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 252.56216549873352 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 252.60190296173096 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 252.64896655082703 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 252.69201731681824 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 252.7397711277008 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 252.7819995880127 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 252.82195448875427 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 252.86250519752502 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 252.90649247169495 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 252.95508742332458 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 252.99809050559998 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 253.04247283935547 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 253.0847568511963 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 253.13141775131226 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 253.17827653884888 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 253.21865034103394 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 253.26627254486084 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 253.3062219619751 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 253.35510563850403 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 253.40267252922058 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 253.44286060333252 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 253.48311519622803 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 253.5272994041443 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 253.56930494308472 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 253.62274193763733 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 253.67049932479858 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 253.71772027015686 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 253.75942182540894 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 253.80215215682983 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 253.85306096076965 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 253.89421439170837 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 253.9344072341919 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 253.98259830474854 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 254.02795481681824 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 254.07666659355164 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 254.12520027160645 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 254.1684765815735 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 254.21110677719116 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 254.2546694278717 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 254.31847858428955 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 254.38810420036316 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 254.45731663703918 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 254.5315682888031 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 254.6020429134369 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 254.6630563735962 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 254.72224760055542 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 254.78899955749512 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 254.8564121723175 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 254.92048716545105 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 254.98541617393494 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 255.06136226654053 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 255.1202826499939 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 255.1795711517334 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 255.24146389961243 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 255.31507873535156 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 255.38012027740479 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 255.44103956222534 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 255.50117754936218 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 255.56656575202942 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 255.62630438804626 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 255.69897174835205 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 255.7589409351349 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 255.82458877563477 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 255.88509893417358 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 255.9438281059265 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 256.0092315673828 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 256.0815839767456 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 256.14053678512573 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 256.19879961013794 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 256.2627673149109 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 256.33626198768616 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 256.39544320106506 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 256.4657413959503 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 256.5252242088318 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 256.6028332710266 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 256.66374611854553 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 256.72888445854187 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 256.7882492542267 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 256.85328674316406 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 256.91287565231323 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 256.97328758239746 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 257.03758907318115 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 257.1000759601593 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 257.1641983985901 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 257.2281107902527 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 257.2868187427521 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 257.35128808021545 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 257.4146192073822 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 257.4805278778076 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 257.5441710948944 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 257.6053397655487 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 257.67030358314514 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 257.73495984077454 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 257.80260396003723 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 257.86690306663513 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 257.9091911315918 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 257.9551320075989 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 257.99533867836 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 258.04121351242065 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 258.0883274078369 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 258.1305706501007 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 258.1704111099243 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 258.2295033931732 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 258.27278184890747 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 258.32215642929077 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 258.36201572418213 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 258.4028129577637 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 258.44267988204956 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 258.4839699268341 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 258.5409150123596 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 258.5841021537781 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 258.62362933158875 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 258.6656219959259 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 258.7090537548065 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 258.75728726387024 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 258.7972083091736 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 258.8368408679962 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 258.87868070602417 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 258.9184741973877 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 258.96348810195923 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 259.0098762512207 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 259.0514163970947 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 259.0941197872162 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 259.13472151756287 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 259.18118500709534 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 259.228967666626 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 259.27371048927307 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 259.31350564956665 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 259.3608157634735 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 259.40876507759094 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 259.44836235046387 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 259.4874978065491 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 259.5363256931305 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 259.5810263156891 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 259.6358983516693 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 259.67520785331726 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 259.71941924095154 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 259.7605040073395 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 259.8006172180176 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 259.84624338150024 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 259.89020228385925 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 259.93286633491516 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 259.9745280742645 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 260.0188875198364 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 260.067996263504 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 260.1091859340668 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 260.14964628219604 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 260.1966235637665 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 260.2381663322449 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 260.2882833480835 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 260.3350019454956 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 260.3749899864197 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 260.4148323535919 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 260.4547152519226 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 260.49940156936646 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 260.54689264297485 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 260.59323596954346 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 260.63913106918335 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 260.6800775527954 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 260.72847628593445 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 260.77380323410034 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 260.8180248737335 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 260.8585081100464 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 260.900160074234 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 260.94707703590393 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 260.988543510437 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 261.0332226753235 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 261.0725529193878 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 261.1123101711273 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 261.16737127304077 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 261.2088096141815 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 261.251638174057 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 261.3119421005249 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 261.3513140678406 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 261.39975237846375 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 261.4463996887207 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 261.4865255355835 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 261.52718591690063 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 261.57530975341797 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 261.623544216156 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 261.6699421405792 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 261.71180391311646 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 261.7521770000458 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 261.7943329811096 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 261.8476963043213 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 261.8883464336395 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 261.9276034832001 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 261.96885776519775 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 262.0111322402954 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 262.0641357898712 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 262.10426211357117 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 262.1440441608429 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 262.19184279441833 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 262.2313141822815 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 262.2776532173157 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 262.31953620910645 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 262.3586254119873 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 262.3982150554657 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 262.43826842308044 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 262.47819471359253 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 262.5251019001007 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 262.5724334716797 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 262.6244056224823 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 262.6653218269348 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 262.71358704566956 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 262.75486040115356 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 262.7981164455414 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 262.83900141716003 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 262.88284277915955 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 262.9301075935364 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 262.97214937210083 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 263.0233995914459 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 263.07570242881775 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 263.1161994934082 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 263.16922903060913 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 263.2116177082062 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 263.25201773643494 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 263.3019995689392 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 263.3416426181793 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 263.3882465362549 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 263.4289162158966 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 263.46960639953613 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 263.5105724334717 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 263.55098128318787 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 263.5922853946686 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 263.6538670063019 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 263.6986458301544 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 263.7405924797058 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 263.7847430706024 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 263.8353955745697 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 263.8786165714264 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 263.9186613559723 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 263.9600396156311 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 264.00101923942566 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 264.05433773994446 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 264.09601068496704 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 264.13682079315186 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 264.176944732666 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 264.2179698944092 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 264.2711560726166 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 264.31212520599365 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 264.35342502593994 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 264.4027590751648 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 264.4437518119812 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 264.4927546977997 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 264.53922605514526 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 264.5811347961426 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 264.62068700790405 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 264.6697533130646 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 264.72235560417175 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 264.76317024230957 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 264.8029489517212 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 264.8444380760193 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 264.88551092147827 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 264.9286437034607 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 264.9730854034424 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 265.01958179473877 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 265.06388807296753 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 265.1037471294403 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 265.158545255661 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 265.1989233493805 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 265.23884868621826 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 265.2801842689514 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 265.32284712791443 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 265.3675374984741 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 265.41178131103516 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 265.4521453380585 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 265.49238753318787 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 265.5393006801605 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 265.59128618240356 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 265.6328341960907 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 265.6829369068146 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 265.72528052330017 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 265.768212556839 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 265.81682801246643 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 265.85893511772156 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 265.902583360672 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 265.9458808898926 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 265.98606729507446 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 266.0356900691986 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 266.08045744895935 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 266.1217107772827 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 266.1668779850006 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 266.20733308792114 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 266.25627970695496 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 266.30896830558777 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 266.34929299354553 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 266.3893413543701 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 266.4292964935303 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 266.47516679763794 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 266.5182056427002 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 266.5584235191345 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 266.59866547584534 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 266.6451132297516 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 266.6981852054596 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 266.74248909950256 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 266.783109664917 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 266.82657122612 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 266.86811923980713 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 266.9169397354126 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 266.9601273536682 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 267.008159160614 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 267.04987025260925 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 267.0914797782898 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 267.1384811401367 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 267.1829798221588 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 267.22359442710876 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 267.26367378234863 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 267.3119924068451 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 267.360714673996 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 267.40193581581116 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 267.44475650787354 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 267.4852149486542 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 267.52554059028625 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 267.5688409805298 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 267.6117126941681 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 267.6527352333069 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 267.70186495780945 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 267.7541034221649 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 267.80192399024963 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 267.84419202804565 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 267.8977999687195 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 267.9573473930359 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 268.0256493091583 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 268.0877194404602 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 268.14766788482666 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 268.20788288116455 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 268.2849349975586 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 268.35617780685425 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 268.41656589508057 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 268.4776430130005 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 268.5436427593231 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 268.6057529449463 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 268.66724157333374 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 268.727801322937 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 268.80756878852844 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 268.86731457710266 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 268.9453389644623 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 269.0441210269928 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 269.1227288246155 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 269.1811602115631 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 269.23903632164 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 269.30399465560913 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 269.36365365982056 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 269.42251086235046 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 269.4806933403015 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 269.54675030708313 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 269.60624980926514 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 269.6651327610016 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 269.7253141403198 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 269.7919783592224 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 269.8691473007202 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 269.9477307796478 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 270.0160160064697 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 270.0807068347931 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 270.1405782699585 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 270.19818663597107 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 270.26304841041565 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 270.321720123291 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 270.37968945503235 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 270.43857526779175 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 270.5017890930176 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 270.56126713752747 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 270.6203033924103 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 270.67935013771057 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 270.75331687927246 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 270.81734800338745 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 270.8849194049835 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 270.94904232025146 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 271.01368379592896 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 271.0751073360443 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 271.13757157325745 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 271.20070457458496 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 271.2646405696869 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 271.323673248291 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 271.38805198669434 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 271.4537355899811 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 271.52390575408936 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 271.5807738304138 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 271.6269483566284 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 271.6683166027069 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 271.7099840641022 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 271.76128911972046 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 271.8023693561554 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 271.85408997535706 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 271.9091320037842 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 271.95118975639343 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 272.0103220939636 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 272.05180859565735 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 272.0911314487457 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 272.13322949409485 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 272.17271661758423 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 272.21518445014954 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 272.26720094680786 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 272.30918312072754 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 272.3537244796753 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 272.3949658870697 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 272.44527077674866 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 272.48506140708923 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 272.5251796245575 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 272.56510972976685 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 272.6050727367401 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 272.64578223228455 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 272.69407653808594 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 272.73751640319824 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 272.77888536453247 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 272.8208980560303 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 272.86784529685974 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 272.915442943573 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 272.9590005874634 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 272.9990029335022 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 273.0411186218262 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 273.09156680107117 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 273.1357126235962 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 273.17583656311035 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 273.21632146835327 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 273.25619745254517 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 273.30482625961304 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 273.3463912010193 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 273.3860414028168 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 273.434597492218 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 273.474072933197 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 273.52262258529663 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 273.56274938583374 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 273.6023485660553 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 273.6420428752899 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 273.68152379989624 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 273.73068380355835 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 273.7741496562958 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 273.8169949054718 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 273.86039423942566 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 273.90159821510315 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 273.9545624256134 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 273.99803161621094 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 274.0404372215271 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 274.0850374698639 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 274.1275496482849 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 274.1842608451843 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 274.22512793540955 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 274.2655301094055 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 274.306086063385 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 274.3457884788513 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 274.385235786438 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 274.4399507045746 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 274.4792628288269 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 274.52340507507324 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 274.56296825408936 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 274.612521648407 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 274.6521987915039 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 274.6937358379364 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 274.7341516017914 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 274.7738263607025 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 274.81581234931946 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 274.8624424934387 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 274.9022092819214 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 274.9441268444061 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 274.9940297603607 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 275.04255270957947 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 275.0833246707916 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 275.12473249435425 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 275.1693067550659 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 275.20978331565857 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 275.2565743923187 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 275.3101444244385 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 275.3508598804474 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 275.390682220459 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 275.4308638572693 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 275.47694277763367 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 275.5198931694031 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 275.5610132217407 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 275.60242986679077 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 275.64352583885193 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 275.69101428985596 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 275.73450803756714 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 275.78098797798157 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 275.8228075504303 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 275.86200499534607 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 275.90850734710693 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 275.9545307159424 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 276.00430846214294 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 276.04482865333557 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 276.09436678886414 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 276.1429886817932 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 276.1853668689728 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 276.22612166404724 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 276.2664268016815 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 276.307279586792 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 276.3538513183594 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 276.3978223800659 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 276.43823432922363 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 276.4788451194763 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 276.520174741745 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 276.5660994052887 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 276.6086845397949 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 276.6480362415314 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 276.68768191337585 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 276.73192071914673 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 276.77918910980225 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 276.82575488090515 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 276.86509823799133 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 276.9063289165497 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 276.9477994441986 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 276.99392080307007 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 277.045533657074 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 277.0867567062378 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 277.1299967765808 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 277.16958379745483 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 277.2157745361328 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 277.2660264968872 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 277.30621910095215 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 277.34644532203674 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 277.3871102333069 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 277.4356927871704 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 277.4763422012329 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 277.5338599681854 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 277.59071588516235 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 277.6525628566742 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 277.70316100120544 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 277.74601650238037 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 277.7887194156647 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 277.8293950557709 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 277.87777519226074 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 277.9193034172058 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 277.96408772468567 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 278.00799202919006 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 278.0608403682709 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 278.1101961135864 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 278.15307664871216 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 278.192982673645 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 278.2339391708374 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 278.27368903160095 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 278.31727504730225 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 278.36129570007324 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 278.405903339386 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 278.4463815689087 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 278.4870934486389 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 278.53590726852417 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 278.58057498931885 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 278.62042260169983 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 278.6635618209839 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 278.70251846313477 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 278.75096464157104 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 278.79312229156494 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 278.8343722820282 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 278.8747720718384 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 278.91987442970276 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 278.9683082103729 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 279.01115798950195 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 279.059428691864 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 279.1098988056183 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 279.15253734588623 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 279.2028419971466 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 279.24359583854675 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 279.28351616859436 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 279.32302498817444 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 279.3623278141022 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 279.4017963409424 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 279.452800989151 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 279.4926235675812 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 279.53524947166443 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 279.5756678581238 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 279.62209391593933 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 279.667578458786 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 279.72239542007446 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 279.769318819046 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 279.81196904182434 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 279.8615298271179 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 279.90155243873596 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 279.9422993659973 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 279.98317313194275 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 280.0271258354187 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 280.07567834854126 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 280.12863326072693 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 280.1710879802704 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 280.2111008167267 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 280.2517292499542 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 280.2980558872223 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 280.3427062034607 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 280.382595539093 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 280.42249059677124 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 280.46769618988037 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 280.5135474205017 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 280.5546860694885 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 280.5937304496765 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 280.6361780166626 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 280.676397562027 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 280.7192769050598 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 280.76976203918457 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 280.8100845813751 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 280.85485434532166 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 280.89683651924133 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 280.945631980896 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 280.9860837459564 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 281.0282881259918 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 281.0685715675354 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 281.12548184394836 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 281.17790055274963 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 281.2195997238159 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 281.2598555088043 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 281.2993607521057 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 281.33917450904846 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 281.37863755226135 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 281.4349389076233 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 281.4755828380585 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 281.51564955711365 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 281.55859446525574 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 281.62798857688904 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 281.69561529159546 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 281.7534770965576 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 281.8116593360901 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 281.8850555419922 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 281.9462218284607 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 282.01280546188354 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 282.07049679756165 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 282.15149545669556 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 282.2204113006592 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 282.29224729537964 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 282.35113978385925 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 282.4139151573181 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 282.4725561141968 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 282.53064703941345 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 282.59510111808777 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 282.65387415885925 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 282.71344566345215 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 282.77489399909973 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 282.8447995185852 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 282.9048271179199 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 282.9646005630493 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 283.0279426574707 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 283.0977077484131 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 283.15922236442566 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 283.22360277175903 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 283.28260684013367 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 283.3484547138214 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 283.4072332382202 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 283.46640181541443 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 283.52459383010864 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 283.5896010398865 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 283.6510148048401 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 283.716938495636 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 283.77666544914246 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 283.84330129623413 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 283.9054503440857 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 283.9677813053131 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 284.029678106308 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 284.09546661376953 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 284.1541576385498 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 284.2154757976532 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 284.2784192562103 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 284.3424198627472 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 284.4010865688324 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 284.4592750072479 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 284.51769518852234 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 284.58833622932434 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 284.654736995697 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 284.7139570713043 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 284.77435874938965 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 284.8429231643677 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 284.910169839859 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 284.97181606292725 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 285.03820514678955 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 285.118173122406 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 285.1850290298462 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 285.2548987865448 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 285.31313920021057 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 285.3641574382782 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 285.40687227249146 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 285.44784784317017 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 285.48828411102295 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 285.5280210971832 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 285.57280445098877 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 285.6220121383667 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 285.6629936695099 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 285.7027316093445 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 285.7423961162567 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 285.79493618011475 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 285.8380904197693 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 285.8791027069092 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 285.9287521839142 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 285.97165989875793 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 286.0229468345642 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 286.0650804042816 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 286.1084761619568 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 286.1488378047943 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 286.19021129608154 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 286.23827862739563 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 286.27932572364807 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 286.32790446281433 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 286.3670675754547 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 286.4080533981323 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 286.4572968482971 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 286.50061225891113 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 286.5424189567566 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 286.5884597301483 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 286.6276330947876 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 286.6777331829071 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 286.72176241874695 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 286.7636573314667 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 286.80393385887146 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 286.8461892604828 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 286.90658235549927 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 286.94981837272644 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 286.99104404449463 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 287.0354001522064 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 287.0758397579193 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 287.12830352783203 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 287.17121267318726 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 287.213835477829 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 287.2541763782501 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 287.3046329021454 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 287.35947608947754 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 287.3990550041199 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 287.4420382976532 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 287.48675203323364 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 287.52701592445374 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 287.57813262939453 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 287.6207447052002 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 287.66218662261963 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 287.7040481567383 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 287.74525690078735 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 287.80148434638977 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 287.8529894351959 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 287.8952600955963 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 287.936425447464 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 287.98119592666626 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 288.03051352500916 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 288.0718493461609 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 288.11979365348816 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 288.16162395477295 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 288.2039096355438 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 288.2518289089203 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 288.2930028438568 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 288.334716796875 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 288.38471579551697 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 288.4275646209717 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 288.4751660823822 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 288.51552653312683 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 288.5633444786072 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 288.60282373428345 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 288.64515113830566 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 288.69219279289246 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 288.7342040538788 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 288.77686047554016 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 288.8184380531311 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 288.8597903251648 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 288.9118413925171 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 288.9565682411194 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 288.99811005592346 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 289.0417528152466 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 289.08367228507996 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 289.132972240448 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 289.1764533519745 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 289.2187623977661 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 289.26691794395447 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 289.30740666389465 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 289.35694313049316 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 289.40403294563293 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 289.44728326797485 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 289.4871075153351 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 289.5273096561432 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 289.5785880088806 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 289.6261827945709 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 289.66925859451294 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 289.71093130111694 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 289.7600245475769 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 289.80622458457947 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 289.84675669670105 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 289.89172315597534 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 289.93895268440247 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 289.9806020259857 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 290.03132581710815 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 290.07245922088623 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 290.11394786834717 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 290.15379428863525 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 290.19383358955383 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 290.2452836036682 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 290.2858874797821 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 290.3256151676178 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 290.3836405277252 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 290.42908000946045 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 290.4765853881836 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 290.51635789871216 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 290.55613374710083 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 290.5974636077881 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 290.6390070915222 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 290.68170261383057 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 290.7291531562805 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 290.7683699131012 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 290.8090674877167 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 290.8498303890228 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 290.89637780189514 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 290.94765639305115 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 290.98764276504517 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 291.0307939052582 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 291.07192063331604 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 291.12646889686584 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 291.1665222644806 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 291.20888352394104 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 291.2506024837494 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 291.2918059825897 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 291.34805631637573 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 291.38786911964417 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 291.43756651878357 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 291.48321199417114 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 291.5244071483612 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 291.5727939605713 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 291.62735247612 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 291.6788067817688 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 291.7207374572754 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 291.7622067928314 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 291.8175313472748 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 291.86035108566284 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 291.90090799331665 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 291.9425530433655 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 291.9892511367798 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 292.0379545688629 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 292.08435559272766 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 292.1258337497711 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 292.16642928123474 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 292.20799016952515 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 292.2541801929474 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 292.29301142692566 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 292.3327615261078 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 292.3723261356354 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 292.4126093387604 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 292.46851682662964 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 292.5145082473755 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 292.5547516345978 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 292.59467577934265 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 292.6521921157837 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 292.7005240917206 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 292.74598240852356 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 292.78862977027893 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 292.8288953304291 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 292.87759947776794 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 292.9284234046936 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 292.9697787761688 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 293.01248478889465 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 293.062294960022 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 293.1048574447632 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 293.153315782547 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 293.19322395324707 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 293.2350552082062 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 293.2748625278473 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 293.31491327285767 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 293.3547546863556 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 293.40421891212463 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 293.4522111415863 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 293.4941713809967 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 293.53437304496765 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 293.58823466300964 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 293.6314001083374 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 293.67298221588135 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 293.7173283100128 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 293.75674772262573 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 293.8024501800537 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 293.8434989452362 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 293.8839919567108 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 293.9231345653534 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 293.96458888053894 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 294.0303268432617 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 294.07380080223083 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 294.11444878578186 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 294.1641745567322 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 294.20434284210205 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 294.2534124851227 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 294.2934491634369 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 294.33441853523254 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 294.3758804798126 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 294.41700196266174 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 294.4619176387787 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 294.5200138092041 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 294.5611503124237 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 294.60129570961 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 294.6412215232849 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 294.68737864494324 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 294.72801780700684 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 294.7699043750763 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 294.8154709339142 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 294.8594014644623 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 294.92384219169617 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 294.9797132015228 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 295.0273015499115 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 295.0682792663574 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 295.1101131439209 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 295.1659984588623 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 295.20734095573425 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 295.25018095970154 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 295.31158995628357 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 295.37580966949463 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 295.44300174713135 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 295.51739978790283 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 295.58186078071594 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 295.6427004337311 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 295.72132444381714 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 295.79734349250793 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 295.86476039886475 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 295.92515802383423 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 295.9855709075928 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 296.0536599159241 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 296.1187264919281 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 296.1768443584442 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 296.23990964889526 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 296.32435035705566 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 296.38405990600586 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 296.4502041339874 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 296.5244212150574 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 296.5947275161743 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 296.66512799263 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 296.73602414131165 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 296.795037984848 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 296.85504126548767 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 296.92948961257935 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 297.00799083709717 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 297.070285320282 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 297.13184785842896 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 297.19975090026855 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 297.2756841182709 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 297.34358167648315 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 297.40620470046997 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 297.46509766578674 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 297.5368711948395 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 297.6029534339905 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 297.6627721786499 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 297.72836351394653 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 297.7956347465515 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 297.85691928863525 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 297.91829800605774 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 297.9835464954376 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 298.05867314338684 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 298.12078833580017 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 298.1850914955139 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 298.2504839897156 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 298.3260726928711 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 298.3951086997986 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 298.45667600631714 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 298.51891446113586 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 298.5857901573181 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 298.65745639801025 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 298.725723028183 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 298.80248856544495 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 298.8689591884613 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 298.9236001968384 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 298.96528840065 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 299.01476669311523 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 299.0642499923706 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 299.1066474914551 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 299.153342962265 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 299.19316506385803 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 299.24374628067017 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 299.2853708267212 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 299.3254737854004 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 299.36581778526306 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 299.4049623012543 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 299.44480323791504 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 299.4976773262024 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 299.53749895095825 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 299.5802381038666 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 299.62199664115906 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 299.6962242126465 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 299.73758578300476 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 299.7885687351227 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 299.8412778377533 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 299.8847756385803 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 299.93930554389954 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 299.9801754951477 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 300.02834248542786 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 300.0711486339569 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 300.1125793457031 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 300.17198872566223 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 300.21512055397034 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 300.2725086212158 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 300.327969789505 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 300.3691132068634 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 300.4185733795166 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 300.46213459968567 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 300.50345396995544 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 300.54699206352234 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 300.5886695384979 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 300.63827180862427 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 300.6799418926239 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 300.7291166782379 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 300.76880264282227 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 300.81055426597595 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 300.86115980148315 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 300.90641713142395 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 300.9475462436676 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 300.98750352859497 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 301.02960753440857 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 301.07676672935486 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 301.11802792549133 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 301.1580488681793 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 301.1982626914978 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 301.23856806755066 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 301.2814989089966 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 301.3397870063782 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 301.3804407119751 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 301.4218258857727 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 301.4624443054199 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 301.50905299186707 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 301.55069303512573 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 301.5920765399933 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 301.6325309276581 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 301.6822819709778 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 301.74464321136475 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 301.78958106040955 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 301.83039689064026 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 301.87182998657227 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 301.9128067493439 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 301.96247935295105 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 302.0025670528412 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 302.04439210891724 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 302.0847313404083 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 302.1257390975952 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 302.17544174194336 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 302.218230009079 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 302.25887846946716 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 302.31063628196716 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 302.34975957870483 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 302.3972144126892 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 302.43698382377625 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 302.4769012928009 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 302.516925573349 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 302.5569181442261 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 302.5972878932953 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 302.6471040248871 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 302.69760179519653 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 302.7385902404785 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 302.79345774650574 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 302.8443088531494 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 302.88679337501526 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 302.9341881275177 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 302.9864523410797 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 303.02912068367004 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 303.08032989501953 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 303.1255931854248 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 303.1691744327545 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 303.2101390361786 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 303.25156903266907 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 303.3051407337189 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 303.34580087661743 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 303.38566160202026 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 303.4274628162384 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 303.46751713752747 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 303.50898122787476 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 303.55575823783875 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 303.59630036354065 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 303.63698148727417 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 303.67806696891785 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 303.73207783699036 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 303.78059697151184 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 303.8208258152008 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 303.8607723712921 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 303.9019582271576 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 303.95252680778503 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 303.9935476779938 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 304.0414514541626 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 304.0818510055542 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 304.12522172927856 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 304.17279863357544 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 304.2119107246399 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 304.2510793209076 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 304.2972996234894 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 304.34175992012024 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 304.3915114402771 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 304.4331097602844 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 304.4737391471863 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 304.5138702392578 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 304.5536892414093 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 304.59506368637085 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 304.64504194259644 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 304.6860656738281 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 304.7317900657654 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 304.77438831329346 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 304.8330543041229 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 304.8740291595459 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 304.9157876968384 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 304.95762395858765 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 304.9980447292328 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 305.04557180404663 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 305.0884847640991 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 305.12934160232544 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 305.1727247238159 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 305.21254539489746 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 305.2651209831238 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 305.30557680130005 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 305.3499355316162 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 305.39013385772705 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 305.43098497390747 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 305.4972105026245 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 305.5439441204071 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 305.5856146812439 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 305.6339008808136 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 305.6771311759949 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 305.7278985977173 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 305.76718831062317 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 305.8136236667633 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 305.85815382003784 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 305.89853167533875 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 305.94905638694763 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 305.9923622608185 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 306.03440380096436 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 306.0747637748718 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 306.11527585983276 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 306.1637897491455 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 306.2088613510132 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 306.24800539016724 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 306.2882442474365 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 306.3383438587189 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 306.3897204399109 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 306.43148255348206 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 306.47190976142883 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 306.5121474266052 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 306.5548005104065 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 306.6039869785309 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 306.64489006996155 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 306.68607664108276 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 306.7278583049774 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 306.7679693698883 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 306.8104546070099 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 306.86954498291016 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 306.9096179008484 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 306.95229840278625 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 306.9937825202942 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 307.04959654808044 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 307.0900573730469 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 307.1323301792145 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 307.1761291027069 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 307.2262785434723 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 307.27902364730835 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 307.3203113079071 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 307.35967445373535 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 307.39939546585083 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 307.44016218185425 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 307.48128509521484 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 307.527366399765 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 307.5724775791168 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 307.61264657974243 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 307.65330362319946 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 307.69937348365784 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 307.7468509674072 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 307.7906837463379 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 307.83360290527344 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 307.88452911376953 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 307.9406044483185 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 307.98097681999207 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 308.0244381427765 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 308.0651361942291 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 308.11175203323364 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 308.15973925590515 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 308.1989860534668 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 308.24919390678406 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 308.2892904281616 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 308.33198380470276 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 308.3790855407715 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 308.4201593399048 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 308.46045088768005 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 308.500638961792 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 308.5412349700928 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 308.59161353111267 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 308.63817596435547 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 308.68156909942627 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 308.72353315353394 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 308.76617407798767 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 308.81471061706543 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 308.85651421546936 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 308.9064004421234 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 308.9708197116852 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 309.044420003891 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 309.1064383983612 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 309.1662063598633 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 309.22858905792236 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 309.29426074028015 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 309.35821294784546 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 309.4167275428772 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 309.4754776954651 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 309.55177330970764 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 309.6148738861084 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 309.67339849472046 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 309.73469591140747 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 309.8065679073334 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 309.8661353588104 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 309.9316415786743 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 309.99828028678894 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 310.06688022613525 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 310.1285996437073 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 310.1875550746918 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 310.24939489364624 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 310.3209071159363 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 310.38335704803467 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 310.4434566497803 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 310.5021460056305 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 310.5668771266937 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 310.62635374069214 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 310.6860566139221 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 310.74845838546753 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 310.8158519268036 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 310.87851095199585 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 310.94046664237976 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 311.0099015235901 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 311.07292580604553 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 311.13472986221313 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 311.19432377815247 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 311.25413060188293 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 311.31630969047546 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 311.37888050079346 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 311.4387218952179 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 311.4984920024872 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 311.56789207458496 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 311.6275625228882 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 311.69683837890625 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 311.7582550048828 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 311.8256366252899 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 311.8932044506073 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 311.95625829696655 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 312.0319559574127 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 312.1037690639496 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 312.16557002067566 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 312.22767162323 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 312.30124592781067 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 312.36513352394104 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 312.4322998523712 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 312.498722076416 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 312.5747582912445 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 312.6273949146271 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 312.66911029815674 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 312.7134139537811 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 312.7608835697174 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 312.80197930336 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 312.8439464569092 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 312.88423109054565 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 312.93384885787964 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 312.98172783851624 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 313.02643966674805 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 313.0741431713104 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 313.1147141456604 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 313.1631853580475 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 313.2030334472656 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 313.2441325187683 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 313.2920832633972 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 313.3318200111389 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 313.38109946250916 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 313.4248023033142 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 313.4651017189026 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 313.5176019668579 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 313.5618734359741 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 313.6137742996216 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 313.65477871894836 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 313.69704151153564 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 313.73745465278625 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 313.77969765663147 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 313.8450620174408 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 313.888671875 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 313.9279634952545 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 313.96985387802124 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 314.0135066509247 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 314.06196308135986 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 314.1118338108063 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 314.15825843811035 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 314.198114156723 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 314.2388970851898 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 314.29586029052734 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 314.33711791038513 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 314.3778178691864 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 314.4201455116272 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 314.460467338562 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 314.503399848938 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 314.54903841018677 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 314.59447956085205 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 314.6355392932892 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 314.6781804561615 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 314.729864358902 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 314.7703185081482 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 314.8099389076233 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 314.8511097431183 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 314.9018003940582 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 314.9539542198181 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 314.9960219860077 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 315.03836822509766 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 315.0787196159363 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 315.1284680366516 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 315.17675137519836 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 315.22328543663025 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 315.2646687030792 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 315.3072044849396 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 315.34741854667664 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 315.39565658569336 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 315.4357416629791 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 315.4796197414398 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 315.5198743343353 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 315.5605731010437 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 315.62547397613525 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 315.66593503952026 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 315.7064027786255 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 315.7480556964874 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 315.7879726886749 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 315.8291642665863 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 315.8755838871002 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 315.91858530044556 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 315.96101808547974 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 316.0187668800354 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 316.0695321559906 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 316.12516355514526 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 316.16928935050964 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 316.20902919769287 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 316.249849319458 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 316.29647183418274 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 316.33741998672485 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 316.37773847579956 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 316.42124795913696 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 316.4687337875366 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 316.5175144672394 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 316.5592632293701 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 316.6002073287964 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 316.64084815979004 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 316.68885564804077 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 316.7456877231598 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 316.7881410121918 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 316.83111810684204 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 316.8714716434479 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 316.91309428215027 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 316.9609258174896 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 317.00703954696655 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 317.0462522506714 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 317.090478181839 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 317.1313223838806 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 317.18494606018066 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 317.23007130622864 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 317.26952505111694 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 317.309828042984 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 317.3530912399292 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 317.4070813655853 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 317.44798016548157 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 317.48775005340576 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 317.52791571617126 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 317.57205986976624 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 317.61704897880554 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 317.66536259651184 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 317.7181899547577 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 317.7593584060669 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 317.7994291782379 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 317.84578251838684 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 317.89781737327576 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 317.95054388046265 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 317.99112582206726 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 318.03313660621643 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 318.0818407535553 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 318.1224093437195 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 318.1720132827759 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 318.2125172615051 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 318.26122069358826 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 318.31327772140503 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 318.35305738449097 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 318.3928394317627 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 318.4353652000427 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 318.4755744934082 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 318.5253987312317 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 318.57479596138 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 318.6170742511749 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 318.65907073020935 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 318.6998496055603 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 318.7512216567993 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 318.79367446899414 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 318.83324813842773 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 318.87791442871094 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 318.9186542034149 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 318.9665777683258 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 319.0169608592987 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 319.05675530433655 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 319.09767985343933 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 319.1385781764984 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 319.19986867904663 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 319.24328684806824 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 319.2834494113922 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 319.32319164276123 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 319.36303186416626 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 319.4052574634552 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 319.45250511169434 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 319.49369168281555 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 319.53426241874695 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 319.57591795921326 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 319.6355414390564 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 319.67898631095886 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 319.71998143196106 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 319.7600176334381 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 319.8025586605072 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 319.8528263568878 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 319.8973150253296 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 319.9411940574646 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 319.9832396507263 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 320.04279255867004 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 320.1042249202728 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 320.14397716522217 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 320.1838011741638 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 320.23159623146057 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 320.27163553237915 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 320.33190298080444 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 320.3729991912842 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 320.4135944843292 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 320.45484828948975 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 320.49508237838745 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 320.5395188331604 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 320.58272910118103 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 320.62828397750854 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 320.6715705394745 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 320.71505880355835 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 320.76415848731995 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 320.80475306510925 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 320.84493041038513 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 320.8865337371826 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 320.9277813434601 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 320.980774641037 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 321.0252614021301 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 321.066193819046 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 321.10667634010315 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 321.1481239795685 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 321.1935610771179 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 321.2464702129364 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 321.28683972358704 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 321.3339583873749 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 321.38394689559937 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 321.4342427253723 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 321.4744563102722 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 321.51441955566406 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 321.55468559265137 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 321.59873843193054 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 321.6506016254425 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 321.6947326660156 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 321.7375383377075 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 321.7776343822479 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 321.817095041275 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 321.8675127029419 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 321.929559469223 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 321.98291087150574 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 322.03799414634705 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 322.09302854537964 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 322.15105390548706 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 322.19537329673767 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 322.2394824028015 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 322.28716254234314 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 322.3536260128021 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 322.39867973327637 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 322.44183683395386 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 322.48245644569397 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 322.5222134590149 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 322.5696976184845 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 322.6190059185028 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 322.6829137802124 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 322.74463629722595 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 322.8195147514343 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 322.8819661140442 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 322.944904088974 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 323.01071763038635 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 323.0732831954956 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 323.1366431713104 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 323.1953012943268 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 323.255464553833 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 323.3306381702423 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 323.40340209007263 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 323.4656500816345 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 323.5249733924866 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 323.58799147605896 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 323.64736580848694 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 323.71152353286743 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 323.77031230926514 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 323.8332860469818 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 323.89313101768494 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 323.96284008026123 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 324.041109085083 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 324.10365056991577 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 324.1628363132477 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 324.22226190567017 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 324.28554797172546 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 324.3535752296448 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 324.42315697669983 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 324.4836525917053 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 324.54495668411255 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 324.60654520988464 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 324.66603231430054 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 324.7290210723877 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 324.8075249195099 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 324.86742520332336 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 324.9275290966034 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 324.9864273071289 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 325.05689096450806 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 325.1246163845062 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 325.1834270954132 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 325.24292826652527 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 325.32108306884766 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 325.38106632232666 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 325.45543384552 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 325.52025628089905 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 325.5916907787323 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 325.6506350040436 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 325.7126121520996 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 325.78579092025757 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 325.8499801158905 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 325.91937232017517 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 325.9807608127594 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 326.05313444137573 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 326.1196279525757 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 326.18432998657227 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 326.2383074760437 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 326.2904064655304 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 326.3307468891144 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 326.37069845199585 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 326.4123184680939 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 326.45167088508606 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 326.5078341960907 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 326.54855823516846 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 326.5888111591339 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 326.62949562072754 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 326.675678730011 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 326.7260391712189 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 326.76990485191345 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 326.8102686405182 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 326.8507037162781 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 326.8915705680847 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 326.93718457221985 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 326.98924136161804 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 327.03327894210815 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 327.0740022659302 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 327.11390709877014 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 327.16487169265747 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 327.2062613964081 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 327.24675846099854 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 327.2916479110718 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 327.33602476119995 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 327.38294529914856 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 327.4264850616455 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 327.4700791835785 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 327.51788687705994 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 327.5577893257141 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 327.61075615882874 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 327.65366530418396 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 327.69624423980713 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 327.737108707428 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 327.77764916419983 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 327.8250620365143 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 327.86670684814453 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 327.9095642566681 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 327.9512972831726 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 327.99147725105286 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 328.04320216178894 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 328.08282351493835 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 328.1285684108734 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 328.17025232315063 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 328.21054911613464 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 328.26922249794006 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 328.30968952178955 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 328.3499357700348 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 328.3902413845062 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 328.43005561828613 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 328.47582626342773 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 328.5385537147522 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 328.5797266960144 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 328.6247045993805 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 328.6646411418915 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 328.71656823158264 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 328.7568509578705 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 328.79698157310486 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 328.83894991874695 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 328.8819065093994 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 328.93561601638794 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 328.9811043739319 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 329.023996591568 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 329.07024216651917 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 329.128253698349 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 329.1909692287445 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 329.2446048259735 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 329.2905879020691 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 329.3303551673889 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 329.37068700790405 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 329.42090463638306 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 329.4625346660614 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 329.50421595573425 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 329.5556468963623 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 329.59669733047485 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 329.65251421928406 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 329.6925094127655 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 329.73483419418335 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 329.7776839733124 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 329.8184356689453 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 329.8627555370331 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 329.90715503692627 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 329.94977593421936 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 329.9903254508972 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 330.0332398414612 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 330.0824465751648 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 330.1296536922455 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 330.17004656791687 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 330.21569085121155 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 330.26866388320923 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 330.31689500808716 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 330.3565835952759 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 330.3960521221161 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 330.43610644340515 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 330.47777557373047 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 330.5173008441925 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 330.5751631259918 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 330.61811423301697 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 330.65952825546265 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 330.70230770111084 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 330.76135754585266 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 330.81352710723877 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 330.8545973300934 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 330.8994755744934 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 330.94211745262146 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 330.98929262161255 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 331.0317075252533 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 331.07593989372253 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 331.11638951301575 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 331.1562111377716 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 331.2044448852539 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 331.25488805770874 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 331.295045375824 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 331.3393325805664 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 331.3954613208771 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 331.44668316841125 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 331.4892153739929 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 331.53313279151917 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 331.5755753517151 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 331.63014936447144 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 331.6773431301117 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 331.7185015678406 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 331.7587969303131 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 331.79949498176575 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 331.8396186828613 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 331.8823482990265 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 331.93313479423523 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 331.9742622375488 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 332.039630651474 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 332.0838055610657 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 332.13079810142517 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 332.17163157463074 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 332.2111828327179 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 332.2505233287811 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 332.2985761165619 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 332.3386516571045 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 332.378333568573 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 332.43746542930603 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 332.48572993278503 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 332.5377838611603 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 332.57974004745483 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 332.62944293022156 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 332.6706807613373 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 332.71357345581055 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 332.76228404045105 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 332.80307817459106 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 332.84434819221497 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 332.8866274356842 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 332.9268877506256 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 332.97565627098083 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 333.0223069190979 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 333.06675958633423 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 333.11214566230774 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 333.15317487716675 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 333.20200300216675 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 333.25195384025574 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 333.29301142692566 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 333.33411931991577 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 333.3749644756317 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 333.42378759384155 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 333.46502232551575 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 333.50803995132446 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 333.5485417842865 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 333.58948135375977 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 333.65612149238586 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 333.704630613327 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 333.7470898628235 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 333.78776717185974 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 333.82892894744873 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 333.8785252571106 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 333.9212312698364 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 333.9636082649231 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 334.0073413848877 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 334.0487859249115 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 334.0956394672394 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 334.13695001602173 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 334.1860899925232 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 334.22653698921204 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 334.2675142288208 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 334.31980538368225 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 334.3683731555939 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 334.4093098640442 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 334.44930481910706 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 334.4939396381378 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 334.5460979938507 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 334.59407448768616 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 334.6351125240326 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 334.6956226825714 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 334.7376718521118 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 334.78598260879517 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 334.8272659778595 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 334.8678865432739 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 334.9094138145447 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 334.9509220123291 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 334.99871587753296 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 335.0451443195343 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 335.0871398448944 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 335.1276819705963 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 335.16735768318176 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 335.2149314880371 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 335.2568383216858 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 335.3006896972656 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 335.3419828414917 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 335.38264775276184 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 335.42767333984375 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 335.4689166545868 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 335.51108598709106 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 335.5514693260193 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 335.5925385951996 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 335.6379904747009 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 335.6933352947235 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 335.7372496128082 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 335.77928137779236 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 335.81958389282227 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 335.869833946228 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 335.91070652008057 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 335.9522955417633 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 335.9935669898987 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 336.03770637512207 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 336.0910029411316 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 336.13391613960266 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 336.1731262207031 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 336.21463346481323 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 336.28590631484985 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 336.3519661426544 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 336.4160461425781 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 336.4762854576111 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 336.5365557670593 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 336.61292552948 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 336.677259683609 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 336.74117612838745 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 336.8003525733948 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 336.86619448661804 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 336.9260907173157 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 336.9865884780884 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 337.04587864875793 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 337.10981249809265 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 337.1681504249573 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 337.22852420806885 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 337.2869167327881 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 337.35149025917053 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 337.4099426269531 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 337.4678945541382 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 337.52830815315247 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 337.5900695323944 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 337.6485137939453 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 337.71101665496826 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 337.7753007411957 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 337.8491084575653 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 337.9100227355957 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 337.9719727039337 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 338.03749799728394 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 338.1144585609436 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 338.17533230781555 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 338.236337184906 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 338.2956829071045 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 338.36724185943604 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 338.4278013706207 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 338.4871735572815 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 338.5481767654419 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 338.61406326293945 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 338.6730275154114 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 338.7327411174774 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 338.8000304698944 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 338.88115096092224 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 338.9421238899231 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 339.0145568847656 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 339.072879076004 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 339.13806891441345 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 339.19897532463074 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 339.26172852516174 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 339.32050013542175 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 339.39670753479004 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 339.45876908302307 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 339.5209250450134 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 339.580691576004 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 339.65778827667236 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 339.7322254180908 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 339.79717993736267 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 339.8706901073456 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 339.92445516586304 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 339.9709939956665 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 340.0158956050873 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 340.0561068058014 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 340.1049156188965 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 340.1476421356201 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 340.1871643066406 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 340.2286260128021 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 340.26939702033997 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 340.32747650146484 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 340.3697578907013 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 340.40986490249634 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 340.450483083725 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 340.4952416419983 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 340.5426290035248 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 340.58791613578796 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 340.63850498199463 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 340.6795964241028 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 340.72100925445557 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 340.7677936553955 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 340.8111307621002 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 340.85272908210754 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 340.8942139148712 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 340.94389295578003 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 341.00080156326294 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 341.05196952819824 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 341.09372448921204 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 341.1349229812622 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 341.17475605010986 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 341.2240936756134 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 341.2631859779358 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 341.309383392334 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 341.34939074516296 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 341.3896827697754 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 341.4355504512787 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 341.4773495197296 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 341.5180423259735 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 341.5608501434326 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 341.6061327457428 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 341.6561162471771 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 341.69668555259705 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 341.73821210861206 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 341.78079867362976 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 341.8223669528961 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 341.86620330810547 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 341.908499956131 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 341.9658031463623 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 342.0138702392578 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 342.0614504814148 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 342.111474275589 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 342.15166425704956 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 342.1912639141083 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 342.23290395736694 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 342.27702593803406 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 342.32470965385437 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 342.3667528629303 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 342.4061005115509 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 342.4460496902466 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 342.4859721660614 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 342.5296165943146 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 342.57583379745483 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 342.6157691478729 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 342.6647701263428 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 342.7081844806671 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 342.7569489479065 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 342.796927690506 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 342.83620262145996 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 342.8769021034241 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 342.9240732192993 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 342.9755356311798 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 343.03019547462463 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 343.0719861984253 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 343.1142272949219 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 343.1551887989044 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 343.20334649086 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 343.2484483718872 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 343.2890303134918 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 343.3289170265198 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 343.3755009174347 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 343.42521929740906 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 343.46519327163696 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 343.50584530830383 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 343.54630875587463 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 343.5901427268982 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 343.64054131507874 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 343.6840491294861 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 343.72491788864136 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 343.76655101776123 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 343.80705738067627 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 343.8519756793976 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 343.8961007595062 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 343.9370594024658 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 343.98026943206787 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 344.0319001674652 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 344.0865390300751 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 344.1378424167633 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 344.19211411476135 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 344.2444739341736 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 344.28959369659424 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 344.3360242843628 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 344.37593483924866 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 344.4161579608917 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 344.4562907218933 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 344.5105724334717 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 344.55223846435547 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 344.59373021125793 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 344.6336319446564 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 344.6735301017761 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 344.71352791786194 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 344.76775074005127 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 344.8098521232605 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 344.86024618148804 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 344.9042720794678 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 344.96183490753174 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 345.00568294525146 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 345.05641174316406 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 345.0985312461853 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 345.1443965435028 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 345.1901841163635 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 345.23809266090393 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 345.28090739250183 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 345.3228385448456 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 345.36421489715576 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 345.41105604171753 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 345.45125818252563 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 345.49075293540955 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 345.5308494567871 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 345.5711851119995 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 345.6187539100647 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 345.6674573421478 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 345.7089354991913 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 345.7495799064636 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 345.79007267951965 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 345.83701825141907 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 345.87765860557556 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 345.9201970100403 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 345.96295142173767 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 346.00324511528015 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 346.06560373306274 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 346.10955238342285 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 346.14946961402893 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 346.18901324272156 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 346.2299258708954 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 346.2730655670166 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 346.32041120529175 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 346.3600137233734 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 346.39989161491394 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 346.44434213638306 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 346.4906601905823 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 346.53165888786316 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 346.5753176212311 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 346.61706137657166 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 346.6598777770996 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 346.7107698917389 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 346.75282526016235 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 346.8020203113556 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 346.842732667923 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 346.8844566345215 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 346.9326901435852 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 346.97539591789246 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 347.0180368423462 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 347.0579581260681 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 347.10770654678345 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 347.1545262336731 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 347.19715309143066 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 347.2391333580017 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 347.2797157764435 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 347.31955790519714 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 347.3631353378296 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 347.4065189361572 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 347.4462077617645 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 347.48656010627747 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 347.5263693332672 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 347.5764033794403 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 347.6198115348816 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 347.6604835987091 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 347.7006154060364 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 347.7414791584015 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 347.7902293205261 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 347.83285307884216 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 347.8752934932709 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 347.9176893234253 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 347.96094131469727 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 348.0115559101105 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 348.0517678260803 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 348.0920624732971 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 348.1468734741211 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 348.18588280677795 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 348.2334804534912 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 348.2741050720215 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 348.3219792842865 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 348.36246037483215 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 348.4025945663452 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 348.4496304988861 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 348.49186062812805 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 348.53173875808716 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 348.5720601081848 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 348.6143021583557 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 348.66084814071655 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 348.7044258117676 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 348.7463586330414 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 348.7897186279297 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 348.8294732570648 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 348.87832045555115 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 348.9241306781769 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 348.96592807769775 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 349.00963950157166 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 349.0535771846771 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 349.1056272983551 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 349.1534767150879 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 349.1989486217499 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 349.2429702281952 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 349.2852849960327 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 349.3338849544525 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 349.3764235973358 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 349.4183073043823 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 349.4605233669281 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 349.5011475086212 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 349.55276322364807 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 349.59916377067566 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 349.64100408554077 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 349.6810665130615 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 349.72209119796753 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 349.7706959247589 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 349.81083726882935 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 349.8530821800232 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 349.8956949710846 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 349.956494808197 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 350.02177476882935 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 350.08096408843994 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 350.1422185897827 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 350.21494603157043 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 350.28355884552 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 350.342985868454 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 350.40417075157166 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 350.4680814743042 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 350.53482460975647 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 350.5949101448059 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 350.65700793266296 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 350.71661472320557 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 350.78575110435486 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 350.84789991378784 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 350.9071385860443 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 350.96841192245483 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 351.0424509048462 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 351.10328817367554 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 351.1635088920593 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 351.2294943332672 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 351.294869184494 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 351.35513138771057 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 351.41453886032104 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 351.47295689582825 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 351.5399720668793 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 351.5999119281769 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 351.6600911617279 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 351.7282292842865 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 351.79627084732056 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 351.85597467422485 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 351.91448497772217 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 351.9756579399109 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 352.05051279067993 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 352.1094424724579 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 352.1676540374756 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 352.22728204727173 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 352.30575346946716 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 352.365136384964 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 352.4234230518341 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 352.48181653022766 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 352.54646039009094 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 352.6209092140198 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 352.68880105018616 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 352.75686955451965 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 352.8299009799957 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 352.8969216346741 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 352.96064949035645 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 353.024090051651 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 353.08423376083374 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 353.15885186195374 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 353.2254104614258 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 353.2889349460602 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 353.3631181716919 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 353.43803906440735 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 353.5039463043213 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 353.571702003479 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 353.6268811225891 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 353.6680543422699 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 353.7086498737335 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 353.74857211112976 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 353.7986423969269 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 353.842089176178 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 353.8838427066803 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 353.9262251853943 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 353.9674277305603 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 354.01539516448975 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 354.05550503730774 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 354.1082820892334 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 354.1484887599945 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 354.18801951408386 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 354.2435257434845 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 354.2839136123657 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 354.3242154121399 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 354.37636160850525 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 354.4201273918152 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 354.4683003425598 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 354.5077838897705 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 354.54785919189453 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 354.5878963470459 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 354.629834651947 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 354.67161202430725 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 354.723069190979 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 354.76745796203613 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 354.8123416900635 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 354.85279870033264 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 354.90200901031494 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 354.9446539878845 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 354.98380970954895 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 355.02803325653076 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 355.06995010375977 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 355.1193616390228 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 355.1587221622467 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 355.1981554031372 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 355.2481269836426 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 355.2893023490906 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 355.35408997535706 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 355.41823649406433 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 355.45867466926575 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 355.4996416568756 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 355.540048122406 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 355.58758878707886 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 355.63030910491943 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 355.67287588119507 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 355.7182729244232 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 355.75944995880127 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 355.806941986084 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 355.8486764431 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 355.893940448761 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 355.9354000091553 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 355.97695755958557 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 356.0265374183655 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 356.06769037246704 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 356.1158480644226 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 356.15672969818115 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 356.19755506515503 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 356.2470488548279 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 356.2875180244446 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 356.3269510269165 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 356.3756971359253 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 356.43323397636414 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 356.48115968704224 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 356.52173686027527 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 356.5618853569031 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 356.60125160217285 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 356.65241265296936 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 356.7108771800995 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 356.7699282169342 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 356.81382513046265 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 356.85902094841003 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 356.9013364315033 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 356.9531772136688 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 356.99723529815674 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 357.0448889732361 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 357.0851755142212 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 357.12745785713196 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 357.1759021282196 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 357.2171788215637 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 357.25873255729675 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 357.29866123199463 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 357.3444404602051 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 357.39997243881226 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 357.45543932914734 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 357.4955234527588 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 357.5365357398987 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 357.5778646469116 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 357.62663173675537 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 357.66934752464294 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 357.7146601676941 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 357.76736998558044 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 357.8101558685303 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 357.85891103744507 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 357.8996617794037 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 357.9408597946167 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 357.98295974731445 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 358.02551794052124 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 358.07277035713196 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 358.11603140830994 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 358.1565682888031 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 358.20108222961426 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 358.24271416664124 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 358.28734707832336 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 358.33882451057434 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 358.37930393218994 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 358.41964769363403 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 358.4759294986725 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 358.526682138443 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 358.56728172302246 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 358.61854791641235 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 358.66466093063354 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 358.70752453804016 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 358.76461005210876 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 358.8185477256775 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 358.859037399292 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 358.90499782562256 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 358.94722390174866 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 358.9941236972809 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 359.0465807914734 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 359.0882604122162 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 359.13048100471497 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 359.1723051071167 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 359.2214913368225 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 359.2626783847809 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 359.30303835868835 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 359.3485541343689 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 359.3890554904938 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 359.43522572517395 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 359.4851152896881 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 359.53358793258667 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 359.5747113227844 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 359.61543226242065 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 359.66828632354736 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 359.72588896751404 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 359.7693347930908 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 359.80962109565735 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 359.8499479293823 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 359.8968632221222 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 359.9385817050934 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 359.98492646217346 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 360.0377881526947 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 360.0788471698761 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 360.12713980674744 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 360.1669406890869 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 360.2067790031433 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 360.2484567165375 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 360.2929005622864 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 360.35219073295593 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 360.3928020000458 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 360.43565464019775 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 360.475075006485 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 360.52329087257385 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 360.57157158851624 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 360.6125044822693 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 360.6558322906494 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 360.7004277706146 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 360.7430770397186 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 360.79429721832275 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 360.8351619243622 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 360.87657952308655 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 360.91883611679077 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 360.9622449874878 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 361.01507210731506 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 361.05744981765747 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 361.1011345386505 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 361.14207220077515 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 361.1871528625488 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 361.2349228858948 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 361.28623628616333 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 361.3375024795532 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 361.3840684890747 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 361.42379212379456 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 361.4698135852814 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 361.50956416130066 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 361.5589382648468 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 361.60378432273865 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 361.6459279060364 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 361.698602437973 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 361.7396938800812 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 361.7804992198944 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 361.8209128379822 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 361.8664610385895 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 361.9148359298706 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 361.9560582637787 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 361.99604773521423 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 362.0379877090454 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 362.0782859325409 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 362.12406158447266 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 362.1698136329651 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 362.21614837646484 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 362.2573912143707 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 362.2974011898041 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 362.3431615829468 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 362.38296389579773 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 362.4265251159668 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 362.4677050113678 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 362.5082049369812 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 362.5625214576721 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 362.6119327545166 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 362.6543266773224 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 362.70438289642334 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 362.7440662384033 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 362.79287910461426 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 362.83358430862427 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 362.8805658817291 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 362.92384934425354 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 362.96675395965576 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 363.01664543151855 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 363.05701780319214 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 363.10690093040466 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 363.14800453186035 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 363.1882059574127 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 363.2438745498657 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 363.28396105766296 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 363.32576632499695 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 363.36589217185974 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 363.4062650203705 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 363.4484579563141 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 363.50019121170044 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 363.54119753837585 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 363.58448028564453 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 363.64716124534607 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 363.71225905418396 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 363.7767233848572 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 363.8394618034363 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 363.8988764286041 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 363.96427512168884 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 364.0287992954254 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 364.08863258361816 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 364.1480026245117 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 364.2131426334381 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 364.27361392974854 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 364.3332920074463 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 364.39300870895386 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 364.45791959762573 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 364.51878333091736 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 364.5782742500305 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 364.64370799064636 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 364.717355966568 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 364.77779030799866 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 364.83784556388855 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 364.9051697254181 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 364.98522186279297 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 365.04786014556885 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 365.1072771549225 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 365.16588020324707 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 365.24012327194214 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 365.3008944988251 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 365.35909247398376 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 365.41853308677673 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 365.48463797569275 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 365.5473027229309 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 365.6103310585022 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 365.6809651851654 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 365.7592444419861 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 365.8240888118744 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 365.88625049591064 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 365.9473092556 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 366.02788376808167 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 366.08687710762024 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 366.153600692749 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 366.2186210155487 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 366.2810277938843 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 366.3402464389801 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 366.3978416919708 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 366.45658254623413 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 366.52152013778687 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 366.58590364456177 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 366.64605617523193 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 366.70835041999817 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 366.78552865982056 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 366.851895570755 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 366.9144616127014 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 366.97683095932007 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 367.04980540275574 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 367.117253780365 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 367.1819040775299 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 367.24864172935486 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 367.30913853645325 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 367.3537492752075 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 367.39509868621826 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 367.4379868507385 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 367.48703598976135 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 367.5277724266052 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 367.5703718662262 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 367.61260867118835 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 367.6560468673706 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 367.7109212875366 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 367.7652380466461 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 367.80670642852783 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 367.8474922180176 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 367.8917615413666 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 367.94393038749695 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 367.9853014945984 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 368.0311963558197 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 368.08077359199524 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 368.12475180625916 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 368.17922711372375 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 368.221617937088 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 368.26353454589844 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 368.3035936355591 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 368.3444676399231 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 368.3915259838104 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 368.4366419315338 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 368.477468252182 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 368.51932072639465 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 368.57001543045044 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 368.6189877986908 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 368.660897731781 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 368.7037122249603 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 368.7451355457306 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 368.79675030708313 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 368.8546953201294 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 368.9049482345581 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 368.94970965385437 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 368.99077796936035 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 369.03399324417114 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 369.08525466918945 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 369.126168012619 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 369.16715812683105 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 369.21133971214294 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 369.2528426647186 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 369.2984654903412 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 369.3493962287903 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 369.39020562171936 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 369.43052792549133 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 369.47122716903687 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 369.52080750465393 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 369.5613043308258 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 369.6021373271942 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 369.6470034122467 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 369.68952560424805 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 369.740425825119 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 369.78656458854675 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 369.83587408065796 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 369.87664222717285 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 369.9340469837189 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 369.9902665615082 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 370.03965640068054 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 370.08200430870056 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 370.1221261024475 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 370.16140365600586 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 370.2078790664673 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 370.24783182144165 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 370.28924202919006 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 370.3343505859375 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 370.3742935657501 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 370.4193069934845 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 370.46310591697693 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 370.50129199028015 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 370.54078483581543 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 370.5806303024292 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 370.6276798248291 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 370.6731276512146 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 370.715704202652 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 370.7567036151886 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 370.80025267601013 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 370.862117767334 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 370.9061288833618 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 370.94987535476685 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 370.99206471443176 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 371.03477358818054 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 371.0886926651001 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 371.129531621933 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 371.16950130462646 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 371.2281367778778 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 371.26985907554626 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 371.3175950050354 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 371.35796761512756 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 371.3979558944702 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 371.4379999637604 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 371.4824652671814 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 371.52855253219604 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 371.57497930526733 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 371.61581587791443 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 371.65599298477173 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 371.69682216644287 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 371.74322986602783 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 371.78434133529663 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 371.83422207832336 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 371.879989862442 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 371.91981625556946 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 371.9689722061157 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 372.01201605796814 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 372.05177211761475 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 372.09290885925293 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 372.1333558559418 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 372.1954092979431 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 372.2346348762512 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 372.2799587249756 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 372.3206226825714 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 372.3606057167053 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 372.4165141582489 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 372.46183681488037 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 372.5015022754669 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 372.5413610935211 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 372.5815770626068 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 372.63941621780396 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 372.682329416275 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 372.7222981452942 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 372.7685327529907 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 372.8144075870514 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 372.86932468414307 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 372.9112491607666 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 372.9550907611847 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 372.9970054626465 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 373.0408034324646 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 373.08833956718445 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 373.12788367271423 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 373.167019367218 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 373.2069284915924 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 373.2502427101135 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 373.2942159175873 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 373.3391890525818 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 373.38286662101746 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 373.4230422973633 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 373.4627697467804 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 373.508953332901 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 373.5501606464386 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 373.59017300605774 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 373.6307497024536 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 373.67396426200867 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 373.73179507255554 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 373.77340507507324 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 373.8167016506195 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 373.87230229377747 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 373.9234461784363 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 373.9736998081207 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 374.01621556282043 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 374.0558388233185 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 374.0952949523926 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 374.1360411643982 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 374.1772713661194 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 374.2273335456848 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 374.26834630966187 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 374.3075964450836 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 374.351126909256 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 374.3999891281128 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 374.4397819042206 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 374.4796566963196 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 374.51900577545166 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 374.5588581562042 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 374.6001591682434 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 374.65404748916626 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 374.6984121799469 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 374.7380278110504 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 374.77814841270447 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 374.8282368183136 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 374.8716313838959 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 374.92066740989685 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 374.9615898132324 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 375.0037627220154 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 375.058224439621 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 375.104777097702 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 375.14526629447937 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 375.18586921691895 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 375.2270698547363 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 375.27351999282837 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 375.3155550956726 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 375.35633993148804 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 375.3961238861084 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 375.43573927879333 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 375.4753577709198 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 375.5240807533264 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 375.57193088531494 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 375.61341381073 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 375.65705394744873 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 375.7065041065216 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 375.74647212028503 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 375.7956705093384 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 375.8400835990906 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 375.8804728984833 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 375.9433617591858 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 375.9854967594147 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 376.0293347835541 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 376.06924772262573 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 376.1105144023895 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 376.15977239608765 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 376.20732831954956 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 376.247526884079 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 376.29564785957336 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 376.33579182624817 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 376.3836464881897 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 376.4243326187134 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 376.48470997810364 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 376.52476048469543 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 376.56613659858704 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 376.6180946826935 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 376.6670835018158 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 376.70934295654297 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 376.75198197364807 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 376.7930130958557 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 376.8453574180603 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 376.8865542411804 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 376.9283232688904 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 376.9794952869415 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 377.0217339992523 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 377.0690140724182 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 377.1115906238556 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 377.1540298461914 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 377.19397258758545 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 377.23916363716125 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 377.297967672348 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 377.35877323150635 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 377.4183373451233 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 377.4777443408966 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 377.5441310405731 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 377.61492705345154 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 377.676819562912 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 377.7357795238495 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 377.80149579048157 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 377.86483430862427 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 377.93440556526184 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 378.00848364830017 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 378.07522320747375 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 378.13773918151855 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 378.2026174068451 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 378.2712652683258 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 378.33078265190125 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 378.39003443717957 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 378.4492506980896 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 378.51695132255554 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 378.57665753364563 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 378.6357960700989 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 378.6987533569336 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 378.76571774482727 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 378.838906288147 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 378.89833331108093 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 378.9590814113617 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 379.02794766426086 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 379.09792017936707 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 379.1570613384247 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 379.2162425518036 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 379.28255820274353 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 379.34574460983276 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 379.4046981334686 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 379.4635338783264 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 379.5282166004181 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 379.5876507759094 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 379.64591097831726 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 379.71088671684265 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 379.7863337993622 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 379.8499162197113 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 379.90952014923096 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 379.9684817790985 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 380.03850293159485 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 380.11433720588684 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 380.18105387687683 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 380.24627470970154 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 380.3075895309448 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 380.3680045604706 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 380.4293131828308 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 380.5025019645691 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 380.56160855293274 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 380.6268239021301 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 380.69573640823364 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 380.77971148490906 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 380.85032057762146 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 380.8910901546478 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 380.9307792186737 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 380.9745807647705 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 381.02450942993164 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 381.06375312805176 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 381.1143066883087 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 381.161700963974 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 381.20252871513367 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 381.2509753704071 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 381.2929527759552 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 381.33268094062805 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 381.3728058338165 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 381.4142119884491 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 381.456894159317 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 381.5036942958832 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 381.54350328445435 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 381.5886845588684 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 381.629812002182 loss tensor(0.3000, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "a3LAIY5wRDbY"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "XNQaGo06Ta49",
        "outputId": "bbb4eeb5-5932-487b-fb07-db04313fad68"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6decd7e7f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6G3P5f8LTdAY",
        "outputId": "1c6bf77d-ae78-4278-f95a-dbf669d29874"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6dec861370>]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "l0LtcyhPTeh8",
        "outputId": "75cf0a7a-c06f-487d-8a56-99b8de3958eb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6dec83bd60>]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}