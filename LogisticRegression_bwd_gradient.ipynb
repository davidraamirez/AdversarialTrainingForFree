{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ/R0ZW0/8czlxB2LcTJad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/LogisticRegression_bwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the necessary packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "x7iZpPFrGWhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rkQFFcg0HXnN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "PZ648ILgHfn2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "ShzuBabDHhVe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "A61m0FPpGijm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "ZHyH8jgfGmnf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "14D3LUb1KU8z"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and preprocessing the data**"
      ],
      "metadata": {
        "id": "G-a43m8xGoJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "penguins = tfds.load('penguins', as_supervised=True, split='train')"
      ],
      "metadata": {
        "id": "ml7IdhKkHjfC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = penguins.batch(500).get_single_element()\n",
        "X, y = X.numpy(), y.numpy()"
      ],
      "metadata": {
        "id": "c2BMFvK7HoFd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "metadata": {
        "id": "bDM9PTN0HrKa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "Xtest = torch.from_numpy(Xtest).float()"
      ],
      "metadata": {
        "id": "JLGZsa5pHtTD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "pubjWXD8Hvva"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Logistic Regression**"
      ],
      "metadata": {
        "id": "9y_Sd0mlG27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, w, b):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(w)\n",
        "    self.bias = nn.Parameter(b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(1, -1)\n",
        "    return torch.softmax(x@self.weight + self.bias, 1)"
      ],
      "metadata": {
        "id": "YjCVZwwrH3ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pv1yTiJH7JV",
        "outputId": "7cf8b83b-5097-41fd-a14d-1297f814779a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize the parameters**"
      ],
      "metadata": {
        "id": "dUvft9uYG_Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "w = torch.randn((4, 3), requires_grad=True)\n",
        "b = torch.randn((3, ), requires_grad=True)\n",
        "LG = SimpleLogisticRegression(4, w, b).to(device)"
      ],
      "metadata": {
        "id": "l2X3STJaH9aY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We try our model with the first example\n",
        "print(LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbykYgnuIAWE",
        "outputId": "bdf8ab68-bc8e-489f-bd65-40e399490b86"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6925, 0.2413, 0.0662]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate predictions"
      ],
      "metadata": {
        "id": "-nxjcQ7-HQh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(x,w,b):\n",
        "  ypred=torch.randn((x.shape[0],3))\n",
        "  for j in range (x.shape[0]):\n",
        "    xj = x[j].reshape(1, -1)\n",
        "    ypred[j]=torch.softmax(xj@w+b,1)\n",
        "  return ypred"
      ],
      "metadata": {
        "id": "2OCd-kbfLV5h"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=pred(Xtrain,w,b)"
      ],
      "metadata": {
        "id": "SzBH4FuVNabv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define accuracy**"
      ],
      "metadata": {
        "id": "1g51kfRQHWSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "_LQ7YyETIB7n"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bDbFhIPEMjic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 33% (random guessing).\n",
        "accuracy(ytrain.to(device),ypred.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bGfj-mfIFwZ",
        "outputId": "c6f8aacc-f4af-48d8-e092-87a4011f71c5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4360)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define cross entropy**"
      ],
      "metadata": {
        "id": "hiEzUJ_GHmQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(ytrue,ypred):\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "1MVXQ3PTILFk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cross_entropy(ytrain,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDzjWsUK6YG",
        "outputId": "d1d6b42a-bb60-443d-c2fb-97614ce81c1d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1858, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and evaluate the network**"
      ],
      "metadata": {
        "id": "sCrAi6M2H3wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bwd_gradient(x,y):\n",
        "\n",
        "  x,y=x.to(device),y.to(device)\n",
        "\n",
        "  losses = [] # Vector with the cross entropy values of test set\n",
        "  accuracies = [] # Vector with the accuracy values of test set\n",
        "  errors=[] # Vector with the number of misclassification of the test set\n",
        "\n",
        "  l_rate0 = 0.2 # Learning rate used \n",
        "\n",
        "  # Initialize the parameters\n",
        "  w = torch.randn((4, 3), requires_grad=True)\n",
        "  b = torch.randn((3, ), requires_grad=True)\n",
        "\n",
        "  ypred=pred(x,w,b)\n",
        "\n",
        "  loss = cross_entropy(ytrain,ypred) # Loss function\n",
        "\n",
        "  # Calculate the start time \n",
        "  t=0\n",
        "  t0=time.time()\n",
        "  print('Time', t, 'loss', loss)\n",
        "\n",
        "  while (loss>0.3): \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Apply gradients \n",
        "      w -= 0.01*w.grad\n",
        "      b -= 0.01*b.grad\n",
        "\n",
        "      # Gradients are accumulated: we need to zero them out before the next iteration.\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "    \n",
        "    # We calculate the number of misclassification of the test set with the updated model and we add to the errors vector\n",
        "    LG = SimpleLogisticRegression(4, w, b)\n",
        "    ypredT=torch.randn(Xtest.size(0),3)\n",
        "    error=0\n",
        "    for i in range (Xtest.size(0)):\n",
        "      ypredT[i]=LG(Xtest[i])\n",
        "      if (LG(Xtest[i]).argmax(1)- ytest[i])!=0:\n",
        "        error = error+ 1\n",
        "    errors.append(error)\n",
        "\n",
        "    ypred=pred(x,w,b)\n",
        "    \n",
        "    # We calculate the accuracy of the test set with the updated model and we add to the accuracy vector\n",
        "    accuracies.append(accuracy(ytest,ypredT).item())\n",
        "\n",
        "    # We calculate the cross_entropy of the test set with the updated model and we add to the accuracy vector\n",
        "    loss = cross_entropy(ytrain,ypred)\n",
        "    losses.append(loss.detach().item())\n",
        "\n",
        "    #We add the execution time of the iteration\n",
        "    t1=time.time()\n",
        "    t+=t1-t0\n",
        "    t0=t1\n",
        "    print('Time', t, 'loss', loss)\n",
        "  \n",
        "  return w,b,errors,losses,accuracies\n"
      ],
      "metadata": {
        "id": "cBld3TwvLDl6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b,errors,losses,accuracies = train_bwd_gradient(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXOhaZSOPSCa",
        "outputId": "63e86371-e5a7-4e83-aa72-397d03d6fc7e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Time 96.17519283294678 loss tensor(0.5958, grad_fn=<NegBackward0>)\n",
            "Time 96.2158145904541 loss tensor(0.5956, grad_fn=<NegBackward0>)\n",
            "Time 96.25538802146912 loss tensor(0.5955, grad_fn=<NegBackward0>)\n",
            "Time 96.29875326156616 loss tensor(0.5953, grad_fn=<NegBackward0>)\n",
            "Time 96.3499846458435 loss tensor(0.5952, grad_fn=<NegBackward0>)\n",
            "Time 96.38950037956238 loss tensor(0.5950, grad_fn=<NegBackward0>)\n",
            "Time 96.42796015739441 loss tensor(0.5949, grad_fn=<NegBackward0>)\n",
            "Time 96.46827983856201 loss tensor(0.5947, grad_fn=<NegBackward0>)\n",
            "Time 96.53486275672913 loss tensor(0.5946, grad_fn=<NegBackward0>)\n",
            "Time 96.57601523399353 loss tensor(0.5944, grad_fn=<NegBackward0>)\n",
            "Time 96.61523985862732 loss tensor(0.5943, grad_fn=<NegBackward0>)\n",
            "Time 96.65546798706055 loss tensor(0.5941, grad_fn=<NegBackward0>)\n",
            "Time 96.69724297523499 loss tensor(0.5940, grad_fn=<NegBackward0>)\n",
            "Time 96.74664068222046 loss tensor(0.5938, grad_fn=<NegBackward0>)\n",
            "Time 96.79086947441101 loss tensor(0.5937, grad_fn=<NegBackward0>)\n",
            "Time 96.82998466491699 loss tensor(0.5935, grad_fn=<NegBackward0>)\n",
            "Time 96.8794207572937 loss tensor(0.5934, grad_fn=<NegBackward0>)\n",
            "Time 96.9180748462677 loss tensor(0.5932, grad_fn=<NegBackward0>)\n",
            "Time 96.9652349948883 loss tensor(0.5931, grad_fn=<NegBackward0>)\n",
            "Time 97.00687670707703 loss tensor(0.5929, grad_fn=<NegBackward0>)\n",
            "Time 97.04638576507568 loss tensor(0.5928, grad_fn=<NegBackward0>)\n",
            "Time 97.08851742744446 loss tensor(0.5926, grad_fn=<NegBackward0>)\n",
            "Time 97.12895274162292 loss tensor(0.5925, grad_fn=<NegBackward0>)\n",
            "Time 97.17339825630188 loss tensor(0.5923, grad_fn=<NegBackward0>)\n",
            "Time 97.2140703201294 loss tensor(0.5922, grad_fn=<NegBackward0>)\n",
            "Time 97.25291466712952 loss tensor(0.5920, grad_fn=<NegBackward0>)\n",
            "Time 97.29193234443665 loss tensor(0.5919, grad_fn=<NegBackward0>)\n",
            "Time 97.33908224105835 loss tensor(0.5917, grad_fn=<NegBackward0>)\n",
            "Time 97.38194537162781 loss tensor(0.5916, grad_fn=<NegBackward0>)\n",
            "Time 97.42331433296204 loss tensor(0.5914, grad_fn=<NegBackward0>)\n",
            "Time 97.4620463848114 loss tensor(0.5913, grad_fn=<NegBackward0>)\n",
            "Time 97.50107955932617 loss tensor(0.5911, grad_fn=<NegBackward0>)\n",
            "Time 97.5400562286377 loss tensor(0.5910, grad_fn=<NegBackward0>)\n",
            "Time 97.57910346984863 loss tensor(0.5908, grad_fn=<NegBackward0>)\n",
            "Time 97.62405562400818 loss tensor(0.5907, grad_fn=<NegBackward0>)\n",
            "Time 97.66363072395325 loss tensor(0.5905, grad_fn=<NegBackward0>)\n",
            "Time 97.70242142677307 loss tensor(0.5904, grad_fn=<NegBackward0>)\n",
            "Time 97.74352931976318 loss tensor(0.5902, grad_fn=<NegBackward0>)\n",
            "Time 97.7834038734436 loss tensor(0.5901, grad_fn=<NegBackward0>)\n",
            "Time 97.82334494590759 loss tensor(0.5899, grad_fn=<NegBackward0>)\n",
            "Time 97.87187194824219 loss tensor(0.5898, grad_fn=<NegBackward0>)\n",
            "Time 97.91866064071655 loss tensor(0.5897, grad_fn=<NegBackward0>)\n",
            "Time 97.96226477622986 loss tensor(0.5895, grad_fn=<NegBackward0>)\n",
            "Time 98.00253510475159 loss tensor(0.5894, grad_fn=<NegBackward0>)\n",
            "Time 98.04738998413086 loss tensor(0.5892, grad_fn=<NegBackward0>)\n",
            "Time 98.0871205329895 loss tensor(0.5891, grad_fn=<NegBackward0>)\n",
            "Time 98.12548470497131 loss tensor(0.5889, grad_fn=<NegBackward0>)\n",
            "Time 98.16618013381958 loss tensor(0.5888, grad_fn=<NegBackward0>)\n",
            "Time 98.20618224143982 loss tensor(0.5886, grad_fn=<NegBackward0>)\n",
            "Time 98.24577116966248 loss tensor(0.5885, grad_fn=<NegBackward0>)\n",
            "Time 98.28927373886108 loss tensor(0.5883, grad_fn=<NegBackward0>)\n",
            "Time 98.33348798751831 loss tensor(0.5882, grad_fn=<NegBackward0>)\n",
            "Time 98.37216663360596 loss tensor(0.5880, grad_fn=<NegBackward0>)\n",
            "Time 98.41112089157104 loss tensor(0.5879, grad_fn=<NegBackward0>)\n",
            "Time 98.44935894012451 loss tensor(0.5878, grad_fn=<NegBackward0>)\n",
            "Time 98.48846673965454 loss tensor(0.5876, grad_fn=<NegBackward0>)\n",
            "Time 98.53220772743225 loss tensor(0.5875, grad_fn=<NegBackward0>)\n",
            "Time 98.57075929641724 loss tensor(0.5873, grad_fn=<NegBackward0>)\n",
            "Time 98.61545252799988 loss tensor(0.5872, grad_fn=<NegBackward0>)\n",
            "Time 98.65514707565308 loss tensor(0.5870, grad_fn=<NegBackward0>)\n",
            "Time 98.6940643787384 loss tensor(0.5869, grad_fn=<NegBackward0>)\n",
            "Time 98.739098072052 loss tensor(0.5867, grad_fn=<NegBackward0>)\n",
            "Time 98.77788043022156 loss tensor(0.5866, grad_fn=<NegBackward0>)\n",
            "Time 98.8190610408783 loss tensor(0.5864, grad_fn=<NegBackward0>)\n",
            "Time 98.85875344276428 loss tensor(0.5863, grad_fn=<NegBackward0>)\n",
            "Time 98.90625405311584 loss tensor(0.5862, grad_fn=<NegBackward0>)\n",
            "Time 98.95079112052917 loss tensor(0.5860, grad_fn=<NegBackward0>)\n",
            "Time 98.99035835266113 loss tensor(0.5859, grad_fn=<NegBackward0>)\n",
            "Time 99.03314900398254 loss tensor(0.5857, grad_fn=<NegBackward0>)\n",
            "Time 99.07239961624146 loss tensor(0.5856, grad_fn=<NegBackward0>)\n",
            "Time 99.11108207702637 loss tensor(0.5854, grad_fn=<NegBackward0>)\n",
            "Time 99.15301942825317 loss tensor(0.5853, grad_fn=<NegBackward0>)\n",
            "Time 99.19789218902588 loss tensor(0.5851, grad_fn=<NegBackward0>)\n",
            "Time 99.23705101013184 loss tensor(0.5850, grad_fn=<NegBackward0>)\n",
            "Time 99.27531433105469 loss tensor(0.5848, grad_fn=<NegBackward0>)\n",
            "Time 99.31298041343689 loss tensor(0.5847, grad_fn=<NegBackward0>)\n",
            "Time 99.35142755508423 loss tensor(0.5846, grad_fn=<NegBackward0>)\n",
            "Time 99.3963234424591 loss tensor(0.5844, grad_fn=<NegBackward0>)\n",
            "Time 99.4347083568573 loss tensor(0.5843, grad_fn=<NegBackward0>)\n",
            "Time 99.47356081008911 loss tensor(0.5841, grad_fn=<NegBackward0>)\n",
            "Time 99.51207685470581 loss tensor(0.5840, grad_fn=<NegBackward0>)\n",
            "Time 99.55010557174683 loss tensor(0.5838, grad_fn=<NegBackward0>)\n",
            "Time 99.5899806022644 loss tensor(0.5837, grad_fn=<NegBackward0>)\n",
            "Time 99.63465094566345 loss tensor(0.5836, grad_fn=<NegBackward0>)\n",
            "Time 99.67350959777832 loss tensor(0.5834, grad_fn=<NegBackward0>)\n",
            "Time 99.71333909034729 loss tensor(0.5833, grad_fn=<NegBackward0>)\n",
            "Time 99.75566530227661 loss tensor(0.5831, grad_fn=<NegBackward0>)\n",
            "Time 99.7963752746582 loss tensor(0.5830, grad_fn=<NegBackward0>)\n",
            "Time 99.83420753479004 loss tensor(0.5828, grad_fn=<NegBackward0>)\n",
            "Time 99.88500690460205 loss tensor(0.5827, grad_fn=<NegBackward0>)\n",
            "Time 99.93343901634216 loss tensor(0.5826, grad_fn=<NegBackward0>)\n",
            "Time 99.9727954864502 loss tensor(0.5824, grad_fn=<NegBackward0>)\n",
            "Time 100.01236152648926 loss tensor(0.5823, grad_fn=<NegBackward0>)\n",
            "Time 100.05508780479431 loss tensor(0.5821, grad_fn=<NegBackward0>)\n",
            "Time 100.09363532066345 loss tensor(0.5820, grad_fn=<NegBackward0>)\n",
            "Time 100.13803458213806 loss tensor(0.5818, grad_fn=<NegBackward0>)\n",
            "Time 100.18664646148682 loss tensor(0.5817, grad_fn=<NegBackward0>)\n",
            "Time 100.22725558280945 loss tensor(0.5816, grad_fn=<NegBackward0>)\n",
            "Time 100.27779912948608 loss tensor(0.5814, grad_fn=<NegBackward0>)\n",
            "Time 100.33157849311829 loss tensor(0.5813, grad_fn=<NegBackward0>)\n",
            "Time 100.37038803100586 loss tensor(0.5811, grad_fn=<NegBackward0>)\n",
            "Time 100.41167497634888 loss tensor(0.5810, grad_fn=<NegBackward0>)\n",
            "Time 100.45047211647034 loss tensor(0.5808, grad_fn=<NegBackward0>)\n",
            "Time 100.49513411521912 loss tensor(0.5807, grad_fn=<NegBackward0>)\n",
            "Time 100.53764843940735 loss tensor(0.5806, grad_fn=<NegBackward0>)\n",
            "Time 100.57796597480774 loss tensor(0.5804, grad_fn=<NegBackward0>)\n",
            "Time 100.61633944511414 loss tensor(0.5803, grad_fn=<NegBackward0>)\n",
            "Time 100.65477013587952 loss tensor(0.5801, grad_fn=<NegBackward0>)\n",
            "Time 100.69319820404053 loss tensor(0.5800, grad_fn=<NegBackward0>)\n",
            "Time 100.7369966506958 loss tensor(0.5799, grad_fn=<NegBackward0>)\n",
            "Time 100.77772641181946 loss tensor(0.5797, grad_fn=<NegBackward0>)\n",
            "Time 100.81758546829224 loss tensor(0.5796, grad_fn=<NegBackward0>)\n",
            "Time 100.8562023639679 loss tensor(0.5794, grad_fn=<NegBackward0>)\n",
            "Time 100.90747380256653 loss tensor(0.5793, grad_fn=<NegBackward0>)\n",
            "Time 100.96276688575745 loss tensor(0.5792, grad_fn=<NegBackward0>)\n",
            "Time 101.00249648094177 loss tensor(0.5790, grad_fn=<NegBackward0>)\n",
            "Time 101.04564905166626 loss tensor(0.5789, grad_fn=<NegBackward0>)\n",
            "Time 101.08670830726624 loss tensor(0.5787, grad_fn=<NegBackward0>)\n",
            "Time 101.12456917762756 loss tensor(0.5786, grad_fn=<NegBackward0>)\n",
            "Time 101.16577959060669 loss tensor(0.5785, grad_fn=<NegBackward0>)\n",
            "Time 101.21049070358276 loss tensor(0.5783, grad_fn=<NegBackward0>)\n",
            "Time 101.249675989151 loss tensor(0.5782, grad_fn=<NegBackward0>)\n",
            "Time 101.28787851333618 loss tensor(0.5780, grad_fn=<NegBackward0>)\n",
            "Time 101.33095932006836 loss tensor(0.5779, grad_fn=<NegBackward0>)\n",
            "Time 101.36875677108765 loss tensor(0.5778, grad_fn=<NegBackward0>)\n",
            "Time 101.41206192970276 loss tensor(0.5776, grad_fn=<NegBackward0>)\n",
            "Time 101.44974279403687 loss tensor(0.5775, grad_fn=<NegBackward0>)\n",
            "Time 101.49473595619202 loss tensor(0.5773, grad_fn=<NegBackward0>)\n",
            "Time 101.53291654586792 loss tensor(0.5772, grad_fn=<NegBackward0>)\n",
            "Time 101.57076835632324 loss tensor(0.5771, grad_fn=<NegBackward0>)\n",
            "Time 101.6102967262268 loss tensor(0.5769, grad_fn=<NegBackward0>)\n",
            "Time 101.65615367889404 loss tensor(0.5768, grad_fn=<NegBackward0>)\n",
            "Time 101.69617247581482 loss tensor(0.5766, grad_fn=<NegBackward0>)\n",
            "Time 101.73559260368347 loss tensor(0.5765, grad_fn=<NegBackward0>)\n",
            "Time 101.77635669708252 loss tensor(0.5764, grad_fn=<NegBackward0>)\n",
            "Time 101.81774806976318 loss tensor(0.5762, grad_fn=<NegBackward0>)\n",
            "Time 101.87611794471741 loss tensor(0.5761, grad_fn=<NegBackward0>)\n",
            "Time 101.91544795036316 loss tensor(0.5759, grad_fn=<NegBackward0>)\n",
            "Time 101.95625972747803 loss tensor(0.5758, grad_fn=<NegBackward0>)\n",
            "Time 102.00054955482483 loss tensor(0.5757, grad_fn=<NegBackward0>)\n",
            "Time 102.03858852386475 loss tensor(0.5755, grad_fn=<NegBackward0>)\n",
            "Time 102.07658362388611 loss tensor(0.5754, grad_fn=<NegBackward0>)\n",
            "Time 102.12210059165955 loss tensor(0.5753, grad_fn=<NegBackward0>)\n",
            "Time 102.16283893585205 loss tensor(0.5751, grad_fn=<NegBackward0>)\n",
            "Time 102.20134425163269 loss tensor(0.5750, grad_fn=<NegBackward0>)\n",
            "Time 102.24147891998291 loss tensor(0.5748, grad_fn=<NegBackward0>)\n",
            "Time 102.27981662750244 loss tensor(0.5747, grad_fn=<NegBackward0>)\n",
            "Time 102.32351636886597 loss tensor(0.5746, grad_fn=<NegBackward0>)\n",
            "Time 102.36199259757996 loss tensor(0.5744, grad_fn=<NegBackward0>)\n",
            "Time 102.40498185157776 loss tensor(0.5743, grad_fn=<NegBackward0>)\n",
            "Time 102.44260954856873 loss tensor(0.5742, grad_fn=<NegBackward0>)\n",
            "Time 102.48088121414185 loss tensor(0.5740, grad_fn=<NegBackward0>)\n",
            "Time 102.5218358039856 loss tensor(0.5739, grad_fn=<NegBackward0>)\n",
            "Time 102.57362222671509 loss tensor(0.5737, grad_fn=<NegBackward0>)\n",
            "Time 102.61207890510559 loss tensor(0.5736, grad_fn=<NegBackward0>)\n",
            "Time 102.65144157409668 loss tensor(0.5735, grad_fn=<NegBackward0>)\n",
            "Time 102.69430375099182 loss tensor(0.5733, grad_fn=<NegBackward0>)\n",
            "Time 102.74151825904846 loss tensor(0.5732, grad_fn=<NegBackward0>)\n",
            "Time 102.7840826511383 loss tensor(0.5731, grad_fn=<NegBackward0>)\n",
            "Time 102.82779622077942 loss tensor(0.5729, grad_fn=<NegBackward0>)\n",
            "Time 102.86758089065552 loss tensor(0.5728, grad_fn=<NegBackward0>)\n",
            "Time 102.90682172775269 loss tensor(0.5726, grad_fn=<NegBackward0>)\n",
            "Time 102.94929480552673 loss tensor(0.5725, grad_fn=<NegBackward0>)\n",
            "Time 102.99866008758545 loss tensor(0.5724, grad_fn=<NegBackward0>)\n",
            "Time 103.04206776618958 loss tensor(0.5722, grad_fn=<NegBackward0>)\n",
            "Time 103.08037877082825 loss tensor(0.5721, grad_fn=<NegBackward0>)\n",
            "Time 103.11825203895569 loss tensor(0.5720, grad_fn=<NegBackward0>)\n",
            "Time 103.17145276069641 loss tensor(0.5718, grad_fn=<NegBackward0>)\n",
            "Time 103.21018934249878 loss tensor(0.5717, grad_fn=<NegBackward0>)\n",
            "Time 103.2498254776001 loss tensor(0.5716, grad_fn=<NegBackward0>)\n",
            "Time 103.28782892227173 loss tensor(0.5714, grad_fn=<NegBackward0>)\n",
            "Time 103.32641386985779 loss tensor(0.5713, grad_fn=<NegBackward0>)\n",
            "Time 103.36500024795532 loss tensor(0.5711, grad_fn=<NegBackward0>)\n",
            "Time 103.40906286239624 loss tensor(0.5710, grad_fn=<NegBackward0>)\n",
            "Time 103.45378684997559 loss tensor(0.5709, grad_fn=<NegBackward0>)\n",
            "Time 103.49287676811218 loss tensor(0.5707, grad_fn=<NegBackward0>)\n",
            "Time 103.53219318389893 loss tensor(0.5706, grad_fn=<NegBackward0>)\n",
            "Time 103.57662630081177 loss tensor(0.5705, grad_fn=<NegBackward0>)\n",
            "Time 103.62056875228882 loss tensor(0.5703, grad_fn=<NegBackward0>)\n",
            "Time 103.66027760505676 loss tensor(0.5702, grad_fn=<NegBackward0>)\n",
            "Time 103.69975233078003 loss tensor(0.5701, grad_fn=<NegBackward0>)\n",
            "Time 103.73869442939758 loss tensor(0.5699, grad_fn=<NegBackward0>)\n",
            "Time 103.7843565940857 loss tensor(0.5698, grad_fn=<NegBackward0>)\n",
            "Time 103.83638334274292 loss tensor(0.5697, grad_fn=<NegBackward0>)\n",
            "Time 103.88276410102844 loss tensor(0.5695, grad_fn=<NegBackward0>)\n",
            "Time 103.94026112556458 loss tensor(0.5694, grad_fn=<NegBackward0>)\n",
            "Time 103.98339438438416 loss tensor(0.5693, grad_fn=<NegBackward0>)\n",
            "Time 104.03116798400879 loss tensor(0.5691, grad_fn=<NegBackward0>)\n",
            "Time 104.07589507102966 loss tensor(0.5690, grad_fn=<NegBackward0>)\n",
            "Time 104.11897778511047 loss tensor(0.5689, grad_fn=<NegBackward0>)\n",
            "Time 104.1606969833374 loss tensor(0.5687, grad_fn=<NegBackward0>)\n",
            "Time 104.20067596435547 loss tensor(0.5686, grad_fn=<NegBackward0>)\n",
            "Time 104.24163770675659 loss tensor(0.5685, grad_fn=<NegBackward0>)\n",
            "Time 104.28345966339111 loss tensor(0.5683, grad_fn=<NegBackward0>)\n",
            "Time 104.32480573654175 loss tensor(0.5682, grad_fn=<NegBackward0>)\n",
            "Time 104.36496806144714 loss tensor(0.5681, grad_fn=<NegBackward0>)\n",
            "Time 104.40381217002869 loss tensor(0.5679, grad_fn=<NegBackward0>)\n",
            "Time 104.47195768356323 loss tensor(0.5678, grad_fn=<NegBackward0>)\n",
            "Time 104.54095983505249 loss tensor(0.5677, grad_fn=<NegBackward0>)\n",
            "Time 104.60094380378723 loss tensor(0.5675, grad_fn=<NegBackward0>)\n",
            "Time 104.65716409683228 loss tensor(0.5674, grad_fn=<NegBackward0>)\n",
            "Time 104.7175657749176 loss tensor(0.5673, grad_fn=<NegBackward0>)\n",
            "Time 104.7822675704956 loss tensor(0.5671, grad_fn=<NegBackward0>)\n",
            "Time 104.84664964675903 loss tensor(0.5670, grad_fn=<NegBackward0>)\n",
            "Time 104.90454506874084 loss tensor(0.5669, grad_fn=<NegBackward0>)\n",
            "Time 104.9619951248169 loss tensor(0.5667, grad_fn=<NegBackward0>)\n",
            "Time 105.03003764152527 loss tensor(0.5666, grad_fn=<NegBackward0>)\n",
            "Time 105.08935618400574 loss tensor(0.5665, grad_fn=<NegBackward0>)\n",
            "Time 105.14689445495605 loss tensor(0.5663, grad_fn=<NegBackward0>)\n",
            "Time 105.20837426185608 loss tensor(0.5662, grad_fn=<NegBackward0>)\n",
            "Time 105.27442955970764 loss tensor(0.5661, grad_fn=<NegBackward0>)\n",
            "Time 105.33184957504272 loss tensor(0.5659, grad_fn=<NegBackward0>)\n",
            "Time 105.3903865814209 loss tensor(0.5658, grad_fn=<NegBackward0>)\n",
            "Time 105.44809007644653 loss tensor(0.5657, grad_fn=<NegBackward0>)\n",
            "Time 105.51106309890747 loss tensor(0.5655, grad_fn=<NegBackward0>)\n",
            "Time 105.58394694328308 loss tensor(0.5654, grad_fn=<NegBackward0>)\n",
            "Time 105.65434265136719 loss tensor(0.5653, grad_fn=<NegBackward0>)\n",
            "Time 105.72018003463745 loss tensor(0.5651, grad_fn=<NegBackward0>)\n",
            "Time 105.78169584274292 loss tensor(0.5650, grad_fn=<NegBackward0>)\n",
            "Time 105.8394079208374 loss tensor(0.5649, grad_fn=<NegBackward0>)\n",
            "Time 105.89717197418213 loss tensor(0.5647, grad_fn=<NegBackward0>)\n",
            "Time 105.95972776412964 loss tensor(0.5646, grad_fn=<NegBackward0>)\n",
            "Time 106.02088022232056 loss tensor(0.5645, grad_fn=<NegBackward0>)\n",
            "Time 106.08217930793762 loss tensor(0.5643, grad_fn=<NegBackward0>)\n",
            "Time 106.14188122749329 loss tensor(0.5642, grad_fn=<NegBackward0>)\n",
            "Time 106.21120262145996 loss tensor(0.5641, grad_fn=<NegBackward0>)\n",
            "Time 106.27034997940063 loss tensor(0.5639, grad_fn=<NegBackward0>)\n",
            "Time 106.3285071849823 loss tensor(0.5638, grad_fn=<NegBackward0>)\n",
            "Time 106.38575553894043 loss tensor(0.5637, grad_fn=<NegBackward0>)\n",
            "Time 106.45304584503174 loss tensor(0.5636, grad_fn=<NegBackward0>)\n",
            "Time 106.51611232757568 loss tensor(0.5634, grad_fn=<NegBackward0>)\n",
            "Time 106.57397603988647 loss tensor(0.5633, grad_fn=<NegBackward0>)\n",
            "Time 106.63072562217712 loss tensor(0.5632, grad_fn=<NegBackward0>)\n",
            "Time 106.69455552101135 loss tensor(0.5630, grad_fn=<NegBackward0>)\n",
            "Time 106.7534294128418 loss tensor(0.5629, grad_fn=<NegBackward0>)\n",
            "Time 106.81320381164551 loss tensor(0.5628, grad_fn=<NegBackward0>)\n",
            "Time 106.87110996246338 loss tensor(0.5626, grad_fn=<NegBackward0>)\n",
            "Time 106.93687033653259 loss tensor(0.5625, grad_fn=<NegBackward0>)\n",
            "Time 107.00143575668335 loss tensor(0.5624, grad_fn=<NegBackward0>)\n",
            "Time 107.06398463249207 loss tensor(0.5622, grad_fn=<NegBackward0>)\n",
            "Time 107.12965703010559 loss tensor(0.5621, grad_fn=<NegBackward0>)\n",
            "Time 107.19351029396057 loss tensor(0.5620, grad_fn=<NegBackward0>)\n",
            "Time 107.23301362991333 loss tensor(0.5619, grad_fn=<NegBackward0>)\n",
            "Time 107.27026438713074 loss tensor(0.5617, grad_fn=<NegBackward0>)\n",
            "Time 107.30794763565063 loss tensor(0.5616, grad_fn=<NegBackward0>)\n",
            "Time 107.34683275222778 loss tensor(0.5615, grad_fn=<NegBackward0>)\n",
            "Time 107.38407969474792 loss tensor(0.5613, grad_fn=<NegBackward0>)\n",
            "Time 107.42848491668701 loss tensor(0.5612, grad_fn=<NegBackward0>)\n",
            "Time 107.47542810440063 loss tensor(0.5611, grad_fn=<NegBackward0>)\n",
            "Time 107.5137083530426 loss tensor(0.5609, grad_fn=<NegBackward0>)\n",
            "Time 107.553551197052 loss tensor(0.5608, grad_fn=<NegBackward0>)\n",
            "Time 107.5930449962616 loss tensor(0.5607, grad_fn=<NegBackward0>)\n",
            "Time 107.63384819030762 loss tensor(0.5606, grad_fn=<NegBackward0>)\n",
            "Time 107.69348645210266 loss tensor(0.5604, grad_fn=<NegBackward0>)\n",
            "Time 107.73782253265381 loss tensor(0.5603, grad_fn=<NegBackward0>)\n",
            "Time 107.7760841846466 loss tensor(0.5602, grad_fn=<NegBackward0>)\n",
            "Time 107.81937336921692 loss tensor(0.5600, grad_fn=<NegBackward0>)\n",
            "Time 107.86580061912537 loss tensor(0.5599, grad_fn=<NegBackward0>)\n",
            "Time 107.90458297729492 loss tensor(0.5598, grad_fn=<NegBackward0>)\n",
            "Time 107.94486975669861 loss tensor(0.5597, grad_fn=<NegBackward0>)\n",
            "Time 107.98379516601562 loss tensor(0.5595, grad_fn=<NegBackward0>)\n",
            "Time 108.02194857597351 loss tensor(0.5594, grad_fn=<NegBackward0>)\n",
            "Time 108.06008625030518 loss tensor(0.5593, grad_fn=<NegBackward0>)\n",
            "Time 108.1092004776001 loss tensor(0.5591, grad_fn=<NegBackward0>)\n",
            "Time 108.15871381759644 loss tensor(0.5590, grad_fn=<NegBackward0>)\n",
            "Time 108.19748950004578 loss tensor(0.5589, grad_fn=<NegBackward0>)\n",
            "Time 108.24230098724365 loss tensor(0.5588, grad_fn=<NegBackward0>)\n",
            "Time 108.28701281547546 loss tensor(0.5586, grad_fn=<NegBackward0>)\n",
            "Time 108.33124446868896 loss tensor(0.5585, grad_fn=<NegBackward0>)\n",
            "Time 108.36978530883789 loss tensor(0.5584, grad_fn=<NegBackward0>)\n",
            "Time 108.40780735015869 loss tensor(0.5582, grad_fn=<NegBackward0>)\n",
            "Time 108.44535303115845 loss tensor(0.5581, grad_fn=<NegBackward0>)\n",
            "Time 108.4827573299408 loss tensor(0.5580, grad_fn=<NegBackward0>)\n",
            "Time 108.52054762840271 loss tensor(0.5579, grad_fn=<NegBackward0>)\n",
            "Time 108.57198429107666 loss tensor(0.5577, grad_fn=<NegBackward0>)\n",
            "Time 108.61084866523743 loss tensor(0.5576, grad_fn=<NegBackward0>)\n",
            "Time 108.64912962913513 loss tensor(0.5575, grad_fn=<NegBackward0>)\n",
            "Time 108.68690419197083 loss tensor(0.5574, grad_fn=<NegBackward0>)\n",
            "Time 108.72745108604431 loss tensor(0.5572, grad_fn=<NegBackward0>)\n",
            "Time 108.77016639709473 loss tensor(0.5571, grad_fn=<NegBackward0>)\n",
            "Time 108.81703186035156 loss tensor(0.5570, grad_fn=<NegBackward0>)\n",
            "Time 108.85533666610718 loss tensor(0.5568, grad_fn=<NegBackward0>)\n",
            "Time 108.89372658729553 loss tensor(0.5567, grad_fn=<NegBackward0>)\n",
            "Time 108.93233561515808 loss tensor(0.5566, grad_fn=<NegBackward0>)\n",
            "Time 108.97378778457642 loss tensor(0.5565, grad_fn=<NegBackward0>)\n",
            "Time 109.01278638839722 loss tensor(0.5563, grad_fn=<NegBackward0>)\n",
            "Time 109.05644083023071 loss tensor(0.5562, grad_fn=<NegBackward0>)\n",
            "Time 109.09800553321838 loss tensor(0.5561, grad_fn=<NegBackward0>)\n",
            "Time 109.13517045974731 loss tensor(0.5560, grad_fn=<NegBackward0>)\n",
            "Time 109.18473863601685 loss tensor(0.5558, grad_fn=<NegBackward0>)\n",
            "Time 109.22922825813293 loss tensor(0.5557, grad_fn=<NegBackward0>)\n",
            "Time 109.27279615402222 loss tensor(0.5556, grad_fn=<NegBackward0>)\n",
            "Time 109.32797169685364 loss tensor(0.5555, grad_fn=<NegBackward0>)\n",
            "Time 109.37994408607483 loss tensor(0.5553, grad_fn=<NegBackward0>)\n",
            "Time 109.41911125183105 loss tensor(0.5552, grad_fn=<NegBackward0>)\n",
            "Time 109.46480798721313 loss tensor(0.5551, grad_fn=<NegBackward0>)\n",
            "Time 109.50848746299744 loss tensor(0.5549, grad_fn=<NegBackward0>)\n",
            "Time 109.54693174362183 loss tensor(0.5548, grad_fn=<NegBackward0>)\n",
            "Time 109.59362816810608 loss tensor(0.5547, grad_fn=<NegBackward0>)\n",
            "Time 109.63212871551514 loss tensor(0.5546, grad_fn=<NegBackward0>)\n",
            "Time 109.67005252838135 loss tensor(0.5544, grad_fn=<NegBackward0>)\n",
            "Time 109.70805478096008 loss tensor(0.5543, grad_fn=<NegBackward0>)\n",
            "Time 109.75734424591064 loss tensor(0.5542, grad_fn=<NegBackward0>)\n",
            "Time 109.79777550697327 loss tensor(0.5541, grad_fn=<NegBackward0>)\n",
            "Time 109.83942246437073 loss tensor(0.5539, grad_fn=<NegBackward0>)\n",
            "Time 109.88095450401306 loss tensor(0.5538, grad_fn=<NegBackward0>)\n",
            "Time 109.92907691001892 loss tensor(0.5537, grad_fn=<NegBackward0>)\n",
            "Time 109.98623633384705 loss tensor(0.5536, grad_fn=<NegBackward0>)\n",
            "Time 110.0311508178711 loss tensor(0.5534, grad_fn=<NegBackward0>)\n",
            "Time 110.06908082962036 loss tensor(0.5533, grad_fn=<NegBackward0>)\n",
            "Time 110.10711574554443 loss tensor(0.5532, grad_fn=<NegBackward0>)\n",
            "Time 110.15387272834778 loss tensor(0.5531, grad_fn=<NegBackward0>)\n",
            "Time 110.20214009284973 loss tensor(0.5529, grad_fn=<NegBackward0>)\n",
            "Time 110.24191188812256 loss tensor(0.5528, grad_fn=<NegBackward0>)\n",
            "Time 110.2802722454071 loss tensor(0.5527, grad_fn=<NegBackward0>)\n",
            "Time 110.31810450553894 loss tensor(0.5526, grad_fn=<NegBackward0>)\n",
            "Time 110.35853910446167 loss tensor(0.5524, grad_fn=<NegBackward0>)\n",
            "Time 110.40406441688538 loss tensor(0.5523, grad_fn=<NegBackward0>)\n",
            "Time 110.44219064712524 loss tensor(0.5522, grad_fn=<NegBackward0>)\n",
            "Time 110.48053097724915 loss tensor(0.5521, grad_fn=<NegBackward0>)\n",
            "Time 110.52367568016052 loss tensor(0.5519, grad_fn=<NegBackward0>)\n",
            "Time 110.5813136100769 loss tensor(0.5518, grad_fn=<NegBackward0>)\n",
            "Time 110.61954188346863 loss tensor(0.5517, grad_fn=<NegBackward0>)\n",
            "Time 110.65878629684448 loss tensor(0.5516, grad_fn=<NegBackward0>)\n",
            "Time 110.69811177253723 loss tensor(0.5515, grad_fn=<NegBackward0>)\n",
            "Time 110.736093044281 loss tensor(0.5513, grad_fn=<NegBackward0>)\n",
            "Time 110.77548861503601 loss tensor(0.5512, grad_fn=<NegBackward0>)\n",
            "Time 110.82561349868774 loss tensor(0.5511, grad_fn=<NegBackward0>)\n",
            "Time 110.8851752281189 loss tensor(0.5510, grad_fn=<NegBackward0>)\n",
            "Time 110.93951201438904 loss tensor(0.5508, grad_fn=<NegBackward0>)\n",
            "Time 110.99388098716736 loss tensor(0.5507, grad_fn=<NegBackward0>)\n",
            "Time 111.04358959197998 loss tensor(0.5506, grad_fn=<NegBackward0>)\n",
            "Time 111.08363509178162 loss tensor(0.5505, grad_fn=<NegBackward0>)\n",
            "Time 111.12276911735535 loss tensor(0.5503, grad_fn=<NegBackward0>)\n",
            "Time 111.16438865661621 loss tensor(0.5502, grad_fn=<NegBackward0>)\n",
            "Time 111.21209383010864 loss tensor(0.5501, grad_fn=<NegBackward0>)\n",
            "Time 111.25720167160034 loss tensor(0.5500, grad_fn=<NegBackward0>)\n",
            "Time 111.2967939376831 loss tensor(0.5498, grad_fn=<NegBackward0>)\n",
            "Time 111.3403971195221 loss tensor(0.5497, grad_fn=<NegBackward0>)\n",
            "Time 111.38160634040833 loss tensor(0.5496, grad_fn=<NegBackward0>)\n",
            "Time 111.42229866981506 loss tensor(0.5495, grad_fn=<NegBackward0>)\n",
            "Time 111.46342349052429 loss tensor(0.5494, grad_fn=<NegBackward0>)\n",
            "Time 111.50573778152466 loss tensor(0.5492, grad_fn=<NegBackward0>)\n",
            "Time 111.54383850097656 loss tensor(0.5491, grad_fn=<NegBackward0>)\n",
            "Time 111.5821807384491 loss tensor(0.5490, grad_fn=<NegBackward0>)\n",
            "Time 111.62070870399475 loss tensor(0.5489, grad_fn=<NegBackward0>)\n",
            "Time 111.6594500541687 loss tensor(0.5487, grad_fn=<NegBackward0>)\n",
            "Time 111.70451641082764 loss tensor(0.5486, grad_fn=<NegBackward0>)\n",
            "Time 111.74600315093994 loss tensor(0.5485, grad_fn=<NegBackward0>)\n",
            "Time 111.78881621360779 loss tensor(0.5484, grad_fn=<NegBackward0>)\n",
            "Time 111.829824924469 loss tensor(0.5483, grad_fn=<NegBackward0>)\n",
            "Time 111.86848258972168 loss tensor(0.5481, grad_fn=<NegBackward0>)\n",
            "Time 111.91057634353638 loss tensor(0.5480, grad_fn=<NegBackward0>)\n",
            "Time 111.95642256736755 loss tensor(0.5479, grad_fn=<NegBackward0>)\n",
            "Time 111.99618911743164 loss tensor(0.5478, grad_fn=<NegBackward0>)\n",
            "Time 112.0359001159668 loss tensor(0.5476, grad_fn=<NegBackward0>)\n",
            "Time 112.07873439788818 loss tensor(0.5475, grad_fn=<NegBackward0>)\n",
            "Time 112.12318754196167 loss tensor(0.5474, grad_fn=<NegBackward0>)\n",
            "Time 112.16496062278748 loss tensor(0.5473, grad_fn=<NegBackward0>)\n",
            "Time 112.21003127098083 loss tensor(0.5472, grad_fn=<NegBackward0>)\n",
            "Time 112.25813937187195 loss tensor(0.5470, grad_fn=<NegBackward0>)\n",
            "Time 112.29626035690308 loss tensor(0.5469, grad_fn=<NegBackward0>)\n",
            "Time 112.34026765823364 loss tensor(0.5468, grad_fn=<NegBackward0>)\n",
            "Time 112.37908935546875 loss tensor(0.5467, grad_fn=<NegBackward0>)\n",
            "Time 112.41768503189087 loss tensor(0.5466, grad_fn=<NegBackward0>)\n",
            "Time 112.4561505317688 loss tensor(0.5464, grad_fn=<NegBackward0>)\n",
            "Time 112.49463081359863 loss tensor(0.5463, grad_fn=<NegBackward0>)\n",
            "Time 112.53343176841736 loss tensor(0.5462, grad_fn=<NegBackward0>)\n",
            "Time 112.5799400806427 loss tensor(0.5461, grad_fn=<NegBackward0>)\n",
            "Time 112.62705564498901 loss tensor(0.5460, grad_fn=<NegBackward0>)\n",
            "Time 112.66571283340454 loss tensor(0.5458, grad_fn=<NegBackward0>)\n",
            "Time 112.70480227470398 loss tensor(0.5457, grad_fn=<NegBackward0>)\n",
            "Time 112.74957633018494 loss tensor(0.5456, grad_fn=<NegBackward0>)\n",
            "Time 112.81189060211182 loss tensor(0.5455, grad_fn=<NegBackward0>)\n",
            "Time 112.8544590473175 loss tensor(0.5454, grad_fn=<NegBackward0>)\n",
            "Time 112.8929054737091 loss tensor(0.5452, grad_fn=<NegBackward0>)\n",
            "Time 112.93423366546631 loss tensor(0.5451, grad_fn=<NegBackward0>)\n",
            "Time 112.97636079788208 loss tensor(0.5450, grad_fn=<NegBackward0>)\n",
            "Time 113.01855802536011 loss tensor(0.5449, grad_fn=<NegBackward0>)\n",
            "Time 113.07550430297852 loss tensor(0.5448, grad_fn=<NegBackward0>)\n",
            "Time 113.12936544418335 loss tensor(0.5446, grad_fn=<NegBackward0>)\n",
            "Time 113.17046999931335 loss tensor(0.5445, grad_fn=<NegBackward0>)\n",
            "Time 113.20895600318909 loss tensor(0.5444, grad_fn=<NegBackward0>)\n",
            "Time 113.26399946212769 loss tensor(0.5443, grad_fn=<NegBackward0>)\n",
            "Time 113.30204463005066 loss tensor(0.5442, grad_fn=<NegBackward0>)\n",
            "Time 113.33994698524475 loss tensor(0.5440, grad_fn=<NegBackward0>)\n",
            "Time 113.37924861907959 loss tensor(0.5439, grad_fn=<NegBackward0>)\n",
            "Time 113.41665840148926 loss tensor(0.5438, grad_fn=<NegBackward0>)\n",
            "Time 113.45459914207458 loss tensor(0.5437, grad_fn=<NegBackward0>)\n",
            "Time 113.50697088241577 loss tensor(0.5436, grad_fn=<NegBackward0>)\n",
            "Time 113.54890155792236 loss tensor(0.5434, grad_fn=<NegBackward0>)\n",
            "Time 113.5877206325531 loss tensor(0.5433, grad_fn=<NegBackward0>)\n",
            "Time 113.6264877319336 loss tensor(0.5432, grad_fn=<NegBackward0>)\n",
            "Time 113.66480112075806 loss tensor(0.5431, grad_fn=<NegBackward0>)\n",
            "Time 113.70329022407532 loss tensor(0.5430, grad_fn=<NegBackward0>)\n",
            "Time 113.74784874916077 loss tensor(0.5428, grad_fn=<NegBackward0>)\n",
            "Time 113.787118434906 loss tensor(0.5427, grad_fn=<NegBackward0>)\n",
            "Time 113.83541464805603 loss tensor(0.5426, grad_fn=<NegBackward0>)\n",
            "Time 113.87495279312134 loss tensor(0.5425, grad_fn=<NegBackward0>)\n",
            "Time 113.91362428665161 loss tensor(0.5424, grad_fn=<NegBackward0>)\n",
            "Time 113.95682525634766 loss tensor(0.5422, grad_fn=<NegBackward0>)\n",
            "Time 113.99616956710815 loss tensor(0.5421, grad_fn=<NegBackward0>)\n",
            "Time 114.03447818756104 loss tensor(0.5420, grad_fn=<NegBackward0>)\n",
            "Time 114.07254719734192 loss tensor(0.5419, grad_fn=<NegBackward0>)\n",
            "Time 114.11223816871643 loss tensor(0.5418, grad_fn=<NegBackward0>)\n",
            "Time 114.15317749977112 loss tensor(0.5417, grad_fn=<NegBackward0>)\n",
            "Time 114.19640326499939 loss tensor(0.5415, grad_fn=<NegBackward0>)\n",
            "Time 114.23933172225952 loss tensor(0.5414, grad_fn=<NegBackward0>)\n",
            "Time 114.28711557388306 loss tensor(0.5413, grad_fn=<NegBackward0>)\n",
            "Time 114.32563376426697 loss tensor(0.5412, grad_fn=<NegBackward0>)\n",
            "Time 114.36377286911011 loss tensor(0.5411, grad_fn=<NegBackward0>)\n",
            "Time 114.4155490398407 loss tensor(0.5409, grad_fn=<NegBackward0>)\n",
            "Time 114.45505595207214 loss tensor(0.5408, grad_fn=<NegBackward0>)\n",
            "Time 114.49351453781128 loss tensor(0.5407, grad_fn=<NegBackward0>)\n",
            "Time 114.53260064125061 loss tensor(0.5406, grad_fn=<NegBackward0>)\n",
            "Time 114.57059240341187 loss tensor(0.5405, grad_fn=<NegBackward0>)\n",
            "Time 114.60830473899841 loss tensor(0.5404, grad_fn=<NegBackward0>)\n",
            "Time 114.65115761756897 loss tensor(0.5402, grad_fn=<NegBackward0>)\n",
            "Time 114.69018387794495 loss tensor(0.5401, grad_fn=<NegBackward0>)\n",
            "Time 114.7317886352539 loss tensor(0.5400, grad_fn=<NegBackward0>)\n",
            "Time 114.77079606056213 loss tensor(0.5399, grad_fn=<NegBackward0>)\n",
            "Time 114.81362342834473 loss tensor(0.5398, grad_fn=<NegBackward0>)\n",
            "Time 114.85428977012634 loss tensor(0.5397, grad_fn=<NegBackward0>)\n",
            "Time 114.8952808380127 loss tensor(0.5395, grad_fn=<NegBackward0>)\n",
            "Time 114.93302702903748 loss tensor(0.5394, grad_fn=<NegBackward0>)\n",
            "Time 114.9711217880249 loss tensor(0.5393, grad_fn=<NegBackward0>)\n",
            "Time 115.009437084198 loss tensor(0.5392, grad_fn=<NegBackward0>)\n",
            "Time 115.047523021698 loss tensor(0.5391, grad_fn=<NegBackward0>)\n",
            "Time 115.09174752235413 loss tensor(0.5390, grad_fn=<NegBackward0>)\n",
            "Time 115.13023734092712 loss tensor(0.5388, grad_fn=<NegBackward0>)\n",
            "Time 115.17032623291016 loss tensor(0.5387, grad_fn=<NegBackward0>)\n",
            "Time 115.20819044113159 loss tensor(0.5386, grad_fn=<NegBackward0>)\n",
            "Time 115.25331592559814 loss tensor(0.5385, grad_fn=<NegBackward0>)\n",
            "Time 115.30365419387817 loss tensor(0.5384, grad_fn=<NegBackward0>)\n",
            "Time 115.34238648414612 loss tensor(0.5383, grad_fn=<NegBackward0>)\n",
            "Time 115.38727307319641 loss tensor(0.5381, grad_fn=<NegBackward0>)\n",
            "Time 115.42454719543457 loss tensor(0.5380, grad_fn=<NegBackward0>)\n",
            "Time 115.46253776550293 loss tensor(0.5379, grad_fn=<NegBackward0>)\n",
            "Time 115.5005738735199 loss tensor(0.5378, grad_fn=<NegBackward0>)\n",
            "Time 115.54917502403259 loss tensor(0.5377, grad_fn=<NegBackward0>)\n",
            "Time 115.58722853660583 loss tensor(0.5376, grad_fn=<NegBackward0>)\n",
            "Time 115.6268675327301 loss tensor(0.5374, grad_fn=<NegBackward0>)\n",
            "Time 115.66894102096558 loss tensor(0.5373, grad_fn=<NegBackward0>)\n",
            "Time 115.70718026161194 loss tensor(0.5372, grad_fn=<NegBackward0>)\n",
            "Time 115.74657869338989 loss tensor(0.5371, grad_fn=<NegBackward0>)\n",
            "Time 115.79197669029236 loss tensor(0.5370, grad_fn=<NegBackward0>)\n",
            "Time 115.83292198181152 loss tensor(0.5369, grad_fn=<NegBackward0>)\n",
            "Time 115.8732738494873 loss tensor(0.5367, grad_fn=<NegBackward0>)\n",
            "Time 115.91558837890625 loss tensor(0.5366, grad_fn=<NegBackward0>)\n",
            "Time 115.95632457733154 loss tensor(0.5365, grad_fn=<NegBackward0>)\n",
            "Time 116.00145053863525 loss tensor(0.5364, grad_fn=<NegBackward0>)\n",
            "Time 116.04072856903076 loss tensor(0.5363, grad_fn=<NegBackward0>)\n",
            "Time 116.0793673992157 loss tensor(0.5362, grad_fn=<NegBackward0>)\n",
            "Time 116.11750626564026 loss tensor(0.5361, grad_fn=<NegBackward0>)\n",
            "Time 116.15908479690552 loss tensor(0.5359, grad_fn=<NegBackward0>)\n",
            "Time 116.19753789901733 loss tensor(0.5358, grad_fn=<NegBackward0>)\n",
            "Time 116.24215507507324 loss tensor(0.5357, grad_fn=<NegBackward0>)\n",
            "Time 116.28473925590515 loss tensor(0.5356, grad_fn=<NegBackward0>)\n",
            "Time 116.34016060829163 loss tensor(0.5355, grad_fn=<NegBackward0>)\n",
            "Time 116.37896299362183 loss tensor(0.5354, grad_fn=<NegBackward0>)\n",
            "Time 116.41773009300232 loss tensor(0.5353, grad_fn=<NegBackward0>)\n",
            "Time 116.46302318572998 loss tensor(0.5351, grad_fn=<NegBackward0>)\n",
            "Time 116.50164842605591 loss tensor(0.5350, grad_fn=<NegBackward0>)\n",
            "Time 116.54589939117432 loss tensor(0.5349, grad_fn=<NegBackward0>)\n",
            "Time 116.58496284484863 loss tensor(0.5348, grad_fn=<NegBackward0>)\n",
            "Time 116.62357783317566 loss tensor(0.5347, grad_fn=<NegBackward0>)\n",
            "Time 116.66202759742737 loss tensor(0.5346, grad_fn=<NegBackward0>)\n",
            "Time 116.7068841457367 loss tensor(0.5345, grad_fn=<NegBackward0>)\n",
            "Time 116.74527883529663 loss tensor(0.5343, grad_fn=<NegBackward0>)\n",
            "Time 116.7848789691925 loss tensor(0.5342, grad_fn=<NegBackward0>)\n",
            "Time 116.82330822944641 loss tensor(0.5341, grad_fn=<NegBackward0>)\n",
            "Time 116.8699836730957 loss tensor(0.5340, grad_fn=<NegBackward0>)\n",
            "Time 116.91597414016724 loss tensor(0.5339, grad_fn=<NegBackward0>)\n",
            "Time 116.95510029792786 loss tensor(0.5338, grad_fn=<NegBackward0>)\n",
            "Time 116.99352240562439 loss tensor(0.5337, grad_fn=<NegBackward0>)\n",
            "Time 117.03138637542725 loss tensor(0.5335, grad_fn=<NegBackward0>)\n",
            "Time 117.06974148750305 loss tensor(0.5334, grad_fn=<NegBackward0>)\n",
            "Time 117.10824275016785 loss tensor(0.5333, grad_fn=<NegBackward0>)\n",
            "Time 117.15493655204773 loss tensor(0.5332, grad_fn=<NegBackward0>)\n",
            "Time 117.20345950126648 loss tensor(0.5331, grad_fn=<NegBackward0>)\n",
            "Time 117.2652657032013 loss tensor(0.5330, grad_fn=<NegBackward0>)\n",
            "Time 117.32983589172363 loss tensor(0.5329, grad_fn=<NegBackward0>)\n",
            "Time 117.41162085533142 loss tensor(0.5327, grad_fn=<NegBackward0>)\n",
            "Time 117.47683143615723 loss tensor(0.5326, grad_fn=<NegBackward0>)\n",
            "Time 117.53476595878601 loss tensor(0.5325, grad_fn=<NegBackward0>)\n",
            "Time 117.59428572654724 loss tensor(0.5324, grad_fn=<NegBackward0>)\n",
            "Time 117.65464210510254 loss tensor(0.5323, grad_fn=<NegBackward0>)\n",
            "Time 117.71319007873535 loss tensor(0.5322, grad_fn=<NegBackward0>)\n",
            "Time 117.77275156974792 loss tensor(0.5321, grad_fn=<NegBackward0>)\n",
            "Time 117.83425521850586 loss tensor(0.5320, grad_fn=<NegBackward0>)\n",
            "Time 117.90438508987427 loss tensor(0.5318, grad_fn=<NegBackward0>)\n",
            "Time 117.96355652809143 loss tensor(0.5317, grad_fn=<NegBackward0>)\n",
            "Time 118.02127027511597 loss tensor(0.5316, grad_fn=<NegBackward0>)\n",
            "Time 118.07962560653687 loss tensor(0.5315, grad_fn=<NegBackward0>)\n",
            "Time 118.1423921585083 loss tensor(0.5314, grad_fn=<NegBackward0>)\n",
            "Time 118.20351910591125 loss tensor(0.5313, grad_fn=<NegBackward0>)\n",
            "Time 118.26413559913635 loss tensor(0.5312, grad_fn=<NegBackward0>)\n",
            "Time 118.32200598716736 loss tensor(0.5311, grad_fn=<NegBackward0>)\n",
            "Time 118.38653230667114 loss tensor(0.5309, grad_fn=<NegBackward0>)\n",
            "Time 118.45037889480591 loss tensor(0.5308, grad_fn=<NegBackward0>)\n",
            "Time 118.52976822853088 loss tensor(0.5307, grad_fn=<NegBackward0>)\n",
            "Time 118.58781623840332 loss tensor(0.5306, grad_fn=<NegBackward0>)\n",
            "Time 118.65028214454651 loss tensor(0.5305, grad_fn=<NegBackward0>)\n",
            "Time 118.70804023742676 loss tensor(0.5304, grad_fn=<NegBackward0>)\n",
            "Time 118.76592421531677 loss tensor(0.5303, grad_fn=<NegBackward0>)\n",
            "Time 118.82968187332153 loss tensor(0.5302, grad_fn=<NegBackward0>)\n",
            "Time 118.89004731178284 loss tensor(0.5301, grad_fn=<NegBackward0>)\n",
            "Time 118.94994378089905 loss tensor(0.5299, grad_fn=<NegBackward0>)\n",
            "Time 119.01136755943298 loss tensor(0.5298, grad_fn=<NegBackward0>)\n",
            "Time 119.07412958145142 loss tensor(0.5297, grad_fn=<NegBackward0>)\n",
            "Time 119.13197445869446 loss tensor(0.5296, grad_fn=<NegBackward0>)\n",
            "Time 119.19315695762634 loss tensor(0.5295, grad_fn=<NegBackward0>)\n",
            "Time 119.25604176521301 loss tensor(0.5294, grad_fn=<NegBackward0>)\n",
            "Time 119.32186889648438 loss tensor(0.5293, grad_fn=<NegBackward0>)\n",
            "Time 119.3805181980133 loss tensor(0.5292, grad_fn=<NegBackward0>)\n",
            "Time 119.44650030136108 loss tensor(0.5290, grad_fn=<NegBackward0>)\n",
            "Time 119.50540328025818 loss tensor(0.5289, grad_fn=<NegBackward0>)\n",
            "Time 119.57096004486084 loss tensor(0.5288, grad_fn=<NegBackward0>)\n",
            "Time 119.63218998908997 loss tensor(0.5287, grad_fn=<NegBackward0>)\n",
            "Time 119.69053649902344 loss tensor(0.5286, grad_fn=<NegBackward0>)\n",
            "Time 119.75545978546143 loss tensor(0.5285, grad_fn=<NegBackward0>)\n",
            "Time 119.82467007637024 loss tensor(0.5284, grad_fn=<NegBackward0>)\n",
            "Time 119.89602518081665 loss tensor(0.5283, grad_fn=<NegBackward0>)\n",
            "Time 119.95602226257324 loss tensor(0.5282, grad_fn=<NegBackward0>)\n",
            "Time 119.99455952644348 loss tensor(0.5280, grad_fn=<NegBackward0>)\n",
            "Time 120.04049110412598 loss tensor(0.5279, grad_fn=<NegBackward0>)\n",
            "Time 120.07987856864929 loss tensor(0.5278, grad_fn=<NegBackward0>)\n",
            "Time 120.12012195587158 loss tensor(0.5277, grad_fn=<NegBackward0>)\n",
            "Time 120.16167378425598 loss tensor(0.5276, grad_fn=<NegBackward0>)\n",
            "Time 120.20073223114014 loss tensor(0.5275, grad_fn=<NegBackward0>)\n",
            "Time 120.24838948249817 loss tensor(0.5274, grad_fn=<NegBackward0>)\n",
            "Time 120.29050970077515 loss tensor(0.5273, grad_fn=<NegBackward0>)\n",
            "Time 120.32950639724731 loss tensor(0.5272, grad_fn=<NegBackward0>)\n",
            "Time 120.36815357208252 loss tensor(0.5271, grad_fn=<NegBackward0>)\n",
            "Time 120.40692257881165 loss tensor(0.5269, grad_fn=<NegBackward0>)\n",
            "Time 120.44604229927063 loss tensor(0.5268, grad_fn=<NegBackward0>)\n",
            "Time 120.49881911277771 loss tensor(0.5267, grad_fn=<NegBackward0>)\n",
            "Time 120.54145669937134 loss tensor(0.5266, grad_fn=<NegBackward0>)\n",
            "Time 120.5795738697052 loss tensor(0.5265, grad_fn=<NegBackward0>)\n",
            "Time 120.61756324768066 loss tensor(0.5264, grad_fn=<NegBackward0>)\n",
            "Time 120.65507936477661 loss tensor(0.5263, grad_fn=<NegBackward0>)\n",
            "Time 120.69289946556091 loss tensor(0.5262, grad_fn=<NegBackward0>)\n",
            "Time 120.73697400093079 loss tensor(0.5261, grad_fn=<NegBackward0>)\n",
            "Time 120.77719473838806 loss tensor(0.5260, grad_fn=<NegBackward0>)\n",
            "Time 120.81705212593079 loss tensor(0.5259, grad_fn=<NegBackward0>)\n",
            "Time 120.85641598701477 loss tensor(0.5257, grad_fn=<NegBackward0>)\n",
            "Time 120.89658308029175 loss tensor(0.5256, grad_fn=<NegBackward0>)\n",
            "Time 120.93614459037781 loss tensor(0.5255, grad_fn=<NegBackward0>)\n",
            "Time 120.98054647445679 loss tensor(0.5254, grad_fn=<NegBackward0>)\n",
            "Time 121.01870369911194 loss tensor(0.5253, grad_fn=<NegBackward0>)\n",
            "Time 121.0566565990448 loss tensor(0.5252, grad_fn=<NegBackward0>)\n",
            "Time 121.09411644935608 loss tensor(0.5251, grad_fn=<NegBackward0>)\n",
            "Time 121.1325433254242 loss tensor(0.5250, grad_fn=<NegBackward0>)\n",
            "Time 121.18484687805176 loss tensor(0.5249, grad_fn=<NegBackward0>)\n",
            "Time 121.22493362426758 loss tensor(0.5248, grad_fn=<NegBackward0>)\n",
            "Time 121.26431107521057 loss tensor(0.5247, grad_fn=<NegBackward0>)\n",
            "Time 121.30236053466797 loss tensor(0.5245, grad_fn=<NegBackward0>)\n",
            "Time 121.34104537963867 loss tensor(0.5244, grad_fn=<NegBackward0>)\n",
            "Time 121.40419435501099 loss tensor(0.5243, grad_fn=<NegBackward0>)\n",
            "Time 121.44270515441895 loss tensor(0.5242, grad_fn=<NegBackward0>)\n",
            "Time 121.48118901252747 loss tensor(0.5241, grad_fn=<NegBackward0>)\n",
            "Time 121.53396964073181 loss tensor(0.5240, grad_fn=<NegBackward0>)\n",
            "Time 121.57364273071289 loss tensor(0.5239, grad_fn=<NegBackward0>)\n",
            "Time 121.61784529685974 loss tensor(0.5238, grad_fn=<NegBackward0>)\n",
            "Time 121.65650272369385 loss tensor(0.5237, grad_fn=<NegBackward0>)\n",
            "Time 121.69540095329285 loss tensor(0.5236, grad_fn=<NegBackward0>)\n",
            "Time 121.73382234573364 loss tensor(0.5235, grad_fn=<NegBackward0>)\n",
            "Time 121.77230787277222 loss tensor(0.5233, grad_fn=<NegBackward0>)\n",
            "Time 121.8190541267395 loss tensor(0.5232, grad_fn=<NegBackward0>)\n",
            "Time 121.86539149284363 loss tensor(0.5231, grad_fn=<NegBackward0>)\n",
            "Time 121.90587425231934 loss tensor(0.5230, grad_fn=<NegBackward0>)\n",
            "Time 121.94548320770264 loss tensor(0.5229, grad_fn=<NegBackward0>)\n",
            "Time 121.98495578765869 loss tensor(0.5228, grad_fn=<NegBackward0>)\n",
            "Time 122.04242062568665 loss tensor(0.5227, grad_fn=<NegBackward0>)\n",
            "Time 122.08228850364685 loss tensor(0.5226, grad_fn=<NegBackward0>)\n",
            "Time 122.12076592445374 loss tensor(0.5225, grad_fn=<NegBackward0>)\n",
            "Time 122.16281247138977 loss tensor(0.5224, grad_fn=<NegBackward0>)\n",
            "Time 122.20253992080688 loss tensor(0.5223, grad_fn=<NegBackward0>)\n",
            "Time 122.24182081222534 loss tensor(0.5222, grad_fn=<NegBackward0>)\n",
            "Time 122.3014748096466 loss tensor(0.5221, grad_fn=<NegBackward0>)\n",
            "Time 122.34170484542847 loss tensor(0.5220, grad_fn=<NegBackward0>)\n",
            "Time 122.38143110275269 loss tensor(0.5218, grad_fn=<NegBackward0>)\n",
            "Time 122.42624831199646 loss tensor(0.5217, grad_fn=<NegBackward0>)\n",
            "Time 122.47139644622803 loss tensor(0.5216, grad_fn=<NegBackward0>)\n",
            "Time 122.51648378372192 loss tensor(0.5215, grad_fn=<NegBackward0>)\n",
            "Time 122.55699801445007 loss tensor(0.5214, grad_fn=<NegBackward0>)\n",
            "Time 122.59493947029114 loss tensor(0.5213, grad_fn=<NegBackward0>)\n",
            "Time 122.63403964042664 loss tensor(0.5212, grad_fn=<NegBackward0>)\n",
            "Time 122.67464566230774 loss tensor(0.5211, grad_fn=<NegBackward0>)\n",
            "Time 122.72265911102295 loss tensor(0.5210, grad_fn=<NegBackward0>)\n",
            "Time 122.76746892929077 loss tensor(0.5209, grad_fn=<NegBackward0>)\n",
            "Time 122.80765461921692 loss tensor(0.5208, grad_fn=<NegBackward0>)\n",
            "Time 122.8473265171051 loss tensor(0.5207, grad_fn=<NegBackward0>)\n",
            "Time 122.8950982093811 loss tensor(0.5206, grad_fn=<NegBackward0>)\n",
            "Time 122.93526768684387 loss tensor(0.5205, grad_fn=<NegBackward0>)\n",
            "Time 122.97490096092224 loss tensor(0.5203, grad_fn=<NegBackward0>)\n",
            "Time 123.01507639884949 loss tensor(0.5202, grad_fn=<NegBackward0>)\n",
            "Time 123.05371689796448 loss tensor(0.5201, grad_fn=<NegBackward0>)\n",
            "Time 123.09152293205261 loss tensor(0.5200, grad_fn=<NegBackward0>)\n",
            "Time 123.13659811019897 loss tensor(0.5199, grad_fn=<NegBackward0>)\n",
            "Time 123.18671679496765 loss tensor(0.5198, grad_fn=<NegBackward0>)\n",
            "Time 123.2253885269165 loss tensor(0.5197, grad_fn=<NegBackward0>)\n",
            "Time 123.26722121238708 loss tensor(0.5196, grad_fn=<NegBackward0>)\n",
            "Time 123.30849623680115 loss tensor(0.5195, grad_fn=<NegBackward0>)\n",
            "Time 123.35308647155762 loss tensor(0.5194, grad_fn=<NegBackward0>)\n",
            "Time 123.39112854003906 loss tensor(0.5193, grad_fn=<NegBackward0>)\n",
            "Time 123.42897963523865 loss tensor(0.5192, grad_fn=<NegBackward0>)\n",
            "Time 123.46684074401855 loss tensor(0.5191, grad_fn=<NegBackward0>)\n",
            "Time 123.505136013031 loss tensor(0.5190, grad_fn=<NegBackward0>)\n",
            "Time 123.5537121295929 loss tensor(0.5189, grad_fn=<NegBackward0>)\n",
            "Time 123.60196709632874 loss tensor(0.5188, grad_fn=<NegBackward0>)\n",
            "Time 123.64056611061096 loss tensor(0.5187, grad_fn=<NegBackward0>)\n",
            "Time 123.67868947982788 loss tensor(0.5185, grad_fn=<NegBackward0>)\n",
            "Time 123.71698307991028 loss tensor(0.5184, grad_fn=<NegBackward0>)\n",
            "Time 123.76075267791748 loss tensor(0.5183, grad_fn=<NegBackward0>)\n",
            "Time 123.80803632736206 loss tensor(0.5182, grad_fn=<NegBackward0>)\n",
            "Time 123.84671092033386 loss tensor(0.5181, grad_fn=<NegBackward0>)\n",
            "Time 123.88579416275024 loss tensor(0.5180, grad_fn=<NegBackward0>)\n",
            "Time 123.92698073387146 loss tensor(0.5179, grad_fn=<NegBackward0>)\n",
            "Time 123.9660975933075 loss tensor(0.5178, grad_fn=<NegBackward0>)\n",
            "Time 124.01545977592468 loss tensor(0.5177, grad_fn=<NegBackward0>)\n",
            "Time 124.05390119552612 loss tensor(0.5176, grad_fn=<NegBackward0>)\n",
            "Time 124.09231805801392 loss tensor(0.5175, grad_fn=<NegBackward0>)\n",
            "Time 124.1308159828186 loss tensor(0.5174, grad_fn=<NegBackward0>)\n",
            "Time 124.1714608669281 loss tensor(0.5173, grad_fn=<NegBackward0>)\n",
            "Time 124.21081519126892 loss tensor(0.5172, grad_fn=<NegBackward0>)\n",
            "Time 124.2561104297638 loss tensor(0.5171, grad_fn=<NegBackward0>)\n",
            "Time 124.2956554889679 loss tensor(0.5170, grad_fn=<NegBackward0>)\n",
            "Time 124.33576130867004 loss tensor(0.5169, grad_fn=<NegBackward0>)\n",
            "Time 124.3753068447113 loss tensor(0.5168, grad_fn=<NegBackward0>)\n",
            "Time 124.41395807266235 loss tensor(0.5167, grad_fn=<NegBackward0>)\n",
            "Time 124.45891451835632 loss tensor(0.5166, grad_fn=<NegBackward0>)\n",
            "Time 124.50495529174805 loss tensor(0.5164, grad_fn=<NegBackward0>)\n",
            "Time 124.54559469223022 loss tensor(0.5163, grad_fn=<NegBackward0>)\n",
            "Time 124.59014296531677 loss tensor(0.5162, grad_fn=<NegBackward0>)\n",
            "Time 124.62814402580261 loss tensor(0.5161, grad_fn=<NegBackward0>)\n",
            "Time 124.67526292800903 loss tensor(0.5160, grad_fn=<NegBackward0>)\n",
            "Time 124.71819233894348 loss tensor(0.5159, grad_fn=<NegBackward0>)\n",
            "Time 124.76207828521729 loss tensor(0.5158, grad_fn=<NegBackward0>)\n",
            "Time 124.8021354675293 loss tensor(0.5157, grad_fn=<NegBackward0>)\n",
            "Time 124.84084439277649 loss tensor(0.5156, grad_fn=<NegBackward0>)\n",
            "Time 124.88352751731873 loss tensor(0.5155, grad_fn=<NegBackward0>)\n",
            "Time 124.92555499076843 loss tensor(0.5154, grad_fn=<NegBackward0>)\n",
            "Time 124.96890020370483 loss tensor(0.5153, grad_fn=<NegBackward0>)\n",
            "Time 125.00738549232483 loss tensor(0.5152, grad_fn=<NegBackward0>)\n",
            "Time 125.04559302330017 loss tensor(0.5151, grad_fn=<NegBackward0>)\n",
            "Time 125.09207582473755 loss tensor(0.5150, grad_fn=<NegBackward0>)\n",
            "Time 125.13376903533936 loss tensor(0.5149, grad_fn=<NegBackward0>)\n",
            "Time 125.17407202720642 loss tensor(0.5148, grad_fn=<NegBackward0>)\n",
            "Time 125.2132477760315 loss tensor(0.5147, grad_fn=<NegBackward0>)\n",
            "Time 125.25227236747742 loss tensor(0.5146, grad_fn=<NegBackward0>)\n",
            "Time 125.30151891708374 loss tensor(0.5145, grad_fn=<NegBackward0>)\n",
            "Time 125.34251594543457 loss tensor(0.5144, grad_fn=<NegBackward0>)\n",
            "Time 125.38081121444702 loss tensor(0.5143, grad_fn=<NegBackward0>)\n",
            "Time 125.41914796829224 loss tensor(0.5142, grad_fn=<NegBackward0>)\n",
            "Time 125.45754075050354 loss tensor(0.5141, grad_fn=<NegBackward0>)\n",
            "Time 125.49583911895752 loss tensor(0.5140, grad_fn=<NegBackward0>)\n",
            "Time 125.54037594795227 loss tensor(0.5139, grad_fn=<NegBackward0>)\n",
            "Time 125.58902907371521 loss tensor(0.5138, grad_fn=<NegBackward0>)\n",
            "Time 125.62791275978088 loss tensor(0.5137, grad_fn=<NegBackward0>)\n",
            "Time 125.6665678024292 loss tensor(0.5135, grad_fn=<NegBackward0>)\n",
            "Time 125.70520305633545 loss tensor(0.5134, grad_fn=<NegBackward0>)\n",
            "Time 125.75380802154541 loss tensor(0.5133, grad_fn=<NegBackward0>)\n",
            "Time 125.79636001586914 loss tensor(0.5132, grad_fn=<NegBackward0>)\n",
            "Time 125.83558654785156 loss tensor(0.5131, grad_fn=<NegBackward0>)\n",
            "Time 125.8774163722992 loss tensor(0.5130, grad_fn=<NegBackward0>)\n",
            "Time 125.92058658599854 loss tensor(0.5129, grad_fn=<NegBackward0>)\n",
            "Time 125.96739745140076 loss tensor(0.5128, grad_fn=<NegBackward0>)\n",
            "Time 126.00878071784973 loss tensor(0.5127, grad_fn=<NegBackward0>)\n",
            "Time 126.04719257354736 loss tensor(0.5126, grad_fn=<NegBackward0>)\n",
            "Time 126.0859386920929 loss tensor(0.5125, grad_fn=<NegBackward0>)\n",
            "Time 126.12490916252136 loss tensor(0.5124, grad_fn=<NegBackward0>)\n",
            "Time 126.16663789749146 loss tensor(0.5123, grad_fn=<NegBackward0>)\n",
            "Time 126.21144938468933 loss tensor(0.5122, grad_fn=<NegBackward0>)\n",
            "Time 126.25056624412537 loss tensor(0.5121, grad_fn=<NegBackward0>)\n",
            "Time 126.29179859161377 loss tensor(0.5120, grad_fn=<NegBackward0>)\n",
            "Time 126.32981967926025 loss tensor(0.5119, grad_fn=<NegBackward0>)\n",
            "Time 126.36846661567688 loss tensor(0.5118, grad_fn=<NegBackward0>)\n",
            "Time 126.41280388832092 loss tensor(0.5117, grad_fn=<NegBackward0>)\n",
            "Time 126.45434379577637 loss tensor(0.5116, grad_fn=<NegBackward0>)\n",
            "Time 126.49369621276855 loss tensor(0.5115, grad_fn=<NegBackward0>)\n",
            "Time 126.53308176994324 loss tensor(0.5114, grad_fn=<NegBackward0>)\n",
            "Time 126.58215165138245 loss tensor(0.5113, grad_fn=<NegBackward0>)\n",
            "Time 126.63703179359436 loss tensor(0.5112, grad_fn=<NegBackward0>)\n",
            "Time 126.67644596099854 loss tensor(0.5111, grad_fn=<NegBackward0>)\n",
            "Time 126.71525025367737 loss tensor(0.5110, grad_fn=<NegBackward0>)\n",
            "Time 126.75399661064148 loss tensor(0.5109, grad_fn=<NegBackward0>)\n",
            "Time 126.79748344421387 loss tensor(0.5108, grad_fn=<NegBackward0>)\n",
            "Time 126.84536814689636 loss tensor(0.5107, grad_fn=<NegBackward0>)\n",
            "Time 126.88547110557556 loss tensor(0.5106, grad_fn=<NegBackward0>)\n",
            "Time 126.93015456199646 loss tensor(0.5105, grad_fn=<NegBackward0>)\n",
            "Time 126.97147059440613 loss tensor(0.5104, grad_fn=<NegBackward0>)\n",
            "Time 127.01160788536072 loss tensor(0.5103, grad_fn=<NegBackward0>)\n",
            "Time 127.0572783946991 loss tensor(0.5102, grad_fn=<NegBackward0>)\n",
            "Time 127.09895515441895 loss tensor(0.5101, grad_fn=<NegBackward0>)\n",
            "Time 127.1372902393341 loss tensor(0.5100, grad_fn=<NegBackward0>)\n",
            "Time 127.18665504455566 loss tensor(0.5099, grad_fn=<NegBackward0>)\n",
            "Time 127.22603225708008 loss tensor(0.5098, grad_fn=<NegBackward0>)\n",
            "Time 127.27052593231201 loss tensor(0.5097, grad_fn=<NegBackward0>)\n",
            "Time 127.30871367454529 loss tensor(0.5096, grad_fn=<NegBackward0>)\n",
            "Time 127.34691667556763 loss tensor(0.5095, grad_fn=<NegBackward0>)\n",
            "Time 127.38648724555969 loss tensor(0.5094, grad_fn=<NegBackward0>)\n",
            "Time 127.42422008514404 loss tensor(0.5093, grad_fn=<NegBackward0>)\n",
            "Time 127.46279573440552 loss tensor(0.5092, grad_fn=<NegBackward0>)\n",
            "Time 127.51839971542358 loss tensor(0.5091, grad_fn=<NegBackward0>)\n",
            "Time 127.5582013130188 loss tensor(0.5090, grad_fn=<NegBackward0>)\n",
            "Time 127.59822821617126 loss tensor(0.5089, grad_fn=<NegBackward0>)\n",
            "Time 127.64526224136353 loss tensor(0.5088, grad_fn=<NegBackward0>)\n",
            "Time 127.68585014343262 loss tensor(0.5087, grad_fn=<NegBackward0>)\n",
            "Time 127.73230481147766 loss tensor(0.5086, grad_fn=<NegBackward0>)\n",
            "Time 127.7739315032959 loss tensor(0.5085, grad_fn=<NegBackward0>)\n",
            "Time 127.81446599960327 loss tensor(0.5084, grad_fn=<NegBackward0>)\n",
            "Time 127.85332202911377 loss tensor(0.5083, grad_fn=<NegBackward0>)\n",
            "Time 127.89217138290405 loss tensor(0.5082, grad_fn=<NegBackward0>)\n",
            "Time 127.9347128868103 loss tensor(0.5081, grad_fn=<NegBackward0>)\n",
            "Time 127.9767234325409 loss tensor(0.5080, grad_fn=<NegBackward0>)\n",
            "Time 128.0200333595276 loss tensor(0.5079, grad_fn=<NegBackward0>)\n",
            "Time 128.05892038345337 loss tensor(0.5078, grad_fn=<NegBackward0>)\n",
            "Time 128.09766936302185 loss tensor(0.5077, grad_fn=<NegBackward0>)\n",
            "Time 128.14915466308594 loss tensor(0.5076, grad_fn=<NegBackward0>)\n",
            "Time 128.1907832622528 loss tensor(0.5075, grad_fn=<NegBackward0>)\n",
            "Time 128.22919607162476 loss tensor(0.5074, grad_fn=<NegBackward0>)\n",
            "Time 128.2678484916687 loss tensor(0.5073, grad_fn=<NegBackward0>)\n",
            "Time 128.30643367767334 loss tensor(0.5072, grad_fn=<NegBackward0>)\n",
            "Time 128.34469389915466 loss tensor(0.5071, grad_fn=<NegBackward0>)\n",
            "Time 128.3894054889679 loss tensor(0.5070, grad_fn=<NegBackward0>)\n",
            "Time 128.4287827014923 loss tensor(0.5069, grad_fn=<NegBackward0>)\n",
            "Time 128.4670763015747 loss tensor(0.5068, grad_fn=<NegBackward0>)\n",
            "Time 128.50584602355957 loss tensor(0.5067, grad_fn=<NegBackward0>)\n",
            "Time 128.5438892841339 loss tensor(0.5066, grad_fn=<NegBackward0>)\n",
            "Time 128.5828673839569 loss tensor(0.5065, grad_fn=<NegBackward0>)\n",
            "Time 128.63324618339539 loss tensor(0.5064, grad_fn=<NegBackward0>)\n",
            "Time 128.67543196678162 loss tensor(0.5063, grad_fn=<NegBackward0>)\n",
            "Time 128.71390581130981 loss tensor(0.5062, grad_fn=<NegBackward0>)\n",
            "Time 128.75316286087036 loss tensor(0.5061, grad_fn=<NegBackward0>)\n",
            "Time 128.79385328292847 loss tensor(0.5060, grad_fn=<NegBackward0>)\n",
            "Time 128.8416736125946 loss tensor(0.5059, grad_fn=<NegBackward0>)\n",
            "Time 128.88542580604553 loss tensor(0.5058, grad_fn=<NegBackward0>)\n",
            "Time 128.9289882183075 loss tensor(0.5057, grad_fn=<NegBackward0>)\n",
            "Time 128.96849632263184 loss tensor(0.5056, grad_fn=<NegBackward0>)\n",
            "Time 129.00754976272583 loss tensor(0.5055, grad_fn=<NegBackward0>)\n",
            "Time 129.0476429462433 loss tensor(0.5054, grad_fn=<NegBackward0>)\n",
            "Time 129.09037017822266 loss tensor(0.5053, grad_fn=<NegBackward0>)\n",
            "Time 129.12904524803162 loss tensor(0.5052, grad_fn=<NegBackward0>)\n",
            "Time 129.1780092716217 loss tensor(0.5051, grad_fn=<NegBackward0>)\n",
            "Time 129.21888494491577 loss tensor(0.5050, grad_fn=<NegBackward0>)\n",
            "Time 129.26886987686157 loss tensor(0.5049, grad_fn=<NegBackward0>)\n",
            "Time 129.31057810783386 loss tensor(0.5048, grad_fn=<NegBackward0>)\n",
            "Time 129.35040926933289 loss tensor(0.5047, grad_fn=<NegBackward0>)\n",
            "Time 129.3892273902893 loss tensor(0.5046, grad_fn=<NegBackward0>)\n",
            "Time 129.42793440818787 loss tensor(0.5045, grad_fn=<NegBackward0>)\n",
            "Time 129.48313903808594 loss tensor(0.5044, grad_fn=<NegBackward0>)\n",
            "Time 129.52430033683777 loss tensor(0.5043, grad_fn=<NegBackward0>)\n",
            "Time 129.5650770664215 loss tensor(0.5042, grad_fn=<NegBackward0>)\n",
            "Time 129.60376381874084 loss tensor(0.5041, grad_fn=<NegBackward0>)\n",
            "Time 129.6430242061615 loss tensor(0.5040, grad_fn=<NegBackward0>)\n",
            "Time 129.69211840629578 loss tensor(0.5039, grad_fn=<NegBackward0>)\n",
            "Time 129.73268818855286 loss tensor(0.5038, grad_fn=<NegBackward0>)\n",
            "Time 129.77978801727295 loss tensor(0.5037, grad_fn=<NegBackward0>)\n",
            "Time 129.82342195510864 loss tensor(0.5036, grad_fn=<NegBackward0>)\n",
            "Time 129.86382961273193 loss tensor(0.5035, grad_fn=<NegBackward0>)\n",
            "Time 129.90822315216064 loss tensor(0.5034, grad_fn=<NegBackward0>)\n",
            "Time 129.95117044448853 loss tensor(0.5033, grad_fn=<NegBackward0>)\n",
            "Time 130.0089144706726 loss tensor(0.5032, grad_fn=<NegBackward0>)\n",
            "Time 130.07123947143555 loss tensor(0.5031, grad_fn=<NegBackward0>)\n",
            "Time 130.14575624465942 loss tensor(0.5030, grad_fn=<NegBackward0>)\n",
            "Time 130.20714020729065 loss tensor(0.5029, grad_fn=<NegBackward0>)\n",
            "Time 130.26567769050598 loss tensor(0.5029, grad_fn=<NegBackward0>)\n",
            "Time 130.32412672042847 loss tensor(0.5028, grad_fn=<NegBackward0>)\n",
            "Time 130.39320588111877 loss tensor(0.5027, grad_fn=<NegBackward0>)\n",
            "Time 130.450852394104 loss tensor(0.5026, grad_fn=<NegBackward0>)\n",
            "Time 130.5080907344818 loss tensor(0.5025, grad_fn=<NegBackward0>)\n",
            "Time 130.56552481651306 loss tensor(0.5024, grad_fn=<NegBackward0>)\n",
            "Time 130.62828278541565 loss tensor(0.5023, grad_fn=<NegBackward0>)\n",
            "Time 130.6913766860962 loss tensor(0.5022, grad_fn=<NegBackward0>)\n",
            "Time 130.7532560825348 loss tensor(0.5021, grad_fn=<NegBackward0>)\n",
            "Time 130.81234335899353 loss tensor(0.5020, grad_fn=<NegBackward0>)\n",
            "Time 130.8792266845703 loss tensor(0.5019, grad_fn=<NegBackward0>)\n",
            "Time 130.94008827209473 loss tensor(0.5018, grad_fn=<NegBackward0>)\n",
            "Time 130.99825382232666 loss tensor(0.5017, grad_fn=<NegBackward0>)\n",
            "Time 131.0568618774414 loss tensor(0.5016, grad_fn=<NegBackward0>)\n",
            "Time 131.119961977005 loss tensor(0.5015, grad_fn=<NegBackward0>)\n",
            "Time 131.1854932308197 loss tensor(0.5014, grad_fn=<NegBackward0>)\n",
            "Time 131.24376463890076 loss tensor(0.5013, grad_fn=<NegBackward0>)\n",
            "Time 131.30230736732483 loss tensor(0.5012, grad_fn=<NegBackward0>)\n",
            "Time 131.36738777160645 loss tensor(0.5011, grad_fn=<NegBackward0>)\n",
            "Time 131.42478847503662 loss tensor(0.5010, grad_fn=<NegBackward0>)\n",
            "Time 131.48234248161316 loss tensor(0.5009, grad_fn=<NegBackward0>)\n",
            "Time 131.54083967208862 loss tensor(0.5008, grad_fn=<NegBackward0>)\n",
            "Time 131.60501098632812 loss tensor(0.5007, grad_fn=<NegBackward0>)\n",
            "Time 131.66314697265625 loss tensor(0.5006, grad_fn=<NegBackward0>)\n",
            "Time 131.72726821899414 loss tensor(0.5005, grad_fn=<NegBackward0>)\n",
            "Time 131.78775715827942 loss tensor(0.5004, grad_fn=<NegBackward0>)\n",
            "Time 131.8659234046936 loss tensor(0.5003, grad_fn=<NegBackward0>)\n",
            "Time 131.93368911743164 loss tensor(0.5002, grad_fn=<NegBackward0>)\n",
            "Time 131.99366736412048 loss tensor(0.5001, grad_fn=<NegBackward0>)\n",
            "Time 132.05703496932983 loss tensor(0.5001, grad_fn=<NegBackward0>)\n",
            "Time 132.11853098869324 loss tensor(0.5000, grad_fn=<NegBackward0>)\n",
            "Time 132.18015670776367 loss tensor(0.4999, grad_fn=<NegBackward0>)\n",
            "Time 132.23820567131042 loss tensor(0.4998, grad_fn=<NegBackward0>)\n",
            "Time 132.29554533958435 loss tensor(0.4997, grad_fn=<NegBackward0>)\n",
            "Time 132.35714888572693 loss tensor(0.4996, grad_fn=<NegBackward0>)\n",
            "Time 132.4168164730072 loss tensor(0.4995, grad_fn=<NegBackward0>)\n",
            "Time 132.4763491153717 loss tensor(0.4994, grad_fn=<NegBackward0>)\n",
            "Time 132.53882122039795 loss tensor(0.4993, grad_fn=<NegBackward0>)\n",
            "Time 132.6076157093048 loss tensor(0.4992, grad_fn=<NegBackward0>)\n",
            "Time 132.69292831420898 loss tensor(0.4991, grad_fn=<NegBackward0>)\n",
            "Time 132.75356554985046 loss tensor(0.4990, grad_fn=<NegBackward0>)\n",
            "Time 132.80348324775696 loss tensor(0.4989, grad_fn=<NegBackward0>)\n",
            "Time 132.85229563713074 loss tensor(0.4988, grad_fn=<NegBackward0>)\n",
            "Time 132.89233303070068 loss tensor(0.4987, grad_fn=<NegBackward0>)\n",
            "Time 132.9308943748474 loss tensor(0.4986, grad_fn=<NegBackward0>)\n",
            "Time 132.97166180610657 loss tensor(0.4985, grad_fn=<NegBackward0>)\n",
            "Time 133.0099368095398 loss tensor(0.4984, grad_fn=<NegBackward0>)\n",
            "Time 133.0477421283722 loss tensor(0.4983, grad_fn=<NegBackward0>)\n",
            "Time 133.09274768829346 loss tensor(0.4982, grad_fn=<NegBackward0>)\n",
            "Time 133.1326425075531 loss tensor(0.4981, grad_fn=<NegBackward0>)\n",
            "Time 133.17342162132263 loss tensor(0.4980, grad_fn=<NegBackward0>)\n",
            "Time 133.21259808540344 loss tensor(0.4980, grad_fn=<NegBackward0>)\n",
            "Time 133.25155782699585 loss tensor(0.4979, grad_fn=<NegBackward0>)\n",
            "Time 133.29144620895386 loss tensor(0.4978, grad_fn=<NegBackward0>)\n",
            "Time 133.33683371543884 loss tensor(0.4977, grad_fn=<NegBackward0>)\n",
            "Time 133.37573313713074 loss tensor(0.4976, grad_fn=<NegBackward0>)\n",
            "Time 133.42322373390198 loss tensor(0.4975, grad_fn=<NegBackward0>)\n",
            "Time 133.46179032325745 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 133.50003027915955 loss tensor(0.4973, grad_fn=<NegBackward0>)\n",
            "Time 133.53895831108093 loss tensor(0.4972, grad_fn=<NegBackward0>)\n",
            "Time 133.58326411247253 loss tensor(0.4971, grad_fn=<NegBackward0>)\n",
            "Time 133.62179374694824 loss tensor(0.4970, grad_fn=<NegBackward0>)\n",
            "Time 133.66603899002075 loss tensor(0.4969, grad_fn=<NegBackward0>)\n",
            "Time 133.70712280273438 loss tensor(0.4968, grad_fn=<NegBackward0>)\n",
            "Time 133.76145553588867 loss tensor(0.4967, grad_fn=<NegBackward0>)\n",
            "Time 133.81151700019836 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 133.85064506530762 loss tensor(0.4965, grad_fn=<NegBackward0>)\n",
            "Time 133.8892481327057 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 133.92765641212463 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 133.97545456886292 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 134.01515769958496 loss tensor(0.4962, grad_fn=<NegBackward0>)\n",
            "Time 134.05372977256775 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 134.09260153770447 loss tensor(0.4960, grad_fn=<NegBackward0>)\n",
            "Time 134.13567852973938 loss tensor(0.4959, grad_fn=<NegBackward0>)\n",
            "Time 134.17765641212463 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 134.22350764274597 loss tensor(0.4957, grad_fn=<NegBackward0>)\n",
            "Time 134.2675700187683 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 134.30790972709656 loss tensor(0.4955, grad_fn=<NegBackward0>)\n",
            "Time 134.34645104408264 loss tensor(0.4954, grad_fn=<NegBackward0>)\n",
            "Time 134.38971090316772 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 134.43245196342468 loss tensor(0.4952, grad_fn=<NegBackward0>)\n",
            "Time 134.4804608821869 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 134.52097606658936 loss tensor(0.4950, grad_fn=<NegBackward0>)\n",
            "Time 134.5597689151764 loss tensor(0.4949, grad_fn=<NegBackward0>)\n",
            "Time 134.61035466194153 loss tensor(0.4949, grad_fn=<NegBackward0>)\n",
            "Time 134.64983129501343 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 134.68799901008606 loss tensor(0.4947, grad_fn=<NegBackward0>)\n",
            "Time 134.72652173042297 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 134.76670503616333 loss tensor(0.4945, grad_fn=<NegBackward0>)\n",
            "Time 134.8353476524353 loss tensor(0.4944, grad_fn=<NegBackward0>)\n",
            "Time 134.88383674621582 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 134.92509412765503 loss tensor(0.4942, grad_fn=<NegBackward0>)\n",
            "Time 134.97002148628235 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 135.00947737693787 loss tensor(0.4940, grad_fn=<NegBackward0>)\n",
            "Time 135.05371236801147 loss tensor(0.4939, grad_fn=<NegBackward0>)\n",
            "Time 135.0923717021942 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 135.13150835037231 loss tensor(0.4937, grad_fn=<NegBackward0>)\n",
            "Time 135.17302918434143 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 135.21295762062073 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 135.25215244293213 loss tensor(0.4935, grad_fn=<NegBackward0>)\n",
            "Time 135.29734921455383 loss tensor(0.4934, grad_fn=<NegBackward0>)\n",
            "Time 135.3358654975891 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 135.3734130859375 loss tensor(0.4932, grad_fn=<NegBackward0>)\n",
            "Time 135.4109182357788 loss tensor(0.4931, grad_fn=<NegBackward0>)\n",
            "Time 135.44867300987244 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 135.48696088790894 loss tensor(0.4929, grad_fn=<NegBackward0>)\n",
            "Time 135.5348780155182 loss tensor(0.4928, grad_fn=<NegBackward0>)\n",
            "Time 135.57382988929749 loss tensor(0.4927, grad_fn=<NegBackward0>)\n",
            "Time 135.61167740821838 loss tensor(0.4926, grad_fn=<NegBackward0>)\n",
            "Time 135.65565419197083 loss tensor(0.4925, grad_fn=<NegBackward0>)\n",
            "Time 135.70034170150757 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 135.7423233985901 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 135.78755259513855 loss tensor(0.4923, grad_fn=<NegBackward0>)\n",
            "Time 135.83414769172668 loss tensor(0.4922, grad_fn=<NegBackward0>)\n",
            "Time 135.8765037059784 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 135.91673159599304 loss tensor(0.4920, grad_fn=<NegBackward0>)\n",
            "Time 135.96478939056396 loss tensor(0.4919, grad_fn=<NegBackward0>)\n",
            "Time 136.0044229030609 loss tensor(0.4918, grad_fn=<NegBackward0>)\n",
            "Time 136.04552626609802 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 136.08416032791138 loss tensor(0.4916, grad_fn=<NegBackward0>)\n",
            "Time 136.12213516235352 loss tensor(0.4915, grad_fn=<NegBackward0>)\n",
            "Time 136.16367721557617 loss tensor(0.4914, grad_fn=<NegBackward0>)\n",
            "Time 136.2096869945526 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 136.2480309009552 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 136.2863254547119 loss tensor(0.4912, grad_fn=<NegBackward0>)\n",
            "Time 136.32988452911377 loss tensor(0.4911, grad_fn=<NegBackward0>)\n",
            "Time 136.3692319393158 loss tensor(0.4910, grad_fn=<NegBackward0>)\n",
            "Time 136.41426515579224 loss tensor(0.4909, grad_fn=<NegBackward0>)\n",
            "Time 136.45221090316772 loss tensor(0.4908, grad_fn=<NegBackward0>)\n",
            "Time 136.490953207016 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 136.530100107193 loss tensor(0.4906, grad_fn=<NegBackward0>)\n",
            "Time 136.56894373893738 loss tensor(0.4905, grad_fn=<NegBackward0>)\n",
            "Time 136.6116852760315 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 136.65808415412903 loss tensor(0.4903, grad_fn=<NegBackward0>)\n",
            "Time 136.69885277748108 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 136.73796129226685 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 136.78053665161133 loss tensor(0.4901, grad_fn=<NegBackward0>)\n",
            "Time 136.81895351409912 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 136.87438225746155 loss tensor(0.4899, grad_fn=<NegBackward0>)\n",
            "Time 136.91450929641724 loss tensor(0.4898, grad_fn=<NegBackward0>)\n",
            "Time 136.95455765724182 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 136.99518871307373 loss tensor(0.4896, grad_fn=<NegBackward0>)\n",
            "Time 137.04008173942566 loss tensor(0.4895, grad_fn=<NegBackward0>)\n",
            "Time 137.08089232444763 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 137.12330532073975 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 137.16410875320435 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 137.2029368877411 loss tensor(0.4892, grad_fn=<NegBackward0>)\n",
            "Time 137.2413558959961 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 137.2794167995453 loss tensor(0.4890, grad_fn=<NegBackward0>)\n",
            "Time 137.3235228061676 loss tensor(0.4889, grad_fn=<NegBackward0>)\n",
            "Time 137.3669683933258 loss tensor(0.4888, grad_fn=<NegBackward0>)\n",
            "Time 137.40524625778198 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 137.4425563812256 loss tensor(0.4886, grad_fn=<NegBackward0>)\n",
            "Time 137.48060011863708 loss tensor(0.4885, grad_fn=<NegBackward0>)\n",
            "Time 137.5190200805664 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 137.5683033466339 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 137.606703042984 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 137.6446888446808 loss tensor(0.4882, grad_fn=<NegBackward0>)\n",
            "Time 137.69020628929138 loss tensor(0.4881, grad_fn=<NegBackward0>)\n",
            "Time 137.72834849357605 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 137.76610326766968 loss tensor(0.4879, grad_fn=<NegBackward0>)\n",
            "Time 137.81095242500305 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 137.84931135177612 loss tensor(0.4877, grad_fn=<NegBackward0>)\n",
            "Time 137.89596271514893 loss tensor(0.4876, grad_fn=<NegBackward0>)\n",
            "Time 137.93940949440002 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 137.98419165611267 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 138.02852296829224 loss tensor(0.4874, grad_fn=<NegBackward0>)\n",
            "Time 138.07368183135986 loss tensor(0.4873, grad_fn=<NegBackward0>)\n",
            "Time 138.1135938167572 loss tensor(0.4872, grad_fn=<NegBackward0>)\n",
            "Time 138.15454268455505 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 138.19364166259766 loss tensor(0.4870, grad_fn=<NegBackward0>)\n",
            "Time 138.237779378891 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 138.3231680393219 loss tensor(0.4868, grad_fn=<NegBackward0>)\n",
            "Time 138.54052114486694 loss tensor(0.4867, grad_fn=<NegBackward0>)\n",
            "Time 138.75721311569214 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 138.9265022277832 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 139.03756308555603 loss tensor(0.4865, grad_fn=<NegBackward0>)\n",
            "Time 139.08066773414612 loss tensor(0.4864, grad_fn=<NegBackward0>)\n",
            "Time 139.11867952346802 loss tensor(0.4863, grad_fn=<NegBackward0>)\n",
            "Time 139.1611385345459 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 139.20066261291504 loss tensor(0.4861, grad_fn=<NegBackward0>)\n",
            "Time 139.24123764038086 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 139.287006855011 loss tensor(0.4859, grad_fn=<NegBackward0>)\n",
            "Time 139.32850122451782 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 139.3671271800995 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 139.40540099143982 loss tensor(0.4857, grad_fn=<NegBackward0>)\n",
            "Time 139.44366669654846 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 139.5178027153015 loss tensor(0.4855, grad_fn=<NegBackward0>)\n",
            "Time 139.64332342147827 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 139.78858757019043 loss tensor(0.4853, grad_fn=<NegBackward0>)\n",
            "Time 139.96527814865112 loss tensor(0.4852, grad_fn=<NegBackward0>)\n",
            "Time 140.10008215904236 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 140.18750309944153 loss tensor(0.4850, grad_fn=<NegBackward0>)\n",
            "Time 140.22662615776062 loss tensor(0.4850, grad_fn=<NegBackward0>)\n",
            "Time 140.26591444015503 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 140.31595993041992 loss tensor(0.4848, grad_fn=<NegBackward0>)\n",
            "Time 140.3599443435669 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 140.39851260185242 loss tensor(0.4846, grad_fn=<NegBackward0>)\n",
            "Time 140.4365062713623 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 140.47489285469055 loss tensor(0.4844, grad_fn=<NegBackward0>)\n",
            "Time 140.51344442367554 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 140.55896043777466 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 140.59831166267395 loss tensor(0.4842, grad_fn=<NegBackward0>)\n",
            "Time 140.64279079437256 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 140.68303871154785 loss tensor(0.4840, grad_fn=<NegBackward0>)\n",
            "Time 140.72213101387024 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 140.7663631439209 loss tensor(0.4838, grad_fn=<NegBackward0>)\n",
            "Time 140.80755424499512 loss tensor(0.4837, grad_fn=<NegBackward0>)\n",
            "Time 140.845867395401 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 140.88403606414795 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 140.92891883850098 loss tensor(0.4835, grad_fn=<NegBackward0>)\n",
            "Time 140.98527359962463 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 141.0272467136383 loss tensor(0.4833, grad_fn=<NegBackward0>)\n",
            "Time 141.06564784049988 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 141.10400080680847 loss tensor(0.4831, grad_fn=<NegBackward0>)\n",
            "Time 141.14336967468262 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 141.18496870994568 loss tensor(0.4829, grad_fn=<NegBackward0>)\n",
            "Time 141.23269510269165 loss tensor(0.4829, grad_fn=<NegBackward0>)\n",
            "Time 141.27176332473755 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 141.31088018417358 loss tensor(0.4827, grad_fn=<NegBackward0>)\n",
            "Time 141.34903764724731 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 141.39137864112854 loss tensor(0.4825, grad_fn=<NegBackward0>)\n",
            "Time 141.4387743473053 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 141.47701811790466 loss tensor(0.4823, grad_fn=<NegBackward0>)\n",
            "Time 141.52179551124573 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 141.56114888191223 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 141.5996458530426 loss tensor(0.4821, grad_fn=<NegBackward0>)\n",
            "Time 141.645183801651 loss tensor(0.4820, grad_fn=<NegBackward0>)\n",
            "Time 141.6902813911438 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 141.72852230072021 loss tensor(0.4818, grad_fn=<NegBackward0>)\n",
            "Time 141.7674696445465 loss tensor(0.4817, grad_fn=<NegBackward0>)\n",
            "Time 141.80744576454163 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 141.8554973602295 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 141.8982503414154 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 141.9371361732483 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 141.9809799194336 loss tensor(0.4813, grad_fn=<NegBackward0>)\n",
            "Time 142.02303338050842 loss tensor(0.4812, grad_fn=<NegBackward0>)\n",
            "Time 142.06657314300537 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 142.1052281856537 loss tensor(0.4810, grad_fn=<NegBackward0>)\n",
            "Time 142.1445426940918 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 142.1852583885193 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 142.22423458099365 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 142.26291489601135 loss tensor(0.4807, grad_fn=<NegBackward0>)\n",
            "Time 142.3082458972931 loss tensor(0.4806, grad_fn=<NegBackward0>)\n",
            "Time 142.34760451316833 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 142.38662028312683 loss tensor(0.4804, grad_fn=<NegBackward0>)\n",
            "Time 142.43425226211548 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 142.48660922050476 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 142.5367283821106 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 142.5764353275299 loss tensor(0.4801, grad_fn=<NegBackward0>)\n",
            "Time 142.61538553237915 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 142.6541726589203 loss tensor(0.4799, grad_fn=<NegBackward0>)\n",
            "Time 142.69265389442444 loss tensor(0.4798, grad_fn=<NegBackward0>)\n",
            "Time 142.73903846740723 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 142.803457736969 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 142.86392283439636 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 142.92097306251526 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 142.9829535484314 loss tensor(0.4794, grad_fn=<NegBackward0>)\n",
            "Time 143.05107831954956 loss tensor(0.4793, grad_fn=<NegBackward0>)\n",
            "Time 143.11156797409058 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 143.1721727848053 loss tensor(0.4791, grad_fn=<NegBackward0>)\n",
            "Time 143.24170351028442 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 143.30084896087646 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 143.35797667503357 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 143.41480255126953 loss tensor(0.4788, grad_fn=<NegBackward0>)\n",
            "Time 143.47357439994812 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 143.5389642715454 loss tensor(0.4786, grad_fn=<NegBackward0>)\n",
            "Time 143.61550974845886 loss tensor(0.4785, grad_fn=<NegBackward0>)\n",
            "Time 143.6904754638672 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 143.7562620639801 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 143.81501269340515 loss tensor(0.4783, grad_fn=<NegBackward0>)\n",
            "Time 143.87236189842224 loss tensor(0.4782, grad_fn=<NegBackward0>)\n",
            "Time 143.9334201812744 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 143.99390697479248 loss tensor(0.4780, grad_fn=<NegBackward0>)\n",
            "Time 144.06266283988953 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 144.12521052360535 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 144.18770241737366 loss tensor(0.4778, grad_fn=<NegBackward0>)\n",
            "Time 144.2450921535492 loss tensor(0.4777, grad_fn=<NegBackward0>)\n",
            "Time 144.30210733413696 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 144.35976767539978 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 144.42724895477295 loss tensor(0.4774, grad_fn=<NegBackward0>)\n",
            "Time 144.48677849769592 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 144.54521584510803 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 144.6032588481903 loss tensor(0.4772, grad_fn=<NegBackward0>)\n",
            "Time 144.6640043258667 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 144.7225878238678 loss tensor(0.4770, grad_fn=<NegBackward0>)\n",
            "Time 144.78362107276917 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 144.84462308883667 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 144.91326427459717 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 144.97737193107605 loss tensor(0.4767, grad_fn=<NegBackward0>)\n",
            "Time 145.03742241859436 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 145.09654593467712 loss tensor(0.4765, grad_fn=<NegBackward0>)\n",
            "Time 145.17491269111633 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 145.2340579032898 loss tensor(0.4763, grad_fn=<NegBackward0>)\n",
            "Time 145.29380011558533 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 145.35149931907654 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 145.42359685897827 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 145.4879858493805 loss tensor(0.4760, grad_fn=<NegBackward0>)\n",
            "Time 145.5510880947113 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 145.60819935798645 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 145.65539479255676 loss tensor(0.4757, grad_fn=<NegBackward0>)\n",
            "Time 145.69490146636963 loss tensor(0.4757, grad_fn=<NegBackward0>)\n",
            "Time 145.7360668182373 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 145.78073501586914 loss tensor(0.4755, grad_fn=<NegBackward0>)\n",
            "Time 145.81989765167236 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 145.86139488220215 loss tensor(0.4753, grad_fn=<NegBackward0>)\n",
            "Time 145.90256333351135 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 145.94113183021545 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 145.9795789718628 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 146.01874542236328 loss tensor(0.4750, grad_fn=<NegBackward0>)\n",
            "Time 146.05907344818115 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 146.10329389572144 loss tensor(0.4748, grad_fn=<NegBackward0>)\n",
            "Time 146.15103197097778 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 146.19989490509033 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 146.23858284950256 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 146.2772295475006 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 146.32095575332642 loss tensor(0.4744, grad_fn=<NegBackward0>)\n",
            "Time 146.35993552207947 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 146.3982651233673 loss tensor(0.4742, grad_fn=<NegBackward0>)\n",
            "Time 146.43660354614258 loss tensor(0.4742, grad_fn=<NegBackward0>)\n",
            "Time 146.47446084022522 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 146.51245522499084 loss tensor(0.4740, grad_fn=<NegBackward0>)\n",
            "Time 146.55998730659485 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 146.5990080833435 loss tensor(0.4738, grad_fn=<NegBackward0>)\n",
            "Time 146.6370165348053 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 146.69054174423218 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 146.74214148521423 loss tensor(0.4736, grad_fn=<NegBackward0>)\n",
            "Time 146.79092693328857 loss tensor(0.4735, grad_fn=<NegBackward0>)\n",
            "Time 146.83683109283447 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 146.87805080413818 loss tensor(0.4733, grad_fn=<NegBackward0>)\n",
            "Time 146.9166557788849 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 146.9574580192566 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 147.008709192276 loss tensor(0.4731, grad_fn=<NegBackward0>)\n",
            "Time 147.04888939857483 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 147.0860731601715 loss tensor(0.4729, grad_fn=<NegBackward0>)\n",
            "Time 147.12390398979187 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 147.16632437705994 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 147.2177255153656 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 147.2580921649933 loss tensor(0.4726, grad_fn=<NegBackward0>)\n",
            "Time 147.2957112789154 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 147.33699131011963 loss tensor(0.4724, grad_fn=<NegBackward0>)\n",
            "Time 147.3745744228363 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 147.41266989707947 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 147.46234035491943 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 147.50290727615356 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 147.54158687591553 loss tensor(0.4720, grad_fn=<NegBackward0>)\n",
            "Time 147.58145189285278 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 147.62336945533752 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 147.66207122802734 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 147.7080225944519 loss tensor(0.4717, grad_fn=<NegBackward0>)\n",
            "Time 147.74701642990112 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 147.7864053249359 loss tensor(0.4715, grad_fn=<NegBackward0>)\n",
            "Time 147.8246717453003 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 147.86950659751892 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 147.9175946712494 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 147.95663118362427 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 147.99571299552917 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 148.03536200523376 loss tensor(0.4710, grad_fn=<NegBackward0>)\n",
            "Time 148.0809841156006 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 148.12122559547424 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 148.1787884235382 loss tensor(0.4708, grad_fn=<NegBackward0>)\n",
            "Time 148.23174667358398 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 148.2701554298401 loss tensor(0.4706, grad_fn=<NegBackward0>)\n",
            "Time 148.314368724823 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 148.35298585891724 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 148.3907778263092 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 148.4281997680664 loss tensor(0.4703, grad_fn=<NegBackward0>)\n",
            "Time 148.46677470207214 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 148.50675106048584 loss tensor(0.4701, grad_fn=<NegBackward0>)\n",
            "Time 148.5794162750244 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 148.62505340576172 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 148.6633276939392 loss tensor(0.4699, grad_fn=<NegBackward0>)\n",
            "Time 148.70239424705505 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 148.74607706069946 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 148.79790782928467 loss tensor(0.4696, grad_fn=<NegBackward0>)\n",
            "Time 148.83794569969177 loss tensor(0.4696, grad_fn=<NegBackward0>)\n",
            "Time 148.87633299827576 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 148.9142460823059 loss tensor(0.4694, grad_fn=<NegBackward0>)\n",
            "Time 148.9526698589325 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 148.99099826812744 loss tensor(0.4692, grad_fn=<NegBackward0>)\n",
            "Time 149.03579306602478 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 149.07719826698303 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 149.11552786827087 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 149.15649580955505 loss tensor(0.4689, grad_fn=<NegBackward0>)\n",
            "Time 149.19522261619568 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 149.24798393249512 loss tensor(0.4687, grad_fn=<NegBackward0>)\n",
            "Time 149.2871823310852 loss tensor(0.4687, grad_fn=<NegBackward0>)\n",
            "Time 149.32714009284973 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 149.37642860412598 loss tensor(0.4685, grad_fn=<NegBackward0>)\n",
            "Time 149.4156482219696 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 149.4591453075409 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 149.5024220943451 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 149.5411114692688 loss tensor(0.4682, grad_fn=<NegBackward0>)\n",
            "Time 149.57877564430237 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 149.61676454544067 loss tensor(0.4680, grad_fn=<NegBackward0>)\n",
            "Time 149.65594124794006 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 149.70045471191406 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 149.74010920524597 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 149.77924823760986 loss tensor(0.4677, grad_fn=<NegBackward0>)\n",
            "Time 149.81824707984924 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 149.86230564117432 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 149.9017539024353 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 149.95068669319153 loss tensor(0.4674, grad_fn=<NegBackward0>)\n",
            "Time 149.99214267730713 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 150.03072142601013 loss tensor(0.4672, grad_fn=<NegBackward0>)\n",
            "Time 150.072913646698 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 150.1156461238861 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 150.15723299980164 loss tensor(0.4670, grad_fn=<NegBackward0>)\n",
            "Time 150.19576692581177 loss tensor(0.4669, grad_fn=<NegBackward0>)\n",
            "Time 150.24387574195862 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 150.28468084335327 loss tensor(0.4667, grad_fn=<NegBackward0>)\n",
            "Time 150.3281090259552 loss tensor(0.4667, grad_fn=<NegBackward0>)\n",
            "Time 150.37857842445374 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 150.41774225234985 loss tensor(0.4665, grad_fn=<NegBackward0>)\n",
            "Time 150.45655846595764 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 150.4963903427124 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 150.54057049751282 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 150.579745054245 loss tensor(0.4662, grad_fn=<NegBackward0>)\n",
            "Time 150.6185290813446 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 150.66207432746887 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 150.70070910453796 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 150.74079966545105 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 150.78588104248047 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 150.82447266578674 loss tensor(0.4657, grad_fn=<NegBackward0>)\n",
            "Time 150.86495780944824 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 150.9062774181366 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 150.94571495056152 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 150.99389815330505 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 151.0330295562744 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 151.07459592819214 loss tensor(0.4652, grad_fn=<NegBackward0>)\n",
            "Time 151.11339807510376 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 151.15458297729492 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 151.19371604919434 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 151.2393639087677 loss tensor(0.4649, grad_fn=<NegBackward0>)\n",
            "Time 151.28688406944275 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 151.32603192329407 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 151.36481285095215 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 151.4064962863922 loss tensor(0.4646, grad_fn=<NegBackward0>)\n",
            "Time 151.45164322853088 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 151.48953223228455 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 151.52783036231995 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 151.56532406806946 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 151.60640287399292 loss tensor(0.4642, grad_fn=<NegBackward0>)\n",
            "Time 151.66122841835022 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 151.70044660568237 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 151.73939061164856 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 151.7791874408722 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 151.82524919509888 loss tensor(0.4638, grad_fn=<NegBackward0>)\n",
            "Time 151.86448550224304 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 151.90374755859375 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 151.9425961971283 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 151.9821252822876 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 152.02483820915222 loss tensor(0.4634, grad_fn=<NegBackward0>)\n",
            "Time 152.07376098632812 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 152.11269092559814 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 152.15413546562195 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 152.19258880615234 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 152.23218870162964 loss tensor(0.4630, grad_fn=<NegBackward0>)\n",
            "Time 152.2726411819458 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 152.3301396369934 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 152.36954188346863 loss tensor(0.4628, grad_fn=<NegBackward0>)\n",
            "Time 152.40827679634094 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 152.44719815254211 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 152.48856711387634 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 152.53171586990356 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 152.57092833518982 loss tensor(0.4624, grad_fn=<NegBackward0>)\n",
            "Time 152.61937355995178 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 152.65915298461914 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 152.70118165016174 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 152.74299359321594 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 152.78298902511597 loss tensor(0.4620, grad_fn=<NegBackward0>)\n",
            "Time 152.82621574401855 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 152.86615824699402 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 152.9049391746521 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 152.95134735107422 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 152.99556016921997 loss tensor(0.4616, grad_fn=<NegBackward0>)\n",
            "Time 153.0463354587555 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 153.086688041687 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 153.13226175308228 loss tensor(0.4614, grad_fn=<NegBackward0>)\n",
            "Time 153.1745045185089 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 153.2137680053711 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 153.25279426574707 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 153.29117345809937 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 153.34864735603333 loss tensor(0.4610, grad_fn=<NegBackward0>)\n",
            "Time 153.38721752166748 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 153.4247486591339 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 153.4626886844635 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 153.5084583759308 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 153.5460023880005 loss tensor(0.4606, grad_fn=<NegBackward0>)\n",
            "Time 153.59056878089905 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 153.62974309921265 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 153.66866493225098 loss tensor(0.4604, grad_fn=<NegBackward0>)\n",
            "Time 153.70767903327942 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 153.74650955200195 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 153.7872622013092 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 153.83364534378052 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 153.8743724822998 loss tensor(0.4600, grad_fn=<NegBackward0>)\n",
            "Time 153.91551423072815 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 153.95526719093323 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 153.9949014186859 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 154.03334188461304 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 154.08094239234924 loss tensor(0.4596, grad_fn=<NegBackward0>)\n",
            "Time 154.11907720565796 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 154.16071486473083 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 154.19991660118103 loss tensor(0.4594, grad_fn=<NegBackward0>)\n",
            "Time 154.2389006614685 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 154.28284001350403 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 154.3227150440216 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 154.36937856674194 loss tensor(0.4591, grad_fn=<NegBackward0>)\n",
            "Time 154.40830278396606 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 154.44704961776733 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 154.4885811805725 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 154.53145146369934 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 154.57807230949402 loss tensor(0.4587, grad_fn=<NegBackward0>)\n",
            "Time 154.61711072921753 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 154.65567231178284 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 154.6951344013214 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 154.7388575077057 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 154.7777943611145 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 154.8194875717163 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 154.85821914672852 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 154.9027316570282 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 154.94426679611206 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 154.98318457603455 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 155.0212368965149 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 155.0586392879486 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 155.09817624092102 loss tensor(0.4577, grad_fn=<NegBackward0>)\n",
            "Time 155.14233565330505 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 155.18308973312378 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 155.22124767303467 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 155.25932502746582 loss tensor(0.4574, grad_fn=<NegBackward0>)\n",
            "Time 155.30089020729065 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 155.34071564674377 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 155.39289498329163 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 155.4302637577057 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 155.46925592422485 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 155.50904726982117 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 155.54870700836182 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 155.58893489837646 loss tensor(0.4568, grad_fn=<NegBackward0>)\n",
            "Time 155.65135550498962 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 155.7142837047577 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 155.76995873451233 loss tensor(0.4566, grad_fn=<NegBackward0>)\n",
            "Time 155.8288974761963 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 155.89668440818787 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 155.955717086792 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 156.01482462882996 loss tensor(0.4563, grad_fn=<NegBackward0>)\n",
            "Time 156.07174944877625 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 156.13379096984863 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 156.19483852386475 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 156.25269174575806 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 156.31369805335999 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 156.37638139724731 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 156.4451723098755 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 156.50250244140625 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 156.56045770645142 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 156.6195776462555 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 156.6777639389038 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 156.7354199886322 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 156.7934877872467 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 156.86379647254944 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 156.9249188899994 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 156.98259115219116 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 157.04034304618835 loss tensor(0.4550, grad_fn=<NegBackward0>)\n",
            "Time 157.10355710983276 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 157.1674702167511 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 157.22603845596313 loss tensor(0.4548, grad_fn=<NegBackward0>)\n",
            "Time 157.28392338752747 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 157.3485734462738 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 157.40667963027954 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 157.47450923919678 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 157.54348134994507 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 157.60638689994812 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 157.6639506816864 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 157.72679233551025 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 157.78940892219543 loss tensor(0.4541, grad_fn=<NegBackward0>)\n",
            "Time 157.8550021648407 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 157.92382550239563 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 157.9946186542511 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 158.05434775352478 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 158.11719822883606 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 158.18321633338928 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 158.2464907169342 loss tensor(0.4536, grad_fn=<NegBackward0>)\n",
            "Time 158.3137171268463 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 158.3732132911682 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 158.41096353530884 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 158.4483551979065 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 158.49767541885376 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 158.56136298179626 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 158.60905742645264 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 158.64720344543457 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 158.6865565776825 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 158.72792744636536 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 158.77566480636597 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 158.8215298652649 loss tensor(0.4527, grad_fn=<NegBackward0>)\n",
            "Time 158.86096119880676 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 158.89966011047363 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 158.93806767463684 loss tensor(0.4525, grad_fn=<NegBackward0>)\n",
            "Time 158.98182582855225 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 159.0258264541626 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 159.0640630722046 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 159.10648155212402 loss tensor(0.4522, grad_fn=<NegBackward0>)\n",
            "Time 159.1749086380005 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 159.2314956188202 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 159.27084970474243 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 159.31121969223022 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 159.35128712654114 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 159.39014959335327 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 159.43203401565552 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 159.48060154914856 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 159.5188708305359 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 159.565101146698 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 159.6038739681244 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 159.6444797515869 loss tensor(0.4513, grad_fn=<NegBackward0>)\n",
            "Time 159.68552017211914 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 159.7235119342804 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 159.76205348968506 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 159.8022859096527 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 159.84319710731506 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 159.89543104171753 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 159.93924236297607 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 159.97765707969666 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 160.01571011543274 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 160.05372953414917 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 160.09244060516357 loss tensor(0.4505, grad_fn=<NegBackward0>)\n",
            "Time 160.14050197601318 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 160.18803334236145 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 160.22861552238464 loss tensor(0.4503, grad_fn=<NegBackward0>)\n",
            "Time 160.26635074615479 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 160.30389642715454 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 160.3444254398346 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 160.3877067565918 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 160.42510604858398 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 160.46283745765686 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 160.50181365013123 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 160.54054307937622 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 160.59333086013794 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 160.6315450668335 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 160.6684696674347 loss tensor(0.4495, grad_fn=<NegBackward0>)\n",
            "Time 160.70694160461426 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 160.7448263168335 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 160.785795211792 loss tensor(0.4493, grad_fn=<NegBackward0>)\n",
            "Time 160.83321952819824 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 160.87028050422668 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 160.9097876548767 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 160.9617645740509 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 161.00163173675537 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 161.04451417922974 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 161.0883665084839 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 161.12694191932678 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 161.16929244995117 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 161.21650576591492 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 161.2611026763916 loss tensor(0.4485, grad_fn=<NegBackward0>)\n",
            "Time 161.30034685134888 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 161.33972883224487 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 161.3781201839447 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 161.41789078712463 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 161.45630884170532 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 161.5022885799408 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 161.5528929233551 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 161.61423468589783 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 161.65457701683044 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 161.69544959068298 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 161.7411322593689 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 161.7804079055786 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 161.8204894065857 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 161.85960268974304 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 161.89660954475403 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 161.9345681667328 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 161.97962617874146 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 162.02162051200867 loss tensor(0.4472, grad_fn=<NegBackward0>)\n",
            "Time 162.0588037967682 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 162.09621715545654 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 162.14428663253784 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 162.1896731853485 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 162.23007225990295 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 162.26862144470215 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 162.30683541297913 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 162.34690618515015 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 162.38715171813965 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 162.4310266971588 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 162.46940660476685 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 162.50748586654663 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 162.54660749435425 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 162.5849814414978 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 162.65487265586853 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 162.6940507888794 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 162.73480439186096 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 162.78033447265625 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 162.81952118873596 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 162.86527061462402 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 162.90714359283447 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 162.9463632106781 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 162.98574471473694 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 163.03201913833618 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 163.07342910766602 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 163.114577293396 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 163.15653324127197 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 163.1964292526245 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 163.23530340194702 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 163.27391505241394 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 163.33532452583313 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 163.37469387054443 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 163.4131007194519 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 163.457200050354 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 163.5046157836914 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 163.54357171058655 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 163.58278727531433 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 163.62314224243164 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 163.66699481010437 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 163.71525979042053 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 163.75522565841675 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 163.7964346408844 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 163.8370063304901 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 163.87564516067505 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 163.91340351104736 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 163.96109533309937 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 164.00576066970825 loss tensor(0.4439, grad_fn=<NegBackward0>)\n",
            "Time 164.04542088508606 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 164.08541822433472 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 164.12515139579773 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 164.1753544807434 loss tensor(0.4436, grad_fn=<NegBackward0>)\n",
            "Time 164.22897696495056 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 164.27514147758484 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 164.3334138393402 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 164.37289094924927 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 164.41746830940247 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 164.45608115196228 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 164.49530458450317 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 164.53394675254822 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 164.58455085754395 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 164.62708163261414 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 164.6770040988922 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 164.7171928882599 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 164.75983381271362 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 164.79965257644653 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 164.8442680835724 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 164.8831808567047 loss tensor(0.4425, grad_fn=<NegBackward0>)\n",
            "Time 164.9229679107666 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 164.96160531044006 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 165.0013551712036 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 165.03972697257996 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 165.0856237411499 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 165.12401604652405 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 165.1682767868042 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 165.21170711517334 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 165.25077891349792 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 165.29293370246887 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 165.3334515094757 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 165.37808871269226 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 165.41674208641052 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 165.45514750480652 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 165.50841617584229 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 165.54822707176208 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 165.58735585212708 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 165.62677907943726 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 165.67139768600464 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 165.72669196128845 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 165.76699566841125 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 165.81151390075684 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 165.85289430618286 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 165.89473938941956 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 165.95315647125244 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 166.00270128250122 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 166.04140329360962 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 166.08127069473267 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 166.12058639526367 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 166.17568802833557 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 166.219646692276 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 166.2688765525818 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 166.3177216053009 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 166.35744833946228 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 166.4034194946289 loss tensor(0.4401, grad_fn=<NegBackward0>)\n",
            "Time 166.44224214553833 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 166.4811568260193 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 166.52000498771667 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 166.55847096443176 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 166.6003556251526 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 166.65035271644592 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 166.69659209251404 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 166.73501801490784 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 166.77324438095093 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 166.81493163108826 loss tensor(0.4394, grad_fn=<NegBackward0>)\n",
            "Time 166.8597059249878 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 166.9007294178009 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 166.9391438961029 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 166.99518156051636 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 167.0361750125885 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 167.08219242095947 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 167.1231985092163 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 167.1652913093567 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 167.2066740989685 loss tensor(0.4388, grad_fn=<NegBackward0>)\n",
            "Time 167.24585604667664 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 167.28507113456726 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 167.32721781730652 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 167.36862421035767 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 167.41256260871887 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 167.45039653778076 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 167.48812174797058 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 167.53171372413635 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 167.57015252113342 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 167.60883617401123 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 167.64720225334167 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 167.68543696403503 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 167.7375111579895 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 167.7865126132965 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 167.82496285438538 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 167.862731218338 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 167.90206575393677 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 167.94114112854004 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 167.98605513572693 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 168.03037357330322 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 168.0708146095276 loss tensor(0.4374, grad_fn=<NegBackward0>)\n",
            "Time 168.12411761283875 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 168.1746006011963 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 168.2158305644989 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 168.25440454483032 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 168.30553102493286 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 168.34419107437134 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 168.40414571762085 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 168.46248650550842 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 168.52620124816895 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 168.58952283859253 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 168.65107607841492 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 168.71320128440857 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 168.78554129600525 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 168.84296584129333 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 168.90497469902039 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 168.9626636505127 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 169.0212845802307 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 169.08494806289673 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 169.15331840515137 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 169.21535110473633 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 169.2729709148407 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 169.3299913406372 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 169.3970820903778 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 169.45445847511292 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 169.51210951805115 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 169.57180786132812 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 169.63359141349792 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 169.69443321228027 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 169.75467681884766 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 169.82114052772522 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 169.8833885192871 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 169.94557428359985 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 170.00646090507507 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 170.06274938583374 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 170.12849807739258 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 170.18803811073303 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 170.24618792533875 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 170.3033504486084 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 170.36565947532654 loss tensor(0.4348, grad_fn=<NegBackward0>)\n",
            "Time 170.42321705818176 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 170.48125553131104 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 170.5442750453949 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 170.60871505737305 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 170.666077375412 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 170.7270212173462 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 170.79347729682922 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 170.86635303497314 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 170.92455387115479 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 170.98462986946106 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 171.0501868724823 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 171.1148121356964 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 171.1836438179016 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 171.2366235256195 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 171.274480342865 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 171.3120608329773 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 171.36097621917725 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 171.39880561828613 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 171.43681573867798 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 171.474134683609 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 171.51966190338135 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 171.57620096206665 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 171.6158094406128 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 171.65405106544495 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 171.6924545764923 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 171.7319791316986 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 171.7850706577301 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 171.82569026947021 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 171.87384510040283 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 171.91443753242493 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 171.95582151412964 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 172.00152897834778 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 172.04143118858337 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 172.07961511611938 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 172.11875009536743 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 172.16230249404907 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 172.2014536857605 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 172.24907279014587 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 172.29000067710876 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 172.33096170425415 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 172.37057876586914 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 172.40890789031982 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 172.4539225101471 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 172.49937987327576 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 172.53731608390808 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 172.58990597724915 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 172.648601770401 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 172.6880385875702 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 172.72712588310242 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 172.7662923336029 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 172.81445288658142 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 172.86702299118042 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 172.91369104385376 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 172.95210456848145 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 172.99238443374634 loss tensor(0.4312, grad_fn=<NegBackward0>)\n",
            "Time 173.0307354927063 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 173.07040166854858 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 173.1185884475708 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 173.1592037677765 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 173.1982171535492 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 173.24605917930603 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 173.28949785232544 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 173.32868695259094 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 173.36766529083252 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 173.40564894676208 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 173.44427609443665 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 173.48396229743958 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 173.5292067527771 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 173.56851029396057 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 173.61220860481262 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 173.65174865722656 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 173.69007349014282 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 173.73236298561096 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 173.77706503868103 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 173.81608390808105 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 173.85481333732605 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 173.89813876152039 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 173.94539284706116 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 173.98539423942566 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 174.02422976493835 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 174.06244921684265 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 174.1003258228302 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 174.15461134910583 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 174.21229481697083 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 174.2531566619873 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 174.29201292991638 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 174.3304843902588 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 174.37690615653992 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 174.4163932800293 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 174.45519399642944 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 174.49366879463196 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 174.53148770332336 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 174.569007396698 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 174.61531853675842 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 174.653963804245 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 174.6921730041504 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 174.7369782924652 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 174.7765052318573 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 174.81673979759216 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 174.8647096157074 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 174.90359950065613 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 174.9520149230957 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 174.99122548103333 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 175.0365629196167 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 175.07718014717102 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 175.11993408203125 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 175.160564661026 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 175.20005440711975 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 175.24442315101624 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 175.2845389842987 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 175.32197546958923 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 175.3597686290741 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 175.40420508384705 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 175.44345664978027 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 175.48915934562683 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 175.5275423526764 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 175.56749844551086 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 175.6063346862793 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 175.64963626861572 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 175.6900691986084 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 175.73605227470398 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 175.77334356307983 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 175.81534123420715 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 175.85343861579895 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 175.89877200126648 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 175.95197987556458 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 175.99276447296143 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 176.03063106536865 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 176.0684061050415 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 176.10659837722778 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 176.15068984031677 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 176.18936133384705 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 176.22883081436157 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 176.26883959770203 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 176.3064558506012 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 176.35209321975708 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 176.39189767837524 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 176.4309527873993 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 176.47292256355286 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 176.51099848747253 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 176.55003881454468 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 176.59406995773315 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 176.63223338127136 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 176.67475390434265 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 176.715473651886 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 176.75691509246826 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 176.8048756122589 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 176.8456208705902 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 176.8845555782318 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 176.92457580566406 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 176.97267985343933 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 177.02118611335754 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 177.06114077568054 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 177.0997896194458 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 177.13851928710938 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 177.1801414489746 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 177.22795510292053 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 177.27194690704346 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 177.30962204933167 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 177.35426998138428 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 177.39350962638855 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 177.43515348434448 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 177.4762372970581 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 177.5144157409668 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 177.553448677063 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 177.5918231010437 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 177.63067841529846 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 177.68110156059265 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 177.72020721435547 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 177.75895428657532 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 177.7992389202118 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 177.83803534507751 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 177.88911199569702 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 177.94827008247375 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 178.0003306865692 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 178.04217672348022 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 178.0818498134613 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 178.13904905319214 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 178.18277955055237 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 178.22384643554688 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 178.26506280899048 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 178.3034851551056 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 178.3452854156494 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 178.38833332061768 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 178.42652893066406 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 178.46537613868713 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 178.50380039215088 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 178.54232716560364 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 178.58841395378113 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 178.62749123573303 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 178.66562581062317 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 178.7089705467224 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 178.75536179542542 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 178.81403350830078 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 178.8543255329132 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 178.8960793018341 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 178.93434596061707 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 178.9733533859253 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 179.03209805488586 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 179.07363271713257 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 179.1124188899994 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 179.15381622314453 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 179.19604015350342 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 179.24006700515747 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 179.28181624412537 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 179.3295168876648 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 179.37422704696655 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 179.4132480621338 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 179.4594383239746 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 179.49847531318665 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 179.53719210624695 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 179.57770895957947 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 179.61776518821716 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 179.6563060283661 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 179.70907306671143 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 179.74965691566467 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 179.79106068611145 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 179.82965970039368 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 179.86805963516235 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 179.90902829170227 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 179.95840716362 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 179.99899077415466 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 180.05594873428345 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 180.09998774528503 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 180.14830684661865 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 180.1881341934204 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 180.2279589176178 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 180.2692301273346 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 180.30761551856995 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 180.3462724685669 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 180.39201402664185 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 180.43009877204895 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 180.46899938583374 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 180.5081980228424 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 180.5466685295105 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 180.58543229103088 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 180.63082695007324 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 180.66948103904724 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 180.70924925804138 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 180.7538034915924 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 180.79320549964905 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 180.83244514465332 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 180.8798701763153 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 180.91805124282837 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 180.95791006088257 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 180.99713349342346 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 181.0397002696991 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 181.08721113204956 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 181.1257450580597 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 181.1788899898529 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 181.22141790390015 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 181.28250002861023 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 181.3432035446167 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 181.40315580368042 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 181.46773743629456 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 181.52677655220032 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 181.59060740470886 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 181.64983129501343 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 181.70790791511536 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 181.76444268226624 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 181.82515358924866 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 181.88597202301025 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 181.94246363639832 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 182.0023193359375 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 182.0658197402954 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 182.13937544822693 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 182.20088458061218 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 182.25870370864868 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 182.32869839668274 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 182.38773441314697 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 182.44523406028748 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 182.50712323188782 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 182.595871925354 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 182.66593527793884 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 182.726380109787 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 182.81899642944336 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 182.88517785072327 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 182.94256567955017 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 183.00129985809326 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 183.0739152431488 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 183.13129138946533 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 183.19720649719238 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 183.2596402168274 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 183.3247594833374 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 183.3920612335205 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 183.44960355758667 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 183.50726342201233 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 183.5671031475067 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 183.62898421287537 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 183.68721103668213 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 183.74738574028015 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 183.81355500221252 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 183.87490677833557 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 183.9362564086914 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 183.9914162158966 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 184.04018640518188 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 184.07892727851868 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 184.11693835258484 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 184.15766429901123 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 184.1961007118225 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 184.24803137779236 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 184.29282355308533 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 184.33321142196655 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 184.37229180335999 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 184.41307830810547 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 184.45425367355347 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 184.49584889411926 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 184.53848838806152 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 184.57658410072327 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 184.61426973342896 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 184.65202260017395 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 184.6979615688324 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 184.7377302646637 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 184.78374767303467 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 184.82228326797485 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 184.86317801475525 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 184.91232132911682 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 184.95112299919128 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 184.9898545742035 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 185.02849864959717 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 185.0670142173767 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 185.1050100326538 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 185.15091490745544 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 185.189777135849 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 185.23292541503906 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 185.27405047416687 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 185.31443905830383 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 185.3538088798523 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 185.40217804908752 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 185.4413332939148 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 185.4806215763092 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 185.51899075508118 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 185.56555199623108 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 185.60615611076355 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 185.64539885520935 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 185.69016098976135 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 185.73061847686768 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 185.77578115463257 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 185.82653999328613 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 185.86551094055176 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 185.9048421382904 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 185.9449384212494 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 185.990553855896 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 186.03107738494873 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 186.0708725452423 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 186.10946106910706 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 186.15567326545715 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 186.1986744403839 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 186.24540281295776 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 186.29663729667664 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 186.338947057724 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 186.37781882286072 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 186.42465710639954 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 186.46383357048035 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 186.5018379688263 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 186.54163026809692 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 186.5814757347107 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 186.62950086593628 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 186.673100233078 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 186.71099209785461 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 186.76530194282532 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 186.8107237815857 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 186.8569839000702 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 186.89591026306152 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 186.94057965278625 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 186.97988963127136 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 187.01876735687256 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 187.05721282958984 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 187.1038064956665 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 187.14315104484558 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 187.1837785243988 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 187.22270321846008 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 187.26266956329346 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 187.31344056129456 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 187.35225462913513 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 187.39117789268494 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 187.42913007736206 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 187.46803092956543 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 187.5068678855896 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 187.55409145355225 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 187.59432435035706 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 187.63387322425842 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 187.67292094230652 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 187.71216893196106 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 187.756733417511 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 187.8016972541809 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 187.83987832069397 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 187.8804965019226 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 187.91950631141663 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 187.95806622505188 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 188.00263595581055 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 188.0411560535431 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 188.07991862297058 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 188.1217007637024 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 188.16627502441406 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 188.2116847038269 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 188.25122022628784 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 188.28933334350586 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 188.339439868927 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 188.38171672821045 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 188.42159247398376 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 188.46504020690918 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 188.50364661216736 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 188.54375386238098 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 188.58192992210388 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 188.62726497650146 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 188.66536331176758 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 188.70496535301208 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 188.74341750144958 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 188.80239176750183 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 188.84328079223633 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 188.88458776474 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 188.93200588226318 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 188.97219729423523 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 189.01766395568848 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 189.05652165412903 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 189.0943558216095 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 189.13859963417053 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 189.1785340309143 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 189.2174997329712 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 189.2635383605957 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 189.30090594291687 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 189.34956407546997 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 189.38999938964844 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 189.43244457244873 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 189.47517848014832 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 189.519216299057 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 189.57279062271118 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 189.61254286766052 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 189.66093182563782 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 189.70009994506836 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 189.74041104316711 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 189.77954602241516 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 189.81810092926025 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 189.8570261001587 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 189.91565251350403 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 189.95539164543152 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 189.99432110786438 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 190.03210735321045 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 190.07083773612976 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 190.1118462085724 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 190.16380214691162 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 190.20314812660217 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 190.24590706825256 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 190.28445386886597 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 190.32177424430847 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 190.37466716766357 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 190.41676664352417 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 190.4542829990387 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 190.49992775917053 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 190.5382297039032 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 190.57757782936096 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 190.61979365348816 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 190.65809988975525 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 190.69605588912964 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 190.73352527618408 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 190.771728515625 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 190.82713103294373 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 190.86819911003113 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 190.90822649002075 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 190.94609022140503 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 190.98507118225098 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 191.0245180130005 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 191.069828748703 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 191.11428308486938 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 191.15550708770752 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 191.19417643547058 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 191.23298239707947 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 191.27077841758728 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 191.318608045578 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 191.363263130188 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 191.4052972793579 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 191.4469919204712 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 191.49002504348755 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 191.5281105041504 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 191.57287788391113 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 191.612229347229 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 191.65045285224915 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 191.68814325332642 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 191.7343020439148 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 191.77720165252686 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 191.81949591636658 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 191.85812520980835 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 191.8963441848755 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 191.93557405471802 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 191.97933077812195 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 192.01779770851135 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 192.0553960800171 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 192.09316754341125 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 192.13266849517822 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 192.18136525154114 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 192.2209403514862 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 192.26383113861084 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 192.30111455917358 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 192.34050345420837 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 192.38577151298523 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 192.4308364391327 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 192.47661566734314 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 192.51582217216492 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 192.55422806739807 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 192.59510469436646 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 192.6386456489563 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 192.67983531951904 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 192.72008872032166 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 192.75862073898315 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 192.80311369895935 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 192.84314155578613 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 192.88151478767395 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 192.91977262496948 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 192.95778632164001 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 192.99693489074707 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 193.04849982261658 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 193.09022450447083 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 193.12893342971802 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 193.17928314208984 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 193.2187783718109 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 193.2631232738495 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 193.30188584327698 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 193.33982467651367 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 193.3802728652954 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 193.42667841911316 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 193.46587896347046 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 193.51435708999634 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 193.552161693573 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 193.58990454673767 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 193.62863063812256 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 193.66716480255127 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 193.7124729156494 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 193.75158715248108 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 193.79190492630005 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 193.83139157295227 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 193.87290143966675 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 193.91258573532104 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 193.95989656448364 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 194.017982006073 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 194.0788652896881 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 194.1385772228241 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 194.20248365402222 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 194.26037549972534 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 194.32128310203552 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 194.38424634933472 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 194.44681978225708 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 194.5110001564026 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 194.56869053840637 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 194.62949872016907 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 194.68721961975098 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 194.74487781524658 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 194.81805300712585 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 194.88694429397583 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 194.94493865966797 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 195.00281715393066 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 195.05992150306702 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 195.13273286819458 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 195.19473099708557 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 195.26712727546692 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 195.32700872421265 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 195.40210270881653 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 195.47807240486145 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 195.54578471183777 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 195.61464262008667 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 195.67971754074097 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 195.74074268341064 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 195.79895424842834 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 195.86135506629944 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 195.91878485679626 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 195.97631788253784 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 196.03320622444153 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 196.10140824317932 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 196.16600704193115 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 196.22686457633972 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 196.28737235069275 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 196.35441970825195 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 196.41652703285217 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 196.47402906417847 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 196.53582119941711 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 196.60266995429993 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 196.6703646183014 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 196.7334156036377 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 196.79692101478577 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 196.85763788223267 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 196.89755392074585 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 196.94294619560242 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 196.98276734352112 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 197.02176785469055 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 197.06137537956238 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 197.10564017295837 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 197.14449858665466 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 197.18516612052917 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 197.22510957717896 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 197.26410365104675 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 197.31163024902344 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 197.35723614692688 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 197.39708375930786 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 197.43814897537231 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 197.47672176361084 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 197.51939463615417 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 197.5654320716858 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 197.61850214004517 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 197.6611385345459 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 197.70177388191223 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 197.7469391822815 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 197.7881462574005 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 197.8289656639099 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 197.8681046962738 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 197.9068911075592 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 197.94486498832703 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 197.9898009300232 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 198.02845573425293 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 198.06719183921814 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 198.10556769371033 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 198.14333629608154 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 198.1839098930359 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 198.23187494277954 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 198.27047157287598 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 198.3079319000244 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 198.3457736968994 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 198.3866798877716 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 198.42811012268066 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 198.47292923927307 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 198.511638879776 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 198.56233739852905 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 198.60897541046143 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 198.64770078659058 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 198.6964626312256 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 198.73720479011536 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 198.77707362174988 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 198.8201241493225 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 198.8598382472992 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 198.9006805419922 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 198.94390106201172 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 198.9822838306427 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 199.02918195724487 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 199.06720352172852 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 199.10579562187195 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 199.1590769290924 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 199.1994559764862 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 199.23828434944153 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 199.2757658958435 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 199.3140046596527 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 199.35979390144348 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 199.3997905254364 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 199.44897723197937 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 199.4962112903595 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 199.53894066810608 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 199.58502745628357 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 199.63197302818298 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 199.67015147209167 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 199.70839858055115 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 199.74661254882812 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 199.78648686408997 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 199.83957529067993 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 199.87729811668396 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 199.91618728637695 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 199.95691967010498 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 199.99583315849304 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 200.0412323474884 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 200.07931685447693 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 200.12221360206604 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 200.16329717636108 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 200.20454788208008 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 200.2472746372223 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 200.28560519218445 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 200.32348942756653 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 200.36114859580994 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 200.3992681503296 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 200.4485743045807 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 200.4877746105194 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 200.52610278129578 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 200.56487250328064 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 200.60352563858032 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 200.6533317565918 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 200.6949977874756 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 200.7475459575653 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 200.79011178016663 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 200.828106880188 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 200.87862300872803 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 200.9180736541748 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 200.95733380317688 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 200.99721717834473 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 201.0355887413025 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 201.07546615600586 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 201.12098240852356 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 201.16255521774292 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 201.20203757286072 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 201.24123287200928 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 201.28395128250122 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 201.32325887680054 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 201.36731886863708 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 201.41248083114624 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 201.4535415172577 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 201.49176454544067 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 201.53402161598206 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 201.5735502243042 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 201.61197710037231 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 201.6587052345276 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 201.7060945034027 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 201.75230526924133 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 201.79450297355652 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 201.83404231071472 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 201.87250781059265 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 201.91037440299988 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 201.95232272148132 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 201.99844121932983 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 202.03669548034668 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 202.0836615562439 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 202.12286043167114 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 202.16810131072998 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 202.20842480659485 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 202.24621319770813 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 202.28459095954895 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 202.3228795528412 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 202.36116194725037 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 202.40997672080994 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 202.45162558555603 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 202.4960868358612 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 202.5341992378235 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 202.5729112625122 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 202.61244201660156 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 202.65591073036194 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 202.70127129554749 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 202.73995923995972 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 202.7785928249359 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 202.82020211219788 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 202.86144137382507 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 202.9032485485077 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 202.9426212310791 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 202.9829866886139 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 203.02685475349426 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 203.08875489234924 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 203.1363809108734 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 203.1771240234375 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 203.21700286865234 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 203.26293540000916 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 203.30153679847717 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 203.34030103683472 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 203.37841820716858 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 203.4175100326538 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 203.45848178863525 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 203.50626730918884 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 203.54921746253967 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 203.58716869354248 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 203.62559485435486 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 203.67276334762573 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 203.72581672668457 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 203.76558113098145 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 203.80797266960144 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 203.84860038757324 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 203.88915610313416 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 203.93721437454224 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 203.98255014419556 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 204.02318477630615 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 204.06323528289795 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 204.10188817977905 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 204.14179968833923 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 204.1853325366974 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 204.22835159301758 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 204.2686583995819 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 204.3074553012848 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 204.3517770767212 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 204.40014362335205 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 204.4408097267151 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 204.48113489151 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 204.51971077919006 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 204.56438541412354 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 204.60488486289978 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 204.64473509788513 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 204.68498635292053 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 204.73386931419373 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 204.7820749282837 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 204.82163214683533 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 204.86013555526733 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 204.89999961853027 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 204.93864464759827 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 204.97737050056458 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 205.02410054206848 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 205.0623471736908 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 205.10265731811523 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 205.14131999015808 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 205.1850619316101 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 205.24383330345154 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 205.28266859054565 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 205.32078623771667 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 205.35897016525269 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 205.39720559120178 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 205.43683505058289 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 205.49160647392273 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 205.53289532661438 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 205.5716941356659 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 205.61109495162964 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 205.65118169784546 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 205.6901397705078 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 205.74359774589539 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 205.78672885894775 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 205.8322594165802 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 205.8696746826172 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 205.9096155166626 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 205.95331168174744 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 206.01373410224915 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 206.0522243976593 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 206.09009885787964 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 206.1307077407837 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 206.17937302589417 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 206.21957778930664 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 206.25821375846863 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 206.29631280899048 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 206.33347868919373 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 206.37046432495117 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 206.42168402671814 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 206.4603681564331 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 206.50418972969055 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 206.54215717315674 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 206.57962226867676 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 206.62521719932556 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 206.67229533195496 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 206.7204692363739 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 206.76687264442444 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 206.8065311908722 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 206.8611934185028 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 206.91761183738708 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 206.97748160362244 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 207.03763031959534 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 207.10033917427063 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 207.16170048713684 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 207.2206015586853 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 207.27836656570435 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 207.35190510749817 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 207.40912771224976 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 207.47469186782837 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 207.5315363407135 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 207.59075593948364 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 207.64873385429382 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 207.7067515850067 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 207.77776432037354 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 207.84378623962402 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 207.90189719200134 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 207.95936918258667 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 208.01764369010925 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 208.07952976226807 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 208.13819003105164 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 208.19869232177734 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 208.25596928596497 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 208.31411147117615 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 208.37140011787415 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 208.42809915542603 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 208.48655343055725 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 208.54787039756775 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 208.6056821346283 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 208.66324377059937 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 208.7212097644806 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 208.79942774772644 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 208.86807537078857 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 208.9311261177063 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 208.9951674938202 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 209.05638194084167 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 209.1162712574005 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 209.17775893211365 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 209.23778915405273 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 209.30262112617493 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 209.36059737205505 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 209.42525815963745 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 209.49032068252563 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 209.57823991775513 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 209.6245276927948 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 209.66356754302979 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 209.70697689056396 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 209.7506618499756 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 209.79758834838867 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 209.84778547286987 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 209.88960790634155 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 209.92836117744446 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 209.9672658443451 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 210.0116307735443 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 210.05309581756592 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 210.09390711784363 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 210.1332311630249 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 210.17510104179382 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 210.2182948589325 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 210.26660704612732 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 210.30542945861816 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 210.34309029579163 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 210.38178277015686 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 210.41989040374756 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 210.47845077514648 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 210.52133750915527 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 210.55921840667725 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 210.59792566299438 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 210.63696217536926 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 210.67559957504272 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 210.72250652313232 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 210.7607982158661 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 210.802148103714 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 210.84320449829102 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 210.88963294029236 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 210.9358696937561 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 210.97493648529053 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 211.0141134262085 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 211.05303359031677 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 211.0909948348999 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 211.1295189857483 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 211.17928457260132 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 211.22036147117615 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 211.25808477401733 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 211.29607224464417 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 211.33436822891235 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 211.3752372264862 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 211.42936444282532 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 211.46859622001648 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 211.5093355178833 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 211.54903364181519 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 211.58802437782288 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 211.6340992450714 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 211.68367958068848 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 211.7274088859558 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 211.775981426239 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 211.83474683761597 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 211.89547491073608 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 211.93814754486084 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 211.97900819778442 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 212.01853394508362 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 212.06387567520142 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 212.10305261611938 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 212.15288543701172 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 212.19170808792114 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 212.2311396598816 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 212.28844237327576 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 212.34771156311035 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 212.39676427841187 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 212.4381184577942 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 212.4840362071991 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 212.53529500961304 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 212.57315039634705 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 212.61195945739746 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 212.6515076160431 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 212.68996357917786 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 212.72834873199463 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 212.7761914730072 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 212.82101559638977 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 212.86316800117493 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 212.91340017318726 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 212.95278596878052 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 212.99900650978088 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 213.03801369667053 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 213.07634210586548 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 213.114919424057 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 213.15650296211243 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 213.19723558425903 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 213.2445890903473 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 213.28306794166565 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 213.3211898803711 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 213.35969853401184 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 213.39795541763306 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 213.43736338615417 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 213.4831986427307 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 213.52715873718262 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 213.57216477394104 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 213.61186718940735 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 213.650705575943 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 213.6958029270172 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 213.7371792793274 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 213.7797691822052 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 213.81801795959473 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 213.85670495033264 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 213.89550375938416 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 213.95156240463257 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 213.9903576374054 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 214.02938437461853 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 214.06772875785828 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 214.11317324638367 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 214.15469670295715 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 214.1935760974884 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 214.23227071762085 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 214.27024459838867 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 214.30880618095398 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 214.36359882354736 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 214.40222024917603 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 214.44139885902405 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 214.48349618911743 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 214.53609776496887 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 214.5807158946991 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 214.61967945098877 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 214.65913271903992 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 214.70675563812256 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 214.74662494659424 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 214.7901954650879 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 214.83208537101746 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 214.87612986564636 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 214.91597199440002 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 214.96445178985596 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 215.01366019248962 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 215.0535306930542 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 215.09266066551208 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 215.1305160522461 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 215.17111682891846 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 215.21204948425293 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 215.2575867176056 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 215.29560089111328 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 215.33399939537048 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 215.37930870056152 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 215.43250107765198 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 215.4777181148529 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 215.51542592048645 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 215.56205892562866 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 215.60224843025208 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 215.64181232452393 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 215.68464636802673 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 215.72607564926147 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 215.76603770256042 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 215.80713558197021 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 215.8493685722351 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 215.90194535255432 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 215.95270919799805 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 216.01116490364075 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 216.05841326713562 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 216.10047817230225 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 216.15272283554077 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 216.19092798233032 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 216.23012828826904 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 216.26947331428528 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 216.30871844291687 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 216.35688662528992 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 216.40244674682617 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 216.44702172279358 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 216.48652052879333 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 216.54376745224 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 216.60026240348816 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 216.6479935646057 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 216.68732380867004 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 216.7275698184967 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 216.77271175384521 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 216.82404708862305 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 216.86373853683472 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 216.90169143676758 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 216.939532995224 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 216.98531222343445 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 217.02676105499268 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 217.07452487945557 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 217.11356234550476 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 217.15491676330566 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 217.1980926990509 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 217.24630308151245 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 217.28544449806213 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 217.3381850719452 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 217.37669897079468 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 217.41369605064392 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 217.46214842796326 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 217.50103378295898 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 217.54258036613464 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 217.58225011825562 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 217.6218078136444 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 217.6758496761322 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 217.7153730392456 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 217.7542998790741 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 217.79451727867126 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 217.83332991600037 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 217.87138628959656 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 217.91796779632568 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 217.96340656280518 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 218.01292037963867 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 218.05110669136047 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 218.08983278274536 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 218.13289642333984 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 218.1741807460785 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 218.2127170562744 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 218.2520146369934 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 218.2902638912201 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 218.32828307151794 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 218.37313866615295 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 218.41037893295288 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 218.44872736930847 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 218.48655724525452 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 218.52486634254456 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 218.5658187866211 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 218.612384557724 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 218.65420794487 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 218.69528698921204 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 218.74415373802185 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 218.7848334312439 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 218.83124828338623 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 218.87327408790588 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 218.9164490699768 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 218.9555082321167 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 218.99500846862793 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 219.05155205726624 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 219.09093189239502 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 219.1292588710785 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 219.1701545715332 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 219.21380710601807 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 219.25387120246887 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 219.29732751846313 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 219.34201455116272 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 219.38058590888977 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 219.41878008842468 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 219.45837020874023 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 219.50462126731873 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 219.54787635803223 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 219.59362292289734 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 219.65306854248047 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 219.71829771995544 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 219.77873873710632 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 219.84429574012756 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 219.9027395248413 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 219.96822714805603 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 220.02704167366028 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 220.0923855304718 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 220.153666973114 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 220.22052001953125 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 220.28720545768738 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 220.34381484985352 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 220.40129113197327 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 220.46353888511658 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 220.51990175247192 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 220.57925295829773 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 220.63438987731934 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 220.69622039794922 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 220.7525224685669 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 220.81025457382202 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 220.8693768978119 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 220.93107652664185 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 220.98904848098755 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 221.04780459403992 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 221.10840821266174 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 221.1800901889801 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 221.23988938331604 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 221.29753279685974 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 221.35423040390015 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 221.41557550430298 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 221.47369241714478 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 221.5312774181366 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 221.5909447669983 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 221.65437579154968 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 221.71145749092102 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 221.7727448940277 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 221.83727383613586 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 221.91057753562927 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 221.9704840183258 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 222.0457465648651 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 222.10960054397583 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 222.17367339134216 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 222.23547959327698 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 222.29726672172546 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 222.36492609977722 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 222.42685914039612 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 222.47373270988464 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 222.51152920722961 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 222.54967212677002 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 222.5968234539032 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 222.63555693626404 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 222.6790475845337 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 222.71776700019836 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 222.75792264938354 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 222.80640697479248 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 222.8511688709259 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 222.89043021202087 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 222.92835450172424 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 222.9671070575714 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 223.00584769248962 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 223.0514256954193 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 223.09006810188293 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 223.13249397277832 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 223.17620539665222 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 223.21906232833862 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 223.26416277885437 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 223.3028883934021 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 223.34112763404846 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 223.38026928901672 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 223.42091345787048 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 223.46772122383118 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 223.50620460510254 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 223.54457449913025 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 223.58374977111816 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 223.63167691230774 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 223.67800641059875 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 223.72353887557983 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 223.76174139976501 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 223.80153131484985 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 223.84002089500427 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 223.90369033813477 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 223.946350812912 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 223.98598217964172 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 224.0251088142395 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 224.0679144859314 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 224.1086609363556 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 224.16609835624695 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 224.20930862426758 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 224.25022149085999 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 224.29713559150696 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 224.35472798347473 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 224.39840745925903 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 224.4365155696869 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 224.47715711593628 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 224.51827931404114 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 224.56436443328857 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 224.61213946342468 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 224.64985275268555 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 224.68788743019104 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 224.7262806892395 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 224.76462411880493 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 224.81470894813538 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 224.85377097129822 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 224.8936061859131 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 224.93466114997864 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 224.97360610961914 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 225.0181920528412 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 225.05623126029968 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 225.09653496742249 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 225.13707208633423 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 225.18570399284363 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 225.25760507583618 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 225.29902505874634 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 225.34711003303528 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 225.38778829574585 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 225.43214559555054 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 225.48684120178223 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 225.52426433563232 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 225.56152248382568 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 225.60103678703308 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 225.64304494857788 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 225.68481183052063 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 225.7234845161438 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 225.76672387123108 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 225.80758357048035 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 225.8499138355255 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 225.890766620636 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 225.92923164367676 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 225.9674472808838 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 226.0053675174713 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 226.04166102409363 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 226.08697271347046 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 226.12957239151 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 226.16919493675232 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 226.20878219604492 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 226.25519061088562 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 226.2966034412384 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 226.33626294136047 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 226.3738148212433 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 226.41441130638123 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 226.45400762557983 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 226.4943253993988 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 226.55579686164856 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 226.59432339668274 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 226.63455772399902 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 226.6724991798401 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 226.7162947654724 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 226.77598023414612 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 226.81636095046997 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 226.85519099235535 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 226.8943965435028 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 226.93294477462769 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 226.97127985954285 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 227.01714181900024 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 227.05585289001465 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 227.10864663124084 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 227.14580416679382 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 227.1880567073822 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 227.2396264076233 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 227.29296731948853 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 227.33062601089478 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 227.369553565979 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 227.40735268592834 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 227.45049691200256 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 227.48980259895325 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 227.52736830711365 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 227.56536769866943 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 227.6064531803131 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 227.64628267288208 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 227.6962924003601 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 227.73617959022522 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 227.77552461624146 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 227.81498742103577 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 227.85239005088806 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 227.89184951782227 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 227.94168972969055 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 227.9804880619049 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 228.02075910568237 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 228.0600824356079 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 228.0992124080658 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 228.13770580291748 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 228.19144797325134 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 228.2304403781891 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 228.26878547668457 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 228.32104659080505 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 228.3583686351776 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 228.40065908432007 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 228.43971061706543 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 228.47891664505005 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 228.531316280365 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 228.5742015838623 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 228.61951327323914 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 228.6689796447754 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 228.7228307723999 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 228.76360154151917 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 228.8052945137024 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 228.85308527946472 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 228.89309453964233 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 228.9313223361969 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 228.96946048736572 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 229.00789523124695 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 229.04538750648499 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 229.0959014892578 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 229.13803267478943 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 229.1789197921753 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 229.21753478050232 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 229.25941109657288 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 229.3078055381775 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 229.3525357246399 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 229.3899736404419 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 229.4269597530365 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 229.46454286575317 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 229.50255012512207 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 229.55040669441223 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 229.58927631378174 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 229.6300618648529 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 229.66723108291626 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 229.7065908908844 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 229.74692344665527 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 229.79553532600403 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 229.835764169693 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 229.87524223327637 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 229.91490268707275 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 229.9573700428009 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 229.99918174743652 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 230.04489254951477 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 230.08193397521973 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 230.1192603111267 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 230.15899515151978 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 230.19702291488647 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 230.24403500556946 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 230.28277587890625 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 230.3261501789093 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 230.3649880886078 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 230.40892148017883 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 230.4511444568634 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 230.49448609352112 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 230.5334804058075 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 230.57196354866028 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 230.61075615882874 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 230.65116333961487 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 230.6980652809143 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 230.7431709766388 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 230.78300714492798 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 230.82132172584534 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 230.86052083969116 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 230.90661239624023 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 230.94763207435608 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 230.98785018920898 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 231.02727222442627 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 231.06515502929688 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 231.1121528148651 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 231.15373539924622 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 231.19222116470337 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 231.23147559165955 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 231.27032709121704 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 231.31059741973877 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 231.37073850631714 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 231.40948700904846 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 231.44798731803894 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 231.48776698112488 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 231.53052735328674 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 231.57163262367249 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 231.61097049713135 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 231.65283155441284 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 231.6914460659027 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 231.72964596748352 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 231.7768976688385 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 231.81894278526306 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 231.86051297187805 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 231.89929676055908 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 231.93773484230042 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 231.9856252670288 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 232.03111028671265 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 232.06972408294678 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 232.10877513885498 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 232.1480906009674 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 232.1877408027649 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 232.23579001426697 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 232.2745659351349 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 232.31214118003845 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 232.35081219673157 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 232.39821243286133 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 232.46784710884094 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 232.5592920780182 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 232.62772965431213 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 232.68941116333008 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 232.75219011306763 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 232.81267499923706 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 232.87934470176697 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 232.94037866592407 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 232.99829578399658 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 233.05563879013062 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 233.12150931358337 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 233.18134331703186 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 233.23925805091858 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 233.29741597175598 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 233.36550784111023 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 233.42586421966553 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 233.48406338691711 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 233.5409471988678 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 233.6019549369812 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 233.66307735443115 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 233.73220109939575 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 233.78921031951904 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 233.8513627052307 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 233.9111680984497 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 233.97259330749512 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 234.03035759925842 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 234.09026956558228 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 234.14792561531067 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 234.20800399780273 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 234.2658064365387 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 234.3257930278778 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 234.38299322128296 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 234.44263315200806 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 234.50819563865662 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 234.58555698394775 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 234.6446454524994 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 234.70335245132446 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 234.76348090171814 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 234.82906866073608 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 234.8880546092987 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 234.94562363624573 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 235.00716352462769 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 235.07271718978882 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 235.13649463653564 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 235.20169377326965 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 235.2514328956604 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 235.30123925209045 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 235.34035634994507 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 235.37941145896912 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 235.41681623458862 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 235.45610976219177 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 235.5079312324524 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 235.5493519306183 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 235.59127163887024 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 235.6307384967804 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 235.6736307144165 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 235.72068452835083 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 235.76822781562805 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 235.80768752098083 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 235.84790897369385 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 235.88742208480835 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 235.93988227844238 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 235.98038983345032 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 236.01952815055847 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 236.05803442001343 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 236.09584712982178 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 236.1337616443634 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 236.18410181999207 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 236.22216200828552 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 236.2609097957611 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 236.29870629310608 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 236.3366470336914 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 236.38032245635986 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 236.43633365631104 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 236.48482704162598 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 236.53156876564026 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 236.56988620758057 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 236.60972690582275 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 236.66252994537354 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 236.70469999313354 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 236.74230885505676 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 236.78098726272583 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 236.81808519363403 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 236.85573649406433 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 236.90183115005493 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 236.9420027732849 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 236.98365330696106 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 237.0224413871765 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 237.06026148796082 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 237.09814310073853 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 237.14392137527466 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 237.1839156150818 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 237.2250337600708 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 237.26405930519104 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 237.30123019218445 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 237.33874583244324 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 237.38456320762634 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 237.42206931114197 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 237.46709442138672 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 237.50621962547302 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 237.56003594398499 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 237.6265504360199 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 237.6656322479248 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 237.70678997039795 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 237.74525022506714 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 237.78671550750732 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 237.8394968509674 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 237.88322687149048 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 237.92283606529236 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 237.96195006370544 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 238.0004210472107 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 238.03951239585876 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 238.08449244499207 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 238.1269085407257 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 238.16781187057495 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 238.20615816116333 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 238.24598670005798 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 238.29384994506836 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 238.33151817321777 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 238.36910676956177 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 238.40789437294006 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 238.4550814628601 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 238.4969608783722 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 238.54122495651245 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 238.58356499671936 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 238.62190699577332 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 238.65962505340576 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 238.6995084285736 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 238.74748277664185 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 238.7916932106018 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 238.83053469657898 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 238.8686604499817 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 238.90791082382202 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 238.95125818252563 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 238.99553608894348 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 239.035382270813 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 239.07379412651062 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 239.1116819381714 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 239.16055917739868 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 239.1995050907135 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 239.23843359947205 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 239.27713823318481 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 239.31804966926575 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 239.3572895526886 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 239.40398740768433 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 239.4504997730255 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 239.4897439479828 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 239.52977776527405 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 239.57657051086426 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 239.62211775779724 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 239.66294956207275 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 239.70291924476624 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 239.7407865524292 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 239.78138995170593 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 239.82050490379333 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 239.86532974243164 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 239.9098722934723 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 239.94954299926758 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 239.99012422561646 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 240.02893447875977 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 240.06666684150696 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 240.11312222480774 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 240.15433025360107 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 240.19695687294006 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 240.23673152923584 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 240.27824711799622 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 240.3219439983368 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 240.3598120212555 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 240.39812469482422 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 240.43617296218872 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 240.4753384590149 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 240.53116488456726 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 240.5702395439148 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 240.62622046470642 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 240.66534852981567 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 240.70649433135986 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 240.75359320640564 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 240.794091463089 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 240.8338418006897 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 240.8755977153778 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 240.9136471748352 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 240.95237517356873 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 241.00278687477112 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 241.04151487350464 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 241.07984447479248 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 241.11821603775024 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 241.16232299804688 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 241.20127081871033 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 241.24756979942322 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 241.2858567237854 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 241.32379055023193 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 241.362131357193 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 241.40164875984192 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 241.44652223587036 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 241.49333262443542 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 241.53240704536438 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 241.5723328590393 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 241.61915349960327 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 241.6585066318512 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 241.71262335777283 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 241.75365328788757 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 241.79728293418884 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 241.83666133880615 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 241.87529134750366 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 241.91366744041443 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 241.95978808403015 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 241.99834990501404 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 242.03979206085205 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 242.0791163444519 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 242.11639666557312 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 242.16656970977783 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 242.22175121307373 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 242.2629234790802 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 242.30131244659424 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 242.33934140205383 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 242.3984899520874 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 242.44270968437195 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 242.48188304901123 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 242.52197074890137 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 242.5767650604248 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 242.63452124595642 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 242.6738097667694 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 242.71883916854858 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 242.7590675354004 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 242.79957127571106 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 242.86399292945862 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 242.90737986564636 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 242.94779229164124 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 242.98751163482666 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 243.02638912200928 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 243.06487131118774 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 243.1171519756317 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 243.1580662727356 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 243.19829440116882 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 243.2375648021698 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 243.2819766998291 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 243.32122588157654 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 243.35989546775818 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 243.3985059261322 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 243.43611431121826 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 243.4743423461914 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 243.5229594707489 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 243.56933188438416 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 243.60948991775513 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 243.65544486045837 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 243.69351863861084 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 243.74042654037476 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 243.78411054611206 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 243.82182002067566 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 243.8662393093109 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 243.90739274024963 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 243.95135307312012 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 243.99211835861206 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 244.03093123435974 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 244.06908512115479 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 244.10760021209717 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 244.14653158187866 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 244.19434547424316 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 244.24000453948975 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 244.284077167511 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 244.3244025707245 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 244.3630006313324 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 244.40469574928284 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 244.44476318359375 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 244.48298358917236 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 244.5216896533966 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 244.56109714508057 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 244.6026313304901 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 244.64854431152344 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 244.69754910469055 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 244.7413251399994 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 244.783438205719 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 244.8220076560974 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 244.86624884605408 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 244.90531587600708 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 244.94453310966492 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 244.98506903648376 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 245.02389550209045 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 245.06241106987 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 245.10836124420166 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 245.14906239509583 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 245.18905019760132 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 245.2286193370819 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 245.28845524787903 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 245.35423398017883 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 245.41065096855164 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 245.46773886680603 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 245.52630758285522 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 245.596444606781 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 245.65720438957214 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 245.73370814323425 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 245.79379057884216 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 245.86639022827148 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 245.92411923408508 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 245.98613572120667 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 246.0537600517273 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 246.11097812652588 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 246.1740083694458 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 246.23153257369995 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 246.30349469184875 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 246.36490321159363 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 246.42276334762573 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 246.4871747493744 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 246.56489062309265 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 246.62160921096802 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 246.68059945106506 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 246.74053835868835 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 246.81897497177124 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 246.87822699546814 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 246.93761491775513 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 246.99373722076416 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 247.06414341926575 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 247.12124156951904 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 247.18190693855286 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 247.23978519439697 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 247.3027310371399 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 247.36199021339417 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 247.42127680778503 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 247.4880015850067 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 247.55791521072388 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 247.61804866790771 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 247.67741417884827 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 247.7405710220337 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 247.80879855155945 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 247.877920627594 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 247.941650390625 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 248.00557470321655 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 248.0744228363037 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 248.12098479270935 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 248.162770986557 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 248.20158743858337 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 248.2404224872589 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 248.2899580001831 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 248.3322479724884 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 248.37050437927246 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 248.4079463481903 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 248.44534015655518 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 248.48942494392395 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 248.54069185256958 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 248.57843565940857 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 248.62252235412598 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 248.6625714302063 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 248.7060580253601 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 248.75096797943115 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 248.80667781829834 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 248.85596251487732 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 248.89847087860107 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 248.9506266117096 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 249.0085413455963 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 249.05164790153503 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 249.09037923812866 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 249.129953622818 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 249.17953610420227 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 249.21947646141052 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 249.26089763641357 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 249.3026843070984 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 249.3485882282257 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 249.39222049713135 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 249.43344235420227 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 249.47216081619263 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 249.51069283485413 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 249.5504240989685 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 249.59156346321106 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 249.63680028915405 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 249.6754469871521 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 249.7179355621338 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 249.75951075553894 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 249.7990472316742 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 249.85014748573303 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 249.9012153148651 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 249.9418342113495 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 249.98052525520325 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 250.02648735046387 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 250.06469678878784 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 250.10368728637695 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 250.14233922958374 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 250.18328380584717 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 250.22258710861206 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 250.2727975845337 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 250.31535458564758 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 250.3540666103363 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 250.394033908844 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 250.43212151527405 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 250.47108221054077 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 250.52485537528992 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 250.5647759437561 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 250.6035487651825 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 250.6415445804596 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 250.67970275878906 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 250.71912908554077 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 250.77237796783447 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 250.81477427482605 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 250.8576319217682 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 250.89998984336853 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 250.9411780834198 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 250.98554253578186 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 251.02515530586243 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 251.0642433166504 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 251.10653018951416 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 251.14590740203857 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 251.1905655860901 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 251.24380898475647 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 251.28803324699402 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 251.3289635181427 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 251.36920738220215 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 251.4160714149475 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 251.45491552352905 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 251.49311923980713 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 251.53581762313843 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 251.5753996372223 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 251.61532926559448 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 251.6618413925171 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 251.70062685012817 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 251.7510678768158 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 251.80871057510376 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 251.86524558067322 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 251.9036364555359 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 251.95311737060547 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 251.9929268360138 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 252.03107404708862 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 252.0729284286499 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 252.1148715019226 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 252.1557638645172 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 252.19445085525513 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 252.23273134231567 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 252.27177619934082 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 252.32262587547302 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 252.3616509437561 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 252.39980745315552 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 252.43732452392578 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 252.47568535804749 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 252.51455760002136 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 252.56641674041748 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 252.6055896282196 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 252.6439139842987 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 252.6823980808258 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 252.7216420173645 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 252.7627468109131 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 252.812495470047 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 252.85318422317505 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 252.89182257652283 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 252.94551539421082 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 252.98593401908875 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 253.03044772148132 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 253.07007908821106 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 253.10864734649658 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 253.15052723884583 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 253.19074130058289 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 253.229327917099 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 253.2957365512848 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 253.34541010856628 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 253.3844838142395 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 253.42281436920166 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 253.4628119468689 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 253.50765705108643 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 253.5485324859619 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 253.58758234977722 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 253.62667226791382 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 253.66609454154968 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 253.70447897911072 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 253.7619445323944 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 253.80545568466187 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 253.84789323806763 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 253.88664364814758 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 253.92474126815796 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 253.97458720207214 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 254.01602363586426 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 254.0564043521881 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 254.0958023071289 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 254.1342272758484 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 254.1760857105255 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 254.22865986824036 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 254.2685866355896 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 254.30777668952942 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 254.34622478485107 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 254.38817405700684 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 254.43346405029297 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 254.48274517059326 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 254.52126622200012 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 254.5701355934143 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 254.61654663085938 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 254.6558132171631 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 254.69577527046204 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 254.73705220222473 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 254.7789430618286 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 254.81719398498535 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 254.86449456214905 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 254.9029495716095 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 254.94209599494934 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 254.98446655273438 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 255.05278754234314 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 255.09724855422974 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 255.13609981536865 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 255.17758083343506 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 255.2163553237915 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 255.26406908035278 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 255.30594968795776 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 255.36273527145386 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 255.41202449798584 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 255.45054149627686 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 255.50558042526245 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 255.5452721118927 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 255.58431887626648 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 255.62283515930176 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 255.6700839996338 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 255.7101788520813 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 255.7529902458191 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 255.79482078552246 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 255.8329360485077 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 255.87436938285828 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 255.91556596755981 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 255.9609673023224 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 256.0003435611725 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 256.0472218990326 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 256.0856382846832 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 256.1242141723633 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 256.174955368042 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 256.2143096923828 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 256.2535574436188 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 256.2908275127411 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 256.32838129997253 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 256.36712670326233 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 256.4125039577484 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 256.450731754303 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 256.48936009407043 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 256.52754950523376 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 256.56539011001587 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 256.60374641418457 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 256.65304136276245 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 256.6963074207306 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 256.73582434654236 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 256.7795350551605 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 256.81936502456665 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 256.8641655445099 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 256.9038360118866 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 256.9415190219879 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 256.98026061058044 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 257.028058052063 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 257.0753216743469 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 257.1205997467041 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 257.1644492149353 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 257.2029461860657 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 257.241986989975 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 257.2918372154236 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 257.33009910583496 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 257.3693656921387 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 257.41655135154724 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 257.4568552970886 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 257.49908924102783 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 257.54242992401123 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 257.5805025100708 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 257.61872935295105 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 257.6622042655945 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 257.70195055007935 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 257.7542510032654 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 257.7961962223053 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 257.83422088623047 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 257.8725311756134 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 257.91103076934814 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 257.95585584640503 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 257.99489760398865 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 258.0359971523285 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 258.08424949645996 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 258.14141869544983 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 258.2064063549042 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 258.2636773586273 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 258.3214273452759 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 258.3784863948822 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 258.44948554039 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 258.5089943408966 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 258.566725730896 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 258.62363862991333 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 258.69794034957886 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 258.75464630126953 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 258.81892108917236 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 258.89590859413147 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 258.9579300880432 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 259.0148160457611 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 259.0751600265503 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 259.15213656425476 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 259.2114853858948 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 259.26904463768005 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 259.32587695121765 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 259.3908007144928 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 259.44872879981995 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 259.5073592662811 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 259.5676941871643 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 259.6298849582672 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 259.6885027885437 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 259.7520503997803 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 259.8133316040039 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 259.87689685821533 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 259.934166431427 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 259.9908215999603 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 260.0467505455017 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 260.1079034805298 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 260.1757462024689 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 260.23776149749756 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 260.29828667640686 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 260.3599314689636 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 260.41955065727234 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 260.47782802581787 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 260.5365891456604 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 260.6013984680176 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 260.65889406204224 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 260.7228133678436 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 260.8128864765167 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 260.8779101371765 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 260.9256308078766 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 260.96361541748047 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 261.00601506233215 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 261.0552351474762 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 261.09438943862915 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 261.1330952644348 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 261.17452239990234 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 261.22042751312256 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 261.2642364501953 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 261.30572986602783 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 261.34346532821655 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 261.38165259361267 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 261.4242877960205 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 261.4633882045746 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 261.5086052417755 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 261.5469636917114 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 261.58411622047424 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 261.62179613113403 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 261.66056728363037 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 261.7108163833618 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 261.7502188682556 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 261.79039335250854 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 261.83546781539917 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 261.8743169307709 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 261.9174108505249 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 261.9602053165436 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 261.99918007850647 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 262.04842877388 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 262.09407448768616 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 262.1460270881653 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 262.1872625350952 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 262.2416503429413 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 262.2805919647217 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 262.3196918964386 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 262.3650059700012 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 262.4053077697754 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 262.44367814064026 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 262.48194909095764 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 262.52014923095703 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 262.58132338523865 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 262.62093710899353 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 262.66034507751465 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 262.69865441322327 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 262.73675322532654 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 262.7769527435303 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 262.8294155597687 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 262.8695890903473 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 262.90915846824646 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 262.9477300643921 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 262.9872250556946 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 263.0257647037506 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 263.07215571403503 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 263.11262583732605 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 263.15445041656494 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 263.1924259662628 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 263.23321509361267 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 263.27962017059326 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 263.3220098018646 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 263.36083984375 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 263.40623664855957 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 263.44542837142944 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 263.48677229881287 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 263.5324230194092 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 263.5715584754944 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 263.6100056171417 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 263.6476831436157 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 263.6864445209503 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 263.7406601905823 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 263.7807981967926 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 263.8197138309479 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 263.8600356578827 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 263.9039180278778 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 263.9440338611603 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 263.9821569919586 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 264.0217182636261 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 264.0650463104248 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 264.10475039482117 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 264.1511240005493 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 264.1889772415161 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 264.22880005836487 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 264.27573323249817 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 264.32281374931335 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 264.36103105545044 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 264.39897871017456 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 264.4447042942047 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 264.48498034477234 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 264.5232799053192 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 264.568736076355 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 264.60782051086426 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 264.6457107067108 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 264.6840150356293 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 264.7232573032379 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 264.77083253860474 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 264.81107568740845 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 264.8538899421692 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 264.90547823905945 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 264.9617578983307 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 265.0114724636078 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 265.0506761074066 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 265.0904870033264 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 265.12958097457886 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 265.1711277961731 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 265.2110071182251 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 265.25881123542786 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 265.30500316619873 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 265.3494322299957 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 265.38877511024475 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 265.43270349502563 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 265.47112560272217 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 265.5100908279419 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 265.5496907234192 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 265.5877001285553 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 265.626118183136 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 265.6790635585785 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 265.7187120914459 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 265.7577896118164 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 265.8014237880707 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 265.8621528148651 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 265.9213533401489 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 265.96047043800354 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 265.99971055984497 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 266.0421676635742 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 266.0811085700989 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 266.1203262805939 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 266.16808581352234 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 266.21196722984314 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 266.2512023448944 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 266.29468631744385 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 266.3489408493042 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 266.3881344795227 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 266.425146818161 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 266.46173119544983 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 266.4997293949127 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 266.538081407547 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 266.5846915245056 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 266.62393856048584 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 266.6625235080719 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 266.7008740901947 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 266.74030232429504 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 266.7834346294403 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 266.8313047885895 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 266.8720602989197 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 266.9100966453552 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 266.94811964035034 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 266.9860279560089 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 267.0245108604431 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 267.0707230567932 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 267.1089470386505 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 267.14731431007385 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 267.18697595596313 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 267.22597455978394 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 267.2643437385559 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 267.31189370155334 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 267.35849595069885 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 267.3959975242615 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 267.4333002567291 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 267.47101879119873 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 267.5094497203827 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 267.56716132164 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 267.6053659915924 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 267.64383339881897 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 267.6825704574585 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 267.7206265926361 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 267.7596867084503 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 267.8088755607605 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 267.8505959510803 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 267.8953363895416 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 267.9371418952942 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 267.97913670539856 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 268.0238404273987 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 268.0632050037384 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 268.10198998451233 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 268.1406497955322 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 268.18304777145386 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 268.2235903739929 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 268.270546913147 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 268.31459164619446 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 268.36254048347473 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 268.4007816314697 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 268.44644236564636 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 268.4856290817261 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 268.52519154548645 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 268.5659272670746 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 268.60382294654846 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 268.64912819862366 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 268.69411993026733 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 268.73444843292236 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 268.7724177837372 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 268.8143792152405 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 268.8546679019928 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 268.89940094947815 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 268.938364982605 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 268.97885727882385 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 269.01849150657654 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 269.0569052696228 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 269.0962176322937 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 269.1433575153351 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 269.18537855148315 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 269.22504925727844 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 269.26814436912537 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 269.3064169883728 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 269.3568081855774 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 269.409982919693 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 269.4487090110779 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 269.4872989654541 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 269.52756428718567 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 269.57425713539124 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 269.612140417099 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 269.6511251926422 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 269.6897876262665 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 269.73229336738586 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 269.77966690063477 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 269.83344292640686 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 269.8812747001648 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 269.93543124198914 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 269.9794797897339 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 270.02976298332214 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 270.07247281074524 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 270.110600233078 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 270.1516764163971 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 270.1971969604492 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 270.24124002456665 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 270.2848856449127 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 270.3236243724823 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 270.36205101013184 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 270.40429973602295 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 270.4507246017456 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 270.4906780719757 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 270.5291702747345 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 270.5756995677948 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 270.62376046180725 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 270.6713898181915 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 270.71176981925964 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 270.75123953819275 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 270.7913725376129 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 270.8291668891907 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 270.86924624443054 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 270.92598962783813 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 270.99437379837036 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 271.0531883239746 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 271.1106972694397 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 271.1767280101776 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 271.2392666339874 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 271.2988064289093 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 271.3568708896637 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 271.4240176677704 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 271.48407530784607 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 271.548335313797 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 271.60812067985535 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 271.67063903808594 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 271.7290892601013 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 271.80910992622375 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 271.87237763404846 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 271.9385132789612 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 271.99618697166443 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 272.05368971824646 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 272.1294343471527 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 272.19512820243835 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 272.2533800601959 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 272.3124406337738 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 272.3766858577728 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 272.43499732017517 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 272.50072145462036 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 272.5604450702667 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 272.62178778648376 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 272.6817219257355 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 272.7422676086426 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 272.8013324737549 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 272.86257696151733 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 272.92167472839355 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 272.9794600009918 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 273.040091753006 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 273.10548520088196 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 273.16807103157043 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 273.22577476501465 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 273.2843677997589 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 273.3513231277466 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 273.40986466407776 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 273.4671366214752 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 273.52787804603577 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 273.5947608947754 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 273.6589996814728 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 273.72226881980896 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 273.7848770618439 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 273.8309540748596 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 273.8691256046295 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 273.91051411628723 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 273.95080637931824 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 273.9925718307495 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 274.03119945526123 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 274.0776493549347 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 274.11682200431824 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 274.1586310863495 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 274.198429107666 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 274.24056482315063 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 274.2824444770813 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 274.3204653263092 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 274.35851669311523 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 274.3971562385559 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 274.43743085861206 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 274.48672699928284 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 274.53567337989807 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 274.5980463027954 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 274.6378240585327 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 274.6768307685852 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 274.72242069244385 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 274.7609980106354 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 274.80059003829956 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 274.8410167694092 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 274.87923789024353 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 274.91941571235657 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 274.96777272224426 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 275.0059630870819 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 275.04413986206055 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 275.0822329521179 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 275.1247103214264 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 275.16660022735596 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 275.21284437179565 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 275.2582747936249 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 275.2982888221741 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 275.33822298049927 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 275.38735914230347 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 275.4285740852356 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 275.4679720401764 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 275.51232528686523 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 275.55242013931274 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 275.60864424705505 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 275.6634638309479 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 275.7032058238983 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 275.7484276294708 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 275.79045128822327 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 275.84158873558044 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 275.88080501556396 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 275.9218249320984 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 275.9603478908539 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 275.99830436706543 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 276.0361931324005 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 276.0839066505432 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 276.1214237213135 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 276.16256737709045 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 276.2016613483429 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 276.2406897544861 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 276.28079891204834 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 276.32790064811707 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 276.3698229789734 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 276.4139475822449 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 276.45445132255554 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 276.4940838813782 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 276.5486741065979 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 276.59153485298157 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 276.635803937912 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 276.6747705936432 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 276.7136449813843 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 276.75568199157715 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 276.80289602279663 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 276.84735012054443 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 276.8867025375366 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 276.9273464679718 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 276.9742727279663 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 277.0163149833679 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 277.05530762672424 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 277.09395265579224 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 277.1328911781311 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 277.1762464046478 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 277.22189378738403 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 277.26257276535034 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 277.3017473220825 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 277.340544462204 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 277.3830301761627 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 277.4309153556824 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 277.4698791503906 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 277.5083396434784 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 277.54738998413086 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 277.58728671073914 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 277.6445109844208 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 277.682914018631 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 277.7219190597534 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 277.76088881492615 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 277.8082036972046 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 277.85597133636475 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 277.8981704711914 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 277.9393424987793 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 277.9784004688263 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 278.02309679985046 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 278.0645844936371 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 278.1130156517029 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 278.1701807975769 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 278.21315455436707 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 278.27583408355713 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 278.31736969947815 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 278.3568229675293 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 278.3964765071869 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 278.4359772205353 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 278.4750339984894 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 278.5211338996887 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 278.5613317489624 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 278.6016662120819 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 278.65602922439575 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 278.70297288894653 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 278.74175930023193 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 278.783029794693 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 278.82434725761414 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 278.86277627944946 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 278.9019114971161 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 278.950697183609 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 278.98996329307556 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 279.0304262638092 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 279.06959557533264 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 279.1086542606354 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 279.1566741466522 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 279.19656324386597 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 279.236186504364 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 279.2768189907074 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 279.31820797920227 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 279.357319355011 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 279.40455865859985 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 279.4488663673401 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 279.48793148994446 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 279.52812671661377 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 279.57125759124756 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 279.6146950721741 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 279.6586637496948 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 279.69997930526733 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 279.7388241291046 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 279.77940034866333 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 279.8289096355438 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 279.8678870201111 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 279.90580654144287 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 279.9465432167053 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 279.9874505996704 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 280.03630924224854 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 280.07700514793396 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 280.1156392097473 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 280.1567244529724 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 280.19523453712463 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 280.2417104244232 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 280.2802495956421 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 280.31766533851624 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 280.355366230011 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 280.3933024406433 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 280.43957781791687 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 280.4782931804657 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 280.51823329925537 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 280.5583882331848 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 280.59868931770325 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 280.6374900341034 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 280.69069051742554 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 280.7296802997589 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 280.7739667892456 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 280.8125422000885 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 280.8807168006897 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 280.9327528476715 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 280.97135615348816 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 281.01022601127625 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 281.04865193367004 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 281.0918354988098 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 281.1305286884308 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 281.18090200424194 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 281.22360920906067 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 281.2624521255493 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 281.3005259037018 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 281.34591007232666 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 281.3887097835541 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 281.43004179000854 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 281.46833419799805 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 281.50651478767395 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 281.5452175140381 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 281.58298444747925 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 281.63124918937683 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 281.6770005226135 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 281.72892665863037 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 281.76854038238525 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 281.8094873428345 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 281.85513710975647 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 281.8930592536926 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 281.9313020706177 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 281.9733097553253 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 282.010835647583 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 282.04888105392456 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 282.0941815376282 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 282.13380765914917 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 282.1780860424042 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 282.2218577861786 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 282.26278805732727 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 282.3051071166992 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 282.3492200374603 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 282.4015233516693 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 282.4412658214569 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 282.4807629585266 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 282.52653336524963 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 282.5657889842987 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 282.60477924346924 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 282.6434676647186 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 282.683468580246 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 282.750342130661 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 282.7918891906738 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 282.8382499217987 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 282.8845160007477 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 282.93027424812317 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 282.9792411327362 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 283.02065992355347 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 283.0595862865448 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 283.0985312461853 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 283.1376130580902 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 283.1784625053406 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 283.22452116012573 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 283.26434564590454 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 283.3035659790039 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 283.34224700927734 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 283.3814392089844 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 283.42890977859497 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 283.4685697555542 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 283.50708961486816 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 283.54513931274414 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 283.584632396698 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 283.6242196559906 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 283.66981291770935 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 283.70779633522034 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 283.7566041946411 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 283.8077871799469 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 283.8695387840271 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 283.9509918689728 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 284.01813769340515 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 284.07697463035583 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 284.144136428833 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 284.2087678909302 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 284.2669801712036 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 284.3365933895111 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 284.39479970932007 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 284.4523968696594 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 284.51042318344116 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 284.5752625465393 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 284.6359701156616 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 284.69414138793945 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 284.7553195953369 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 284.829763174057 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 284.8882474899292 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 284.95496344566345 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 285.02019906044006 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 285.08445024490356 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 285.14216351509094 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 285.2016296386719 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 285.2595703601837 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 285.3296711444855 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 285.38832664489746 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 285.4452271461487 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 285.50296354293823 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 285.57071447372437 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 285.63104701042175 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 285.69177889823914 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 285.750611782074 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 285.81677651405334 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 285.87988233566284 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 285.9384641647339 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 285.9985384941101 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 286.06638407707214 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 286.125141620636 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 286.1862316131592 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 286.24341797828674 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 286.3182473182678 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 286.38158082962036 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 286.45028162002563 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 286.51471424102783 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 286.5643560886383 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 286.60430121421814 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 286.6431875228882 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 286.68150997161865 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 286.71878600120544 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 286.75714635849 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 286.8029170036316 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 286.84852600097656 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 286.8890347480774 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 286.928671836853 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 286.9676704406738 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 287.0076117515564 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 287.050822019577 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 287.08944368362427 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 287.1273431777954 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 287.16774821281433 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 287.2061240673065 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 287.25357842445374 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 287.2916958332062 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 287.32924723625183 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 287.36701917648315 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 287.4049859046936 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 287.44302582740784 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 287.49001955986023 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 287.528377532959 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 287.5664086341858 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 287.6062994003296 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 287.64457869529724 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 287.6836726665497 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 287.7288258075714 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 287.76753854751587 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 287.80809688568115 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 287.8469047546387 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 287.8938388824463 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 287.93140482902527 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 287.9763069152832 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 288.01518177986145 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 288.05390453338623 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 288.09434390068054 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 288.13308477401733 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 288.18028569221497 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 288.21871280670166 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 288.2566752433777 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 288.294531583786 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 288.3319568634033 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 288.3689124584198 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 288.4146249294281 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 288.4518332481384 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 288.4894986152649 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 288.52714252471924 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 288.56562781333923 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 288.60547399520874 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 288.66748237609863 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 288.7123370170593 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 288.75153040885925 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 288.7910780906677 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 288.8290185928345 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 288.86741065979004 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 288.9244210720062 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 288.9613094329834 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 289.0020503997803 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 289.0400218963623 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 289.0812315940857 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 289.1219575405121 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 289.1629228591919 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 289.20223450660706 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 289.2412106990814 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 289.2805585861206 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 289.3264331817627 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 289.36462116241455 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 289.4024872779846 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 289.44017791748047 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 289.4780783653259 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 289.5158100128174 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 289.5615336894989 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 289.6010682582855 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 289.63877511024475 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 289.6769640445709 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 289.71443271636963 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 289.75325751304626 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 289.8001251220703 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 289.8392403125763 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 289.8813157081604 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 289.9270269870758 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 289.966833114624 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 290.0139617919922 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 290.054279088974 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 290.092618227005 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 290.1306173801422 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 290.17013359069824 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 290.2079966068268 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 290.25316977500916 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 290.29138708114624 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 290.3285050392151 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 290.36585807800293 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 290.404052734375 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 290.4422404766083 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 290.4881691932678 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 290.52593183517456 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 290.5659101009369 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 290.60547828674316 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 290.64384031295776 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 290.6823034286499 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 290.72852897644043 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 290.7690660953522 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 290.81056475639343 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 290.8505940437317 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 290.88974022865295 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 290.9281027317047 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 290.98654890060425 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 291.0261662006378 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 291.0643825531006 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 291.1032543182373 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 291.14803862571716 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 291.1909511089325 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 291.2295072078705 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 291.2680242061615 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 291.3064777851105 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 291.34494042396545 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 291.39188528060913 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 291.43026471138 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 291.46852135658264 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 291.50609254837036 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 291.5445623397827 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 291.6001422405243 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 291.64443159103394 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 291.6871988773346 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 291.72765254974365 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 291.7659680843353 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 291.8053846359253 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 291.8530602455139 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 291.8926296234131 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 291.9309446811676 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 291.97783398628235 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 292.02333521842957 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 292.0647373199463 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 292.1038193702698 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 292.1426856517792 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 292.18342208862305 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 292.2222354412079 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 292.2707259654999 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 292.3094787597656 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 292.3477711677551 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 292.38658332824707 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 292.424840927124 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 292.46342849731445 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 292.5123052597046 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 292.5514016151428 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 292.5898904800415 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 292.6292579174042 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 292.66737627983093 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 292.70775532722473 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 292.7606682777405 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 292.8004894256592 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 292.8399419784546 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 292.87941431999207 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 292.92024278640747 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 292.95959186553955 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 293.0174911022186 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 293.0560293197632 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 293.0962038040161 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 293.14132165908813 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 293.18258929252625 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 293.23392510414124 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 293.27516627311707 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 293.31375074386597 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 293.35483026504517 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 293.3941824436188 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 293.45279479026794 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 293.4926002025604 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 293.5305733680725 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 293.56948161125183 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 293.61124420166016 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 293.65051341056824 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 293.6984267234802 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 293.7374060153961 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 293.7754878997803 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 293.81543922424316 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 293.8562846183777 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 293.89412665367126 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 293.9393804073334 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 293.97854924201965 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 294.03321385383606 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 294.07254695892334 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 294.1123309135437 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 294.16031551361084 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 294.1989998817444 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 294.2375695705414 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 294.2761969566345 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 294.3141143321991 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 294.35203409194946 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 294.3975074291229 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 294.43541979789734 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 294.4741406440735 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 294.5126760005951 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 294.55070185661316 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 294.58853578567505 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 294.63811588287354 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 294.6768946647644 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 294.716689825058 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 294.7568507194519 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 294.7956190109253 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 294.835618019104 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 294.88711619377136 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 294.92606496810913 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 294.9641993045807 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 295.0053508281708 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 295.0506851673126 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 295.08977222442627 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 295.13254976272583 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 295.17332196235657 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 295.2118167877197 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 295.2490441799164 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 295.28624844551086 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 295.3318133354187 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 295.3705985546112 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 295.4082715511322 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 295.44614601135254 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 295.4845960140228 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 295.52315878868103 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 295.56862115859985 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 295.6085867881775 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 295.64888548851013 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 295.68744134902954 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 295.7260367870331 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 295.7643492221832 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 295.8112425804138 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 295.8505132198334 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 295.8892078399658 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 295.92903113365173 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 295.9684052467346 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 296.00965666770935 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 296.0767467021942 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 296.1167778968811 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 296.15787863731384 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 296.1967806816101 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 296.23596119880676 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 296.2742929458618 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 296.32012271881104 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 296.3585307598114 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 296.39646887779236 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 296.43474292755127 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 296.4730079174042 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 296.533198595047 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 296.59534311294556 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 296.6577367782593 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 296.72346591949463 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 296.7845437526703 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 296.8483855724335 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 296.90913462638855 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 296.9664776325226 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 297.0321624279022 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 297.1017258167267 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 297.1626183986664 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 297.2191836833954 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 297.2905418872833 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 297.3475389480591 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 297.40498328208923 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 297.46181869506836 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 297.5251703262329 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 297.5845799446106 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 297.6446967124939 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 297.7091820240021 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 297.7735786437988 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 297.8322720527649 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 297.8888690471649 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 297.9463760852814 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 298.0087323188782 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 298.0680248737335 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 298.12802386283875 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 298.19615626335144 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 298.2572000026703 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 298.31482338905334 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 298.3715341091156 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 298.42779421806335 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 298.4902985095978 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 298.5508728027344 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 298.6109278202057 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 298.6683304309845 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 298.73296451568604 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 298.7960526943207 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 298.8564488887787 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 298.91566944122314 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 298.9837329387665 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 299.049275636673 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 299.1139883995056 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 299.179603099823 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 299.23019313812256 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 299.26834082603455 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 299.30680871009827 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 299.3450446128845 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 299.38381791114807 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 299.43393325805664 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 299.48076939582825 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 299.51935338974 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 299.5584590435028 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 299.5969114303589 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 299.63760113716125 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 299.68395256996155 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 299.7219934463501 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 299.7605240345001 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 299.80007457733154 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 299.83835339546204 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 299.89069509506226 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 299.93017506599426 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 299.96982622146606 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 300.0089223384857 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 300.04778718948364 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 300.08931589126587 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 300.1353061199188 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 300.1765556335449 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 300.2286193370819 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 300.2675681114197 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 300.30620884895325 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 300.35073828697205 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 300.3906397819519 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 300.42898201942444 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 300.4675269126892 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 300.5062606334686 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 300.54428815841675 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 300.5913951396942 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 300.6316108703613 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 300.66960859298706 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 300.71092772483826 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 300.7504642009735 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 300.79062366485596 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 300.84300112724304 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 300.8810908794403 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 300.919401884079 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 300.957754611969 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 300.9965660572052 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 301.0441560745239 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 301.085072517395 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 301.1234652996063 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 301.1640582084656 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 301.20181107521057 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 301.25325894355774 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 301.29473185539246 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 301.33270144462585 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 301.37077617645264 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 301.40823698043823 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 301.4450695514679 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 301.4907958507538 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 301.53027606010437 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 301.5684769153595 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 301.6065728664398 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 301.64608812332153 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 301.6847231388092 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 301.73200702667236 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 301.7716271877289 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 301.8110120296478 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 301.8498604297638 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 301.887752532959 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 301.9279487133026 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 301.97712993621826 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 302.0272979736328 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 302.07996010780334 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 302.13003611564636 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 302.1697244644165 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 302.21399188041687 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 302.2754735946655 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 302.3137438297272 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 302.35242557525635 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 302.3913652896881 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 302.4385612010956 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 302.47749519348145 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 302.5162899494171 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 302.55452370643616 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 302.5939862728119 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 302.63407826423645 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 302.6792206764221 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 302.71766471862793 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 302.7583997249603 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 302.8162479400635 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 302.86505484580994 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 302.91132068634033 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 302.95206236839294 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 302.9910626411438 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 303.03010606765747 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 303.0715763568878 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 303.11165618896484 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 303.15935468673706 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 303.1979594230652 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 303.2359471321106 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 303.27421379089355 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 303.3194971084595 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 303.3647789955139 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 303.40272212028503 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 303.4409604072571 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 303.47889041900635 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 303.51720356941223 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 303.563925743103 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 303.60249423980713 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 303.64308857917786 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 303.68275117874146 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 303.72423124313354 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 303.77590894699097 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 303.81684923171997 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 303.85530376434326 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 303.8931155204773 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 303.9309170246124 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 303.9757089614868 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 304.0378828048706 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 304.09079003334045 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 304.1419520378113 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 304.18382239341736 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 304.2275528907776 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 304.26615023612976 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 304.3104827404022 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 304.3502576351166 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 304.38829612731934 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 304.4347450733185 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 304.47289633750916 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 304.51092433929443 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 304.5489275455475 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 304.5879080295563 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 304.6357419490814 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 304.6746709346771 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 304.712518453598 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 304.7541561126709 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 304.79647731781006 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 304.8342869281769 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 304.88312554359436 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 304.923814535141 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 304.9628462791443 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 305.0012834072113 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 305.03916025161743 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 305.0785002708435 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 305.12395119667053 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 305.16484093666077 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 305.20294761657715 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 305.2414200305939 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 305.2798774242401 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 305.3180911540985 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 305.37108540534973 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 305.40939807891846 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 305.4472405910492 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 305.4850335121155 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 305.523640871048 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 305.56326055526733 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 305.6120626926422 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 305.65304803848267 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 305.6917927265167 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 305.72991394996643 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 305.7715449333191 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 305.81234431266785 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 305.8586356639862 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 305.89818596839905 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 305.9364628791809 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 305.97477197647095 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 306.01273369789124 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 306.05961632728577 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 306.0999629497528 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 306.1411693096161 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 306.18160367012024 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 306.2197115421295 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 306.25806856155396 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 306.30340909957886 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 306.3450057506561 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 306.3952088356018 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 306.433846950531 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 306.4758746623993 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 306.51961278915405 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 306.5672392845154 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 306.60642290115356 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 306.66203904151917 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 306.70928144454956 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 306.7500820159912 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 306.79824686050415 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 306.83794021606445 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 306.87747502326965 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 306.9238793849945 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 306.9663543701172 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 307.00999331474304 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 307.04823446273804 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 307.0903899669647 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 307.1368815898895 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 307.1808092594147 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 307.21949458122253 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 307.2577040195465 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 307.29857444763184 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 307.34711360931396 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 307.39659428596497 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 307.44305777549744 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 307.48196744918823 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 307.53092408180237 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 307.57732605934143 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 307.61725330352783 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 307.6576199531555 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 307.69508171081543 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 307.7331385612488 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 307.7716100215912 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 307.82226037979126 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 307.8626501560211 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 307.9019305706024 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 307.9437561035156 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 307.9843912124634 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 308.0236089229584 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 308.07181882858276 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 308.1121070384979 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 308.1523540019989 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 308.19070172309875 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 308.2292046546936 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 308.2734022140503 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 308.31152749061584 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 308.34908413887024 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 308.39156579971313 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 308.44505071640015 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 308.4915111064911 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 308.53005385398865 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 308.56756591796875 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 308.60722756385803 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 308.6469111442566 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 308.69197702407837 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 308.7302167415619 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 308.7740879058838 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 308.8136513233185 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 308.85440397262573 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 308.9036600589752 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 308.94196105003357 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 308.9799795150757 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 309.0189552307129 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 309.0599522590637 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 309.0996401309967 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 309.1448087692261 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 309.1866657733917 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 309.2441062927246 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 309.3034155368805 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 309.3753228187561 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 309.4349937438965 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 309.49864053726196 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 309.55817890167236 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 309.6246156692505 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 309.6823766231537 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 309.7414255142212 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 309.80335116386414 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 309.86681056022644 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 309.9241864681244 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 309.9830255508423 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 310.0401566028595 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 310.1060242652893 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 310.1652407646179 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 310.2222406864166 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 310.28206396102905 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 310.34556579589844 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 310.40766763687134 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 310.46466732025146 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 310.5361611843109 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 310.6090478897095 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 310.66747784614563 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 310.7254407405853 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 310.78342747688293 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 310.84582114219666 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 310.9031665325165 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 310.9607048034668 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 311.01916909217834 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 311.0843093395233 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 311.17085361480713 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 311.23558354377747 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 311.3025631904602 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 311.3689022064209 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 311.4298334121704 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 311.4898102283478 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 311.5583562850952 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 311.6168100833893 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 311.6782269477844 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 311.7444133758545 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 311.8182647228241 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 311.8894352912903 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 311.93829345703125 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 311.9773280620575 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 312.0224494934082 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 312.065532207489 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 312.10376739501953 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 312.1446475982666 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 312.1834695339203 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 312.22189354896545 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 312.268296957016 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 312.3070635795593 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 312.3457624912262 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 312.3843283653259 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 312.4225389957428 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 312.4614951610565 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 312.5084800720215 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 312.54674911499023 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 312.59850335121155 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 312.6384627819061 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 312.6780481338501 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 312.7207672595978 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 312.7701003551483 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 312.8107008934021 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 312.8487787246704 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 312.88818097114563 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 312.92968940734863 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 312.9704489707947 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 313.0089955329895 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 313.04756593704224 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 313.0857448577881 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 313.13142228126526 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 313.1797912120819 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 313.2185616493225 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 313.25721168518066 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 313.29552817344666 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 313.3336327075958 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 313.37257409095764 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 313.41740441322327 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 313.454891204834 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 313.49352192878723 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 313.5314791202545 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 313.57034945487976 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 313.617299079895 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 313.6665930747986 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 313.70496559143066 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 313.74294543266296 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 313.7827949523926 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 313.82255697250366 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 313.8692057132721 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 313.908127784729 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 313.9550447463989 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 313.9959089756012 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 314.0395987033844 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 314.0795590877533 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 314.1177875995636 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 314.16400146484375 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 314.20284056663513 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 314.24804162979126 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 314.29057240486145 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 314.3295910358429 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 314.36760425567627 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 314.40591049194336 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 314.4445080757141 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 314.4899673461914 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 314.5286068916321 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 314.5690472126007 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 314.62523102760315 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 314.66580510139465 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 314.71238565444946 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 314.75172424316406 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 314.79378509521484 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 314.83668279647827 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 314.87791562080383 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 314.92903780937195 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 314.96862149238586 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 315.0133230686188 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 315.052109003067 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 315.09178256988525 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 315.14337944984436 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 315.1875488758087 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 315.2260844707489 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 315.2709367275238 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 315.309547662735 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 315.35889863967896 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 315.3992655277252 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 315.4370369911194 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 315.47567653656006 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 315.514769077301 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 315.5537950992584 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 315.600563287735 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 315.6484286785126 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 315.6881182193756 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 315.72633838653564 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 315.767715215683 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 315.8166844844818 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 315.855516910553 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 315.8942241668701 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 315.9330940246582 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 315.97206687927246 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 316.0110170841217 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 316.0560784339905 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 316.0939965248108 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 316.1461126804352 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 316.2107267379761 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 316.2514889240265 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 316.3002886772156 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 316.3392870426178 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 316.38404846191406 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 316.42258858680725 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 316.4615309238434 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 316.4997057914734 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 316.5483992099762 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 316.58734822273254 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 316.62516689300537 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 316.6733548641205 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 316.7185945510864 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 316.75815057754517 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 316.79922103881836 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 316.8408987522125 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 316.8816182613373 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 316.9211480617523 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 316.97021770477295 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 317.0112028121948 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 317.04920291900635 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 317.08764028549194 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 317.1359341144562 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 317.1804723739624 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 317.2187805175781 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 317.25777196884155 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 317.29564452171326 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 317.333984375 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 317.3791172504425 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 317.4170079231262 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 317.45496940612793 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 317.49344062805176 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 317.5320625305176 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 317.5818109512329 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 317.62434482574463 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 317.66579580307007 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 317.7110102176666 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 317.7488269805908 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 317.79219007492065 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 317.83950757980347 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 317.8823142051697 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 317.92427587509155 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 317.96417117118835 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 318.0101914405823 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 318.0500786304474 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 318.09017610549927 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 318.1298859119415 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 318.17344307899475 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 318.2147090435028 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 318.257600069046 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 318.2969546318054 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 318.335412979126 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 318.37499475479126 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 318.42973732948303 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 318.473735332489 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 318.51508831977844 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 318.56078815460205 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 318.6034622192383 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 318.6488494873047 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 318.69606733322144 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 318.7355718612671 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 318.7783589363098 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 318.81970477104187 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 318.8646721839905 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 318.9031262397766 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 318.94219636917114 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 318.98044180870056 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 319.0195963382721 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 319.05783224105835 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 319.10278367996216 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 319.1408543586731 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 319.187726020813 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 319.22642731666565 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 319.2646517753601 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 319.30200386047363 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 319.3467423915863 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 319.38797307014465 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 319.42530393600464 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 319.4633581638336 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 319.5017189979553 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 319.54852056503296 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 319.58697533607483 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 319.62529826164246 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 319.67210245132446 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 319.72508430480957 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 319.7718906402588 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 319.8117575645447 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 319.8511378765106 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 319.8893003463745 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 319.9277582168579 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 319.9651210308075 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 320.0101668834686 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 320.04751777648926 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 320.0853114128113 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 320.12304735183716 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 320.16498947143555 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 320.20544481277466 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 320.2542417049408 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 320.29200863838196 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 320.328697681427 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 320.3665232658386 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 320.4042332172394 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 320.4477860927582 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 320.4954102039337 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 320.5336802005768 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 320.57107734680176 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 320.6100573539734 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 320.65649342536926 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 320.6965310573578 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 320.75178718566895 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 320.79133701324463 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 320.8297007083893 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 320.8685848712921 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 320.9141778945923 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 320.9634690284729 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 321.00194478034973 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 321.0396943092346 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 321.0777792930603 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 321.1168305873871 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 321.1639988422394 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 321.20440793037415 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 321.2425847053528 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 321.2814450263977 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 321.3188033103943 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 321.3657524585724 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 321.404589176178 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 321.4424524307251 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 321.48078751564026 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 321.5209918022156 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 321.5606687068939 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 321.6237895488739 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 321.6781220436096 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 321.7185060977936 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 321.767457485199 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 321.81020641326904 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 321.8737983703613 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 321.91628766059875 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 321.9790277481079 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 322.04161047935486 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 322.1175971031189 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 322.1789972782135 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 322.24123764038086 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 322.3035011291504 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 322.3788034915924 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 322.4368667602539 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 322.495019197464 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 322.55240416526794 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 322.62388610839844 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 322.6822624206543 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 322.74197602272034 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 322.81620049476624 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 322.8858675956726 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 322.94315934181213 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 323.00200963020325 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 323.0780313014984 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 323.1580111980438 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 323.2173936367035 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 323.27468061447144 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 323.3320782184601 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 323.39462637901306 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 323.4523754119873 loss tensor(0.3000, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "XNQaGo06Ta49",
        "outputId": "ddb58649-904c-4a1b-fd61-bb6ca426d721"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd876e61ee0>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6G3P5f8LTdAY",
        "outputId": "33303251-96ab-4722-b173-7c26fc76b6bd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd876df9f40>]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "l0LtcyhPTeh8",
        "outputId": "f5dbadec-5a2f-42c5-d187-389335879c59"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd876915940>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}