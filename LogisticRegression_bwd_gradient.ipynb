{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/LogisticRegression_bwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the necessary packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "x7iZpPFrGWhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rkQFFcg0HXnN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "ShzuBabDHhVe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "A61m0FPpGijm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "ZHyH8jgfGmnf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "14D3LUb1KU8z"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading and preprocessing the data**"
      ],
      "metadata": {
        "id": "G-a43m8xGoJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "penguins = tfds.load('penguins', as_supervised=True, split='train')"
      ],
      "metadata": {
        "id": "ml7IdhKkHjfC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = penguins.batch(500).get_single_element()\n",
        "X, y = X.numpy(), y.numpy()"
      ],
      "metadata": {
        "id": "c2BMFvK7HoFd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "metadata": {
        "id": "bDM9PTN0HrKa"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "Xtest = torch.from_numpy(Xtest).float()"
      ],
      "metadata": {
        "id": "JLGZsa5pHtTD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "pubjWXD8Hvva"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Logistic Regression**"
      ],
      "metadata": {
        "id": "9y_Sd0mlG27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, w, b):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(w)\n",
        "    self.bias = nn.Parameter(b)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(1, -1)\n",
        "    return torch.softmax(x@self.weight + self.bias, 1)"
      ],
      "metadata": {
        "id": "YjCVZwwrH3ah"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pv1yTiJH7JV",
        "outputId": "652f1237-ce9e-4f99-e792-8d595fa731c7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize the parameters**"
      ],
      "metadata": {
        "id": "dUvft9uYG_Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "w = torch.randn((4, 3), requires_grad=True)\n",
        "b = torch.randn((3, ), requires_grad=True)\n",
        "LG = SimpleLogisticRegression(4, w, b).to(device)"
      ],
      "metadata": {
        "id": "l2X3STJaH9aY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We try our model with the first example\n",
        "print(LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbykYgnuIAWE",
        "outputId": "ade9ac37-1e85-45ce-ed3b-1619788e876a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0920, 0.3390, 0.5690]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate predictions"
      ],
      "metadata": {
        "id": "-nxjcQ7-HQh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(x,w,b):\n",
        "  ypred=torch.randn((x.shape[0],3))\n",
        "  for j in range (x.shape[0]):\n",
        "    xj = x[j].reshape(1, -1)\n",
        "    ypred[j]=torch.softmax(xj@w+b,1)\n",
        "  return ypred"
      ],
      "metadata": {
        "id": "2OCd-kbfLV5h"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=pred(Xtrain,w,b)"
      ],
      "metadata": {
        "id": "SzBH4FuVNabv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define accuracy**"
      ],
      "metadata": {
        "id": "1g51kfRQHWSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "_LQ7YyETIB7n"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 33% (random guessing).\n",
        "accuracy(ytrain.to(device),ypred.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bGfj-mfIFwZ",
        "outputId": "98a27c9b-a034-4682-dbad-b99d44a99503"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3600)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define cross entropy**"
      ],
      "metadata": {
        "id": "hiEzUJ_GHmQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(ytrue,ypred):\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "1MVXQ3PTILFk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cross_entropy(ytrain.to(device),ypred.to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDzjWsUK6YG",
        "outputId": "8d24b744-2891-4d36-8af8-f4c30e479e67"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5569, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and evaluate the network**"
      ],
      "metadata": {
        "id": "sCrAi6M2H3wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bwd_gradient(x,y):\n",
        "\n",
        "  x,y=x.to(device),y.to(device)\n",
        "\n",
        "  losses = [] # Vector with the cross entropy values of test set\n",
        "  accuracies = [] # Vector with the accuracy values of test set\n",
        "  errors=[] # Vector with the number of misclassification of the test set\n",
        "\n",
        "  l_rate0 = 0.2 # Learning rate used \n",
        "\n",
        "  # Initialize the parameters\n",
        "  w = torch.randn((4, 3), requires_grad=True)\n",
        "  b = torch.randn((3, ), requires_grad=True)\n",
        "\n",
        "  w, b = w.to(device), b.to(device)\n",
        "\n",
        "  ypred=pred(x,w,b)\n",
        "  ypred = ypred.to(device)\n",
        "  loss = cross_entropy(y,ypred) # Loss function\n",
        "\n",
        "  # Calculate the start time \n",
        "  t=0\n",
        "  it=0\n",
        "  t0=time.time()\n",
        "  print('Time', t, 'loss', loss)\n",
        "\n",
        "  while (loss>0.3): \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Apply gradients \n",
        "      w -= 0.01*w.grad\n",
        "      b -= 0.01*b.grad\n",
        "\n",
        "      # Gradients are accumulated: we need to zero them out before the next iteration.\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "    \n",
        "    # We calculate the number of misclassification of the test set with the updated model and we add to the errors vector\n",
        "    LG = SimpleLogisticRegression(4, w, b).to(device)\n",
        "    ypredT = torch.randn(Xtest.size(0),3)\n",
        "    error=0\n",
        "    for i in range (Xtest.size(0)):\n",
        "      ypredT[i]=LG(Xtest[i].to(device))\n",
        "      if (LG(Xtest[i].to(device)).argmax(1)- ytest[i])!=0:\n",
        "        error = error+ 1\n",
        "    errors.append(error)\n",
        "    ypredT = ypredT.to(device)\n",
        "\n",
        "    ypred=pred(x,w,b)\n",
        "    \n",
        "    # We calculate the accuracy of the test set with the updated model and we add to the accuracy vector\n",
        "    accuracies.append(accuracy(ytest,ypredT).item())\n",
        "\n",
        "    # We calculate the cross_entropy of the test set with the updated model and we add to the accuracy vector\n",
        "    loss = cross_entropy(y,ypred.to(device))\n",
        "    lossT = cross_entropy(ytest,ypredT)\n",
        "    losses.append(lossT.detach().item())\n",
        "\n",
        "    #We add the execution time of the iteration\n",
        "    t1=time.time()\n",
        "    t+=t1-t0\n",
        "    t0=t1\n",
        "    it+=1\n",
        "    print('Time', t, 'loss', loss)\n",
        "    \n",
        "  print('Final execution time', t)  \n",
        "  print('Number of iterations', it)\n",
        "  print('Mean execution time of an iteration', t/it)\n",
        "  \n",
        "  return w,b,errors,losses,accuracies\n"
      ],
      "metadata": {
        "id": "cBld3TwvLDl6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b,errors,losses,accuracies = train_bwd_gradient(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXOhaZSOPSCa",
        "outputId": "dd8cbfaf-dc71-412d-a3ab-206ed9068074"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Time 67.25415658950806 loss tensor(0.5035, grad_fn=<NegBackward0>)\n",
            "Time 67.28198432922363 loss tensor(0.5034, grad_fn=<NegBackward0>)\n",
            "Time 67.31034421920776 loss tensor(0.5034, grad_fn=<NegBackward0>)\n",
            "Time 67.33848643302917 loss tensor(0.5033, grad_fn=<NegBackward0>)\n",
            "Time 67.38493323326111 loss tensor(0.5032, grad_fn=<NegBackward0>)\n",
            "Time 67.41351318359375 loss tensor(0.5031, grad_fn=<NegBackward0>)\n",
            "Time 67.4418683052063 loss tensor(0.5031, grad_fn=<NegBackward0>)\n",
            "Time 67.46955156326294 loss tensor(0.5030, grad_fn=<NegBackward0>)\n",
            "Time 67.50058221817017 loss tensor(0.5029, grad_fn=<NegBackward0>)\n",
            "Time 67.52919316291809 loss tensor(0.5028, grad_fn=<NegBackward0>)\n",
            "Time 67.56655073165894 loss tensor(0.5028, grad_fn=<NegBackward0>)\n",
            "Time 67.59743928909302 loss tensor(0.5027, grad_fn=<NegBackward0>)\n",
            "Time 67.62715125083923 loss tensor(0.5026, grad_fn=<NegBackward0>)\n",
            "Time 67.65513134002686 loss tensor(0.5025, grad_fn=<NegBackward0>)\n",
            "Time 67.68373942375183 loss tensor(0.5025, grad_fn=<NegBackward0>)\n",
            "Time 67.71168994903564 loss tensor(0.5024, grad_fn=<NegBackward0>)\n",
            "Time 67.74075675010681 loss tensor(0.5023, grad_fn=<NegBackward0>)\n",
            "Time 67.77519965171814 loss tensor(0.5022, grad_fn=<NegBackward0>)\n",
            "Time 67.8070936203003 loss tensor(0.5022, grad_fn=<NegBackward0>)\n",
            "Time 67.84050989151001 loss tensor(0.5021, grad_fn=<NegBackward0>)\n",
            "Time 67.87020564079285 loss tensor(0.5020, grad_fn=<NegBackward0>)\n",
            "Time 67.90080165863037 loss tensor(0.5020, grad_fn=<NegBackward0>)\n",
            "Time 67.93058562278748 loss tensor(0.5019, grad_fn=<NegBackward0>)\n",
            "Time 67.96067953109741 loss tensor(0.5018, grad_fn=<NegBackward0>)\n",
            "Time 67.99442672729492 loss tensor(0.5017, grad_fn=<NegBackward0>)\n",
            "Time 68.02522087097168 loss tensor(0.5017, grad_fn=<NegBackward0>)\n",
            "Time 68.05309820175171 loss tensor(0.5016, grad_fn=<NegBackward0>)\n",
            "Time 68.08067798614502 loss tensor(0.5015, grad_fn=<NegBackward0>)\n",
            "Time 68.1100103855133 loss tensor(0.5014, grad_fn=<NegBackward0>)\n",
            "Time 68.14458918571472 loss tensor(0.5014, grad_fn=<NegBackward0>)\n",
            "Time 68.17382597923279 loss tensor(0.5013, grad_fn=<NegBackward0>)\n",
            "Time 68.20742964744568 loss tensor(0.5012, grad_fn=<NegBackward0>)\n",
            "Time 68.23489689826965 loss tensor(0.5011, grad_fn=<NegBackward0>)\n",
            "Time 68.26343536376953 loss tensor(0.5011, grad_fn=<NegBackward0>)\n",
            "Time 68.29278588294983 loss tensor(0.5010, grad_fn=<NegBackward0>)\n",
            "Time 68.32153534889221 loss tensor(0.5009, grad_fn=<NegBackward0>)\n",
            "Time 68.35471558570862 loss tensor(0.5008, grad_fn=<NegBackward0>)\n",
            "Time 68.39428043365479 loss tensor(0.5008, grad_fn=<NegBackward0>)\n",
            "Time 68.42635226249695 loss tensor(0.5007, grad_fn=<NegBackward0>)\n",
            "Time 68.4563455581665 loss tensor(0.5006, grad_fn=<NegBackward0>)\n",
            "Time 68.485506772995 loss tensor(0.5006, grad_fn=<NegBackward0>)\n",
            "Time 68.51483654975891 loss tensor(0.5005, grad_fn=<NegBackward0>)\n",
            "Time 68.54083585739136 loss tensor(0.5004, grad_fn=<NegBackward0>)\n",
            "Time 68.56663465499878 loss tensor(0.5003, grad_fn=<NegBackward0>)\n",
            "Time 68.59446668624878 loss tensor(0.5003, grad_fn=<NegBackward0>)\n",
            "Time 68.62175393104553 loss tensor(0.5002, grad_fn=<NegBackward0>)\n",
            "Time 68.6561164855957 loss tensor(0.5001, grad_fn=<NegBackward0>)\n",
            "Time 68.68264842033386 loss tensor(0.5000, grad_fn=<NegBackward0>)\n",
            "Time 68.7094337940216 loss tensor(0.5000, grad_fn=<NegBackward0>)\n",
            "Time 68.73563075065613 loss tensor(0.4999, grad_fn=<NegBackward0>)\n",
            "Time 68.76695203781128 loss tensor(0.4998, grad_fn=<NegBackward0>)\n",
            "Time 68.79674363136292 loss tensor(0.4998, grad_fn=<NegBackward0>)\n",
            "Time 68.82363080978394 loss tensor(0.4997, grad_fn=<NegBackward0>)\n",
            "Time 68.85469913482666 loss tensor(0.4996, grad_fn=<NegBackward0>)\n",
            "Time 68.89063310623169 loss tensor(0.4995, grad_fn=<NegBackward0>)\n",
            "Time 68.92651987075806 loss tensor(0.4995, grad_fn=<NegBackward0>)\n",
            "Time 68.95643520355225 loss tensor(0.4994, grad_fn=<NegBackward0>)\n",
            "Time 68.98443818092346 loss tensor(0.4993, grad_fn=<NegBackward0>)\n",
            "Time 69.01512336730957 loss tensor(0.4992, grad_fn=<NegBackward0>)\n",
            "Time 69.04190993309021 loss tensor(0.4992, grad_fn=<NegBackward0>)\n",
            "Time 69.07044577598572 loss tensor(0.4991, grad_fn=<NegBackward0>)\n",
            "Time 69.10375666618347 loss tensor(0.4990, grad_fn=<NegBackward0>)\n",
            "Time 69.1332836151123 loss tensor(0.4989, grad_fn=<NegBackward0>)\n",
            "Time 69.16092157363892 loss tensor(0.4989, grad_fn=<NegBackward0>)\n",
            "Time 69.19090414047241 loss tensor(0.4988, grad_fn=<NegBackward0>)\n",
            "Time 69.21970391273499 loss tensor(0.4987, grad_fn=<NegBackward0>)\n",
            "Time 69.24878573417664 loss tensor(0.4987, grad_fn=<NegBackward0>)\n",
            "Time 69.28081059455872 loss tensor(0.4986, grad_fn=<NegBackward0>)\n",
            "Time 69.32457828521729 loss tensor(0.4985, grad_fn=<NegBackward0>)\n",
            "Time 69.35767102241516 loss tensor(0.4984, grad_fn=<NegBackward0>)\n",
            "Time 69.38831424713135 loss tensor(0.4984, grad_fn=<NegBackward0>)\n",
            "Time 69.42513108253479 loss tensor(0.4983, grad_fn=<NegBackward0>)\n",
            "Time 69.45252275466919 loss tensor(0.4982, grad_fn=<NegBackward0>)\n",
            "Time 69.48565554618835 loss tensor(0.4981, grad_fn=<NegBackward0>)\n",
            "Time 69.51563429832458 loss tensor(0.4981, grad_fn=<NegBackward0>)\n",
            "Time 69.55201125144958 loss tensor(0.4980, grad_fn=<NegBackward0>)\n",
            "Time 69.58587622642517 loss tensor(0.4979, grad_fn=<NegBackward0>)\n",
            "Time 69.61474299430847 loss tensor(0.4979, grad_fn=<NegBackward0>)\n",
            "Time 69.64259886741638 loss tensor(0.4978, grad_fn=<NegBackward0>)\n",
            "Time 69.67314457893372 loss tensor(0.4977, grad_fn=<NegBackward0>)\n",
            "Time 69.70178627967834 loss tensor(0.4976, grad_fn=<NegBackward0>)\n",
            "Time 69.7313539981842 loss tensor(0.4976, grad_fn=<NegBackward0>)\n",
            "Time 69.76621675491333 loss tensor(0.4975, grad_fn=<NegBackward0>)\n",
            "Time 69.79499411582947 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 69.82353734970093 loss tensor(0.4974, grad_fn=<NegBackward0>)\n",
            "Time 69.85558795928955 loss tensor(0.4973, grad_fn=<NegBackward0>)\n",
            "Time 69.88747072219849 loss tensor(0.4972, grad_fn=<NegBackward0>)\n",
            "Time 69.91651129722595 loss tensor(0.4971, grad_fn=<NegBackward0>)\n",
            "Time 69.9459240436554 loss tensor(0.4971, grad_fn=<NegBackward0>)\n",
            "Time 69.98085618019104 loss tensor(0.4970, grad_fn=<NegBackward0>)\n",
            "Time 70.0116651058197 loss tensor(0.4969, grad_fn=<NegBackward0>)\n",
            "Time 70.03925132751465 loss tensor(0.4968, grad_fn=<NegBackward0>)\n",
            "Time 70.06716847419739 loss tensor(0.4968, grad_fn=<NegBackward0>)\n",
            "Time 70.09558010101318 loss tensor(0.4967, grad_fn=<NegBackward0>)\n",
            "Time 70.12406897544861 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 70.15296244621277 loss tensor(0.4966, grad_fn=<NegBackward0>)\n",
            "Time 70.19159317016602 loss tensor(0.4965, grad_fn=<NegBackward0>)\n",
            "Time 70.22381138801575 loss tensor(0.4964, grad_fn=<NegBackward0>)\n",
            "Time 70.25358867645264 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 70.28282475471497 loss tensor(0.4963, grad_fn=<NegBackward0>)\n",
            "Time 70.31199193000793 loss tensor(0.4962, grad_fn=<NegBackward0>)\n",
            "Time 70.34007000923157 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 70.36827945709229 loss tensor(0.4961, grad_fn=<NegBackward0>)\n",
            "Time 70.40748071670532 loss tensor(0.4960, grad_fn=<NegBackward0>)\n",
            "Time 70.44346594810486 loss tensor(0.4959, grad_fn=<NegBackward0>)\n",
            "Time 70.47036814689636 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 70.49916410446167 loss tensor(0.4958, grad_fn=<NegBackward0>)\n",
            "Time 70.528391122818 loss tensor(0.4957, grad_fn=<NegBackward0>)\n",
            "Time 70.55824565887451 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 70.586745262146 loss tensor(0.4956, grad_fn=<NegBackward0>)\n",
            "Time 70.6272497177124 loss tensor(0.4955, grad_fn=<NegBackward0>)\n",
            "Time 70.65680193901062 loss tensor(0.4954, grad_fn=<NegBackward0>)\n",
            "Time 70.68597388267517 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 70.71648859977722 loss tensor(0.4953, grad_fn=<NegBackward0>)\n",
            "Time 70.74882197380066 loss tensor(0.4952, grad_fn=<NegBackward0>)\n",
            "Time 70.77778625488281 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 70.80525469779968 loss tensor(0.4951, grad_fn=<NegBackward0>)\n",
            "Time 70.83842587471008 loss tensor(0.4950, grad_fn=<NegBackward0>)\n",
            "Time 70.8743371963501 loss tensor(0.4949, grad_fn=<NegBackward0>)\n",
            "Time 70.9034264087677 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 70.93158292770386 loss tensor(0.4948, grad_fn=<NegBackward0>)\n",
            "Time 70.96049618721008 loss tensor(0.4947, grad_fn=<NegBackward0>)\n",
            "Time 70.98791313171387 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 71.01995134353638 loss tensor(0.4946, grad_fn=<NegBackward0>)\n",
            "Time 71.05644750595093 loss tensor(0.4945, grad_fn=<NegBackward0>)\n",
            "Time 71.0865228176117 loss tensor(0.4944, grad_fn=<NegBackward0>)\n",
            "Time 71.11556339263916 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 71.14416742324829 loss tensor(0.4943, grad_fn=<NegBackward0>)\n",
            "Time 71.17477607727051 loss tensor(0.4942, grad_fn=<NegBackward0>)\n",
            "Time 71.20364761352539 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 71.23301649093628 loss tensor(0.4941, grad_fn=<NegBackward0>)\n",
            "Time 71.27242946624756 loss tensor(0.4940, grad_fn=<NegBackward0>)\n",
            "Time 71.30170774459839 loss tensor(0.4939, grad_fn=<NegBackward0>)\n",
            "Time 71.33034777641296 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 71.35952711105347 loss tensor(0.4938, grad_fn=<NegBackward0>)\n",
            "Time 71.39033579826355 loss tensor(0.4937, grad_fn=<NegBackward0>)\n",
            "Time 71.42366862297058 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 71.4584424495697 loss tensor(0.4936, grad_fn=<NegBackward0>)\n",
            "Time 71.4912679195404 loss tensor(0.4935, grad_fn=<NegBackward0>)\n",
            "Time 71.52303457260132 loss tensor(0.4934, grad_fn=<NegBackward0>)\n",
            "Time 71.55681157112122 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 71.5857720375061 loss tensor(0.4933, grad_fn=<NegBackward0>)\n",
            "Time 71.62515211105347 loss tensor(0.4932, grad_fn=<NegBackward0>)\n",
            "Time 71.65466928482056 loss tensor(0.4931, grad_fn=<NegBackward0>)\n",
            "Time 71.68327045440674 loss tensor(0.4931, grad_fn=<NegBackward0>)\n",
            "Time 71.71956753730774 loss tensor(0.4930, grad_fn=<NegBackward0>)\n",
            "Time 71.7493486404419 loss tensor(0.4929, grad_fn=<NegBackward0>)\n",
            "Time 71.78152990341187 loss tensor(0.4929, grad_fn=<NegBackward0>)\n",
            "Time 71.81074523925781 loss tensor(0.4928, grad_fn=<NegBackward0>)\n",
            "Time 71.83868503570557 loss tensor(0.4927, grad_fn=<NegBackward0>)\n",
            "Time 71.86763858795166 loss tensor(0.4926, grad_fn=<NegBackward0>)\n",
            "Time 71.89569473266602 loss tensor(0.4926, grad_fn=<NegBackward0>)\n",
            "Time 71.93433618545532 loss tensor(0.4925, grad_fn=<NegBackward0>)\n",
            "Time 71.97015905380249 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 71.99868035316467 loss tensor(0.4924, grad_fn=<NegBackward0>)\n",
            "Time 72.02857995033264 loss tensor(0.4923, grad_fn=<NegBackward0>)\n",
            "Time 72.05633974075317 loss tensor(0.4922, grad_fn=<NegBackward0>)\n",
            "Time 72.08290886878967 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 72.11077451705933 loss tensor(0.4921, grad_fn=<NegBackward0>)\n",
            "Time 72.14109802246094 loss tensor(0.4920, grad_fn=<NegBackward0>)\n",
            "Time 72.1683828830719 loss tensor(0.4919, grad_fn=<NegBackward0>)\n",
            "Time 72.19587469100952 loss tensor(0.4919, grad_fn=<NegBackward0>)\n",
            "Time 72.22967624664307 loss tensor(0.4918, grad_fn=<NegBackward0>)\n",
            "Time 72.25996375083923 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 72.28958702087402 loss tensor(0.4917, grad_fn=<NegBackward0>)\n",
            "Time 72.31797409057617 loss tensor(0.4916, grad_fn=<NegBackward0>)\n",
            "Time 72.35166573524475 loss tensor(0.4915, grad_fn=<NegBackward0>)\n",
            "Time 72.3825409412384 loss tensor(0.4914, grad_fn=<NegBackward0>)\n",
            "Time 72.41254353523254 loss tensor(0.4914, grad_fn=<NegBackward0>)\n",
            "Time 72.44719004631042 loss tensor(0.4913, grad_fn=<NegBackward0>)\n",
            "Time 72.48619985580444 loss tensor(0.4912, grad_fn=<NegBackward0>)\n",
            "Time 72.5415358543396 loss tensor(0.4912, grad_fn=<NegBackward0>)\n",
            "Time 72.59934735298157 loss tensor(0.4911, grad_fn=<NegBackward0>)\n",
            "Time 72.64639830589294 loss tensor(0.4910, grad_fn=<NegBackward0>)\n",
            "Time 72.68774247169495 loss tensor(0.4909, grad_fn=<NegBackward0>)\n",
            "Time 72.73125624656677 loss tensor(0.4909, grad_fn=<NegBackward0>)\n",
            "Time 72.77648091316223 loss tensor(0.4908, grad_fn=<NegBackward0>)\n",
            "Time 72.82048225402832 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 72.85987401008606 loss tensor(0.4907, grad_fn=<NegBackward0>)\n",
            "Time 72.90326070785522 loss tensor(0.4906, grad_fn=<NegBackward0>)\n",
            "Time 72.94276976585388 loss tensor(0.4905, grad_fn=<NegBackward0>)\n",
            "Time 72.98173093795776 loss tensor(0.4905, grad_fn=<NegBackward0>)\n",
            "Time 73.02834343910217 loss tensor(0.4904, grad_fn=<NegBackward0>)\n",
            "Time 73.06689691543579 loss tensor(0.4903, grad_fn=<NegBackward0>)\n",
            "Time 73.10560894012451 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 73.14454507827759 loss tensor(0.4902, grad_fn=<NegBackward0>)\n",
            "Time 73.18428063392639 loss tensor(0.4901, grad_fn=<NegBackward0>)\n",
            "Time 73.2226197719574 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 73.27254986763 loss tensor(0.4900, grad_fn=<NegBackward0>)\n",
            "Time 73.31642627716064 loss tensor(0.4899, grad_fn=<NegBackward0>)\n",
            "Time 73.35636711120605 loss tensor(0.4898, grad_fn=<NegBackward0>)\n",
            "Time 73.39841151237488 loss tensor(0.4898, grad_fn=<NegBackward0>)\n",
            "Time 73.43691825866699 loss tensor(0.4897, grad_fn=<NegBackward0>)\n",
            "Time 73.48098254203796 loss tensor(0.4896, grad_fn=<NegBackward0>)\n",
            "Time 73.530921459198 loss tensor(0.4896, grad_fn=<NegBackward0>)\n",
            "Time 73.57258296012878 loss tensor(0.4895, grad_fn=<NegBackward0>)\n",
            "Time 73.61468267440796 loss tensor(0.4894, grad_fn=<NegBackward0>)\n",
            "Time 73.65571093559265 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 73.69927835464478 loss tensor(0.4893, grad_fn=<NegBackward0>)\n",
            "Time 73.73929715156555 loss tensor(0.4892, grad_fn=<NegBackward0>)\n",
            "Time 73.78135204315186 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 73.8319935798645 loss tensor(0.4891, grad_fn=<NegBackward0>)\n",
            "Time 73.87851762771606 loss tensor(0.4890, grad_fn=<NegBackward0>)\n",
            "Time 73.92604112625122 loss tensor(0.4889, grad_fn=<NegBackward0>)\n",
            "Time 73.9696249961853 loss tensor(0.4889, grad_fn=<NegBackward0>)\n",
            "Time 74.01452851295471 loss tensor(0.4888, grad_fn=<NegBackward0>)\n",
            "Time 74.05633997917175 loss tensor(0.4887, grad_fn=<NegBackward0>)\n",
            "Time 74.09765791893005 loss tensor(0.4886, grad_fn=<NegBackward0>)\n",
            "Time 74.13916110992432 loss tensor(0.4886, grad_fn=<NegBackward0>)\n",
            "Time 74.16804480552673 loss tensor(0.4885, grad_fn=<NegBackward0>)\n",
            "Time 74.20274376869202 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 74.2315845489502 loss tensor(0.4884, grad_fn=<NegBackward0>)\n",
            "Time 74.2630774974823 loss tensor(0.4883, grad_fn=<NegBackward0>)\n",
            "Time 74.29507064819336 loss tensor(0.4882, grad_fn=<NegBackward0>)\n",
            "Time 74.32367897033691 loss tensor(0.4882, grad_fn=<NegBackward0>)\n",
            "Time 74.36061906814575 loss tensor(0.4881, grad_fn=<NegBackward0>)\n",
            "Time 74.38962507247925 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 74.42246580123901 loss tensor(0.4880, grad_fn=<NegBackward0>)\n",
            "Time 74.45027494430542 loss tensor(0.4879, grad_fn=<NegBackward0>)\n",
            "Time 74.48032069206238 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 74.5093343257904 loss tensor(0.4878, grad_fn=<NegBackward0>)\n",
            "Time 74.5471043586731 loss tensor(0.4877, grad_fn=<NegBackward0>)\n",
            "Time 74.58032441139221 loss tensor(0.4876, grad_fn=<NegBackward0>)\n",
            "Time 74.61233139038086 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 74.64143228530884 loss tensor(0.4875, grad_fn=<NegBackward0>)\n",
            "Time 74.6728515625 loss tensor(0.4874, grad_fn=<NegBackward0>)\n",
            "Time 74.7016167640686 loss tensor(0.4873, grad_fn=<NegBackward0>)\n",
            "Time 74.73148727416992 loss tensor(0.4873, grad_fn=<NegBackward0>)\n",
            "Time 74.76211452484131 loss tensor(0.4872, grad_fn=<NegBackward0>)\n",
            "Time 74.80186533927917 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 74.83025002479553 loss tensor(0.4871, grad_fn=<NegBackward0>)\n",
            "Time 74.8577253818512 loss tensor(0.4870, grad_fn=<NegBackward0>)\n",
            "Time 74.88645815849304 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 74.9158456325531 loss tensor(0.4869, grad_fn=<NegBackward0>)\n",
            "Time 74.94357562065125 loss tensor(0.4868, grad_fn=<NegBackward0>)\n",
            "Time 74.97031235694885 loss tensor(0.4867, grad_fn=<NegBackward0>)\n",
            "Time 74.99753475189209 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 75.03356575965881 loss tensor(0.4866, grad_fn=<NegBackward0>)\n",
            "Time 75.06254887580872 loss tensor(0.4865, grad_fn=<NegBackward0>)\n",
            "Time 75.08986639976501 loss tensor(0.4864, grad_fn=<NegBackward0>)\n",
            "Time 75.11760020256042 loss tensor(0.4864, grad_fn=<NegBackward0>)\n",
            "Time 75.14531779289246 loss tensor(0.4863, grad_fn=<NegBackward0>)\n",
            "Time 75.17737579345703 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 75.20624423027039 loss tensor(0.4862, grad_fn=<NegBackward0>)\n",
            "Time 75.23313093185425 loss tensor(0.4861, grad_fn=<NegBackward0>)\n",
            "Time 75.26603269577026 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 75.29302668571472 loss tensor(0.4860, grad_fn=<NegBackward0>)\n",
            "Time 75.32229566574097 loss tensor(0.4859, grad_fn=<NegBackward0>)\n",
            "Time 75.35260605812073 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 75.38428115844727 loss tensor(0.4858, grad_fn=<NegBackward0>)\n",
            "Time 75.4146203994751 loss tensor(0.4857, grad_fn=<NegBackward0>)\n",
            "Time 75.4477105140686 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 75.47643494606018 loss tensor(0.4856, grad_fn=<NegBackward0>)\n",
            "Time 75.50502705574036 loss tensor(0.4855, grad_fn=<NegBackward0>)\n",
            "Time 75.53300046920776 loss tensor(0.4854, grad_fn=<NegBackward0>)\n",
            "Time 75.56942367553711 loss tensor(0.4853, grad_fn=<NegBackward0>)\n",
            "Time 75.59774589538574 loss tensor(0.4853, grad_fn=<NegBackward0>)\n",
            "Time 75.62477469444275 loss tensor(0.4852, grad_fn=<NegBackward0>)\n",
            "Time 75.6567006111145 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 75.68794226646423 loss tensor(0.4851, grad_fn=<NegBackward0>)\n",
            "Time 75.71737837791443 loss tensor(0.4850, grad_fn=<NegBackward0>)\n",
            "Time 75.74673795700073 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 75.7755343914032 loss tensor(0.4849, grad_fn=<NegBackward0>)\n",
            "Time 75.80800986289978 loss tensor(0.4848, grad_fn=<NegBackward0>)\n",
            "Time 75.83625555038452 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 75.87209415435791 loss tensor(0.4847, grad_fn=<NegBackward0>)\n",
            "Time 75.90102910995483 loss tensor(0.4846, grad_fn=<NegBackward0>)\n",
            "Time 75.9297194480896 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 75.95876622200012 loss tensor(0.4845, grad_fn=<NegBackward0>)\n",
            "Time 75.98752403259277 loss tensor(0.4844, grad_fn=<NegBackward0>)\n",
            "Time 76.01798248291016 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 76.04599618911743 loss tensor(0.4843, grad_fn=<NegBackward0>)\n",
            "Time 76.07439756393433 loss tensor(0.4842, grad_fn=<NegBackward0>)\n",
            "Time 76.10687375068665 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 76.13873744010925 loss tensor(0.4841, grad_fn=<NegBackward0>)\n",
            "Time 76.16776371002197 loss tensor(0.4840, grad_fn=<NegBackward0>)\n",
            "Time 76.20059370994568 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 76.23215389251709 loss tensor(0.4839, grad_fn=<NegBackward0>)\n",
            "Time 76.26111364364624 loss tensor(0.4838, grad_fn=<NegBackward0>)\n",
            "Time 76.29574513435364 loss tensor(0.4837, grad_fn=<NegBackward0>)\n",
            "Time 76.32574486732483 loss tensor(0.4837, grad_fn=<NegBackward0>)\n",
            "Time 76.3562867641449 loss tensor(0.4836, grad_fn=<NegBackward0>)\n",
            "Time 76.38436913490295 loss tensor(0.4835, grad_fn=<NegBackward0>)\n",
            "Time 76.41449213027954 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 76.44901084899902 loss tensor(0.4834, grad_fn=<NegBackward0>)\n",
            "Time 76.47664952278137 loss tensor(0.4833, grad_fn=<NegBackward0>)\n",
            "Time 76.51396107673645 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 76.54138779640198 loss tensor(0.4832, grad_fn=<NegBackward0>)\n",
            "Time 76.57990598678589 loss tensor(0.4831, grad_fn=<NegBackward0>)\n",
            "Time 76.61023879051208 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 76.6377203464508 loss tensor(0.4830, grad_fn=<NegBackward0>)\n",
            "Time 76.66465830802917 loss tensor(0.4829, grad_fn=<NegBackward0>)\n",
            "Time 76.69237637519836 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 76.73337268829346 loss tensor(0.4828, grad_fn=<NegBackward0>)\n",
            "Time 76.76874589920044 loss tensor(0.4827, grad_fn=<NegBackward0>)\n",
            "Time 76.79906845092773 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 76.82903599739075 loss tensor(0.4826, grad_fn=<NegBackward0>)\n",
            "Time 76.85819721221924 loss tensor(0.4825, grad_fn=<NegBackward0>)\n",
            "Time 76.8895149230957 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 76.91842126846313 loss tensor(0.4824, grad_fn=<NegBackward0>)\n",
            "Time 76.95271325111389 loss tensor(0.4823, grad_fn=<NegBackward0>)\n",
            "Time 76.98197221755981 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 77.01343965530396 loss tensor(0.4822, grad_fn=<NegBackward0>)\n",
            "Time 77.04614543914795 loss tensor(0.4821, grad_fn=<NegBackward0>)\n",
            "Time 77.07407665252686 loss tensor(0.4820, grad_fn=<NegBackward0>)\n",
            "Time 77.10215616226196 loss tensor(0.4820, grad_fn=<NegBackward0>)\n",
            "Time 77.13000893592834 loss tensor(0.4819, grad_fn=<NegBackward0>)\n",
            "Time 77.16464376449585 loss tensor(0.4818, grad_fn=<NegBackward0>)\n",
            "Time 77.19618558883667 loss tensor(0.4818, grad_fn=<NegBackward0>)\n",
            "Time 77.22404456138611 loss tensor(0.4817, grad_fn=<NegBackward0>)\n",
            "Time 77.25269770622253 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 77.28103590011597 loss tensor(0.4816, grad_fn=<NegBackward0>)\n",
            "Time 77.30922627449036 loss tensor(0.4815, grad_fn=<NegBackward0>)\n",
            "Time 77.3365581035614 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 77.3644757270813 loss tensor(0.4814, grad_fn=<NegBackward0>)\n",
            "Time 77.39882636070251 loss tensor(0.4813, grad_fn=<NegBackward0>)\n",
            "Time 77.4287211894989 loss tensor(0.4812, grad_fn=<NegBackward0>)\n",
            "Time 77.45635294914246 loss tensor(0.4812, grad_fn=<NegBackward0>)\n",
            "Time 77.48430824279785 loss tensor(0.4811, grad_fn=<NegBackward0>)\n",
            "Time 77.5131766796112 loss tensor(0.4810, grad_fn=<NegBackward0>)\n",
            "Time 77.54068779945374 loss tensor(0.4810, grad_fn=<NegBackward0>)\n",
            "Time 77.56803774833679 loss tensor(0.4809, grad_fn=<NegBackward0>)\n",
            "Time 77.60733127593994 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 77.63577938079834 loss tensor(0.4808, grad_fn=<NegBackward0>)\n",
            "Time 77.66622400283813 loss tensor(0.4807, grad_fn=<NegBackward0>)\n",
            "Time 77.69855237007141 loss tensor(0.4806, grad_fn=<NegBackward0>)\n",
            "Time 77.73302292823792 loss tensor(0.4806, grad_fn=<NegBackward0>)\n",
            "Time 77.76161527633667 loss tensor(0.4805, grad_fn=<NegBackward0>)\n",
            "Time 77.79357933998108 loss tensor(0.4804, grad_fn=<NegBackward0>)\n",
            "Time 77.83042430877686 loss tensor(0.4804, grad_fn=<NegBackward0>)\n",
            "Time 77.86503624916077 loss tensor(0.4803, grad_fn=<NegBackward0>)\n",
            "Time 77.89382004737854 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 77.92203664779663 loss tensor(0.4802, grad_fn=<NegBackward0>)\n",
            "Time 77.95039486885071 loss tensor(0.4801, grad_fn=<NegBackward0>)\n",
            "Time 77.97816276550293 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 78.00592613220215 loss tensor(0.4800, grad_fn=<NegBackward0>)\n",
            "Time 78.04214882850647 loss tensor(0.4799, grad_fn=<NegBackward0>)\n",
            "Time 78.07151126861572 loss tensor(0.4798, grad_fn=<NegBackward0>)\n",
            "Time 78.09975862503052 loss tensor(0.4798, grad_fn=<NegBackward0>)\n",
            "Time 78.12785983085632 loss tensor(0.4797, grad_fn=<NegBackward0>)\n",
            "Time 78.15562129020691 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 78.18936491012573 loss tensor(0.4796, grad_fn=<NegBackward0>)\n",
            "Time 78.21759963035583 loss tensor(0.4795, grad_fn=<NegBackward0>)\n",
            "Time 78.2510290145874 loss tensor(0.4794, grad_fn=<NegBackward0>)\n",
            "Time 78.28035116195679 loss tensor(0.4794, grad_fn=<NegBackward0>)\n",
            "Time 78.30862545967102 loss tensor(0.4793, grad_fn=<NegBackward0>)\n",
            "Time 78.33695888519287 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 78.36495876312256 loss tensor(0.4792, grad_fn=<NegBackward0>)\n",
            "Time 78.39513111114502 loss tensor(0.4791, grad_fn=<NegBackward0>)\n",
            "Time 78.42430138587952 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 78.45777201652527 loss tensor(0.4790, grad_fn=<NegBackward0>)\n",
            "Time 78.48849987983704 loss tensor(0.4789, grad_fn=<NegBackward0>)\n",
            "Time 78.51746869087219 loss tensor(0.4788, grad_fn=<NegBackward0>)\n",
            "Time 78.5598726272583 loss tensor(0.4788, grad_fn=<NegBackward0>)\n",
            "Time 78.59608674049377 loss tensor(0.4787, grad_fn=<NegBackward0>)\n",
            "Time 78.62556290626526 loss tensor(0.4786, grad_fn=<NegBackward0>)\n",
            "Time 78.65895080566406 loss tensor(0.4786, grad_fn=<NegBackward0>)\n",
            "Time 78.69444632530212 loss tensor(0.4785, grad_fn=<NegBackward0>)\n",
            "Time 78.72436594963074 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 78.75308418273926 loss tensor(0.4784, grad_fn=<NegBackward0>)\n",
            "Time 78.78168439865112 loss tensor(0.4783, grad_fn=<NegBackward0>)\n",
            "Time 78.80984139442444 loss tensor(0.4782, grad_fn=<NegBackward0>)\n",
            "Time 78.83778309822083 loss tensor(0.4782, grad_fn=<NegBackward0>)\n",
            "Time 78.87296032905579 loss tensor(0.4781, grad_fn=<NegBackward0>)\n",
            "Time 78.90138268470764 loss tensor(0.4780, grad_fn=<NegBackward0>)\n",
            "Time 78.92860531806946 loss tensor(0.4780, grad_fn=<NegBackward0>)\n",
            "Time 78.95584487915039 loss tensor(0.4779, grad_fn=<NegBackward0>)\n",
            "Time 78.98375153541565 loss tensor(0.4778, grad_fn=<NegBackward0>)\n",
            "Time 79.01883459091187 loss tensor(0.4778, grad_fn=<NegBackward0>)\n",
            "Time 79.04622435569763 loss tensor(0.4777, grad_fn=<NegBackward0>)\n",
            "Time 79.07763314247131 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 79.10812282562256 loss tensor(0.4776, grad_fn=<NegBackward0>)\n",
            "Time 79.13659739494324 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 79.16398286819458 loss tensor(0.4775, grad_fn=<NegBackward0>)\n",
            "Time 79.19326782226562 loss tensor(0.4774, grad_fn=<NegBackward0>)\n",
            "Time 79.2214343547821 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 79.24972462654114 loss tensor(0.4773, grad_fn=<NegBackward0>)\n",
            "Time 79.27982783317566 loss tensor(0.4772, grad_fn=<NegBackward0>)\n",
            "Time 79.31408095359802 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 79.34865665435791 loss tensor(0.4771, grad_fn=<NegBackward0>)\n",
            "Time 79.3767523765564 loss tensor(0.4770, grad_fn=<NegBackward0>)\n",
            "Time 79.40463972091675 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 79.43450713157654 loss tensor(0.4769, grad_fn=<NegBackward0>)\n",
            "Time 79.4637999534607 loss tensor(0.4768, grad_fn=<NegBackward0>)\n",
            "Time 79.49190330505371 loss tensor(0.4767, grad_fn=<NegBackward0>)\n",
            "Time 79.52597618103027 loss tensor(0.4767, grad_fn=<NegBackward0>)\n",
            "Time 79.55376505851746 loss tensor(0.4766, grad_fn=<NegBackward0>)\n",
            "Time 79.58400654792786 loss tensor(0.4765, grad_fn=<NegBackward0>)\n",
            "Time 79.6221354007721 loss tensor(0.4765, grad_fn=<NegBackward0>)\n",
            "Time 79.64922165870667 loss tensor(0.4764, grad_fn=<NegBackward0>)\n",
            "Time 79.67711901664734 loss tensor(0.4763, grad_fn=<NegBackward0>)\n",
            "Time 79.70440578460693 loss tensor(0.4763, grad_fn=<NegBackward0>)\n",
            "Time 79.73954248428345 loss tensor(0.4762, grad_fn=<NegBackward0>)\n",
            "Time 79.77137207984924 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 79.79954838752747 loss tensor(0.4761, grad_fn=<NegBackward0>)\n",
            "Time 79.82645916938782 loss tensor(0.4760, grad_fn=<NegBackward0>)\n",
            "Time 79.85314869880676 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 79.8817412853241 loss tensor(0.4759, grad_fn=<NegBackward0>)\n",
            "Time 79.90800404548645 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 79.93441796302795 loss tensor(0.4758, grad_fn=<NegBackward0>)\n",
            "Time 79.96712565422058 loss tensor(0.4757, grad_fn=<NegBackward0>)\n",
            "Time 79.99739146232605 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 80.0359480381012 loss tensor(0.4756, grad_fn=<NegBackward0>)\n",
            "Time 80.06561064720154 loss tensor(0.4755, grad_fn=<NegBackward0>)\n",
            "Time 80.09673047065735 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 80.12495589256287 loss tensor(0.4754, grad_fn=<NegBackward0>)\n",
            "Time 80.1526665687561 loss tensor(0.4753, grad_fn=<NegBackward0>)\n",
            "Time 80.18713903427124 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 80.2154974937439 loss tensor(0.4752, grad_fn=<NegBackward0>)\n",
            "Time 80.24357485771179 loss tensor(0.4751, grad_fn=<NegBackward0>)\n",
            "Time 80.27368927001953 loss tensor(0.4750, grad_fn=<NegBackward0>)\n",
            "Time 80.30263710021973 loss tensor(0.4750, grad_fn=<NegBackward0>)\n",
            "Time 80.33703088760376 loss tensor(0.4749, grad_fn=<NegBackward0>)\n",
            "Time 80.36590886116028 loss tensor(0.4748, grad_fn=<NegBackward0>)\n",
            "Time 80.39942002296448 loss tensor(0.4748, grad_fn=<NegBackward0>)\n",
            "Time 80.43251180648804 loss tensor(0.4747, grad_fn=<NegBackward0>)\n",
            "Time 80.46148896217346 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 80.49057960510254 loss tensor(0.4746, grad_fn=<NegBackward0>)\n",
            "Time 80.51957368850708 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 80.54681944847107 loss tensor(0.4745, grad_fn=<NegBackward0>)\n",
            "Time 80.57486987113953 loss tensor(0.4744, grad_fn=<NegBackward0>)\n",
            "Time 80.60726189613342 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 80.64942598342896 loss tensor(0.4743, grad_fn=<NegBackward0>)\n",
            "Time 80.67962741851807 loss tensor(0.4742, grad_fn=<NegBackward0>)\n",
            "Time 80.71042394638062 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 80.7407615184784 loss tensor(0.4741, grad_fn=<NegBackward0>)\n",
            "Time 80.77778315544128 loss tensor(0.4740, grad_fn=<NegBackward0>)\n",
            "Time 80.80862164497375 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 80.84585905075073 loss tensor(0.4739, grad_fn=<NegBackward0>)\n",
            "Time 80.877188205719 loss tensor(0.4738, grad_fn=<NegBackward0>)\n",
            "Time 80.90603232383728 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 80.94061160087585 loss tensor(0.4737, grad_fn=<NegBackward0>)\n",
            "Time 80.96907043457031 loss tensor(0.4736, grad_fn=<NegBackward0>)\n",
            "Time 80.99671268463135 loss tensor(0.4735, grad_fn=<NegBackward0>)\n",
            "Time 81.03426575660706 loss tensor(0.4735, grad_fn=<NegBackward0>)\n",
            "Time 81.06104159355164 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 81.0879225730896 loss tensor(0.4734, grad_fn=<NegBackward0>)\n",
            "Time 81.11474418640137 loss tensor(0.4733, grad_fn=<NegBackward0>)\n",
            "Time 81.14142060279846 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 81.1676709651947 loss tensor(0.4732, grad_fn=<NegBackward0>)\n",
            "Time 81.19617867469788 loss tensor(0.4731, grad_fn=<NegBackward0>)\n",
            "Time 81.22348380088806 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 81.26528811454773 loss tensor(0.4730, grad_fn=<NegBackward0>)\n",
            "Time 81.29255795478821 loss tensor(0.4729, grad_fn=<NegBackward0>)\n",
            "Time 81.32022500038147 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 81.34697842597961 loss tensor(0.4728, grad_fn=<NegBackward0>)\n",
            "Time 81.3735978603363 loss tensor(0.4727, grad_fn=<NegBackward0>)\n",
            "Time 81.4002628326416 loss tensor(0.4726, grad_fn=<NegBackward0>)\n",
            "Time 81.42995190620422 loss tensor(0.4726, grad_fn=<NegBackward0>)\n",
            "Time 81.45573830604553 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 81.48885130882263 loss tensor(0.4725, grad_fn=<NegBackward0>)\n",
            "Time 81.5165023803711 loss tensor(0.4724, grad_fn=<NegBackward0>)\n",
            "Time 81.54342031478882 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 81.56974339485168 loss tensor(0.4723, grad_fn=<NegBackward0>)\n",
            "Time 81.6032931804657 loss tensor(0.4722, grad_fn=<NegBackward0>)\n",
            "Time 81.63257932662964 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 81.67153429985046 loss tensor(0.4721, grad_fn=<NegBackward0>)\n",
            "Time 81.71053004264832 loss tensor(0.4720, grad_fn=<NegBackward0>)\n",
            "Time 81.74131345748901 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 81.77252888679504 loss tensor(0.4719, grad_fn=<NegBackward0>)\n",
            "Time 81.8031415939331 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 81.83165502548218 loss tensor(0.4718, grad_fn=<NegBackward0>)\n",
            "Time 81.86244535446167 loss tensor(0.4717, grad_fn=<NegBackward0>)\n",
            "Time 81.89428377151489 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 81.92989993095398 loss tensor(0.4716, grad_fn=<NegBackward0>)\n",
            "Time 81.95810770988464 loss tensor(0.4715, grad_fn=<NegBackward0>)\n",
            "Time 81.98562741279602 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 82.01602101325989 loss tensor(0.4714, grad_fn=<NegBackward0>)\n",
            "Time 82.04224896430969 loss tensor(0.4713, grad_fn=<NegBackward0>)\n",
            "Time 82.06923532485962 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 82.10218477249146 loss tensor(0.4712, grad_fn=<NegBackward0>)\n",
            "Time 82.12890195846558 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 82.16350173950195 loss tensor(0.4711, grad_fn=<NegBackward0>)\n",
            "Time 82.1933958530426 loss tensor(0.4710, grad_fn=<NegBackward0>)\n",
            "Time 82.22127532958984 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 82.24857211112976 loss tensor(0.4709, grad_fn=<NegBackward0>)\n",
            "Time 82.27673387527466 loss tensor(0.4708, grad_fn=<NegBackward0>)\n",
            "Time 82.30499649047852 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 82.33380699157715 loss tensor(0.4707, grad_fn=<NegBackward0>)\n",
            "Time 82.363272190094 loss tensor(0.4706, grad_fn=<NegBackward0>)\n",
            "Time 82.39604139328003 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 82.4261121749878 loss tensor(0.4705, grad_fn=<NegBackward0>)\n",
            "Time 82.4539098739624 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 82.48846650123596 loss tensor(0.4704, grad_fn=<NegBackward0>)\n",
            "Time 82.51755547523499 loss tensor(0.4703, grad_fn=<NegBackward0>)\n",
            "Time 82.54560804367065 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 82.57474207878113 loss tensor(0.4702, grad_fn=<NegBackward0>)\n",
            "Time 82.61067700386047 loss tensor(0.4701, grad_fn=<NegBackward0>)\n",
            "Time 82.63971590995789 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 82.6763243675232 loss tensor(0.4700, grad_fn=<NegBackward0>)\n",
            "Time 82.70524954795837 loss tensor(0.4699, grad_fn=<NegBackward0>)\n",
            "Time 82.73708462715149 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 82.77558159828186 loss tensor(0.4698, grad_fn=<NegBackward0>)\n",
            "Time 82.81143593788147 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 82.8422589302063 loss tensor(0.4697, grad_fn=<NegBackward0>)\n",
            "Time 82.87161350250244 loss tensor(0.4696, grad_fn=<NegBackward0>)\n",
            "Time 82.90055847167969 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 82.9343752861023 loss tensor(0.4695, grad_fn=<NegBackward0>)\n",
            "Time 82.9716386795044 loss tensor(0.4694, grad_fn=<NegBackward0>)\n",
            "Time 83.00316214561462 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 83.04499959945679 loss tensor(0.4693, grad_fn=<NegBackward0>)\n",
            "Time 83.07270574569702 loss tensor(0.4692, grad_fn=<NegBackward0>)\n",
            "Time 83.10093760490417 loss tensor(0.4692, grad_fn=<NegBackward0>)\n",
            "Time 83.13027882575989 loss tensor(0.4691, grad_fn=<NegBackward0>)\n",
            "Time 83.16765999794006 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 83.19723105430603 loss tensor(0.4690, grad_fn=<NegBackward0>)\n",
            "Time 83.22607707977295 loss tensor(0.4689, grad_fn=<NegBackward0>)\n",
            "Time 83.26126217842102 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 83.28964853286743 loss tensor(0.4688, grad_fn=<NegBackward0>)\n",
            "Time 83.32063937187195 loss tensor(0.4687, grad_fn=<NegBackward0>)\n",
            "Time 83.35062909126282 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 83.37983417510986 loss tensor(0.4686, grad_fn=<NegBackward0>)\n",
            "Time 83.41526103019714 loss tensor(0.4685, grad_fn=<NegBackward0>)\n",
            "Time 83.44950580596924 loss tensor(0.4685, grad_fn=<NegBackward0>)\n",
            "Time 83.48336935043335 loss tensor(0.4684, grad_fn=<NegBackward0>)\n",
            "Time 83.51224374771118 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 83.5397253036499 loss tensor(0.4683, grad_fn=<NegBackward0>)\n",
            "Time 83.56685400009155 loss tensor(0.4682, grad_fn=<NegBackward0>)\n",
            "Time 83.59432911872864 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 83.62202286720276 loss tensor(0.4681, grad_fn=<NegBackward0>)\n",
            "Time 83.64893174171448 loss tensor(0.4680, grad_fn=<NegBackward0>)\n",
            "Time 83.68226408958435 loss tensor(0.4680, grad_fn=<NegBackward0>)\n",
            "Time 83.72063684463501 loss tensor(0.4679, grad_fn=<NegBackward0>)\n",
            "Time 83.75277829170227 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 83.78328657150269 loss tensor(0.4678, grad_fn=<NegBackward0>)\n",
            "Time 83.8126175403595 loss tensor(0.4677, grad_fn=<NegBackward0>)\n",
            "Time 83.84343385696411 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 83.87692403793335 loss tensor(0.4676, grad_fn=<NegBackward0>)\n",
            "Time 83.9235725402832 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 83.95682787895203 loss tensor(0.4675, grad_fn=<NegBackward0>)\n",
            "Time 83.98358392715454 loss tensor(0.4674, grad_fn=<NegBackward0>)\n",
            "Time 84.01364588737488 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 84.04381132125854 loss tensor(0.4673, grad_fn=<NegBackward0>)\n",
            "Time 84.07196855545044 loss tensor(0.4672, grad_fn=<NegBackward0>)\n",
            "Time 84.1003303527832 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 84.14737510681152 loss tensor(0.4671, grad_fn=<NegBackward0>)\n",
            "Time 84.19855427742004 loss tensor(0.4670, grad_fn=<NegBackward0>)\n",
            "Time 84.25057315826416 loss tensor(0.4670, grad_fn=<NegBackward0>)\n",
            "Time 84.2962019443512 loss tensor(0.4669, grad_fn=<NegBackward0>)\n",
            "Time 84.33962750434875 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 84.3988664150238 loss tensor(0.4668, grad_fn=<NegBackward0>)\n",
            "Time 84.43933606147766 loss tensor(0.4667, grad_fn=<NegBackward0>)\n",
            "Time 84.47826194763184 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 84.51696157455444 loss tensor(0.4666, grad_fn=<NegBackward0>)\n",
            "Time 84.55492210388184 loss tensor(0.4665, grad_fn=<NegBackward0>)\n",
            "Time 84.5940945148468 loss tensor(0.4665, grad_fn=<NegBackward0>)\n",
            "Time 84.64357781410217 loss tensor(0.4664, grad_fn=<NegBackward0>)\n",
            "Time 84.6832959651947 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 84.73528480529785 loss tensor(0.4663, grad_fn=<NegBackward0>)\n",
            "Time 84.7774772644043 loss tensor(0.4662, grad_fn=<NegBackward0>)\n",
            "Time 84.81776857376099 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 84.86020517349243 loss tensor(0.4661, grad_fn=<NegBackward0>)\n",
            "Time 84.9067964553833 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 84.94700860977173 loss tensor(0.4660, grad_fn=<NegBackward0>)\n",
            "Time 84.99404287338257 loss tensor(0.4659, grad_fn=<NegBackward0>)\n",
            "Time 85.03368473052979 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 85.07628989219666 loss tensor(0.4658, grad_fn=<NegBackward0>)\n",
            "Time 85.1137957572937 loss tensor(0.4657, grad_fn=<NegBackward0>)\n",
            "Time 85.15112686157227 loss tensor(0.4657, grad_fn=<NegBackward0>)\n",
            "Time 85.18826341629028 loss tensor(0.4656, grad_fn=<NegBackward0>)\n",
            "Time 85.22890329360962 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 85.26736807823181 loss tensor(0.4655, grad_fn=<NegBackward0>)\n",
            "Time 85.30822205543518 loss tensor(0.4654, grad_fn=<NegBackward0>)\n",
            "Time 85.35082387924194 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 85.38943672180176 loss tensor(0.4653, grad_fn=<NegBackward0>)\n",
            "Time 85.44073438644409 loss tensor(0.4652, grad_fn=<NegBackward0>)\n",
            "Time 85.48553252220154 loss tensor(0.4652, grad_fn=<NegBackward0>)\n",
            "Time 85.52912402153015 loss tensor(0.4651, grad_fn=<NegBackward0>)\n",
            "Time 85.57188630104065 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 85.61575388908386 loss tensor(0.4650, grad_fn=<NegBackward0>)\n",
            "Time 85.66123008728027 loss tensor(0.4649, grad_fn=<NegBackward0>)\n",
            "Time 85.70023226737976 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 85.753657579422 loss tensor(0.4648, grad_fn=<NegBackward0>)\n",
            "Time 85.78377223014832 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 85.81229019165039 loss tensor(0.4647, grad_fn=<NegBackward0>)\n",
            "Time 85.84094738960266 loss tensor(0.4646, grad_fn=<NegBackward0>)\n",
            "Time 85.87123489379883 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 85.90025424957275 loss tensor(0.4645, grad_fn=<NegBackward0>)\n",
            "Time 85.92902636528015 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 85.96270442008972 loss tensor(0.4644, grad_fn=<NegBackward0>)\n",
            "Time 85.99019265174866 loss tensor(0.4643, grad_fn=<NegBackward0>)\n",
            "Time 86.01941132545471 loss tensor(0.4642, grad_fn=<NegBackward0>)\n",
            "Time 86.04717969894409 loss tensor(0.4642, grad_fn=<NegBackward0>)\n",
            "Time 86.07523989677429 loss tensor(0.4641, grad_fn=<NegBackward0>)\n",
            "Time 86.10384202003479 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 86.13214635848999 loss tensor(0.4640, grad_fn=<NegBackward0>)\n",
            "Time 86.1599428653717 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 86.19776701927185 loss tensor(0.4639, grad_fn=<NegBackward0>)\n",
            "Time 86.226238489151 loss tensor(0.4638, grad_fn=<NegBackward0>)\n",
            "Time 86.25470542907715 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 86.28265523910522 loss tensor(0.4637, grad_fn=<NegBackward0>)\n",
            "Time 86.31048846244812 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 86.33879399299622 loss tensor(0.4636, grad_fn=<NegBackward0>)\n",
            "Time 86.36822748184204 loss tensor(0.4635, grad_fn=<NegBackward0>)\n",
            "Time 86.39792323112488 loss tensor(0.4634, grad_fn=<NegBackward0>)\n",
            "Time 86.43237376213074 loss tensor(0.4634, grad_fn=<NegBackward0>)\n",
            "Time 86.4623339176178 loss tensor(0.4633, grad_fn=<NegBackward0>)\n",
            "Time 86.493821144104 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 86.52158451080322 loss tensor(0.4632, grad_fn=<NegBackward0>)\n",
            "Time 86.5505142211914 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 86.58664679527283 loss tensor(0.4631, grad_fn=<NegBackward0>)\n",
            "Time 86.62385439872742 loss tensor(0.4630, grad_fn=<NegBackward0>)\n",
            "Time 86.65188074111938 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 86.68080139160156 loss tensor(0.4629, grad_fn=<NegBackward0>)\n",
            "Time 86.70799422264099 loss tensor(0.4628, grad_fn=<NegBackward0>)\n",
            "Time 86.73501491546631 loss tensor(0.4628, grad_fn=<NegBackward0>)\n",
            "Time 86.76892232894897 loss tensor(0.4627, grad_fn=<NegBackward0>)\n",
            "Time 86.80404043197632 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 86.83947443962097 loss tensor(0.4626, grad_fn=<NegBackward0>)\n",
            "Time 86.87042617797852 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 86.90949654579163 loss tensor(0.4625, grad_fn=<NegBackward0>)\n",
            "Time 86.93738627433777 loss tensor(0.4624, grad_fn=<NegBackward0>)\n",
            "Time 86.9668664932251 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 86.99681568145752 loss tensor(0.4623, grad_fn=<NegBackward0>)\n",
            "Time 87.02620029449463 loss tensor(0.4622, grad_fn=<NegBackward0>)\n",
            "Time 87.06035733222961 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 87.08790612220764 loss tensor(0.4621, grad_fn=<NegBackward0>)\n",
            "Time 87.11509084701538 loss tensor(0.4620, grad_fn=<NegBackward0>)\n",
            "Time 87.14187216758728 loss tensor(0.4620, grad_fn=<NegBackward0>)\n",
            "Time 87.1689715385437 loss tensor(0.4619, grad_fn=<NegBackward0>)\n",
            "Time 87.19966554641724 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 87.22876930236816 loss tensor(0.4618, grad_fn=<NegBackward0>)\n",
            "Time 87.25738739967346 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 87.29337668418884 loss tensor(0.4617, grad_fn=<NegBackward0>)\n",
            "Time 87.32697772979736 loss tensor(0.4616, grad_fn=<NegBackward0>)\n",
            "Time 87.3569061756134 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 87.38579893112183 loss tensor(0.4615, grad_fn=<NegBackward0>)\n",
            "Time 87.4173674583435 loss tensor(0.4614, grad_fn=<NegBackward0>)\n",
            "Time 87.44643807411194 loss tensor(0.4614, grad_fn=<NegBackward0>)\n",
            "Time 87.47454452514648 loss tensor(0.4613, grad_fn=<NegBackward0>)\n",
            "Time 87.50880670547485 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 87.53892302513123 loss tensor(0.4612, grad_fn=<NegBackward0>)\n",
            "Time 87.5651319026947 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 87.59386348724365 loss tensor(0.4611, grad_fn=<NegBackward0>)\n",
            "Time 87.63250684738159 loss tensor(0.4610, grad_fn=<NegBackward0>)\n",
            "Time 87.66240763664246 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 87.70018792152405 loss tensor(0.4609, grad_fn=<NegBackward0>)\n",
            "Time 87.73855400085449 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 87.76650881767273 loss tensor(0.4608, grad_fn=<NegBackward0>)\n",
            "Time 87.80375814437866 loss tensor(0.4607, grad_fn=<NegBackward0>)\n",
            "Time 87.83182954788208 loss tensor(0.4606, grad_fn=<NegBackward0>)\n",
            "Time 87.86014699935913 loss tensor(0.4606, grad_fn=<NegBackward0>)\n",
            "Time 87.89758157730103 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 87.92656445503235 loss tensor(0.4605, grad_fn=<NegBackward0>)\n",
            "Time 87.96017718315125 loss tensor(0.4604, grad_fn=<NegBackward0>)\n",
            "Time 87.98833060264587 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 88.01857995986938 loss tensor(0.4603, grad_fn=<NegBackward0>)\n",
            "Time 88.04625701904297 loss tensor(0.4602, grad_fn=<NegBackward0>)\n",
            "Time 88.07369017601013 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 88.10218238830566 loss tensor(0.4601, grad_fn=<NegBackward0>)\n",
            "Time 88.13015174865723 loss tensor(0.4600, grad_fn=<NegBackward0>)\n",
            "Time 88.15753626823425 loss tensor(0.4600, grad_fn=<NegBackward0>)\n",
            "Time 88.19779372215271 loss tensor(0.4599, grad_fn=<NegBackward0>)\n",
            "Time 88.22585248947144 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 88.25448751449585 loss tensor(0.4598, grad_fn=<NegBackward0>)\n",
            "Time 88.28309869766235 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 88.31164956092834 loss tensor(0.4597, grad_fn=<NegBackward0>)\n",
            "Time 88.34256219863892 loss tensor(0.4596, grad_fn=<NegBackward0>)\n",
            "Time 88.37044978141785 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 88.3995201587677 loss tensor(0.4595, grad_fn=<NegBackward0>)\n",
            "Time 88.43479824066162 loss tensor(0.4594, grad_fn=<NegBackward0>)\n",
            "Time 88.4645562171936 loss tensor(0.4594, grad_fn=<NegBackward0>)\n",
            "Time 88.49387550354004 loss tensor(0.4593, grad_fn=<NegBackward0>)\n",
            "Time 88.52249956130981 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 88.55033874511719 loss tensor(0.4592, grad_fn=<NegBackward0>)\n",
            "Time 88.57875752449036 loss tensor(0.4591, grad_fn=<NegBackward0>)\n",
            "Time 88.61098670959473 loss tensor(0.4591, grad_fn=<NegBackward0>)\n",
            "Time 88.64268064498901 loss tensor(0.4590, grad_fn=<NegBackward0>)\n",
            "Time 88.67211651802063 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 88.70226550102234 loss tensor(0.4589, grad_fn=<NegBackward0>)\n",
            "Time 88.729088306427 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 88.75716280937195 loss tensor(0.4588, grad_fn=<NegBackward0>)\n",
            "Time 88.7836709022522 loss tensor(0.4587, grad_fn=<NegBackward0>)\n",
            "Time 88.82137703895569 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 88.85025334358215 loss tensor(0.4586, grad_fn=<NegBackward0>)\n",
            "Time 88.8813145160675 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 88.91217994689941 loss tensor(0.4585, grad_fn=<NegBackward0>)\n",
            "Time 88.94048237800598 loss tensor(0.4584, grad_fn=<NegBackward0>)\n",
            "Time 88.97111582756042 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 89.01895928382874 loss tensor(0.4583, grad_fn=<NegBackward0>)\n",
            "Time 89.0596067905426 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 89.09219980239868 loss tensor(0.4582, grad_fn=<NegBackward0>)\n",
            "Time 89.12845516204834 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 89.15744423866272 loss tensor(0.4581, grad_fn=<NegBackward0>)\n",
            "Time 89.18662738800049 loss tensor(0.4580, grad_fn=<NegBackward0>)\n",
            "Time 89.21799397468567 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 89.24535393714905 loss tensor(0.4579, grad_fn=<NegBackward0>)\n",
            "Time 89.27826881408691 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 89.30625343322754 loss tensor(0.4578, grad_fn=<NegBackward0>)\n",
            "Time 89.3377320766449 loss tensor(0.4577, grad_fn=<NegBackward0>)\n",
            "Time 89.36560416221619 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 89.39273405075073 loss tensor(0.4576, grad_fn=<NegBackward0>)\n",
            "Time 89.41987872123718 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 89.45462107658386 loss tensor(0.4575, grad_fn=<NegBackward0>)\n",
            "Time 89.48865675926208 loss tensor(0.4574, grad_fn=<NegBackward0>)\n",
            "Time 89.51869821548462 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 89.54552125930786 loss tensor(0.4573, grad_fn=<NegBackward0>)\n",
            "Time 89.57275915145874 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 89.60003018379211 loss tensor(0.4572, grad_fn=<NegBackward0>)\n",
            "Time 89.6298475265503 loss tensor(0.4571, grad_fn=<NegBackward0>)\n",
            "Time 89.65826988220215 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 89.68840956687927 loss tensor(0.4570, grad_fn=<NegBackward0>)\n",
            "Time 89.72449088096619 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 89.75971817970276 loss tensor(0.4569, grad_fn=<NegBackward0>)\n",
            "Time 89.78832983970642 loss tensor(0.4568, grad_fn=<NegBackward0>)\n",
            "Time 89.82745504379272 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 89.85623812675476 loss tensor(0.4567, grad_fn=<NegBackward0>)\n",
            "Time 89.88697814941406 loss tensor(0.4566, grad_fn=<NegBackward0>)\n",
            "Time 89.92172718048096 loss tensor(0.4566, grad_fn=<NegBackward0>)\n",
            "Time 89.95008325576782 loss tensor(0.4565, grad_fn=<NegBackward0>)\n",
            "Time 89.97823309898376 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 90.00648045539856 loss tensor(0.4564, grad_fn=<NegBackward0>)\n",
            "Time 90.03726291656494 loss tensor(0.4563, grad_fn=<NegBackward0>)\n",
            "Time 90.06548595428467 loss tensor(0.4563, grad_fn=<NegBackward0>)\n",
            "Time 90.09332871437073 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 90.12071657180786 loss tensor(0.4562, grad_fn=<NegBackward0>)\n",
            "Time 90.15879392623901 loss tensor(0.4561, grad_fn=<NegBackward0>)\n",
            "Time 90.18571448326111 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 90.21250295639038 loss tensor(0.4560, grad_fn=<NegBackward0>)\n",
            "Time 90.2400815486908 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 90.26660108566284 loss tensor(0.4559, grad_fn=<NegBackward0>)\n",
            "Time 90.29559350013733 loss tensor(0.4558, grad_fn=<NegBackward0>)\n",
            "Time 90.32375431060791 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 90.35171890258789 loss tensor(0.4557, grad_fn=<NegBackward0>)\n",
            "Time 90.38851475715637 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 90.41731142997742 loss tensor(0.4556, grad_fn=<NegBackward0>)\n",
            "Time 90.44580221176147 loss tensor(0.4555, grad_fn=<NegBackward0>)\n",
            "Time 90.4757661819458 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 90.50453639030457 loss tensor(0.4554, grad_fn=<NegBackward0>)\n",
            "Time 90.53292536735535 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 90.56117725372314 loss tensor(0.4553, grad_fn=<NegBackward0>)\n",
            "Time 90.5926582813263 loss tensor(0.4552, grad_fn=<NegBackward0>)\n",
            "Time 90.62447571754456 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 90.65265202522278 loss tensor(0.4551, grad_fn=<NegBackward0>)\n",
            "Time 90.68087863922119 loss tensor(0.4550, grad_fn=<NegBackward0>)\n",
            "Time 90.71145939826965 loss tensor(0.4550, grad_fn=<NegBackward0>)\n",
            "Time 90.74108409881592 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 90.77015352249146 loss tensor(0.4549, grad_fn=<NegBackward0>)\n",
            "Time 90.79792356491089 loss tensor(0.4548, grad_fn=<NegBackward0>)\n",
            "Time 90.84459972381592 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 90.87336754798889 loss tensor(0.4547, grad_fn=<NegBackward0>)\n",
            "Time 90.90036988258362 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 90.9284930229187 loss tensor(0.4546, grad_fn=<NegBackward0>)\n",
            "Time 90.95538830757141 loss tensor(0.4545, grad_fn=<NegBackward0>)\n",
            "Time 90.98337745666504 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 91.0184485912323 loss tensor(0.4544, grad_fn=<NegBackward0>)\n",
            "Time 91.04653763771057 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 91.07379865646362 loss tensor(0.4543, grad_fn=<NegBackward0>)\n",
            "Time 91.10108423233032 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 91.12853455543518 loss tensor(0.4542, grad_fn=<NegBackward0>)\n",
            "Time 91.1557366847992 loss tensor(0.4541, grad_fn=<NegBackward0>)\n",
            "Time 91.18802738189697 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 91.21713542938232 loss tensor(0.4540, grad_fn=<NegBackward0>)\n",
            "Time 91.25081777572632 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 91.27835178375244 loss tensor(0.4539, grad_fn=<NegBackward0>)\n",
            "Time 91.30478310585022 loss tensor(0.4538, grad_fn=<NegBackward0>)\n",
            "Time 91.33202123641968 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 91.35889220237732 loss tensor(0.4537, grad_fn=<NegBackward0>)\n",
            "Time 91.38558387756348 loss tensor(0.4536, grad_fn=<NegBackward0>)\n",
            "Time 91.41300988197327 loss tensor(0.4536, grad_fn=<NegBackward0>)\n",
            "Time 91.44237279891968 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 91.4853732585907 loss tensor(0.4535, grad_fn=<NegBackward0>)\n",
            "Time 91.51339983940125 loss tensor(0.4534, grad_fn=<NegBackward0>)\n",
            "Time 91.54114151000977 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 91.56978750228882 loss tensor(0.4533, grad_fn=<NegBackward0>)\n",
            "Time 91.59954047203064 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 91.62949728965759 loss tensor(0.4532, grad_fn=<NegBackward0>)\n",
            "Time 91.65891861915588 loss tensor(0.4531, grad_fn=<NegBackward0>)\n",
            "Time 91.69262146949768 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 91.72195291519165 loss tensor(0.4530, grad_fn=<NegBackward0>)\n",
            "Time 91.75071835517883 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 91.77924346923828 loss tensor(0.4529, grad_fn=<NegBackward0>)\n",
            "Time 91.81041145324707 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 91.8406093120575 loss tensor(0.4528, grad_fn=<NegBackward0>)\n",
            "Time 91.87785792350769 loss tensor(0.4527, grad_fn=<NegBackward0>)\n",
            "Time 91.91347861289978 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 91.9414291381836 loss tensor(0.4526, grad_fn=<NegBackward0>)\n",
            "Time 91.97042489051819 loss tensor(0.4525, grad_fn=<NegBackward0>)\n",
            "Time 91.99741005897522 loss tensor(0.4525, grad_fn=<NegBackward0>)\n",
            "Time 92.02816581726074 loss tensor(0.4524, grad_fn=<NegBackward0>)\n",
            "Time 92.057368516922 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 92.08917427062988 loss tensor(0.4523, grad_fn=<NegBackward0>)\n",
            "Time 92.13002252578735 loss tensor(0.4522, grad_fn=<NegBackward0>)\n",
            "Time 92.1592218875885 loss tensor(0.4522, grad_fn=<NegBackward0>)\n",
            "Time 92.18711519241333 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 92.2164535522461 loss tensor(0.4521, grad_fn=<NegBackward0>)\n",
            "Time 92.24332451820374 loss tensor(0.4520, grad_fn=<NegBackward0>)\n",
            "Time 92.27059626579285 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 92.29739046096802 loss tensor(0.4519, grad_fn=<NegBackward0>)\n",
            "Time 92.32648015022278 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 92.36365962028503 loss tensor(0.4518, grad_fn=<NegBackward0>)\n",
            "Time 92.3938410282135 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 92.4290840625763 loss tensor(0.4517, grad_fn=<NegBackward0>)\n",
            "Time 92.45613074302673 loss tensor(0.4516, grad_fn=<NegBackward0>)\n",
            "Time 92.48675918579102 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 92.51600813865662 loss tensor(0.4515, grad_fn=<NegBackward0>)\n",
            "Time 92.54467940330505 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 92.58065366744995 loss tensor(0.4514, grad_fn=<NegBackward0>)\n",
            "Time 92.61096525192261 loss tensor(0.4513, grad_fn=<NegBackward0>)\n",
            "Time 92.6389274597168 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 92.66727185249329 loss tensor(0.4512, grad_fn=<NegBackward0>)\n",
            "Time 92.69572043418884 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 92.72785449028015 loss tensor(0.4511, grad_fn=<NegBackward0>)\n",
            "Time 92.75664281845093 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 92.79232001304626 loss tensor(0.4510, grad_fn=<NegBackward0>)\n",
            "Time 92.82385301589966 loss tensor(0.4509, grad_fn=<NegBackward0>)\n",
            "Time 92.85153985023499 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 92.88990211486816 loss tensor(0.4508, grad_fn=<NegBackward0>)\n",
            "Time 92.9179105758667 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 92.94527339935303 loss tensor(0.4507, grad_fn=<NegBackward0>)\n",
            "Time 92.97304606437683 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 93.01259684562683 loss tensor(0.4506, grad_fn=<NegBackward0>)\n",
            "Time 93.04071092605591 loss tensor(0.4505, grad_fn=<NegBackward0>)\n",
            "Time 93.0693941116333 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 93.0974292755127 loss tensor(0.4504, grad_fn=<NegBackward0>)\n",
            "Time 93.1258864402771 loss tensor(0.4503, grad_fn=<NegBackward0>)\n",
            "Time 93.15366172790527 loss tensor(0.4503, grad_fn=<NegBackward0>)\n",
            "Time 93.18157529830933 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 93.21007823944092 loss tensor(0.4502, grad_fn=<NegBackward0>)\n",
            "Time 93.24901366233826 loss tensor(0.4501, grad_fn=<NegBackward0>)\n",
            "Time 93.27752947807312 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 93.30513572692871 loss tensor(0.4500, grad_fn=<NegBackward0>)\n",
            "Time 93.33210182189941 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 93.35987496376038 loss tensor(0.4499, grad_fn=<NegBackward0>)\n",
            "Time 93.39109802246094 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 93.41992926597595 loss tensor(0.4498, grad_fn=<NegBackward0>)\n",
            "Time 93.44832134246826 loss tensor(0.4497, grad_fn=<NegBackward0>)\n",
            "Time 93.48389863967896 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 93.51661276817322 loss tensor(0.4496, grad_fn=<NegBackward0>)\n",
            "Time 93.54669690132141 loss tensor(0.4495, grad_fn=<NegBackward0>)\n",
            "Time 93.57584428787231 loss tensor(0.4495, grad_fn=<NegBackward0>)\n",
            "Time 93.6094479560852 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 93.63726019859314 loss tensor(0.4494, grad_fn=<NegBackward0>)\n",
            "Time 93.67155957221985 loss tensor(0.4493, grad_fn=<NegBackward0>)\n",
            "Time 93.70067930221558 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 93.73247194290161 loss tensor(0.4492, grad_fn=<NegBackward0>)\n",
            "Time 93.76412749290466 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 93.79204797744751 loss tensor(0.4491, grad_fn=<NegBackward0>)\n",
            "Time 93.82037329673767 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 93.84840059280396 loss tensor(0.4490, grad_fn=<NegBackward0>)\n",
            "Time 93.88478112220764 loss tensor(0.4489, grad_fn=<NegBackward0>)\n",
            "Time 93.92286777496338 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 93.955326795578 loss tensor(0.4488, grad_fn=<NegBackward0>)\n",
            "Time 93.98310041427612 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 94.01297426223755 loss tensor(0.4487, grad_fn=<NegBackward0>)\n",
            "Time 94.03984522819519 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 94.06830143928528 loss tensor(0.4486, grad_fn=<NegBackward0>)\n",
            "Time 94.10219621658325 loss tensor(0.4485, grad_fn=<NegBackward0>)\n",
            "Time 94.13042974472046 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 94.15854287147522 loss tensor(0.4484, grad_fn=<NegBackward0>)\n",
            "Time 94.18735456466675 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 94.21677470207214 loss tensor(0.4483, grad_fn=<NegBackward0>)\n",
            "Time 94.24520945549011 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 94.2814462184906 loss tensor(0.4482, grad_fn=<NegBackward0>)\n",
            "Time 94.31522989273071 loss tensor(0.4481, grad_fn=<NegBackward0>)\n",
            "Time 94.3439393043518 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 94.37283730506897 loss tensor(0.4480, grad_fn=<NegBackward0>)\n",
            "Time 94.4031012058258 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 94.43289995193481 loss tensor(0.4479, grad_fn=<NegBackward0>)\n",
            "Time 94.46042823791504 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 94.48964858055115 loss tensor(0.4478, grad_fn=<NegBackward0>)\n",
            "Time 94.5195369720459 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 94.55508780479431 loss tensor(0.4477, grad_fn=<NegBackward0>)\n",
            "Time 94.58287119865417 loss tensor(0.4476, grad_fn=<NegBackward0>)\n",
            "Time 94.60899543762207 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 94.63814163208008 loss tensor(0.4475, grad_fn=<NegBackward0>)\n",
            "Time 94.66614723205566 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 94.69360399246216 loss tensor(0.4474, grad_fn=<NegBackward0>)\n",
            "Time 94.73082208633423 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 94.76500368118286 loss tensor(0.4473, grad_fn=<NegBackward0>)\n",
            "Time 94.79209351539612 loss tensor(0.4472, grad_fn=<NegBackward0>)\n",
            "Time 94.82264637947083 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 94.85087966918945 loss tensor(0.4471, grad_fn=<NegBackward0>)\n",
            "Time 94.88247299194336 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 94.9247076511383 loss tensor(0.4470, grad_fn=<NegBackward0>)\n",
            "Time 94.96036267280579 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 94.98795628547668 loss tensor(0.4469, grad_fn=<NegBackward0>)\n",
            "Time 95.0174651145935 loss tensor(0.4468, grad_fn=<NegBackward0>)\n",
            "Time 95.04444980621338 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 95.0725450515747 loss tensor(0.4467, grad_fn=<NegBackward0>)\n",
            "Time 95.09997820854187 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 95.12762570381165 loss tensor(0.4466, grad_fn=<NegBackward0>)\n",
            "Time 95.15536189079285 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 95.19138145446777 loss tensor(0.4465, grad_fn=<NegBackward0>)\n",
            "Time 95.2207612991333 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 95.24826741218567 loss tensor(0.4464, grad_fn=<NegBackward0>)\n",
            "Time 95.27712607383728 loss tensor(0.4463, grad_fn=<NegBackward0>)\n",
            "Time 95.30483222007751 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 95.33170580863953 loss tensor(0.4462, grad_fn=<NegBackward0>)\n",
            "Time 95.35964035987854 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 95.38779783248901 loss tensor(0.4461, grad_fn=<NegBackward0>)\n",
            "Time 95.42351746559143 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 95.45097994804382 loss tensor(0.4460, grad_fn=<NegBackward0>)\n",
            "Time 95.48777604103088 loss tensor(0.4459, grad_fn=<NegBackward0>)\n",
            "Time 95.51524543762207 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 95.54412794113159 loss tensor(0.4458, grad_fn=<NegBackward0>)\n",
            "Time 95.5721001625061 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 95.60017013549805 loss tensor(0.4457, grad_fn=<NegBackward0>)\n",
            "Time 95.6313226222992 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 95.66076350212097 loss tensor(0.4456, grad_fn=<NegBackward0>)\n",
            "Time 95.68861508369446 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 95.71581077575684 loss tensor(0.4455, grad_fn=<NegBackward0>)\n",
            "Time 95.75902009010315 loss tensor(0.4454, grad_fn=<NegBackward0>)\n",
            "Time 95.81375575065613 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 95.86685419082642 loss tensor(0.4453, grad_fn=<NegBackward0>)\n",
            "Time 95.92128825187683 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 95.96285963058472 loss tensor(0.4452, grad_fn=<NegBackward0>)\n",
            "Time 96.01090741157532 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 96.05324673652649 loss tensor(0.4451, grad_fn=<NegBackward0>)\n",
            "Time 96.10388422012329 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 96.14328503608704 loss tensor(0.4450, grad_fn=<NegBackward0>)\n",
            "Time 96.18252372741699 loss tensor(0.4449, grad_fn=<NegBackward0>)\n",
            "Time 96.222731590271 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 96.261305809021 loss tensor(0.4448, grad_fn=<NegBackward0>)\n",
            "Time 96.30182933807373 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 96.35625290870667 loss tensor(0.4447, grad_fn=<NegBackward0>)\n",
            "Time 96.3978922367096 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 96.43914437294006 loss tensor(0.4446, grad_fn=<NegBackward0>)\n",
            "Time 96.47960042953491 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 96.51992416381836 loss tensor(0.4445, grad_fn=<NegBackward0>)\n",
            "Time 96.57170605659485 loss tensor(0.4444, grad_fn=<NegBackward0>)\n",
            "Time 96.61110663414001 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 96.64904356002808 loss tensor(0.4443, grad_fn=<NegBackward0>)\n",
            "Time 96.69162559509277 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 96.73245429992676 loss tensor(0.4442, grad_fn=<NegBackward0>)\n",
            "Time 96.77126121520996 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 96.81651663780212 loss tensor(0.4441, grad_fn=<NegBackward0>)\n",
            "Time 96.85603308677673 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 96.89735317230225 loss tensor(0.4440, grad_fn=<NegBackward0>)\n",
            "Time 96.94130301475525 loss tensor(0.4439, grad_fn=<NegBackward0>)\n",
            "Time 96.99346446990967 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 97.03457379341125 loss tensor(0.4438, grad_fn=<NegBackward0>)\n",
            "Time 97.08188843727112 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 97.12833404541016 loss tensor(0.4437, grad_fn=<NegBackward0>)\n",
            "Time 97.16794443130493 loss tensor(0.4436, grad_fn=<NegBackward0>)\n",
            "Time 97.21980309486389 loss tensor(0.4436, grad_fn=<NegBackward0>)\n",
            "Time 97.26758527755737 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 97.31134629249573 loss tensor(0.4435, grad_fn=<NegBackward0>)\n",
            "Time 97.35050344467163 loss tensor(0.4434, grad_fn=<NegBackward0>)\n",
            "Time 97.39693593978882 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 97.43109655380249 loss tensor(0.4433, grad_fn=<NegBackward0>)\n",
            "Time 97.45815706253052 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 97.48535180091858 loss tensor(0.4432, grad_fn=<NegBackward0>)\n",
            "Time 97.51523303985596 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 97.5414526462555 loss tensor(0.4431, grad_fn=<NegBackward0>)\n",
            "Time 97.56787967681885 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 97.59606313705444 loss tensor(0.4430, grad_fn=<NegBackward0>)\n",
            "Time 97.6232237815857 loss tensor(0.4429, grad_fn=<NegBackward0>)\n",
            "Time 97.67042684555054 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 97.69967341423035 loss tensor(0.4428, grad_fn=<NegBackward0>)\n",
            "Time 97.72861671447754 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 97.75700068473816 loss tensor(0.4427, grad_fn=<NegBackward0>)\n",
            "Time 97.78901648521423 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 97.81843185424805 loss tensor(0.4426, grad_fn=<NegBackward0>)\n",
            "Time 97.85198664665222 loss tensor(0.4425, grad_fn=<NegBackward0>)\n",
            "Time 97.88976168632507 loss tensor(0.4425, grad_fn=<NegBackward0>)\n",
            "Time 97.92025136947632 loss tensor(0.4424, grad_fn=<NegBackward0>)\n",
            "Time 97.95044112205505 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 97.98638224601746 loss tensor(0.4423, grad_fn=<NegBackward0>)\n",
            "Time 98.02695631980896 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 98.05495142936707 loss tensor(0.4422, grad_fn=<NegBackward0>)\n",
            "Time 98.08443975448608 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 98.11830234527588 loss tensor(0.4421, grad_fn=<NegBackward0>)\n",
            "Time 98.14710903167725 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 98.17453956604004 loss tensor(0.4420, grad_fn=<NegBackward0>)\n",
            "Time 98.20439267158508 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 98.2341456413269 loss tensor(0.4419, grad_fn=<NegBackward0>)\n",
            "Time 98.27162790298462 loss tensor(0.4418, grad_fn=<NegBackward0>)\n",
            "Time 98.30114817619324 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 98.33794021606445 loss tensor(0.4417, grad_fn=<NegBackward0>)\n",
            "Time 98.36762690544128 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 98.39543986320496 loss tensor(0.4416, grad_fn=<NegBackward0>)\n",
            "Time 98.42373824119568 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 98.45141386985779 loss tensor(0.4415, grad_fn=<NegBackward0>)\n",
            "Time 98.47980833053589 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 98.51064991950989 loss tensor(0.4414, grad_fn=<NegBackward0>)\n",
            "Time 98.54364275932312 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 98.582674741745 loss tensor(0.4413, grad_fn=<NegBackward0>)\n",
            "Time 98.61106324195862 loss tensor(0.4412, grad_fn=<NegBackward0>)\n",
            "Time 98.6395103931427 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 98.66830945014954 loss tensor(0.4411, grad_fn=<NegBackward0>)\n",
            "Time 98.69636511802673 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 98.724844455719 loss tensor(0.4410, grad_fn=<NegBackward0>)\n",
            "Time 98.76112127304077 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 98.79314470291138 loss tensor(0.4409, grad_fn=<NegBackward0>)\n",
            "Time 98.82285571098328 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 98.85117268562317 loss tensor(0.4408, grad_fn=<NegBackward0>)\n",
            "Time 98.88091444969177 loss tensor(0.4407, grad_fn=<NegBackward0>)\n",
            "Time 98.90918755531311 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 98.9368679523468 loss tensor(0.4406, grad_fn=<NegBackward0>)\n",
            "Time 98.973881483078 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 99.00173735618591 loss tensor(0.4405, grad_fn=<NegBackward0>)\n",
            "Time 99.04033946990967 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 99.06761574745178 loss tensor(0.4404, grad_fn=<NegBackward0>)\n",
            "Time 99.09461236000061 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 99.12214422225952 loss tensor(0.4403, grad_fn=<NegBackward0>)\n",
            "Time 99.14977478981018 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 99.18058729171753 loss tensor(0.4402, grad_fn=<NegBackward0>)\n",
            "Time 99.21291661262512 loss tensor(0.4401, grad_fn=<NegBackward0>)\n",
            "Time 99.24139356613159 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 99.26937794685364 loss tensor(0.4400, grad_fn=<NegBackward0>)\n",
            "Time 99.29735398292542 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 99.32489061355591 loss tensor(0.4399, grad_fn=<NegBackward0>)\n",
            "Time 99.35325598716736 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 99.38723993301392 loss tensor(0.4398, grad_fn=<NegBackward0>)\n",
            "Time 99.41793155670166 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 99.44639110565186 loss tensor(0.4397, grad_fn=<NegBackward0>)\n",
            "Time 99.4778847694397 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 99.50918769836426 loss tensor(0.4396, grad_fn=<NegBackward0>)\n",
            "Time 99.53768801689148 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 99.56663227081299 loss tensor(0.4395, grad_fn=<NegBackward0>)\n",
            "Time 99.59979820251465 loss tensor(0.4394, grad_fn=<NegBackward0>)\n",
            "Time 99.62927460670471 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 99.65642213821411 loss tensor(0.4393, grad_fn=<NegBackward0>)\n",
            "Time 99.68506336212158 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 99.71293258666992 loss tensor(0.4392, grad_fn=<NegBackward0>)\n",
            "Time 99.76057553291321 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 99.79827094078064 loss tensor(0.4391, grad_fn=<NegBackward0>)\n",
            "Time 99.83362245559692 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 99.86700582504272 loss tensor(0.4390, grad_fn=<NegBackward0>)\n",
            "Time 99.89440989494324 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 99.92152190208435 loss tensor(0.4389, grad_fn=<NegBackward0>)\n",
            "Time 99.95026707649231 loss tensor(0.4388, grad_fn=<NegBackward0>)\n",
            "Time 99.9791271686554 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 100.00699353218079 loss tensor(0.4387, grad_fn=<NegBackward0>)\n",
            "Time 100.05086040496826 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 100.07887268066406 loss tensor(0.4386, grad_fn=<NegBackward0>)\n",
            "Time 100.11097574234009 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 100.13781237602234 loss tensor(0.4385, grad_fn=<NegBackward0>)\n",
            "Time 100.16436100006104 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 100.19162321090698 loss tensor(0.4384, grad_fn=<NegBackward0>)\n",
            "Time 100.2195794582367 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 100.24734544754028 loss tensor(0.4383, grad_fn=<NegBackward0>)\n",
            "Time 100.28248143196106 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 100.30917310714722 loss tensor(0.4382, grad_fn=<NegBackward0>)\n",
            "Time 100.33596968650818 loss tensor(0.4381, grad_fn=<NegBackward0>)\n",
            "Time 100.3649091720581 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 100.39515256881714 loss tensor(0.4380, grad_fn=<NegBackward0>)\n",
            "Time 100.42258763313293 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 100.45014524459839 loss tensor(0.4379, grad_fn=<NegBackward0>)\n",
            "Time 100.4780752658844 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 100.51947236061096 loss tensor(0.4378, grad_fn=<NegBackward0>)\n",
            "Time 100.54688382148743 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 100.57531094551086 loss tensor(0.4377, grad_fn=<NegBackward0>)\n",
            "Time 100.6036422252655 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 100.63069581985474 loss tensor(0.4376, grad_fn=<NegBackward0>)\n",
            "Time 100.66142010688782 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 100.69070339202881 loss tensor(0.4375, grad_fn=<NegBackward0>)\n",
            "Time 100.71821761131287 loss tensor(0.4374, grad_fn=<NegBackward0>)\n",
            "Time 100.7516143321991 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 100.78356742858887 loss tensor(0.4373, grad_fn=<NegBackward0>)\n",
            "Time 100.81675696372986 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 100.84724068641663 loss tensor(0.4372, grad_fn=<NegBackward0>)\n",
            "Time 100.87889766693115 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 100.9104585647583 loss tensor(0.4371, grad_fn=<NegBackward0>)\n",
            "Time 100.940847158432 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 100.97351336479187 loss tensor(0.4370, grad_fn=<NegBackward0>)\n",
            "Time 101.00021266937256 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 101.02999591827393 loss tensor(0.4369, grad_fn=<NegBackward0>)\n",
            "Time 101.06584239006042 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 101.09410786628723 loss tensor(0.4368, grad_fn=<NegBackward0>)\n",
            "Time 101.1223738193512 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 101.15052032470703 loss tensor(0.4367, grad_fn=<NegBackward0>)\n",
            "Time 101.18256497383118 loss tensor(0.4366, grad_fn=<NegBackward0>)\n",
            "Time 101.21674132347107 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 101.24624872207642 loss tensor(0.4365, grad_fn=<NegBackward0>)\n",
            "Time 101.27693939208984 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 101.30387258529663 loss tensor(0.4364, grad_fn=<NegBackward0>)\n",
            "Time 101.33067440986633 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 101.35781073570251 loss tensor(0.4363, grad_fn=<NegBackward0>)\n",
            "Time 101.38714957237244 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 101.4219491481781 loss tensor(0.4362, grad_fn=<NegBackward0>)\n",
            "Time 101.44961261749268 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 101.4813814163208 loss tensor(0.4361, grad_fn=<NegBackward0>)\n",
            "Time 101.51328873634338 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 101.54288363456726 loss tensor(0.4360, grad_fn=<NegBackward0>)\n",
            "Time 101.57075190544128 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 101.60811114311218 loss tensor(0.4359, grad_fn=<NegBackward0>)\n",
            "Time 101.63646101951599 loss tensor(0.4358, grad_fn=<NegBackward0>)\n",
            "Time 101.6653139591217 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 101.69474625587463 loss tensor(0.4357, grad_fn=<NegBackward0>)\n",
            "Time 101.72488069534302 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 101.75477361679077 loss tensor(0.4356, grad_fn=<NegBackward0>)\n",
            "Time 101.7827365398407 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 101.8201014995575 loss tensor(0.4355, grad_fn=<NegBackward0>)\n",
            "Time 101.84927940368652 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 101.88034391403198 loss tensor(0.4354, grad_fn=<NegBackward0>)\n",
            "Time 101.90990591049194 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 101.9391119480133 loss tensor(0.4353, grad_fn=<NegBackward0>)\n",
            "Time 101.9684407711029 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 102.00133848190308 loss tensor(0.4352, grad_fn=<NegBackward0>)\n",
            "Time 102.0398416519165 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 102.07548451423645 loss tensor(0.4351, grad_fn=<NegBackward0>)\n",
            "Time 102.11893844604492 loss tensor(0.4350, grad_fn=<NegBackward0>)\n",
            "Time 102.1495246887207 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 102.18010997772217 loss tensor(0.4349, grad_fn=<NegBackward0>)\n",
            "Time 102.20969414710999 loss tensor(0.4348, grad_fn=<NegBackward0>)\n",
            "Time 102.23970866203308 loss tensor(0.4348, grad_fn=<NegBackward0>)\n",
            "Time 102.27300453186035 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 102.30043911933899 loss tensor(0.4347, grad_fn=<NegBackward0>)\n",
            "Time 102.3286497592926 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 102.3580904006958 loss tensor(0.4346, grad_fn=<NegBackward0>)\n",
            "Time 102.38483619689941 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 102.41340613365173 loss tensor(0.4345, grad_fn=<NegBackward0>)\n",
            "Time 102.44371962547302 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 102.47781133651733 loss tensor(0.4344, grad_fn=<NegBackward0>)\n",
            "Time 102.50673413276672 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 102.53568434715271 loss tensor(0.4343, grad_fn=<NegBackward0>)\n",
            "Time 102.56359553337097 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 102.59251952171326 loss tensor(0.4342, grad_fn=<NegBackward0>)\n",
            "Time 102.61999559402466 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 102.6525228023529 loss tensor(0.4341, grad_fn=<NegBackward0>)\n",
            "Time 102.68730354309082 loss tensor(0.4340, grad_fn=<NegBackward0>)\n",
            "Time 102.71881365776062 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 102.7525007724762 loss tensor(0.4339, grad_fn=<NegBackward0>)\n",
            "Time 102.7797200679779 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 102.80832815170288 loss tensor(0.4338, grad_fn=<NegBackward0>)\n",
            "Time 102.83528709411621 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 102.86237835884094 loss tensor(0.4337, grad_fn=<NegBackward0>)\n",
            "Time 102.89954781532288 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 102.93823337554932 loss tensor(0.4336, grad_fn=<NegBackward0>)\n",
            "Time 102.9676411151886 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 102.99597406387329 loss tensor(0.4335, grad_fn=<NegBackward0>)\n",
            "Time 103.02717351913452 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 103.05673313140869 loss tensor(0.4334, grad_fn=<NegBackward0>)\n",
            "Time 103.09251952171326 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 103.12865281105042 loss tensor(0.4333, grad_fn=<NegBackward0>)\n",
            "Time 103.15728640556335 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 103.19157457351685 loss tensor(0.4332, grad_fn=<NegBackward0>)\n",
            "Time 103.22014951705933 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 103.25046181678772 loss tensor(0.4331, grad_fn=<NegBackward0>)\n",
            "Time 103.28004145622253 loss tensor(0.4330, grad_fn=<NegBackward0>)\n",
            "Time 103.31319260597229 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 103.34661841392517 loss tensor(0.4329, grad_fn=<NegBackward0>)\n",
            "Time 103.37512230873108 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 103.40164637565613 loss tensor(0.4328, grad_fn=<NegBackward0>)\n",
            "Time 103.42801904678345 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 103.45443224906921 loss tensor(0.4327, grad_fn=<NegBackward0>)\n",
            "Time 103.48086094856262 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 103.50746488571167 loss tensor(0.4326, grad_fn=<NegBackward0>)\n",
            "Time 103.5363175868988 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 103.57013440132141 loss tensor(0.4325, grad_fn=<NegBackward0>)\n",
            "Time 103.59747171401978 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 103.62407875061035 loss tensor(0.4324, grad_fn=<NegBackward0>)\n",
            "Time 103.65888094902039 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 103.68752145767212 loss tensor(0.4323, grad_fn=<NegBackward0>)\n",
            "Time 103.71589517593384 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 103.74520301818848 loss tensor(0.4322, grad_fn=<NegBackward0>)\n",
            "Time 103.77654480934143 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 103.80958104133606 loss tensor(0.4321, grad_fn=<NegBackward0>)\n",
            "Time 103.837411403656 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 103.86776065826416 loss tensor(0.4320, grad_fn=<NegBackward0>)\n",
            "Time 103.89711809158325 loss tensor(0.4319, grad_fn=<NegBackward0>)\n",
            "Time 103.92670845985413 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 103.95558023452759 loss tensor(0.4318, grad_fn=<NegBackward0>)\n",
            "Time 103.99098491668701 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 104.0206446647644 loss tensor(0.4317, grad_fn=<NegBackward0>)\n",
            "Time 104.0484185218811 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 104.07634782791138 loss tensor(0.4316, grad_fn=<NegBackward0>)\n",
            "Time 104.11313104629517 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 104.14168190956116 loss tensor(0.4315, grad_fn=<NegBackward0>)\n",
            "Time 104.16983532905579 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 104.21095538139343 loss tensor(0.4314, grad_fn=<NegBackward0>)\n",
            "Time 104.24058890342712 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 104.27111601829529 loss tensor(0.4313, grad_fn=<NegBackward0>)\n",
            "Time 104.2985827922821 loss tensor(0.4312, grad_fn=<NegBackward0>)\n",
            "Time 104.32858419418335 loss tensor(0.4312, grad_fn=<NegBackward0>)\n",
            "Time 104.35788083076477 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 104.38688731193542 loss tensor(0.4311, grad_fn=<NegBackward0>)\n",
            "Time 104.42207288742065 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 104.44981122016907 loss tensor(0.4310, grad_fn=<NegBackward0>)\n",
            "Time 104.47735142707825 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 104.50551986694336 loss tensor(0.4309, grad_fn=<NegBackward0>)\n",
            "Time 104.53473854064941 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 104.56378602981567 loss tensor(0.4308, grad_fn=<NegBackward0>)\n",
            "Time 104.59352731704712 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 104.6274483203888 loss tensor(0.4307, grad_fn=<NegBackward0>)\n",
            "Time 104.65963172912598 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 104.69007015228271 loss tensor(0.4306, grad_fn=<NegBackward0>)\n",
            "Time 104.72029757499695 loss tensor(0.4305, grad_fn=<NegBackward0>)\n",
            "Time 104.75034308433533 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 104.78269624710083 loss tensor(0.4304, grad_fn=<NegBackward0>)\n",
            "Time 104.81255173683167 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 104.84642148017883 loss tensor(0.4303, grad_fn=<NegBackward0>)\n",
            "Time 104.87849426269531 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 104.90982675552368 loss tensor(0.4302, grad_fn=<NegBackward0>)\n",
            "Time 104.94118428230286 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 104.97031450271606 loss tensor(0.4301, grad_fn=<NegBackward0>)\n",
            "Time 105.00372195243835 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 105.0370454788208 loss tensor(0.4300, grad_fn=<NegBackward0>)\n",
            "Time 105.068767786026 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 105.09916162490845 loss tensor(0.4299, grad_fn=<NegBackward0>)\n",
            "Time 105.13578987121582 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 105.16338658332825 loss tensor(0.4298, grad_fn=<NegBackward0>)\n",
            "Time 105.19183111190796 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 105.2189953327179 loss tensor(0.4297, grad_fn=<NegBackward0>)\n",
            "Time 105.24708724021912 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 105.27782368659973 loss tensor(0.4296, grad_fn=<NegBackward0>)\n",
            "Time 105.31234335899353 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 105.34069347381592 loss tensor(0.4295, grad_fn=<NegBackward0>)\n",
            "Time 105.3684446811676 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 105.39723539352417 loss tensor(0.4294, grad_fn=<NegBackward0>)\n",
            "Time 105.42797541618347 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 105.458744764328 loss tensor(0.4293, grad_fn=<NegBackward0>)\n",
            "Time 105.49627900123596 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 105.52665638923645 loss tensor(0.4292, grad_fn=<NegBackward0>)\n",
            "Time 105.55477809906006 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 105.58288979530334 loss tensor(0.4291, grad_fn=<NegBackward0>)\n",
            "Time 105.61334180831909 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 105.64675664901733 loss tensor(0.4290, grad_fn=<NegBackward0>)\n",
            "Time 105.67520093917847 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 105.71194267272949 loss tensor(0.4289, grad_fn=<NegBackward0>)\n",
            "Time 105.7393410205841 loss tensor(0.4288, grad_fn=<NegBackward0>)\n",
            "Time 105.77388405799866 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 105.80411863327026 loss tensor(0.4287, grad_fn=<NegBackward0>)\n",
            "Time 105.83183646202087 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 105.85919690132141 loss tensor(0.4286, grad_fn=<NegBackward0>)\n",
            "Time 105.88695001602173 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 105.91815900802612 loss tensor(0.4285, grad_fn=<NegBackward0>)\n",
            "Time 105.94946002960205 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 105.9771842956543 loss tensor(0.4284, grad_fn=<NegBackward0>)\n",
            "Time 106.00458240509033 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 106.03449249267578 loss tensor(0.4283, grad_fn=<NegBackward0>)\n",
            "Time 106.06166195869446 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 106.08912515640259 loss tensor(0.4282, grad_fn=<NegBackward0>)\n",
            "Time 106.11702251434326 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 106.15672755241394 loss tensor(0.4281, grad_fn=<NegBackward0>)\n",
            "Time 106.18479132652283 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 106.21326804161072 loss tensor(0.4280, grad_fn=<NegBackward0>)\n",
            "Time 106.24282813072205 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 106.27061724662781 loss tensor(0.4279, grad_fn=<NegBackward0>)\n",
            "Time 106.29934620857239 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 106.33237099647522 loss tensor(0.4278, grad_fn=<NegBackward0>)\n",
            "Time 106.36169791221619 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 106.38992238044739 loss tensor(0.4277, grad_fn=<NegBackward0>)\n",
            "Time 106.41744303703308 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 106.44994592666626 loss tensor(0.4276, grad_fn=<NegBackward0>)\n",
            "Time 106.47847127914429 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 106.50723481178284 loss tensor(0.4275, grad_fn=<NegBackward0>)\n",
            "Time 106.54527020454407 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 106.57488870620728 loss tensor(0.4274, grad_fn=<NegBackward0>)\n",
            "Time 106.60346984863281 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 106.63125371932983 loss tensor(0.4273, grad_fn=<NegBackward0>)\n",
            "Time 106.6619975566864 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 106.68954730033875 loss tensor(0.4272, grad_fn=<NegBackward0>)\n",
            "Time 106.72048020362854 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 106.7508897781372 loss tensor(0.4271, grad_fn=<NegBackward0>)\n",
            "Time 106.7821614742279 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 106.81014943122864 loss tensor(0.4270, grad_fn=<NegBackward0>)\n",
            "Time 106.83863258361816 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 106.87002444267273 loss tensor(0.4269, grad_fn=<NegBackward0>)\n",
            "Time 106.89780926704407 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 106.9257640838623 loss tensor(0.4268, grad_fn=<NegBackward0>)\n",
            "Time 106.95457983016968 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 106.99128532409668 loss tensor(0.4267, grad_fn=<NegBackward0>)\n",
            "Time 107.02384972572327 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 107.05186557769775 loss tensor(0.4266, grad_fn=<NegBackward0>)\n",
            "Time 107.0817596912384 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 107.10895419120789 loss tensor(0.4265, grad_fn=<NegBackward0>)\n",
            "Time 107.13650560379028 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 107.18583464622498 loss tensor(0.4264, grad_fn=<NegBackward0>)\n",
            "Time 107.21434569358826 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 107.24674868583679 loss tensor(0.4263, grad_fn=<NegBackward0>)\n",
            "Time 107.27990651130676 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 107.3107283115387 loss tensor(0.4262, grad_fn=<NegBackward0>)\n",
            "Time 107.34046506881714 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 107.36908483505249 loss tensor(0.4261, grad_fn=<NegBackward0>)\n",
            "Time 107.41802477836609 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 107.46618556976318 loss tensor(0.4260, grad_fn=<NegBackward0>)\n",
            "Time 107.516193151474 loss tensor(0.4259, grad_fn=<NegBackward0>)\n",
            "Time 107.56810593605042 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 107.61310195922852 loss tensor(0.4258, grad_fn=<NegBackward0>)\n",
            "Time 107.66371178627014 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 107.70593523979187 loss tensor(0.4257, grad_fn=<NegBackward0>)\n",
            "Time 107.74733901023865 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 107.78774380683899 loss tensor(0.4256, grad_fn=<NegBackward0>)\n",
            "Time 107.82709503173828 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 107.87792944908142 loss tensor(0.4255, grad_fn=<NegBackward0>)\n",
            "Time 107.9189224243164 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 107.95783281326294 loss tensor(0.4254, grad_fn=<NegBackward0>)\n",
            "Time 107.99620652198792 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 108.03645300865173 loss tensor(0.4253, grad_fn=<NegBackward0>)\n",
            "Time 108.07419848442078 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 108.1294937133789 loss tensor(0.4252, grad_fn=<NegBackward0>)\n",
            "Time 108.16760039329529 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 108.22535634040833 loss tensor(0.4251, grad_fn=<NegBackward0>)\n",
            "Time 108.26378536224365 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 108.30282258987427 loss tensor(0.4250, grad_fn=<NegBackward0>)\n",
            "Time 108.35442900657654 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 108.39329695701599 loss tensor(0.4249, grad_fn=<NegBackward0>)\n",
            "Time 108.43135952949524 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 108.46950054168701 loss tensor(0.4248, grad_fn=<NegBackward0>)\n",
            "Time 108.50704431533813 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 108.54646348953247 loss tensor(0.4247, grad_fn=<NegBackward0>)\n",
            "Time 108.59625315666199 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 108.63760280609131 loss tensor(0.4246, grad_fn=<NegBackward0>)\n",
            "Time 108.67613554000854 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 108.71848154067993 loss tensor(0.4245, grad_fn=<NegBackward0>)\n",
            "Time 108.77048683166504 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 108.82290768623352 loss tensor(0.4244, grad_fn=<NegBackward0>)\n",
            "Time 108.8673164844513 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 108.91288995742798 loss tensor(0.4243, grad_fn=<NegBackward0>)\n",
            "Time 108.95518279075623 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 108.99569511413574 loss tensor(0.4242, grad_fn=<NegBackward0>)\n",
            "Time 109.04495191574097 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 109.0778021812439 loss tensor(0.4241, grad_fn=<NegBackward0>)\n",
            "Time 109.10557651519775 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 109.13278841972351 loss tensor(0.4240, grad_fn=<NegBackward0>)\n",
            "Time 109.16002917289734 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 109.19225740432739 loss tensor(0.4239, grad_fn=<NegBackward0>)\n",
            "Time 109.22910380363464 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 109.26359248161316 loss tensor(0.4238, grad_fn=<NegBackward0>)\n",
            "Time 109.29227614402771 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 109.31941318511963 loss tensor(0.4237, grad_fn=<NegBackward0>)\n",
            "Time 109.34640836715698 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 109.37679886817932 loss tensor(0.4236, grad_fn=<NegBackward0>)\n",
            "Time 109.4040093421936 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 109.43133974075317 loss tensor(0.4235, grad_fn=<NegBackward0>)\n",
            "Time 109.45878005027771 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 109.50429248809814 loss tensor(0.4234, grad_fn=<NegBackward0>)\n",
            "Time 109.53212571144104 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 109.56130194664001 loss tensor(0.4233, grad_fn=<NegBackward0>)\n",
            "Time 109.5895037651062 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 109.61802935600281 loss tensor(0.4232, grad_fn=<NegBackward0>)\n",
            "Time 109.64773917198181 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 109.67777395248413 loss tensor(0.4231, grad_fn=<NegBackward0>)\n",
            "Time 109.71520566940308 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 109.74670028686523 loss tensor(0.4230, grad_fn=<NegBackward0>)\n",
            "Time 109.77628326416016 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 109.80579042434692 loss tensor(0.4229, grad_fn=<NegBackward0>)\n",
            "Time 109.8338451385498 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 109.86258125305176 loss tensor(0.4228, grad_fn=<NegBackward0>)\n",
            "Time 109.89395594596863 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 109.9300274848938 loss tensor(0.4227, grad_fn=<NegBackward0>)\n",
            "Time 109.96077084541321 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 109.98910784721375 loss tensor(0.4226, grad_fn=<NegBackward0>)\n",
            "Time 110.01958346366882 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 110.04860520362854 loss tensor(0.4225, grad_fn=<NegBackward0>)\n",
            "Time 110.07567000389099 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 110.10283184051514 loss tensor(0.4224, grad_fn=<NegBackward0>)\n",
            "Time 110.13045835494995 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 110.16717171669006 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 110.19676446914673 loss tensor(0.4223, grad_fn=<NegBackward0>)\n",
            "Time 110.22680759429932 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 110.26404118537903 loss tensor(0.4222, grad_fn=<NegBackward0>)\n",
            "Time 110.2916259765625 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 110.32249546051025 loss tensor(0.4221, grad_fn=<NegBackward0>)\n",
            "Time 110.35845375061035 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 110.38704204559326 loss tensor(0.4220, grad_fn=<NegBackward0>)\n",
            "Time 110.41481423377991 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 110.44194102287292 loss tensor(0.4219, grad_fn=<NegBackward0>)\n",
            "Time 110.488454580307 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 110.5199933052063 loss tensor(0.4218, grad_fn=<NegBackward0>)\n",
            "Time 110.54864192008972 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 110.58655762672424 loss tensor(0.4217, grad_fn=<NegBackward0>)\n",
            "Time 110.61601614952087 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 110.64396286010742 loss tensor(0.4216, grad_fn=<NegBackward0>)\n",
            "Time 110.67244458198547 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 110.701007604599 loss tensor(0.4215, grad_fn=<NegBackward0>)\n",
            "Time 110.72917056083679 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 110.75939655303955 loss tensor(0.4214, grad_fn=<NegBackward0>)\n",
            "Time 110.79148817062378 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 110.824462890625 loss tensor(0.4213, grad_fn=<NegBackward0>)\n",
            "Time 110.8656325340271 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 110.90240669250488 loss tensor(0.4212, grad_fn=<NegBackward0>)\n",
            "Time 110.93175649642944 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 110.96295690536499 loss tensor(0.4211, grad_fn=<NegBackward0>)\n",
            "Time 110.99144458770752 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 111.0300805568695 loss tensor(0.4210, grad_fn=<NegBackward0>)\n",
            "Time 111.05834698677063 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 111.08639335632324 loss tensor(0.4209, grad_fn=<NegBackward0>)\n",
            "Time 111.11465120315552 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 111.14543104171753 loss tensor(0.4208, grad_fn=<NegBackward0>)\n",
            "Time 111.1738212108612 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 111.20214080810547 loss tensor(0.4207, grad_fn=<NegBackward0>)\n",
            "Time 111.2299554347992 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 111.2730917930603 loss tensor(0.4206, grad_fn=<NegBackward0>)\n",
            "Time 111.3003876209259 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 111.32685327529907 loss tensor(0.4205, grad_fn=<NegBackward0>)\n",
            "Time 111.35416078567505 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 111.38148784637451 loss tensor(0.4204, grad_fn=<NegBackward0>)\n",
            "Time 111.41017365455627 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 111.43936514854431 loss tensor(0.4203, grad_fn=<NegBackward0>)\n",
            "Time 111.47895574569702 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 111.50534987449646 loss tensor(0.4202, grad_fn=<NegBackward0>)\n",
            "Time 111.532710313797 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 111.56134104728699 loss tensor(0.4201, grad_fn=<NegBackward0>)\n",
            "Time 111.58843541145325 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 111.61596441268921 loss tensor(0.4200, grad_fn=<NegBackward0>)\n",
            "Time 111.64282011985779 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 111.6750259399414 loss tensor(0.4199, grad_fn=<NegBackward0>)\n",
            "Time 111.70210552215576 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 111.73311877250671 loss tensor(0.4198, grad_fn=<NegBackward0>)\n",
            "Time 111.76739120483398 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 111.79809665679932 loss tensor(0.4197, grad_fn=<NegBackward0>)\n",
            "Time 111.83374214172363 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 111.87225151062012 loss tensor(0.4196, grad_fn=<NegBackward0>)\n",
            "Time 111.9017448425293 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 111.93077087402344 loss tensor(0.4195, grad_fn=<NegBackward0>)\n",
            "Time 111.95940089225769 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 111.98801636695862 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 112.01883339881897 loss tensor(0.4194, grad_fn=<NegBackward0>)\n",
            "Time 112.04618883132935 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 112.08561277389526 loss tensor(0.4193, grad_fn=<NegBackward0>)\n",
            "Time 112.11380791664124 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 112.14166712760925 loss tensor(0.4192, grad_fn=<NegBackward0>)\n",
            "Time 112.16949105262756 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 112.19925546646118 loss tensor(0.4191, grad_fn=<NegBackward0>)\n",
            "Time 112.22846245765686 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 112.25636076927185 loss tensor(0.4190, grad_fn=<NegBackward0>)\n",
            "Time 112.29938745498657 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 112.3271849155426 loss tensor(0.4189, grad_fn=<NegBackward0>)\n",
            "Time 112.35429239273071 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 112.38274478912354 loss tensor(0.4188, grad_fn=<NegBackward0>)\n",
            "Time 112.4100091457367 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 112.44007968902588 loss tensor(0.4187, grad_fn=<NegBackward0>)\n",
            "Time 112.46929740905762 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 112.5066487789154 loss tensor(0.4186, grad_fn=<NegBackward0>)\n",
            "Time 112.5387225151062 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 112.56763315200806 loss tensor(0.4185, grad_fn=<NegBackward0>)\n",
            "Time 112.59612894058228 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 112.6237313747406 loss tensor(0.4184, grad_fn=<NegBackward0>)\n",
            "Time 112.65184617042542 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 112.68219494819641 loss tensor(0.4183, grad_fn=<NegBackward0>)\n",
            "Time 112.71179270744324 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 112.74571132659912 loss tensor(0.4182, grad_fn=<NegBackward0>)\n",
            "Time 112.77388739585876 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 112.80126953125 loss tensor(0.4181, grad_fn=<NegBackward0>)\n",
            "Time 112.83142232894897 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 112.85953688621521 loss tensor(0.4180, grad_fn=<NegBackward0>)\n",
            "Time 112.89015316963196 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 112.9272472858429 loss tensor(0.4179, grad_fn=<NegBackward0>)\n",
            "Time 112.95747661590576 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 112.98510980606079 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 113.01432633399963 loss tensor(0.4178, grad_fn=<NegBackward0>)\n",
            "Time 113.04193592071533 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 113.06907367706299 loss tensor(0.4177, grad_fn=<NegBackward0>)\n",
            "Time 113.09551620483398 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 113.1228084564209 loss tensor(0.4176, grad_fn=<NegBackward0>)\n",
            "Time 113.15875315666199 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 113.18703699111938 loss tensor(0.4175, grad_fn=<NegBackward0>)\n",
            "Time 113.21413731575012 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 113.24059677124023 loss tensor(0.4174, grad_fn=<NegBackward0>)\n",
            "Time 113.26869869232178 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 113.30910181999207 loss tensor(0.4173, grad_fn=<NegBackward0>)\n",
            "Time 113.33619046211243 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 113.36706686019897 loss tensor(0.4172, grad_fn=<NegBackward0>)\n",
            "Time 113.39969801902771 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 113.42628622055054 loss tensor(0.4171, grad_fn=<NegBackward0>)\n",
            "Time 113.4535129070282 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 113.48129153251648 loss tensor(0.4170, grad_fn=<NegBackward0>)\n",
            "Time 113.50848841667175 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 113.53544020652771 loss tensor(0.4169, grad_fn=<NegBackward0>)\n",
            "Time 113.5631628036499 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 113.5978307723999 loss tensor(0.4168, grad_fn=<NegBackward0>)\n",
            "Time 113.63277912139893 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 113.65956044197083 loss tensor(0.4167, grad_fn=<NegBackward0>)\n",
            "Time 113.6867287158966 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 113.71803283691406 loss tensor(0.4166, grad_fn=<NegBackward0>)\n",
            "Time 113.74612951278687 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 113.77489590644836 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 113.80597758293152 loss tensor(0.4165, grad_fn=<NegBackward0>)\n",
            "Time 113.83535385131836 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 113.86123275756836 loss tensor(0.4164, grad_fn=<NegBackward0>)\n",
            "Time 113.89113855361938 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 113.92525219917297 loss tensor(0.4163, grad_fn=<NegBackward0>)\n",
            "Time 113.95399403572083 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 113.97993540763855 loss tensor(0.4162, grad_fn=<NegBackward0>)\n",
            "Time 114.01271629333496 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 114.04513120651245 loss tensor(0.4161, grad_fn=<NegBackward0>)\n",
            "Time 114.0729455947876 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 114.10000801086426 loss tensor(0.4160, grad_fn=<NegBackward0>)\n",
            "Time 114.12744498252869 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 114.15360355377197 loss tensor(0.4159, grad_fn=<NegBackward0>)\n",
            "Time 114.18246865272522 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 114.21133708953857 loss tensor(0.4158, grad_fn=<NegBackward0>)\n",
            "Time 114.25448799133301 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 114.28248143196106 loss tensor(0.4157, grad_fn=<NegBackward0>)\n",
            "Time 114.32166528701782 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 114.34985303878784 loss tensor(0.4156, grad_fn=<NegBackward0>)\n",
            "Time 114.3783438205719 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 114.4075825214386 loss tensor(0.4155, grad_fn=<NegBackward0>)\n",
            "Time 114.43616104125977 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 114.47283887863159 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 114.5014796257019 loss tensor(0.4154, grad_fn=<NegBackward0>)\n",
            "Time 114.52989101409912 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 114.55802154541016 loss tensor(0.4153, grad_fn=<NegBackward0>)\n",
            "Time 114.58982586860657 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 114.62066149711609 loss tensor(0.4152, grad_fn=<NegBackward0>)\n",
            "Time 114.65243816375732 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 114.68760967254639 loss tensor(0.4151, grad_fn=<NegBackward0>)\n",
            "Time 114.71811246871948 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 114.74711036682129 loss tensor(0.4150, grad_fn=<NegBackward0>)\n",
            "Time 114.778635263443 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 114.80999636650085 loss tensor(0.4149, grad_fn=<NegBackward0>)\n",
            "Time 114.8402750492096 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 114.86943483352661 loss tensor(0.4148, grad_fn=<NegBackward0>)\n",
            "Time 114.90765476226807 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 114.93528413772583 loss tensor(0.4147, grad_fn=<NegBackward0>)\n",
            "Time 114.96239447593689 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 114.98890471458435 loss tensor(0.4146, grad_fn=<NegBackward0>)\n",
            "Time 115.02228856086731 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 115.04898762702942 loss tensor(0.4145, grad_fn=<NegBackward0>)\n",
            "Time 115.07530546188354 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 115.10251021385193 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 115.13558650016785 loss tensor(0.4144, grad_fn=<NegBackward0>)\n",
            "Time 115.16247463226318 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 115.18963432312012 loss tensor(0.4143, grad_fn=<NegBackward0>)\n",
            "Time 115.21622395515442 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 115.24983263015747 loss tensor(0.4142, grad_fn=<NegBackward0>)\n",
            "Time 115.28242135047913 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 115.31313157081604 loss tensor(0.4141, grad_fn=<NegBackward0>)\n",
            "Time 115.35376334190369 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 115.38521027565002 loss tensor(0.4140, grad_fn=<NegBackward0>)\n",
            "Time 115.41201901435852 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 115.43863797187805 loss tensor(0.4139, grad_fn=<NegBackward0>)\n",
            "Time 115.46532940864563 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 115.49351000785828 loss tensor(0.4138, grad_fn=<NegBackward0>)\n",
            "Time 115.52183055877686 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 115.54997658729553 loss tensor(0.4137, grad_fn=<NegBackward0>)\n",
            "Time 115.59031915664673 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 115.61858105659485 loss tensor(0.4136, grad_fn=<NegBackward0>)\n",
            "Time 115.64676070213318 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 115.6753134727478 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 115.70886516571045 loss tensor(0.4135, grad_fn=<NegBackward0>)\n",
            "Time 115.73863244056702 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 115.76583957672119 loss tensor(0.4134, grad_fn=<NegBackward0>)\n",
            "Time 115.79649710655212 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 115.82683944702148 loss tensor(0.4133, grad_fn=<NegBackward0>)\n",
            "Time 115.85932302474976 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 115.88940930366516 loss tensor(0.4132, grad_fn=<NegBackward0>)\n",
            "Time 115.91950368881226 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 115.94849491119385 loss tensor(0.4131, grad_fn=<NegBackward0>)\n",
            "Time 115.97826886177063 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 116.01634359359741 loss tensor(0.4130, grad_fn=<NegBackward0>)\n",
            "Time 116.04470205307007 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 116.07228994369507 loss tensor(0.4129, grad_fn=<NegBackward0>)\n",
            "Time 116.10161089897156 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 116.13099360466003 loss tensor(0.4128, grad_fn=<NegBackward0>)\n",
            "Time 116.1584541797638 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 116.19332313537598 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 116.2263400554657 loss tensor(0.4127, grad_fn=<NegBackward0>)\n",
            "Time 116.25854516029358 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 116.2870979309082 loss tensor(0.4126, grad_fn=<NegBackward0>)\n",
            "Time 116.31558609008789 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 116.35203146934509 loss tensor(0.4125, grad_fn=<NegBackward0>)\n",
            "Time 116.37869048118591 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 116.40596055984497 loss tensor(0.4124, grad_fn=<NegBackward0>)\n",
            "Time 116.44075059890747 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 116.47540545463562 loss tensor(0.4123, grad_fn=<NegBackward0>)\n",
            "Time 116.5034589767456 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 116.53094220161438 loss tensor(0.4122, grad_fn=<NegBackward0>)\n",
            "Time 116.55983018875122 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 116.59245729446411 loss tensor(0.4121, grad_fn=<NegBackward0>)\n",
            "Time 116.61991214752197 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 116.65874028205872 loss tensor(0.4120, grad_fn=<NegBackward0>)\n",
            "Time 116.68721437454224 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 116.71580147743225 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 116.74414706230164 loss tensor(0.4119, grad_fn=<NegBackward0>)\n",
            "Time 116.77387690544128 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 116.80193257331848 loss tensor(0.4118, grad_fn=<NegBackward0>)\n",
            "Time 116.82926154136658 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 116.86202192306519 loss tensor(0.4117, grad_fn=<NegBackward0>)\n",
            "Time 116.89865040779114 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 116.92669224739075 loss tensor(0.4116, grad_fn=<NegBackward0>)\n",
            "Time 116.95390486717224 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 116.98069500923157 loss tensor(0.4115, grad_fn=<NegBackward0>)\n",
            "Time 117.01229071617126 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 117.04036521911621 loss tensor(0.4114, grad_fn=<NegBackward0>)\n",
            "Time 117.074214220047 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 117.10322093963623 loss tensor(0.4113, grad_fn=<NegBackward0>)\n",
            "Time 117.13008618354797 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 117.15643429756165 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 117.1846570968628 loss tensor(0.4112, grad_fn=<NegBackward0>)\n",
            "Time 117.21151232719421 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 117.23785448074341 loss tensor(0.4111, grad_fn=<NegBackward0>)\n",
            "Time 117.26612401008606 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 117.30466151237488 loss tensor(0.4110, grad_fn=<NegBackward0>)\n",
            "Time 117.3329131603241 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 117.3692684173584 loss tensor(0.4109, grad_fn=<NegBackward0>)\n",
            "Time 117.39795517921448 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 117.42529654502869 loss tensor(0.4108, grad_fn=<NegBackward0>)\n",
            "Time 117.45236420631409 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 117.47974586486816 loss tensor(0.4107, grad_fn=<NegBackward0>)\n",
            "Time 117.51344084739685 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 117.54453229904175 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 117.57200837135315 loss tensor(0.4106, grad_fn=<NegBackward0>)\n",
            "Time 117.60190796852112 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 117.62981581687927 loss tensor(0.4105, grad_fn=<NegBackward0>)\n",
            "Time 117.6571843624115 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 117.68577837944031 loss tensor(0.4104, grad_fn=<NegBackward0>)\n",
            "Time 117.71356749534607 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 117.74885988235474 loss tensor(0.4103, grad_fn=<NegBackward0>)\n",
            "Time 117.77596068382263 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 117.80851244926453 loss tensor(0.4102, grad_fn=<NegBackward0>)\n",
            "Time 117.83742141723633 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 117.86509323120117 loss tensor(0.4101, grad_fn=<NegBackward0>)\n",
            "Time 117.8930082321167 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 117.92095899581909 loss tensor(0.4100, grad_fn=<NegBackward0>)\n",
            "Time 117.95241117477417 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 117.97934675216675 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 118.00703835487366 loss tensor(0.4099, grad_fn=<NegBackward0>)\n",
            "Time 118.03580284118652 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 118.06282949447632 loss tensor(0.4098, grad_fn=<NegBackward0>)\n",
            "Time 118.09791779518127 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 118.13099908828735 loss tensor(0.4097, grad_fn=<NegBackward0>)\n",
            "Time 118.16071891784668 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 118.18920230865479 loss tensor(0.4096, grad_fn=<NegBackward0>)\n",
            "Time 118.21680283546448 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 118.24457621574402 loss tensor(0.4095, grad_fn=<NegBackward0>)\n",
            "Time 118.27382183074951 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 118.3012273311615 loss tensor(0.4094, grad_fn=<NegBackward0>)\n",
            "Time 118.3289897441864 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 118.37407541275024 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 118.40764164924622 loss tensor(0.4093, grad_fn=<NegBackward0>)\n",
            "Time 118.43579435348511 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 118.46336555480957 loss tensor(0.4092, grad_fn=<NegBackward0>)\n",
            "Time 118.49172711372375 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 118.51909375190735 loss tensor(0.4091, grad_fn=<NegBackward0>)\n",
            "Time 118.54649519920349 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 118.57399702072144 loss tensor(0.4090, grad_fn=<NegBackward0>)\n",
            "Time 118.60911273956299 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 118.63613367080688 loss tensor(0.4089, grad_fn=<NegBackward0>)\n",
            "Time 118.6626935005188 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 118.69860553741455 loss tensor(0.4088, grad_fn=<NegBackward0>)\n",
            "Time 118.7266743183136 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 118.75775718688965 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 118.79341864585876 loss tensor(0.4087, grad_fn=<NegBackward0>)\n",
            "Time 118.82130837440491 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 118.84834003448486 loss tensor(0.4086, grad_fn=<NegBackward0>)\n",
            "Time 118.87772512435913 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 118.90700840950012 loss tensor(0.4085, grad_fn=<NegBackward0>)\n",
            "Time 118.93631529808044 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 118.96613764762878 loss tensor(0.4084, grad_fn=<NegBackward0>)\n",
            "Time 118.99413728713989 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 119.03570866584778 loss tensor(0.4083, grad_fn=<NegBackward0>)\n",
            "Time 119.07201027870178 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 119.1230137348175 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 119.16863179206848 loss tensor(0.4082, grad_fn=<NegBackward0>)\n",
            "Time 119.21792888641357 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 119.26336431503296 loss tensor(0.4081, grad_fn=<NegBackward0>)\n",
            "Time 119.3066463470459 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 119.34855008125305 loss tensor(0.4080, grad_fn=<NegBackward0>)\n",
            "Time 119.39115381240845 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 119.43767046928406 loss tensor(0.4079, grad_fn=<NegBackward0>)\n",
            "Time 119.47576594352722 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 119.51394534111023 loss tensor(0.4078, grad_fn=<NegBackward0>)\n",
            "Time 119.55192518234253 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 119.59270811080933 loss tensor(0.4077, grad_fn=<NegBackward0>)\n",
            "Time 119.63098573684692 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 119.67725944519043 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 119.71589088439941 loss tensor(0.4076, grad_fn=<NegBackward0>)\n",
            "Time 119.75319838523865 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 119.79634213447571 loss tensor(0.4075, grad_fn=<NegBackward0>)\n",
            "Time 119.83587574958801 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 119.88491535186768 loss tensor(0.4074, grad_fn=<NegBackward0>)\n",
            "Time 119.93015503883362 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 119.97010040283203 loss tensor(0.4073, grad_fn=<NegBackward0>)\n",
            "Time 120.01067590713501 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 120.04901504516602 loss tensor(0.4072, grad_fn=<NegBackward0>)\n",
            "Time 120.09125900268555 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 120.13261675834656 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 120.17162013053894 loss tensor(0.4071, grad_fn=<NegBackward0>)\n",
            "Time 120.21366119384766 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 120.25331497192383 loss tensor(0.4070, grad_fn=<NegBackward0>)\n",
            "Time 120.29602026939392 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 120.34296011924744 loss tensor(0.4069, grad_fn=<NegBackward0>)\n",
            "Time 120.38772344589233 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 120.44167232513428 loss tensor(0.4068, grad_fn=<NegBackward0>)\n",
            "Time 120.48515009880066 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 120.54034447669983 loss tensor(0.4067, grad_fn=<NegBackward0>)\n",
            "Time 120.58118271827698 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 120.62165260314941 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 120.66251730918884 loss tensor(0.4066, grad_fn=<NegBackward0>)\n",
            "Time 120.7070381641388 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 120.73749017715454 loss tensor(0.4065, grad_fn=<NegBackward0>)\n",
            "Time 120.77823543548584 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 120.81060671806335 loss tensor(0.4064, grad_fn=<NegBackward0>)\n",
            "Time 120.84466862678528 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 120.87684535980225 loss tensor(0.4063, grad_fn=<NegBackward0>)\n",
            "Time 120.9158878326416 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 120.94842028617859 loss tensor(0.4062, grad_fn=<NegBackward0>)\n",
            "Time 120.97641706466675 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 121.01400852203369 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 121.0414571762085 loss tensor(0.4061, grad_fn=<NegBackward0>)\n",
            "Time 121.06951642036438 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 121.0979528427124 loss tensor(0.4060, grad_fn=<NegBackward0>)\n",
            "Time 121.12580251693726 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 121.15321016311646 loss tensor(0.4059, grad_fn=<NegBackward0>)\n",
            "Time 121.18157196044922 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 121.210040807724 loss tensor(0.4058, grad_fn=<NegBackward0>)\n",
            "Time 121.24599361419678 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 121.27545022964478 loss tensor(0.4057, grad_fn=<NegBackward0>)\n",
            "Time 121.3034155368805 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 121.33234333992004 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 121.36041212081909 loss tensor(0.4056, grad_fn=<NegBackward0>)\n",
            "Time 121.3900842666626 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 121.41865849494934 loss tensor(0.4055, grad_fn=<NegBackward0>)\n",
            "Time 121.45801067352295 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 121.49247908592224 loss tensor(0.4054, grad_fn=<NegBackward0>)\n",
            "Time 121.520742893219 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 121.54876327514648 loss tensor(0.4053, grad_fn=<NegBackward0>)\n",
            "Time 121.58055090904236 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 121.60972356796265 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 121.63983345031738 loss tensor(0.4052, grad_fn=<NegBackward0>)\n",
            "Time 121.67545938491821 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 121.70554041862488 loss tensor(0.4051, grad_fn=<NegBackward0>)\n",
            "Time 121.73312759399414 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 121.76322102546692 loss tensor(0.4050, grad_fn=<NegBackward0>)\n",
            "Time 121.79076194763184 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 121.81728076934814 loss tensor(0.4049, grad_fn=<NegBackward0>)\n",
            "Time 121.84467792510986 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 121.8730239868164 loss tensor(0.4048, grad_fn=<NegBackward0>)\n",
            "Time 121.91230583190918 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 121.94079780578613 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 121.96812176704407 loss tensor(0.4047, grad_fn=<NegBackward0>)\n",
            "Time 121.99566173553467 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 122.02490282058716 loss tensor(0.4046, grad_fn=<NegBackward0>)\n",
            "Time 122.0524582862854 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 122.0798168182373 loss tensor(0.4045, grad_fn=<NegBackward0>)\n",
            "Time 122.1064522266388 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 122.14225363731384 loss tensor(0.4044, grad_fn=<NegBackward0>)\n",
            "Time 122.16903805732727 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 122.20518445968628 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 122.23195743560791 loss tensor(0.4043, grad_fn=<NegBackward0>)\n",
            "Time 122.26298356056213 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 122.2918872833252 loss tensor(0.4042, grad_fn=<NegBackward0>)\n",
            "Time 122.32074046134949 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 122.3573215007782 loss tensor(0.4041, grad_fn=<NegBackward0>)\n",
            "Time 122.3872938156128 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 122.41656637191772 loss tensor(0.4040, grad_fn=<NegBackward0>)\n",
            "Time 122.44657921791077 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 122.49161791801453 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 122.51989960670471 loss tensor(0.4039, grad_fn=<NegBackward0>)\n",
            "Time 122.54683113098145 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 122.5816400051117 loss tensor(0.4038, grad_fn=<NegBackward0>)\n",
            "Time 122.61347150802612 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 122.64599871635437 loss tensor(0.4037, grad_fn=<NegBackward0>)\n",
            "Time 122.67710256576538 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 122.70639181137085 loss tensor(0.4036, grad_fn=<NegBackward0>)\n",
            "Time 122.73633432388306 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 122.76773309707642 loss tensor(0.4035, grad_fn=<NegBackward0>)\n",
            "Time 122.80392479896545 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 122.83360505104065 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 122.865553855896 loss tensor(0.4034, grad_fn=<NegBackward0>)\n",
            "Time 122.89432263374329 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 122.92459654808044 loss tensor(0.4033, grad_fn=<NegBackward0>)\n",
            "Time 122.95337510108948 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 122.98401689529419 loss tensor(0.4032, grad_fn=<NegBackward0>)\n",
            "Time 123.02529048919678 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 123.06126356124878 loss tensor(0.4031, grad_fn=<NegBackward0>)\n",
            "Time 123.09058213233948 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 123.11959171295166 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 123.14946579933167 loss tensor(0.4030, grad_fn=<NegBackward0>)\n",
            "Time 123.17756223678589 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 123.20624256134033 loss tensor(0.4029, grad_fn=<NegBackward0>)\n",
            "Time 123.2421350479126 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 123.27317142486572 loss tensor(0.4028, grad_fn=<NegBackward0>)\n",
            "Time 123.30120301246643 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 123.32988810539246 loss tensor(0.4027, grad_fn=<NegBackward0>)\n",
            "Time 123.35888314247131 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 123.38762283325195 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 123.41741466522217 loss tensor(0.4026, grad_fn=<NegBackward0>)\n",
            "Time 123.45241856575012 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 123.48570561408997 loss tensor(0.4025, grad_fn=<NegBackward0>)\n",
            "Time 123.52318620681763 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 123.55126404762268 loss tensor(0.4024, grad_fn=<NegBackward0>)\n",
            "Time 123.57943153381348 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 123.60755825042725 loss tensor(0.4023, grad_fn=<NegBackward0>)\n",
            "Time 123.63758373260498 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 123.67382192611694 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 123.70114541053772 loss tensor(0.4022, grad_fn=<NegBackward0>)\n",
            "Time 123.72957754135132 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 123.75938320159912 loss tensor(0.4021, grad_fn=<NegBackward0>)\n",
            "Time 123.78749942779541 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 123.8182418346405 loss tensor(0.4020, grad_fn=<NegBackward0>)\n",
            "Time 123.8491325378418 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 123.88627743721008 loss tensor(0.4019, grad_fn=<NegBackward0>)\n",
            "Time 123.91595959663391 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 123.94475436210632 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 123.97279715538025 loss tensor(0.4018, grad_fn=<NegBackward0>)\n",
            "Time 124.00127387046814 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 124.03272724151611 loss tensor(0.4017, grad_fn=<NegBackward0>)\n",
            "Time 124.06437993049622 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 124.100426197052 loss tensor(0.4016, grad_fn=<NegBackward0>)\n",
            "Time 124.1309163570404 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 124.16174006462097 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 124.19080305099487 loss tensor(0.4015, grad_fn=<NegBackward0>)\n",
            "Time 124.2200677394867 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 124.24782943725586 loss tensor(0.4014, grad_fn=<NegBackward0>)\n",
            "Time 124.27657556533813 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 124.30742740631104 loss tensor(0.4013, grad_fn=<NegBackward0>)\n",
            "Time 124.33950710296631 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 124.36589002609253 loss tensor(0.4012, grad_fn=<NegBackward0>)\n",
            "Time 124.39346933364868 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 124.42260241508484 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 124.45009183883667 loss tensor(0.4011, grad_fn=<NegBackward0>)\n",
            "Time 124.48487758636475 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 124.52763509750366 loss tensor(0.4010, grad_fn=<NegBackward0>)\n",
            "Time 124.5592851638794 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 124.58669853210449 loss tensor(0.4009, grad_fn=<NegBackward0>)\n",
            "Time 124.61711692810059 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 124.64617586135864 loss tensor(0.4008, grad_fn=<NegBackward0>)\n",
            "Time 124.67369103431702 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 124.70158505439758 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 124.73630237579346 loss tensor(0.4007, grad_fn=<NegBackward0>)\n",
            "Time 124.76896333694458 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 124.80425953865051 loss tensor(0.4006, grad_fn=<NegBackward0>)\n",
            "Time 124.83135318756104 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 124.86003255844116 loss tensor(0.4005, grad_fn=<NegBackward0>)\n",
            "Time 124.88815689086914 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 124.91662240028381 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 124.95319032669067 loss tensor(0.4004, grad_fn=<NegBackward0>)\n",
            "Time 124.98259496688843 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 125.01526379585266 loss tensor(0.4003, grad_fn=<NegBackward0>)\n",
            "Time 125.04266285896301 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 125.07448506355286 loss tensor(0.4002, grad_fn=<NegBackward0>)\n",
            "Time 125.10226249694824 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 125.12965989112854 loss tensor(0.4001, grad_fn=<NegBackward0>)\n",
            "Time 125.16297578811646 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 125.19938063621521 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 125.22712659835815 loss tensor(0.4000, grad_fn=<NegBackward0>)\n",
            "Time 125.25564694404602 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 125.28583002090454 loss tensor(0.3999, grad_fn=<NegBackward0>)\n",
            "Time 125.31456661224365 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 125.34293246269226 loss tensor(0.3998, grad_fn=<NegBackward0>)\n",
            "Time 125.37972259521484 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 125.40835690498352 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 125.4381844997406 loss tensor(0.3997, grad_fn=<NegBackward0>)\n",
            "Time 125.46598863601685 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 125.49476623535156 loss tensor(0.3996, grad_fn=<NegBackward0>)\n",
            "Time 125.52449798583984 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 125.55936002731323 loss tensor(0.3995, grad_fn=<NegBackward0>)\n",
            "Time 125.59467339515686 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 125.62565088272095 loss tensor(0.3994, grad_fn=<NegBackward0>)\n",
            "Time 125.65616583824158 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 125.68364262580872 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 125.71174454689026 loss tensor(0.3993, grad_fn=<NegBackward0>)\n",
            "Time 125.74004364013672 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 125.76803374290466 loss tensor(0.3992, grad_fn=<NegBackward0>)\n",
            "Time 125.79919052124023 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 125.8349380493164 loss tensor(0.3991, grad_fn=<NegBackward0>)\n",
            "Time 125.86382794380188 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 125.89154481887817 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 125.91965413093567 loss tensor(0.3990, grad_fn=<NegBackward0>)\n",
            "Time 125.94811630249023 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 125.97627830505371 loss tensor(0.3989, grad_fn=<NegBackward0>)\n",
            "Time 126.00871872901917 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 126.03959941864014 loss tensor(0.3988, grad_fn=<NegBackward0>)\n",
            "Time 126.07006931304932 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 126.09859609603882 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 126.13219475746155 loss tensor(0.3987, grad_fn=<NegBackward0>)\n",
            "Time 126.16070508956909 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 126.19058084487915 loss tensor(0.3986, grad_fn=<NegBackward0>)\n",
            "Time 126.22786116600037 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 126.25785756111145 loss tensor(0.3985, grad_fn=<NegBackward0>)\n",
            "Time 126.28684067726135 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 126.31463122367859 loss tensor(0.3984, grad_fn=<NegBackward0>)\n",
            "Time 126.34309220314026 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 126.37137961387634 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 126.4028685092926 loss tensor(0.3983, grad_fn=<NegBackward0>)\n",
            "Time 126.44050407409668 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 126.46855449676514 loss tensor(0.3982, grad_fn=<NegBackward0>)\n",
            "Time 126.49643754959106 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 126.52473187446594 loss tensor(0.3981, grad_fn=<NegBackward0>)\n",
            "Time 126.5662670135498 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 126.59389972686768 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 126.62194037437439 loss tensor(0.3980, grad_fn=<NegBackward0>)\n",
            "Time 126.65957355499268 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 126.68712258338928 loss tensor(0.3979, grad_fn=<NegBackward0>)\n",
            "Time 126.71595883369446 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 126.74265193939209 loss tensor(0.3978, grad_fn=<NegBackward0>)\n",
            "Time 126.77400517463684 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 126.80242323875427 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 126.8325674533844 loss tensor(0.3977, grad_fn=<NegBackward0>)\n",
            "Time 126.86153960227966 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 126.8951575756073 loss tensor(0.3976, grad_fn=<NegBackward0>)\n",
            "Time 126.92487454414368 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 126.95193004608154 loss tensor(0.3975, grad_fn=<NegBackward0>)\n",
            "Time 126.97898697853088 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 127.0064172744751 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 127.03433394432068 loss tensor(0.3974, grad_fn=<NegBackward0>)\n",
            "Time 127.06082010269165 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 127.08743405342102 loss tensor(0.3973, grad_fn=<NegBackward0>)\n",
            "Time 127.12051463127136 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 127.14773726463318 loss tensor(0.3972, grad_fn=<NegBackward0>)\n",
            "Time 127.1753556728363 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 127.20330333709717 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 127.23560833930969 loss tensor(0.3971, grad_fn=<NegBackward0>)\n",
            "Time 127.26300597190857 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 127.29046487808228 loss tensor(0.3970, grad_fn=<NegBackward0>)\n",
            "Time 127.31840252876282 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 127.35427784919739 loss tensor(0.3969, grad_fn=<NegBackward0>)\n",
            "Time 127.38397789001465 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 127.41337847709656 loss tensor(0.3968, grad_fn=<NegBackward0>)\n",
            "Time 127.44098258018494 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 127.46863889694214 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 127.49622297286987 loss tensor(0.3967, grad_fn=<NegBackward0>)\n",
            "Time 127.5236701965332 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 127.55739188194275 loss tensor(0.3966, grad_fn=<NegBackward0>)\n",
            "Time 127.59671115875244 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 127.62397170066833 loss tensor(0.3965, grad_fn=<NegBackward0>)\n",
            "Time 127.6529860496521 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 127.67982196807861 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 127.7062475681305 loss tensor(0.3964, grad_fn=<NegBackward0>)\n",
            "Time 127.73519730567932 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 127.76380395889282 loss tensor(0.3963, grad_fn=<NegBackward0>)\n",
            "Time 127.80559277534485 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 127.83402967453003 loss tensor(0.3962, grad_fn=<NegBackward0>)\n",
            "Time 127.86272048950195 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 127.89085221290588 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 127.91950917243958 loss tensor(0.3961, grad_fn=<NegBackward0>)\n",
            "Time 127.94765758514404 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 127.9791476726532 loss tensor(0.3960, grad_fn=<NegBackward0>)\n",
            "Time 128.01397585868835 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 128.04611253738403 loss tensor(0.3959, grad_fn=<NegBackward0>)\n",
            "Time 128.07419848442078 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 128.10167360305786 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 128.12824773788452 loss tensor(0.3958, grad_fn=<NegBackward0>)\n",
            "Time 128.1552073955536 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 128.1825976371765 loss tensor(0.3957, grad_fn=<NegBackward0>)\n",
            "Time 128.21976113319397 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 128.24751377105713 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 128.2760832309723 loss tensor(0.3956, grad_fn=<NegBackward0>)\n",
            "Time 128.3032464981079 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 128.33329796791077 loss tensor(0.3955, grad_fn=<NegBackward0>)\n",
            "Time 128.36260342597961 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 128.39134097099304 loss tensor(0.3954, grad_fn=<NegBackward0>)\n",
            "Time 128.4283583164215 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 128.45710158348083 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 128.48499011993408 loss tensor(0.3953, grad_fn=<NegBackward0>)\n",
            "Time 128.51330971717834 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 128.54050040245056 loss tensor(0.3952, grad_fn=<NegBackward0>)\n",
            "Time 128.56782150268555 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 128.60869765281677 loss tensor(0.3951, grad_fn=<NegBackward0>)\n",
            "Time 128.64561247825623 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 128.67525100708008 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 128.70341110229492 loss tensor(0.3950, grad_fn=<NegBackward0>)\n",
            "Time 128.7391541004181 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 128.76813578605652 loss tensor(0.3949, grad_fn=<NegBackward0>)\n",
            "Time 128.79681706428528 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 128.8246612548828 loss tensor(0.3948, grad_fn=<NegBackward0>)\n",
            "Time 128.85952877998352 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 128.8901948928833 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 128.92038798332214 loss tensor(0.3947, grad_fn=<NegBackward0>)\n",
            "Time 128.94988799095154 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 128.9793574810028 loss tensor(0.3946, grad_fn=<NegBackward0>)\n",
            "Time 129.007230758667 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 129.0421497821808 loss tensor(0.3945, grad_fn=<NegBackward0>)\n",
            "Time 129.0773150920868 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 129.10562300682068 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 129.13402795791626 loss tensor(0.3944, grad_fn=<NegBackward0>)\n",
            "Time 129.16255378723145 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 129.18999123573303 loss tensor(0.3943, grad_fn=<NegBackward0>)\n",
            "Time 129.21815967559814 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 129.24615669250488 loss tensor(0.3942, grad_fn=<NegBackward0>)\n",
            "Time 129.27591347694397 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 129.31092429161072 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 129.3390073776245 loss tensor(0.3941, grad_fn=<NegBackward0>)\n",
            "Time 129.36713433265686 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 129.39541602134705 loss tensor(0.3940, grad_fn=<NegBackward0>)\n",
            "Time 129.4237575531006 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 129.45711851119995 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 129.4848988056183 loss tensor(0.3939, grad_fn=<NegBackward0>)\n",
            "Time 129.51402115821838 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 129.5498149394989 loss tensor(0.3938, grad_fn=<NegBackward0>)\n",
            "Time 129.57924675941467 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 129.61410760879517 loss tensor(0.3937, grad_fn=<NegBackward0>)\n",
            "Time 129.64577054977417 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 129.67331194877625 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 129.70557165145874 loss tensor(0.3936, grad_fn=<NegBackward0>)\n",
            "Time 129.74042797088623 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 129.77035522460938 loss tensor(0.3935, grad_fn=<NegBackward0>)\n",
            "Time 129.8042197227478 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 129.8316991329193 loss tensor(0.3934, grad_fn=<NegBackward0>)\n",
            "Time 129.8588469028473 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 129.88884019851685 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 129.9162459373474 loss tensor(0.3933, grad_fn=<NegBackward0>)\n",
            "Time 129.9508855342865 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 129.9802370071411 loss tensor(0.3932, grad_fn=<NegBackward0>)\n",
            "Time 130.0071506500244 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 130.03613138198853 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 130.06501936912537 loss tensor(0.3931, grad_fn=<NegBackward0>)\n",
            "Time 130.09351420402527 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 130.12123203277588 loss tensor(0.3930, grad_fn=<NegBackward0>)\n",
            "Time 130.14762949943542 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 130.18299531936646 loss tensor(0.3929, grad_fn=<NegBackward0>)\n",
            "Time 130.220552444458 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 130.24795866012573 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 130.2765989303589 loss tensor(0.3928, grad_fn=<NegBackward0>)\n",
            "Time 130.30372619628906 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 130.33199763298035 loss tensor(0.3927, grad_fn=<NegBackward0>)\n",
            "Time 130.36142659187317 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 130.39807772636414 loss tensor(0.3926, grad_fn=<NegBackward0>)\n",
            "Time 130.42752408981323 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 130.45519614219666 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 130.48297142982483 loss tensor(0.3925, grad_fn=<NegBackward0>)\n",
            "Time 130.5105357170105 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 130.53793835639954 loss tensor(0.3924, grad_fn=<NegBackward0>)\n",
            "Time 130.5650975704193 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 130.59278678894043 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 130.63785552978516 loss tensor(0.3923, grad_fn=<NegBackward0>)\n",
            "Time 130.6674382686615 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 130.69596672058105 loss tensor(0.3922, grad_fn=<NegBackward0>)\n",
            "Time 130.73622369766235 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 130.78796100616455 loss tensor(0.3921, grad_fn=<NegBackward0>)\n",
            "Time 130.83717966079712 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 130.89062595367432 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 130.93529438972473 loss tensor(0.3920, grad_fn=<NegBackward0>)\n",
            "Time 130.97466135025024 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 131.0153365135193 loss tensor(0.3919, grad_fn=<NegBackward0>)\n",
            "Time 131.06464171409607 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 131.10422277450562 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 131.14402437210083 loss tensor(0.3918, grad_fn=<NegBackward0>)\n",
            "Time 131.1845200061798 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 131.2234823703766 loss tensor(0.3917, grad_fn=<NegBackward0>)\n",
            "Time 131.2654275894165 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 131.31658291816711 loss tensor(0.3916, grad_fn=<NegBackward0>)\n",
            "Time 131.3565411567688 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 131.39594340324402 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 131.4344527721405 loss tensor(0.3915, grad_fn=<NegBackward0>)\n",
            "Time 131.48852729797363 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 131.54447436332703 loss tensor(0.3914, grad_fn=<NegBackward0>)\n",
            "Time 131.58371591567993 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 131.62672185897827 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 131.67654585838318 loss tensor(0.3913, grad_fn=<NegBackward0>)\n",
            "Time 131.71953415870667 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 131.76004695892334 loss tensor(0.3912, grad_fn=<NegBackward0>)\n",
            "Time 131.80279731750488 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 131.8434181213379 loss tensor(0.3911, grad_fn=<NegBackward0>)\n",
            "Time 131.88342237472534 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 131.92901968955994 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 131.97148609161377 loss tensor(0.3910, grad_fn=<NegBackward0>)\n",
            "Time 132.01292538642883 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 132.05921053886414 loss tensor(0.3909, grad_fn=<NegBackward0>)\n",
            "Time 132.10794115066528 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 132.15447664260864 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 132.19902801513672 loss tensor(0.3908, grad_fn=<NegBackward0>)\n",
            "Time 132.24289298057556 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 132.28622269630432 loss tensor(0.3907, grad_fn=<NegBackward0>)\n",
            "Time 132.32368326187134 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 132.37362480163574 loss tensor(0.3906, grad_fn=<NegBackward0>)\n",
            "Time 132.40138578414917 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 132.42898797988892 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 132.4557330608368 loss tensor(0.3905, grad_fn=<NegBackward0>)\n",
            "Time 132.48320531845093 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 132.5106372833252 loss tensor(0.3904, grad_fn=<NegBackward0>)\n",
            "Time 132.54045224189758 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 132.5684049129486 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 132.6028435230255 loss tensor(0.3903, grad_fn=<NegBackward0>)\n",
            "Time 132.62934517860413 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 132.65598011016846 loss tensor(0.3902, grad_fn=<NegBackward0>)\n",
            "Time 132.6950650215149 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 132.72667384147644 loss tensor(0.3901, grad_fn=<NegBackward0>)\n",
            "Time 132.754296541214 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 132.78232336044312 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 132.8169026374817 loss tensor(0.3900, grad_fn=<NegBackward0>)\n",
            "Time 132.84465765953064 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 132.8740360736847 loss tensor(0.3899, grad_fn=<NegBackward0>)\n",
            "Time 132.9017767906189 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 132.9300410747528 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 132.95731616020203 loss tensor(0.3898, grad_fn=<NegBackward0>)\n",
            "Time 132.98464250564575 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 133.01440501213074 loss tensor(0.3897, grad_fn=<NegBackward0>)\n",
            "Time 133.04963064193726 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 133.07690405845642 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 133.10391092300415 loss tensor(0.3896, grad_fn=<NegBackward0>)\n",
            "Time 133.13262367248535 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 133.1681933403015 loss tensor(0.3895, grad_fn=<NegBackward0>)\n",
            "Time 133.19645929336548 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 133.22512817382812 loss tensor(0.3894, grad_fn=<NegBackward0>)\n",
            "Time 133.2526454925537 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 133.28719902038574 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 133.31592082977295 loss tensor(0.3893, grad_fn=<NegBackward0>)\n",
            "Time 133.34609723091125 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 133.37677454948425 loss tensor(0.3892, grad_fn=<NegBackward0>)\n",
            "Time 133.4064908027649 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 133.43848514556885 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 133.4856698513031 loss tensor(0.3891, grad_fn=<NegBackward0>)\n",
            "Time 133.51539206504822 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 133.54562497138977 loss tensor(0.3890, grad_fn=<NegBackward0>)\n",
            "Time 133.57510781288147 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 133.60284447669983 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 133.6302719116211 loss tensor(0.3889, grad_fn=<NegBackward0>)\n",
            "Time 133.65714597702026 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 133.69694876670837 loss tensor(0.3888, grad_fn=<NegBackward0>)\n",
            "Time 133.73526644706726 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 133.76752948760986 loss tensor(0.3887, grad_fn=<NegBackward0>)\n",
            "Time 133.79756999015808 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 133.82720589637756 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 133.85690832138062 loss tensor(0.3886, grad_fn=<NegBackward0>)\n",
            "Time 133.88829803466797 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 133.92323780059814 loss tensor(0.3885, grad_fn=<NegBackward0>)\n",
            "Time 133.9530975818634 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 133.9814965724945 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 134.01224899291992 loss tensor(0.3884, grad_fn=<NegBackward0>)\n",
            "Time 134.04020142555237 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 134.06747269630432 loss tensor(0.3883, grad_fn=<NegBackward0>)\n",
            "Time 134.0949432849884 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 134.1268277168274 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 134.1617546081543 loss tensor(0.3882, grad_fn=<NegBackward0>)\n",
            "Time 134.1900281906128 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 134.21825075149536 loss tensor(0.3881, grad_fn=<NegBackward0>)\n",
            "Time 134.24607968330383 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 134.2821764945984 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 134.30997347831726 loss tensor(0.3880, grad_fn=<NegBackward0>)\n",
            "Time 134.3457760810852 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 134.37473559379578 loss tensor(0.3879, grad_fn=<NegBackward0>)\n",
            "Time 134.40283870697021 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 134.43050384521484 loss tensor(0.3878, grad_fn=<NegBackward0>)\n",
            "Time 134.45852780342102 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 134.48635077476501 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 134.5173101425171 loss tensor(0.3877, grad_fn=<NegBackward0>)\n",
            "Time 134.5451991558075 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 134.58059906959534 loss tensor(0.3876, grad_fn=<NegBackward0>)\n",
            "Time 134.6085662841797 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 134.64544248580933 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 134.6762890815735 loss tensor(0.3875, grad_fn=<NegBackward0>)\n",
            "Time 134.70452189445496 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 134.7418656349182 loss tensor(0.3874, grad_fn=<NegBackward0>)\n",
            "Time 134.77831506729126 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 134.80665707588196 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 134.83654737472534 loss tensor(0.3873, grad_fn=<NegBackward0>)\n",
            "Time 134.86576509475708 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 134.8944389820099 loss tensor(0.3872, grad_fn=<NegBackward0>)\n",
            "Time 134.92296409606934 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 134.95204639434814 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 134.98150086402893 loss tensor(0.3871, grad_fn=<NegBackward0>)\n",
            "Time 135.01966857910156 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 135.04742121696472 loss tensor(0.3870, grad_fn=<NegBackward0>)\n",
            "Time 135.08257675170898 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 135.11248016357422 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 135.1405804157257 loss tensor(0.3869, grad_fn=<NegBackward0>)\n",
            "Time 135.167640209198 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 135.20251655578613 loss tensor(0.3868, grad_fn=<NegBackward0>)\n",
            "Time 135.22931456565857 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 135.25732350349426 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 135.28884625434875 loss tensor(0.3867, grad_fn=<NegBackward0>)\n",
            "Time 135.31751585006714 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 135.34686064720154 loss tensor(0.3866, grad_fn=<NegBackward0>)\n",
            "Time 135.38046765327454 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 135.41501808166504 loss tensor(0.3865, grad_fn=<NegBackward0>)\n",
            "Time 135.44349145889282 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 135.47319841384888 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 135.50363993644714 loss tensor(0.3864, grad_fn=<NegBackward0>)\n",
            "Time 135.53417420387268 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 135.56196665763855 loss tensor(0.3863, grad_fn=<NegBackward0>)\n",
            "Time 135.5922772884369 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 135.6287384033203 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 135.65981674194336 loss tensor(0.3862, grad_fn=<NegBackward0>)\n",
            "Time 135.69101667404175 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 135.72595953941345 loss tensor(0.3861, grad_fn=<NegBackward0>)\n",
            "Time 135.7624316215515 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 135.79509210586548 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 135.82411551475525 loss tensor(0.3860, grad_fn=<NegBackward0>)\n",
            "Time 135.860191822052 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 135.89365887641907 loss tensor(0.3859, grad_fn=<NegBackward0>)\n",
            "Time 135.9272608757019 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 135.95646810531616 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 135.98615050315857 loss tensor(0.3858, grad_fn=<NegBackward0>)\n",
            "Time 136.01807761192322 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 136.0519187450409 loss tensor(0.3857, grad_fn=<NegBackward0>)\n",
            "Time 136.08702445030212 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 136.11552047729492 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 136.1430630683899 loss tensor(0.3856, grad_fn=<NegBackward0>)\n",
            "Time 136.1716911792755 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 136.20225310325623 loss tensor(0.3855, grad_fn=<NegBackward0>)\n",
            "Time 136.23028874397278 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 136.25872611999512 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 136.29351568222046 loss tensor(0.3854, grad_fn=<NegBackward0>)\n",
            "Time 136.33361887931824 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 136.36126947402954 loss tensor(0.3853, grad_fn=<NegBackward0>)\n",
            "Time 136.3891053199768 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 136.41712379455566 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 136.4488821029663 loss tensor(0.3852, grad_fn=<NegBackward0>)\n",
            "Time 136.4778733253479 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 136.5154812335968 loss tensor(0.3851, grad_fn=<NegBackward0>)\n",
            "Time 136.5446879863739 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 136.57284140586853 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 136.6027798652649 loss tensor(0.3850, grad_fn=<NegBackward0>)\n",
            "Time 136.63243746757507 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 136.66045784950256 loss tensor(0.3849, grad_fn=<NegBackward0>)\n",
            "Time 136.69144105911255 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 136.72376203536987 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 136.76654767990112 loss tensor(0.3848, grad_fn=<NegBackward0>)\n",
            "Time 136.79912877082825 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 136.83527636528015 loss tensor(0.3847, grad_fn=<NegBackward0>)\n",
            "Time 136.86461544036865 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 136.8945586681366 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 136.9240186214447 loss tensor(0.3846, grad_fn=<NegBackward0>)\n",
            "Time 136.96685361862183 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 136.99655485153198 loss tensor(0.3845, grad_fn=<NegBackward0>)\n",
            "Time 137.03116488456726 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 137.05933713912964 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 137.08973479270935 loss tensor(0.3844, grad_fn=<NegBackward0>)\n",
            "Time 137.11750721931458 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 137.1455225944519 loss tensor(0.3843, grad_fn=<NegBackward0>)\n",
            "Time 137.1827428340912 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 137.21162462234497 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 137.24044156074524 loss tensor(0.3842, grad_fn=<NegBackward0>)\n",
            "Time 137.2687668800354 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 137.29824113845825 loss tensor(0.3841, grad_fn=<NegBackward0>)\n",
            "Time 137.3266167640686 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 137.35659384727478 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 137.3877580165863 loss tensor(0.3840, grad_fn=<NegBackward0>)\n",
            "Time 137.42000269889832 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 137.44884395599365 loss tensor(0.3839, grad_fn=<NegBackward0>)\n",
            "Time 137.47807812690735 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 137.50628542900085 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 137.53472089767456 loss tensor(0.3838, grad_fn=<NegBackward0>)\n",
            "Time 137.5640413761139 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 137.59169030189514 loss tensor(0.3837, grad_fn=<NegBackward0>)\n",
            "Time 137.62782287597656 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 137.66032767295837 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 137.6972062587738 loss tensor(0.3836, grad_fn=<NegBackward0>)\n",
            "Time 137.7254354953766 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 137.75609421730042 loss tensor(0.3835, grad_fn=<NegBackward0>)\n",
            "Time 137.79460096359253 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 137.8252785205841 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 137.8594832420349 loss tensor(0.3834, grad_fn=<NegBackward0>)\n",
            "Time 137.8926157951355 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 137.92228889465332 loss tensor(0.3833, grad_fn=<NegBackward0>)\n",
            "Time 137.95221543312073 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 137.9809591770172 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 138.01461672782898 loss tensor(0.3832, grad_fn=<NegBackward0>)\n",
            "Time 138.05003595352173 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 138.0840926170349 loss tensor(0.3831, grad_fn=<NegBackward0>)\n",
            "Time 138.11299180984497 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 138.14186549186707 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 138.17036294937134 loss tensor(0.3830, grad_fn=<NegBackward0>)\n",
            "Time 138.1986448764801 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 138.2278642654419 loss tensor(0.3829, grad_fn=<NegBackward0>)\n",
            "Time 138.25677061080933 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 138.2951648235321 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 138.32970356941223 loss tensor(0.3828, grad_fn=<NegBackward0>)\n",
            "Time 138.3615427017212 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 138.39395666122437 loss tensor(0.3827, grad_fn=<NegBackward0>)\n",
            "Time 138.4213855266571 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 138.45183205604553 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 138.48120641708374 loss tensor(0.3826, grad_fn=<NegBackward0>)\n",
            "Time 138.51669907569885 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 138.54468321800232 loss tensor(0.3825, grad_fn=<NegBackward0>)\n",
            "Time 138.5744686126709 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 138.60510969161987 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 138.63271260261536 loss tensor(0.3824, grad_fn=<NegBackward0>)\n",
            "Time 138.6596474647522 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 138.69515752792358 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 138.73262476921082 loss tensor(0.3823, grad_fn=<NegBackward0>)\n",
            "Time 138.7603416442871 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 138.79838490486145 loss tensor(0.3822, grad_fn=<NegBackward0>)\n",
            "Time 138.82872343063354 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 138.8571457862854 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 138.88829922676086 loss tensor(0.3821, grad_fn=<NegBackward0>)\n",
            "Time 138.91774106025696 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 138.95335268974304 loss tensor(0.3820, grad_fn=<NegBackward0>)\n",
            "Time 138.988951921463 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 139.02015447616577 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 139.04770302772522 loss tensor(0.3819, grad_fn=<NegBackward0>)\n",
            "Time 139.07633447647095 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 139.1042935848236 loss tensor(0.3818, grad_fn=<NegBackward0>)\n",
            "Time 139.13219356536865 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 139.16682410240173 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 139.19697093963623 loss tensor(0.3817, grad_fn=<NegBackward0>)\n",
            "Time 139.2254090309143 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 139.2542073726654 loss tensor(0.3816, grad_fn=<NegBackward0>)\n",
            "Time 139.28414154052734 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 139.31310844421387 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 139.34063601493835 loss tensor(0.3815, grad_fn=<NegBackward0>)\n",
            "Time 139.3672637939453 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 139.40073776245117 loss tensor(0.3814, grad_fn=<NegBackward0>)\n",
            "Time 139.42754817008972 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 139.4552116394043 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 139.484299659729 loss tensor(0.3813, grad_fn=<NegBackward0>)\n",
            "Time 139.5155692100525 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 139.54481530189514 loss tensor(0.3812, grad_fn=<NegBackward0>)\n",
            "Time 139.5728588104248 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 139.60737776756287 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 139.63609719276428 loss tensor(0.3811, grad_fn=<NegBackward0>)\n",
            "Time 139.6640110015869 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 139.69799089431763 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 139.72808527946472 loss tensor(0.3810, grad_fn=<NegBackward0>)\n",
            "Time 139.75825452804565 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 139.79103231430054 loss tensor(0.3809, grad_fn=<NegBackward0>)\n",
            "Time 139.83715891838074 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 139.8676676750183 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 139.89766645431519 loss tensor(0.3808, grad_fn=<NegBackward0>)\n",
            "Time 139.9272801876068 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 139.95613646507263 loss tensor(0.3807, grad_fn=<NegBackward0>)\n",
            "Time 139.98410320281982 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 140.02071833610535 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 140.04801964759827 loss tensor(0.3806, grad_fn=<NegBackward0>)\n",
            "Time 140.07548189163208 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 140.104727268219 loss tensor(0.3805, grad_fn=<NegBackward0>)\n",
            "Time 140.13370561599731 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 140.16751146316528 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 140.19646763801575 loss tensor(0.3804, grad_fn=<NegBackward0>)\n",
            "Time 140.23250579833984 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 140.2642948627472 loss tensor(0.3803, grad_fn=<NegBackward0>)\n",
            "Time 140.2923719882965 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 140.32277059555054 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 140.3517951965332 loss tensor(0.3802, grad_fn=<NegBackward0>)\n",
            "Time 140.38031005859375 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 140.40995573997498 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 140.4462013244629 loss tensor(0.3801, grad_fn=<NegBackward0>)\n",
            "Time 140.47692918777466 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 140.505544424057 loss tensor(0.3800, grad_fn=<NegBackward0>)\n",
            "Time 140.53488421440125 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 140.5687005519867 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 140.5980453491211 loss tensor(0.3799, grad_fn=<NegBackward0>)\n",
            "Time 140.62742733955383 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 140.6647846698761 loss tensor(0.3798, grad_fn=<NegBackward0>)\n",
            "Time 140.69581174850464 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 140.72850275039673 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 140.75651741027832 loss tensor(0.3797, grad_fn=<NegBackward0>)\n",
            "Time 140.78434658050537 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 140.81226205825806 loss tensor(0.3796, grad_fn=<NegBackward0>)\n",
            "Time 140.84873294830322 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 140.89152812957764 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 140.91910934448242 loss tensor(0.3795, grad_fn=<NegBackward0>)\n",
            "Time 140.94740891456604 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 140.98877692222595 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 141.0195550918579 loss tensor(0.3794, grad_fn=<NegBackward0>)\n",
            "Time 141.04861760139465 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 141.07786870002747 loss tensor(0.3793, grad_fn=<NegBackward0>)\n",
            "Time 141.11271595954895 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 141.1407732963562 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 141.1689956188202 loss tensor(0.3792, grad_fn=<NegBackward0>)\n",
            "Time 141.19748520851135 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 141.22633934020996 loss tensor(0.3791, grad_fn=<NegBackward0>)\n",
            "Time 141.2577531337738 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 141.28793215751648 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 141.32118964195251 loss tensor(0.3790, grad_fn=<NegBackward0>)\n",
            "Time 141.35187792778015 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 141.38341426849365 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 141.411847114563 loss tensor(0.3789, grad_fn=<NegBackward0>)\n",
            "Time 141.43900609016418 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 141.46856546401978 loss tensor(0.3788, grad_fn=<NegBackward0>)\n",
            "Time 141.49446320533752 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 141.52124571800232 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 141.55974340438843 loss tensor(0.3787, grad_fn=<NegBackward0>)\n",
            "Time 141.5900912284851 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 141.62143421173096 loss tensor(0.3786, grad_fn=<NegBackward0>)\n",
            "Time 141.65000462532043 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 141.67878222465515 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 141.7143087387085 loss tensor(0.3785, grad_fn=<NegBackward0>)\n",
            "Time 141.7417459487915 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 141.77512311935425 loss tensor(0.3784, grad_fn=<NegBackward0>)\n",
            "Time 141.80564093589783 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 141.8341588973999 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 141.87452054023743 loss tensor(0.3783, grad_fn=<NegBackward0>)\n",
            "Time 141.90378093719482 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 141.93119025230408 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 141.98783230781555 loss tensor(0.3782, grad_fn=<NegBackward0>)\n",
            "Time 142.02079129219055 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 142.04898285865784 loss tensor(0.3781, grad_fn=<NegBackward0>)\n",
            "Time 142.0766565799713 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 142.10407328605652 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 142.1314446926117 loss tensor(0.3780, grad_fn=<NegBackward0>)\n",
            "Time 142.15895247459412 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 142.18740797042847 loss tensor(0.3779, grad_fn=<NegBackward0>)\n",
            "Time 142.2212221622467 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 142.24947094917297 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 142.27694988250732 loss tensor(0.3778, grad_fn=<NegBackward0>)\n",
            "Time 142.3076069355011 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 142.33595824241638 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 142.36923050880432 loss tensor(0.3777, grad_fn=<NegBackward0>)\n",
            "Time 142.42206478118896 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 142.47253704071045 loss tensor(0.3776, grad_fn=<NegBackward0>)\n",
            "Time 142.5187132358551 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 142.56278038024902 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 142.606751203537 loss tensor(0.3775, grad_fn=<NegBackward0>)\n",
            "Time 142.65515851974487 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 142.69691562652588 loss tensor(0.3774, grad_fn=<NegBackward0>)\n",
            "Time 142.7357907295227 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 142.77869606018066 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 142.82063245773315 loss tensor(0.3773, grad_fn=<NegBackward0>)\n",
            "Time 142.8692479133606 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 142.91794967651367 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 142.95726490020752 loss tensor(0.3772, grad_fn=<NegBackward0>)\n",
            "Time 143.00219559669495 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 143.04940581321716 loss tensor(0.3771, grad_fn=<NegBackward0>)\n",
            "Time 143.09581446647644 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 143.13609766960144 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 143.1749927997589 loss tensor(0.3770, grad_fn=<NegBackward0>)\n",
            "Time 143.2230043411255 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 143.2696897983551 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 143.31893944740295 loss tensor(0.3769, grad_fn=<NegBackward0>)\n",
            "Time 143.3640160560608 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 143.40479731559753 loss tensor(0.3768, grad_fn=<NegBackward0>)\n",
            "Time 143.44650959968567 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 143.48678135871887 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 143.53158926963806 loss tensor(0.3767, grad_fn=<NegBackward0>)\n",
            "Time 143.570983171463 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 143.61026215553284 loss tensor(0.3766, grad_fn=<NegBackward0>)\n",
            "Time 143.6480348110199 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 143.6882643699646 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 143.74171590805054 loss tensor(0.3765, grad_fn=<NegBackward0>)\n",
            "Time 143.7936942577362 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 143.83531260490417 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 143.87986397743225 loss tensor(0.3764, grad_fn=<NegBackward0>)\n",
            "Time 143.9328281879425 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 143.9807677268982 loss tensor(0.3763, grad_fn=<NegBackward0>)\n",
            "Time 144.025648355484 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 144.06881737709045 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 144.0993390083313 loss tensor(0.3762, grad_fn=<NegBackward0>)\n",
            "Time 144.12697887420654 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 144.15471386909485 loss tensor(0.3761, grad_fn=<NegBackward0>)\n",
            "Time 144.1930708885193 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 144.2230405807495 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 144.25083684921265 loss tensor(0.3760, grad_fn=<NegBackward0>)\n",
            "Time 144.2786350250244 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 144.3106837272644 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 144.33856391906738 loss tensor(0.3759, grad_fn=<NegBackward0>)\n",
            "Time 144.36813688278198 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 144.39886116981506 loss tensor(0.3758, grad_fn=<NegBackward0>)\n",
            "Time 144.43611359596252 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 144.464093208313 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 144.49386286735535 loss tensor(0.3757, grad_fn=<NegBackward0>)\n",
            "Time 144.5207507610321 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 144.55612063407898 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 144.5866949558258 loss tensor(0.3756, grad_fn=<NegBackward0>)\n",
            "Time 144.62251234054565 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 144.65111780166626 loss tensor(0.3755, grad_fn=<NegBackward0>)\n",
            "Time 144.6800148487091 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 144.70794081687927 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 144.73865151405334 loss tensor(0.3754, grad_fn=<NegBackward0>)\n",
            "Time 144.76688385009766 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 144.79770398139954 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 144.83016514778137 loss tensor(0.3753, grad_fn=<NegBackward0>)\n",
            "Time 144.86562991142273 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 144.89609479904175 loss tensor(0.3752, grad_fn=<NegBackward0>)\n",
            "Time 144.92461109161377 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 144.961754322052 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 144.98925352096558 loss tensor(0.3751, grad_fn=<NegBackward0>)\n",
            "Time 145.01995825767517 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 145.0561945438385 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 145.08383083343506 loss tensor(0.3750, grad_fn=<NegBackward0>)\n",
            "Time 145.11142826080322 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 145.138418674469 loss tensor(0.3749, grad_fn=<NegBackward0>)\n",
            "Time 145.16710138320923 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 145.19963908195496 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 145.22804498672485 loss tensor(0.3748, grad_fn=<NegBackward0>)\n",
            "Time 145.25560903549194 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 145.2968180179596 loss tensor(0.3747, grad_fn=<NegBackward0>)\n",
            "Time 145.32978105545044 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 145.35871481895447 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 145.3866786956787 loss tensor(0.3746, grad_fn=<NegBackward0>)\n",
            "Time 145.41473484039307 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 145.44262027740479 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 145.47318172454834 loss tensor(0.3745, grad_fn=<NegBackward0>)\n",
            "Time 145.5147352218628 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 145.54322743415833 loss tensor(0.3744, grad_fn=<NegBackward0>)\n",
            "Time 145.57126307487488 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 145.59963130950928 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 145.62767791748047 loss tensor(0.3743, grad_fn=<NegBackward0>)\n",
            "Time 145.660737991333 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 145.69601249694824 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 145.7273769378662 loss tensor(0.3742, grad_fn=<NegBackward0>)\n",
            "Time 145.75657439231873 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 145.7881314754486 loss tensor(0.3741, grad_fn=<NegBackward0>)\n",
            "Time 145.8160216808319 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 145.8455045223236 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 145.874746799469 loss tensor(0.3740, grad_fn=<NegBackward0>)\n",
            "Time 145.90973138809204 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 145.93816423416138 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 145.97808694839478 loss tensor(0.3739, grad_fn=<NegBackward0>)\n",
            "Time 146.01123142242432 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 146.0406060218811 loss tensor(0.3738, grad_fn=<NegBackward0>)\n",
            "Time 146.0686821937561 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 146.09767246246338 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 146.1329221725464 loss tensor(0.3737, grad_fn=<NegBackward0>)\n",
            "Time 146.1613097190857 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 146.18870568275452 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 146.21598029136658 loss tensor(0.3736, grad_fn=<NegBackward0>)\n",
            "Time 146.244238615036 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 146.2738037109375 loss tensor(0.3735, grad_fn=<NegBackward0>)\n",
            "Time 146.30200386047363 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 146.3298156261444 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 146.36965036392212 loss tensor(0.3734, grad_fn=<NegBackward0>)\n",
            "Time 146.39730167388916 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 146.4253168106079 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 146.45207595825195 loss tensor(0.3733, grad_fn=<NegBackward0>)\n",
            "Time 146.47938632965088 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 146.5061116218567 loss tensor(0.3732, grad_fn=<NegBackward0>)\n",
            "Time 146.53498458862305 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 146.56294441223145 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 146.60253643989563 loss tensor(0.3731, grad_fn=<NegBackward0>)\n",
            "Time 146.6370038986206 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 146.66591143608093 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 146.6959090232849 loss tensor(0.3730, grad_fn=<NegBackward0>)\n",
            "Time 146.7266719341278 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 146.7550950050354 loss tensor(0.3729, grad_fn=<NegBackward0>)\n",
            "Time 146.79126834869385 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 146.83003664016724 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 146.8584725856781 loss tensor(0.3728, grad_fn=<NegBackward0>)\n",
            "Time 146.89201045036316 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 146.9193377494812 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 146.95269560813904 loss tensor(0.3727, grad_fn=<NegBackward0>)\n",
            "Time 146.98391675949097 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 147.01743865013123 loss tensor(0.3726, grad_fn=<NegBackward0>)\n",
            "Time 147.0550091266632 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 147.08307552337646 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 147.1105728149414 loss tensor(0.3725, grad_fn=<NegBackward0>)\n",
            "Time 147.13831090927124 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 147.16600799560547 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 147.19330763816833 loss tensor(0.3724, grad_fn=<NegBackward0>)\n",
            "Time 147.22535395622253 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 147.25367784500122 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 147.28973245620728 loss tensor(0.3723, grad_fn=<NegBackward0>)\n",
            "Time 147.3185555934906 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 147.34642124176025 loss tensor(0.3722, grad_fn=<NegBackward0>)\n",
            "Time 147.3771858215332 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 147.40483927726746 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 147.43570160865784 loss tensor(0.3721, grad_fn=<NegBackward0>)\n",
            "Time 147.46364665031433 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 147.49282431602478 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 147.52719712257385 loss tensor(0.3720, grad_fn=<NegBackward0>)\n",
            "Time 147.5537850856781 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 147.58167362213135 loss tensor(0.3719, grad_fn=<NegBackward0>)\n",
            "Time 147.61239361763 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 147.6418752670288 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 147.6695373058319 loss tensor(0.3718, grad_fn=<NegBackward0>)\n",
            "Time 147.70230555534363 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 147.7332420349121 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 147.76299142837524 loss tensor(0.3717, grad_fn=<NegBackward0>)\n",
            "Time 147.79768109321594 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 147.82546067237854 loss tensor(0.3716, grad_fn=<NegBackward0>)\n",
            "Time 147.85342955589294 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 147.88332438468933 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 147.92146396636963 loss tensor(0.3715, grad_fn=<NegBackward0>)\n",
            "Time 147.95008277893066 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 147.97734475135803 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 148.01872563362122 loss tensor(0.3714, grad_fn=<NegBackward0>)\n",
            "Time 148.04744744300842 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 148.07539105415344 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 148.1029086112976 loss tensor(0.3713, grad_fn=<NegBackward0>)\n",
            "Time 148.1355857849121 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 148.16297316551208 loss tensor(0.3712, grad_fn=<NegBackward0>)\n",
            "Time 148.19022488594055 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 148.21660542488098 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 148.24260187149048 loss tensor(0.3711, grad_fn=<NegBackward0>)\n",
            "Time 148.2718563079834 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 148.29975056648254 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 148.33394742012024 loss tensor(0.3710, grad_fn=<NegBackward0>)\n",
            "Time 148.36713647842407 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 148.394291639328 loss tensor(0.3709, grad_fn=<NegBackward0>)\n",
            "Time 148.42261958122253 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 148.4526469707489 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 148.4805507659912 loss tensor(0.3708, grad_fn=<NegBackward0>)\n",
            "Time 148.50849795341492 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 148.53543376922607 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 148.56317114830017 loss tensor(0.3707, grad_fn=<NegBackward0>)\n",
            "Time 148.5989692211151 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 148.6268928050995 loss tensor(0.3706, grad_fn=<NegBackward0>)\n",
            "Time 148.65487432479858 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 148.68312883377075 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 148.71307945251465 loss tensor(0.3705, grad_fn=<NegBackward0>)\n",
            "Time 148.74314904212952 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 148.76997303962708 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 148.80152010917664 loss tensor(0.3704, grad_fn=<NegBackward0>)\n",
            "Time 148.83822965621948 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 148.86735892295837 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 148.89603304862976 loss tensor(0.3703, grad_fn=<NegBackward0>)\n",
            "Time 148.92478251457214 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 148.95784664154053 loss tensor(0.3702, grad_fn=<NegBackward0>)\n",
            "Time 148.98575043678284 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 149.02643418312073 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 149.06189274787903 loss tensor(0.3701, grad_fn=<NegBackward0>)\n",
            "Time 149.08980464935303 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 149.11840844154358 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 149.15220046043396 loss tensor(0.3700, grad_fn=<NegBackward0>)\n",
            "Time 149.18114805221558 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 149.2097761631012 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 149.24980473518372 loss tensor(0.3699, grad_fn=<NegBackward0>)\n",
            "Time 149.28178119659424 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 149.3146014213562 loss tensor(0.3698, grad_fn=<NegBackward0>)\n",
            "Time 149.3454978466034 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 149.37346839904785 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 149.40132212638855 loss tensor(0.3697, grad_fn=<NegBackward0>)\n",
            "Time 149.42835521697998 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 149.4638156890869 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 149.4917345046997 loss tensor(0.3696, grad_fn=<NegBackward0>)\n",
            "Time 149.51986455917358 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 149.5496153831482 loss tensor(0.3695, grad_fn=<NegBackward0>)\n",
            "Time 149.58037185668945 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 149.60721278190613 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 149.63437795639038 loss tensor(0.3694, grad_fn=<NegBackward0>)\n",
            "Time 149.6609401702881 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 149.6981360912323 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 149.72752475738525 loss tensor(0.3693, grad_fn=<NegBackward0>)\n",
            "Time 149.75844359397888 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 149.78580355644226 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 149.81359219551086 loss tensor(0.3692, grad_fn=<NegBackward0>)\n",
            "Time 149.84292364120483 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 149.87713742256165 loss tensor(0.3691, grad_fn=<NegBackward0>)\n",
            "Time 149.91326808929443 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 149.94336247444153 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 149.97246313095093 loss tensor(0.3690, grad_fn=<NegBackward0>)\n",
            "Time 150.0002784729004 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 150.02988743782043 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 150.06597137451172 loss tensor(0.3689, grad_fn=<NegBackward0>)\n",
            "Time 150.09298419952393 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 150.1276240348816 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 150.15540480613708 loss tensor(0.3688, grad_fn=<NegBackward0>)\n",
            "Time 150.1828076839447 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 150.21631503105164 loss tensor(0.3687, grad_fn=<NegBackward0>)\n",
            "Time 150.24285626411438 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 150.26991271972656 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 150.29640746116638 loss tensor(0.3686, grad_fn=<NegBackward0>)\n",
            "Time 150.3235957622528 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 150.35983180999756 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 150.38649940490723 loss tensor(0.3685, grad_fn=<NegBackward0>)\n",
            "Time 150.41387486457825 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 150.44065284729004 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 150.46785759925842 loss tensor(0.3684, grad_fn=<NegBackward0>)\n",
            "Time 150.49467372894287 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 150.5214273929596 loss tensor(0.3683, grad_fn=<NegBackward0>)\n",
            "Time 150.5477979183197 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 150.5858278274536 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 150.61666250228882 loss tensor(0.3682, grad_fn=<NegBackward0>)\n",
            "Time 150.64647603034973 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 150.67414569854736 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 150.70228147506714 loss tensor(0.3681, grad_fn=<NegBackward0>)\n",
            "Time 150.73233675956726 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 150.7642114162445 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 150.80581068992615 loss tensor(0.3680, grad_fn=<NegBackward0>)\n",
            "Time 150.83378100395203 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 150.86217713356018 loss tensor(0.3679, grad_fn=<NegBackward0>)\n",
            "Time 150.89098405838013 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 150.9194324016571 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 150.94704174995422 loss tensor(0.3678, grad_fn=<NegBackward0>)\n",
            "Time 150.9738655090332 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 151.00157570838928 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 151.04051041603088 loss tensor(0.3677, grad_fn=<NegBackward0>)\n",
            "Time 151.07686161994934 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 151.10499215126038 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 151.13225269317627 loss tensor(0.3676, grad_fn=<NegBackward0>)\n",
            "Time 151.159606218338 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 151.18757939338684 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 151.21892523765564 loss tensor(0.3675, grad_fn=<NegBackward0>)\n",
            "Time 151.25534415245056 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 151.28357219696045 loss tensor(0.3674, grad_fn=<NegBackward0>)\n",
            "Time 151.31097722053528 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 151.33912181854248 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 151.3659152984619 loss tensor(0.3673, grad_fn=<NegBackward0>)\n",
            "Time 151.39310550689697 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 151.42067790031433 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 151.45085835456848 loss tensor(0.3672, grad_fn=<NegBackward0>)\n",
            "Time 151.48742699623108 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 151.51945400238037 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 151.54768538475037 loss tensor(0.3671, grad_fn=<NegBackward0>)\n",
            "Time 151.57877159118652 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 151.60766458511353 loss tensor(0.3670, grad_fn=<NegBackward0>)\n",
            "Time 151.63384556770325 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 151.66324615478516 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 151.6940200328827 loss tensor(0.3669, grad_fn=<NegBackward0>)\n",
            "Time 151.7263524532318 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 151.75602531433105 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 151.78554368019104 loss tensor(0.3668, grad_fn=<NegBackward0>)\n",
            "Time 151.81956934928894 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 151.85187077522278 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 151.8811993598938 loss tensor(0.3667, grad_fn=<NegBackward0>)\n",
            "Time 151.91688776016235 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 151.94728255271912 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 151.98362064361572 loss tensor(0.3666, grad_fn=<NegBackward0>)\n",
            "Time 152.01557183265686 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 152.04284977912903 loss tensor(0.3665, grad_fn=<NegBackward0>)\n",
            "Time 152.0793719291687 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 152.1098313331604 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 152.1489098072052 loss tensor(0.3664, grad_fn=<NegBackward0>)\n",
            "Time 152.17768597602844 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 152.2063319683075 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 152.23417901992798 loss tensor(0.3663, grad_fn=<NegBackward0>)\n",
            "Time 152.2621786594391 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 152.29046416282654 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 152.3190131187439 loss tensor(0.3662, grad_fn=<NegBackward0>)\n",
            "Time 152.34634566307068 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 152.3801040649414 loss tensor(0.3661, grad_fn=<NegBackward0>)\n",
            "Time 152.4084780216217 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 152.43524312973022 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 152.46260356903076 loss tensor(0.3660, grad_fn=<NegBackward0>)\n",
            "Time 152.4903163909912 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 152.51829886436462 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 152.54623246192932 loss tensor(0.3659, grad_fn=<NegBackward0>)\n",
            "Time 152.57435703277588 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 152.63303804397583 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 152.66184544563293 loss tensor(0.3658, grad_fn=<NegBackward0>)\n",
            "Time 152.69340896606445 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 152.72430658340454 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 152.75791716575623 loss tensor(0.3657, grad_fn=<NegBackward0>)\n",
            "Time 152.7875111103058 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 152.81667971611023 loss tensor(0.3656, grad_fn=<NegBackward0>)\n",
            "Time 152.85245633125305 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 152.8823139667511 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 152.91041231155396 loss tensor(0.3655, grad_fn=<NegBackward0>)\n",
            "Time 152.94210743904114 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 152.96888542175293 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 152.99709296226501 loss tensor(0.3654, grad_fn=<NegBackward0>)\n",
            "Time 153.03075313568115 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 153.0683572292328 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 153.10792064666748 loss tensor(0.3653, grad_fn=<NegBackward0>)\n",
            "Time 153.13573217391968 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 153.1636791229248 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 153.19247841835022 loss tensor(0.3652, grad_fn=<NegBackward0>)\n",
            "Time 153.22151374816895 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 153.25514960289001 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 153.28987455368042 loss tensor(0.3651, grad_fn=<NegBackward0>)\n",
            "Time 153.32420086860657 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 153.3514256477356 loss tensor(0.3650, grad_fn=<NegBackward0>)\n",
            "Time 153.37828516960144 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 153.40555930137634 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 153.43232703208923 loss tensor(0.3649, grad_fn=<NegBackward0>)\n",
            "Time 153.45799255371094 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 153.49084973335266 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 153.5256667137146 loss tensor(0.3648, grad_fn=<NegBackward0>)\n",
            "Time 153.56256914138794 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 153.59136724472046 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 153.62346243858337 loss tensor(0.3647, grad_fn=<NegBackward0>)\n",
            "Time 153.65595698356628 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 153.68456935882568 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 153.71945333480835 loss tensor(0.3646, grad_fn=<NegBackward0>)\n",
            "Time 153.74885034561157 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 153.77839636802673 loss tensor(0.3645, grad_fn=<NegBackward0>)\n",
            "Time 153.8065013885498 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 153.8327980041504 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 153.86351323127747 loss tensor(0.3644, grad_fn=<NegBackward0>)\n",
            "Time 153.89207196235657 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 153.92101764678955 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 153.95657444000244 loss tensor(0.3643, grad_fn=<NegBackward0>)\n",
            "Time 153.98433089256287 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 154.01378345489502 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 154.0416443347931 loss tensor(0.3642, grad_fn=<NegBackward0>)\n",
            "Time 154.06944465637207 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 154.12130451202393 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 154.1677987575531 loss tensor(0.3641, grad_fn=<NegBackward0>)\n",
            "Time 154.21485376358032 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 154.263019323349 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 154.30739665031433 loss tensor(0.3640, grad_fn=<NegBackward0>)\n",
            "Time 154.3551425933838 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 154.39454436302185 loss tensor(0.3639, grad_fn=<NegBackward0>)\n",
            "Time 154.43430185317993 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 154.4722752571106 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 154.51126551628113 loss tensor(0.3638, grad_fn=<NegBackward0>)\n",
            "Time 154.54780554771423 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 154.5907335281372 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 154.63329100608826 loss tensor(0.3637, grad_fn=<NegBackward0>)\n",
            "Time 154.6773121356964 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 154.71918058395386 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 154.76092195510864 loss tensor(0.3636, grad_fn=<NegBackward0>)\n",
            "Time 154.80844259262085 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 154.84792804718018 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 154.89023327827454 loss tensor(0.3635, grad_fn=<NegBackward0>)\n",
            "Time 154.940354347229 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 154.97931098937988 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 155.0268383026123 loss tensor(0.3634, grad_fn=<NegBackward0>)\n",
            "Time 155.0658712387085 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 155.10453462600708 loss tensor(0.3633, grad_fn=<NegBackward0>)\n",
            "Time 155.15122771263123 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 155.19051027297974 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 155.23488473892212 loss tensor(0.3632, grad_fn=<NegBackward0>)\n",
            "Time 155.27982759475708 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 155.3187141418457 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 155.36165285110474 loss tensor(0.3631, grad_fn=<NegBackward0>)\n",
            "Time 155.40612983703613 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 155.456120967865 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 155.50640320777893 loss tensor(0.3630, grad_fn=<NegBackward0>)\n",
            "Time 155.5466377735138 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 155.59014105796814 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 155.63317108154297 loss tensor(0.3629, grad_fn=<NegBackward0>)\n",
            "Time 155.68563556671143 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 155.7286536693573 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 155.77969479560852 loss tensor(0.3628, grad_fn=<NegBackward0>)\n",
            "Time 155.80917882919312 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 155.83644318580627 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 155.86537909507751 loss tensor(0.3627, grad_fn=<NegBackward0>)\n",
            "Time 155.9008276462555 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 155.9323410987854 loss tensor(0.3626, grad_fn=<NegBackward0>)\n",
            "Time 155.9602267742157 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 155.98802042007446 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 156.02278304100037 loss tensor(0.3625, grad_fn=<NegBackward0>)\n",
            "Time 156.05100417137146 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 156.07908058166504 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 156.11628031730652 loss tensor(0.3624, grad_fn=<NegBackward0>)\n",
            "Time 156.14641189575195 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 156.1841938495636 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 156.21241641044617 loss tensor(0.3623, grad_fn=<NegBackward0>)\n",
            "Time 156.24060535430908 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 156.26968598365784 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 156.29740619659424 loss tensor(0.3622, grad_fn=<NegBackward0>)\n",
            "Time 156.33778548240662 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 156.36559963226318 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 156.3961763381958 loss tensor(0.3621, grad_fn=<NegBackward0>)\n",
            "Time 156.42415833473206 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 156.45237565040588 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 156.48445463180542 loss tensor(0.3620, grad_fn=<NegBackward0>)\n",
            "Time 156.5127351284027 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 156.5428810119629 loss tensor(0.3619, grad_fn=<NegBackward0>)\n",
            "Time 156.5803782939911 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 156.60896611213684 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 156.64121270179749 loss tensor(0.3618, grad_fn=<NegBackward0>)\n",
            "Time 156.66983938217163 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 156.70142555236816 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 156.7321276664734 loss tensor(0.3617, grad_fn=<NegBackward0>)\n",
            "Time 156.77122282981873 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 156.8003969192505 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 156.8332805633545 loss tensor(0.3616, grad_fn=<NegBackward0>)\n",
            "Time 156.8626353740692 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 156.89115405082703 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 156.9196422100067 loss tensor(0.3615, grad_fn=<NegBackward0>)\n",
            "Time 156.94831800460815 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 156.98090529441833 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 157.01483154296875 loss tensor(0.3614, grad_fn=<NegBackward0>)\n",
            "Time 157.0427906513214 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 157.07068276405334 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 157.09812927246094 loss tensor(0.3613, grad_fn=<NegBackward0>)\n",
            "Time 157.1256024837494 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 157.15388560295105 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 157.19833278656006 loss tensor(0.3612, grad_fn=<NegBackward0>)\n",
            "Time 157.23335886001587 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 157.2618293762207 loss tensor(0.3611, grad_fn=<NegBackward0>)\n",
            "Time 157.293301820755 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 157.32099962234497 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 157.3485231399536 loss tensor(0.3610, grad_fn=<NegBackward0>)\n",
            "Time 157.37894701957703 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 157.41312432289124 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 157.44061183929443 loss tensor(0.3609, grad_fn=<NegBackward0>)\n",
            "Time 157.46788239479065 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 157.5005431175232 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 157.5373694896698 loss tensor(0.3608, grad_fn=<NegBackward0>)\n",
            "Time 157.56728386878967 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 157.59603881835938 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 157.62982058525085 loss tensor(0.3607, grad_fn=<NegBackward0>)\n",
            "Time 157.65975642204285 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 157.6891806125641 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 157.7160165309906 loss tensor(0.3606, grad_fn=<NegBackward0>)\n",
            "Time 157.74715900421143 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 157.77800488471985 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 157.80723428726196 loss tensor(0.3605, grad_fn=<NegBackward0>)\n",
            "Time 157.8482151031494 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 157.8784260749817 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 157.90854406356812 loss tensor(0.3604, grad_fn=<NegBackward0>)\n",
            "Time 157.93811988830566 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 157.96690368652344 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 157.99758076667786 loss tensor(0.3603, grad_fn=<NegBackward0>)\n",
            "Time 158.02758479118347 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 158.06144618988037 loss tensor(0.3602, grad_fn=<NegBackward0>)\n",
            "Time 158.09188842773438 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 158.1267569065094 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 158.15407872200012 loss tensor(0.3601, grad_fn=<NegBackward0>)\n",
            "Time 158.1820821762085 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 158.21669149398804 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 158.24422550201416 loss tensor(0.3600, grad_fn=<NegBackward0>)\n",
            "Time 158.27839541435242 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 158.30680751800537 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 158.33579230308533 loss tensor(0.3599, grad_fn=<NegBackward0>)\n",
            "Time 158.36257600784302 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 158.3891623020172 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 158.4164891242981 loss tensor(0.3598, grad_fn=<NegBackward0>)\n",
            "Time 158.44277381896973 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 158.4691617488861 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 158.50684332847595 loss tensor(0.3597, grad_fn=<NegBackward0>)\n",
            "Time 158.53796482086182 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 158.56821393966675 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 158.5980682373047 loss tensor(0.3596, grad_fn=<NegBackward0>)\n",
            "Time 158.62678933143616 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 158.65989899635315 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 158.6894211769104 loss tensor(0.3595, grad_fn=<NegBackward0>)\n",
            "Time 158.72754836082458 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 158.7578558921814 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 158.79246282577515 loss tensor(0.3594, grad_fn=<NegBackward0>)\n",
            "Time 158.82039952278137 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 158.84862685203552 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 158.8774061203003 loss tensor(0.3593, grad_fn=<NegBackward0>)\n",
            "Time 158.90524053573608 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 158.94096398353577 loss tensor(0.3592, grad_fn=<NegBackward0>)\n",
            "Time 158.97124338150024 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 159.0000343322754 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 159.02960109710693 loss tensor(0.3591, grad_fn=<NegBackward0>)\n",
            "Time 159.0575602054596 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 159.08629751205444 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 159.11432075500488 loss tensor(0.3590, grad_fn=<NegBackward0>)\n",
            "Time 159.14332914352417 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 159.18064761161804 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 159.20781016349792 loss tensor(0.3589, grad_fn=<NegBackward0>)\n",
            "Time 159.2455461025238 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 159.27459335327148 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 159.30725407600403 loss tensor(0.3588, grad_fn=<NegBackward0>)\n",
            "Time 159.33756303787231 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 159.37237811088562 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 159.40065264701843 loss tensor(0.3587, grad_fn=<NegBackward0>)\n",
            "Time 159.42922949790955 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 159.45816349983215 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 159.48749208450317 loss tensor(0.3586, grad_fn=<NegBackward0>)\n",
            "Time 159.51759362220764 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 159.54466843605042 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 159.5731475353241 loss tensor(0.3585, grad_fn=<NegBackward0>)\n",
            "Time 159.61202788352966 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 159.6422061920166 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 159.67114233970642 loss tensor(0.3584, grad_fn=<NegBackward0>)\n",
            "Time 159.69801592826843 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 159.7330412864685 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 159.76055526733398 loss tensor(0.3583, grad_fn=<NegBackward0>)\n",
            "Time 159.7983329296112 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 159.82627153396606 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 159.8542673587799 loss tensor(0.3582, grad_fn=<NegBackward0>)\n",
            "Time 159.88434743881226 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 159.9203405380249 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 159.9490385055542 loss tensor(0.3581, grad_fn=<NegBackward0>)\n",
            "Time 159.97784757614136 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 160.01648020744324 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 160.0526430606842 loss tensor(0.3580, grad_fn=<NegBackward0>)\n",
            "Time 160.08208441734314 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 160.11351990699768 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 160.14203429222107 loss tensor(0.3579, grad_fn=<NegBackward0>)\n",
            "Time 160.16939616203308 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 160.196763753891 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 160.23167967796326 loss tensor(0.3578, grad_fn=<NegBackward0>)\n",
            "Time 160.26646375656128 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 160.2945213317871 loss tensor(0.3577, grad_fn=<NegBackward0>)\n",
            "Time 160.3260223865509 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 160.35709071159363 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 160.38517117500305 loss tensor(0.3576, grad_fn=<NegBackward0>)\n",
            "Time 160.41302275657654 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 160.45183324813843 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 160.48053431510925 loss tensor(0.3575, grad_fn=<NegBackward0>)\n",
            "Time 160.5082824230194 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 160.53839468955994 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 160.5658986568451 loss tensor(0.3574, grad_fn=<NegBackward0>)\n",
            "Time 160.59592509269714 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 160.62282872200012 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 160.65006566047668 loss tensor(0.3573, grad_fn=<NegBackward0>)\n",
            "Time 160.68743681907654 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 160.71650075912476 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 160.74908661842346 loss tensor(0.3572, grad_fn=<NegBackward0>)\n",
            "Time 160.77766346931458 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 160.80390334129333 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 160.8307011127472 loss tensor(0.3571, grad_fn=<NegBackward0>)\n",
            "Time 160.85701704025269 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 160.88469648361206 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 160.918851852417 loss tensor(0.3570, grad_fn=<NegBackward0>)\n",
            "Time 160.95177125930786 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 160.9783113002777 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 161.00533318519592 loss tensor(0.3569, grad_fn=<NegBackward0>)\n",
            "Time 161.03658938407898 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 161.06408286094666 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 161.0919177532196 loss tensor(0.3568, grad_fn=<NegBackward0>)\n",
            "Time 161.12044858932495 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 161.15565752983093 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 161.18343496322632 loss tensor(0.3567, grad_fn=<NegBackward0>)\n",
            "Time 161.21161437034607 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 161.24499535560608 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 161.28050088882446 loss tensor(0.3566, grad_fn=<NegBackward0>)\n",
            "Time 161.30739879608154 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 161.34313797950745 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 161.3719654083252 loss tensor(0.3565, grad_fn=<NegBackward0>)\n",
            "Time 161.3995144367218 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 161.42894577980042 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 161.45410776138306 loss tensor(0.3564, grad_fn=<NegBackward0>)\n",
            "Time 161.48034071922302 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 161.50820517539978 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 161.5340118408203 loss tensor(0.3563, grad_fn=<NegBackward0>)\n",
            "Time 161.56877875328064 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 161.60164856910706 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 161.6354923248291 loss tensor(0.3562, grad_fn=<NegBackward0>)\n",
            "Time 161.66633677482605 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 161.69473814964294 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 161.7260880470276 loss tensor(0.3561, grad_fn=<NegBackward0>)\n",
            "Time 161.75533080101013 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 161.79455304145813 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 161.82510828971863 loss tensor(0.3560, grad_fn=<NegBackward0>)\n",
            "Time 161.85330939292908 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 161.88264346122742 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 161.91030764579773 loss tensor(0.3559, grad_fn=<NegBackward0>)\n",
            "Time 161.93842029571533 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 161.9698441028595 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 162.0001311302185 loss tensor(0.3558, grad_fn=<NegBackward0>)\n",
            "Time 162.03457236289978 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 162.0609905719757 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 162.08750939369202 loss tensor(0.3557, grad_fn=<NegBackward0>)\n",
            "Time 162.1148817539215 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 162.14262557029724 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 162.17066431045532 loss tensor(0.3556, grad_fn=<NegBackward0>)\n",
            "Time 162.1981041431427 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 162.234450340271 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 162.26519107818604 loss tensor(0.3555, grad_fn=<NegBackward0>)\n",
            "Time 162.30066561698914 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 162.33018279075623 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 162.3647975921631 loss tensor(0.3554, grad_fn=<NegBackward0>)\n",
            "Time 162.39243626594543 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 162.42063879966736 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 162.45757508277893 loss tensor(0.3553, grad_fn=<NegBackward0>)\n",
            "Time 162.48634004592896 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 162.51454663276672 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 162.5556333065033 loss tensor(0.3552, grad_fn=<NegBackward0>)\n",
            "Time 162.5852997303009 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 162.6123068332672 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 162.64283800125122 loss tensor(0.3551, grad_fn=<NegBackward0>)\n",
            "Time 162.6822865009308 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 162.71294283866882 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 162.75207948684692 loss tensor(0.3550, grad_fn=<NegBackward0>)\n",
            "Time 162.7816243171692 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 162.81171011924744 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 162.83958649635315 loss tensor(0.3549, grad_fn=<NegBackward0>)\n",
            "Time 162.87244033813477 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 162.90622353553772 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 162.93426609039307 loss tensor(0.3548, grad_fn=<NegBackward0>)\n",
            "Time 162.96196794509888 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 162.9893593788147 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 163.0192039012909 loss tensor(0.3547, grad_fn=<NegBackward0>)\n",
            "Time 163.04575848579407 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 163.0731964111328 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 163.10034942626953 loss tensor(0.3546, grad_fn=<NegBackward0>)\n",
            "Time 163.13407588005066 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 163.16127967834473 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 163.18893933296204 loss tensor(0.3545, grad_fn=<NegBackward0>)\n",
            "Time 163.21615195274353 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 163.24373722076416 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 163.27150464057922 loss tensor(0.3544, grad_fn=<NegBackward0>)\n",
            "Time 163.30689907073975 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 163.33400201797485 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 163.37203788757324 loss tensor(0.3543, grad_fn=<NegBackward0>)\n",
            "Time 163.41459155082703 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 163.44341707229614 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 163.47160148620605 loss tensor(0.3542, grad_fn=<NegBackward0>)\n",
            "Time 163.50024795532227 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 163.52887201309204 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 163.55913281440735 loss tensor(0.3541, grad_fn=<NegBackward0>)\n",
            "Time 163.60489106178284 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 163.63377261161804 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 163.6626477241516 loss tensor(0.3540, grad_fn=<NegBackward0>)\n",
            "Time 163.693865776062 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 163.72285556793213 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 163.75195980072021 loss tensor(0.3539, grad_fn=<NegBackward0>)\n",
            "Time 163.78373003005981 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 163.81963729858398 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 163.85138487815857 loss tensor(0.3538, grad_fn=<NegBackward0>)\n",
            "Time 163.87962245941162 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 163.90653824806213 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 163.93356347084045 loss tensor(0.3537, grad_fn=<NegBackward0>)\n",
            "Time 163.9649727344513 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 163.9921326637268 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 164.03568863868713 loss tensor(0.3536, grad_fn=<NegBackward0>)\n",
            "Time 164.0641040802002 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 164.09284281730652 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 164.11996698379517 loss tensor(0.3535, grad_fn=<NegBackward0>)\n",
            "Time 164.1477997303009 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 164.17432856559753 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 164.2015655040741 loss tensor(0.3534, grad_fn=<NegBackward0>)\n",
            "Time 164.22880005836487 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 164.2681484222412 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 164.3009066581726 loss tensor(0.3533, grad_fn=<NegBackward0>)\n",
            "Time 164.33164072036743 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 164.3618528842926 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 164.3894760608673 loss tensor(0.3532, grad_fn=<NegBackward0>)\n",
            "Time 164.42642998695374 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 164.45473742485046 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 164.48823475837708 loss tensor(0.3531, grad_fn=<NegBackward0>)\n",
            "Time 164.51602959632874 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 164.54331803321838 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 164.57062816619873 loss tensor(0.3530, grad_fn=<NegBackward0>)\n",
            "Time 164.59855031967163 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 164.62583327293396 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 164.6531457901001 loss tensor(0.3529, grad_fn=<NegBackward0>)\n",
            "Time 164.6838140487671 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 164.7215518951416 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 164.75393748283386 loss tensor(0.3528, grad_fn=<NegBackward0>)\n",
            "Time 164.784987449646 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 164.8152630329132 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 164.84985947608948 loss tensor(0.3527, grad_fn=<NegBackward0>)\n",
            "Time 164.88106894493103 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 164.9096405506134 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 164.94375610351562 loss tensor(0.3526, grad_fn=<NegBackward0>)\n",
            "Time 164.97350978851318 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 165.0026888847351 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 165.03341698646545 loss tensor(0.3525, grad_fn=<NegBackward0>)\n",
            "Time 165.06087183952332 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 165.0885350704193 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 165.11768078804016 loss tensor(0.3524, grad_fn=<NegBackward0>)\n",
            "Time 165.14799571037292 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 165.1817491054535 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 165.20782256126404 loss tensor(0.3523, grad_fn=<NegBackward0>)\n",
            "Time 165.23467898368835 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 165.26217937469482 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 165.28950595855713 loss tensor(0.3522, grad_fn=<NegBackward0>)\n",
            "Time 165.3311150074005 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 165.3714737892151 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 165.39760398864746 loss tensor(0.3521, grad_fn=<NegBackward0>)\n",
            "Time 165.42399430274963 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 165.4517526626587 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 165.4788041114807 loss tensor(0.3520, grad_fn=<NegBackward0>)\n",
            "Time 165.50650238990784 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 165.53293871879578 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 165.56296038627625 loss tensor(0.3519, grad_fn=<NegBackward0>)\n",
            "Time 165.59951901435852 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 165.6278374195099 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 165.65811252593994 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 165.6873972415924 loss tensor(0.3518, grad_fn=<NegBackward0>)\n",
            "Time 165.71512699127197 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 165.74888825416565 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 165.77553510665894 loss tensor(0.3517, grad_fn=<NegBackward0>)\n",
            "Time 165.8261682987213 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 165.87146854400635 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 165.91694974899292 loss tensor(0.3516, grad_fn=<NegBackward0>)\n",
            "Time 165.96263194084167 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 166.00253701210022 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 166.05571794509888 loss tensor(0.3515, grad_fn=<NegBackward0>)\n",
            "Time 166.09808230400085 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 166.13593006134033 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 166.1745159626007 loss tensor(0.3514, grad_fn=<NegBackward0>)\n",
            "Time 166.21408534049988 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 166.25284576416016 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 166.29610466957092 loss tensor(0.3513, grad_fn=<NegBackward0>)\n",
            "Time 166.33522701263428 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 166.38581919670105 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 166.42383670806885 loss tensor(0.3512, grad_fn=<NegBackward0>)\n",
            "Time 166.46433115005493 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 166.506769657135 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 166.5488154888153 loss tensor(0.3511, grad_fn=<NegBackward0>)\n",
            "Time 166.58801341056824 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 166.6321883201599 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 166.67037987709045 loss tensor(0.3510, grad_fn=<NegBackward0>)\n",
            "Time 166.71112489700317 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 166.75225377082825 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 166.79185461997986 loss tensor(0.3509, grad_fn=<NegBackward0>)\n",
            "Time 166.83633518218994 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 166.88040590286255 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 166.92612504959106 loss tensor(0.3508, grad_fn=<NegBackward0>)\n",
            "Time 166.96565890312195 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 167.00308394432068 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 167.04194116592407 loss tensor(0.3507, grad_fn=<NegBackward0>)\n",
            "Time 167.08001828193665 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 167.12016820907593 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 167.17425847053528 loss tensor(0.3506, grad_fn=<NegBackward0>)\n",
            "Time 167.22052025794983 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 167.25949215888977 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 167.30298948287964 loss tensor(0.3505, grad_fn=<NegBackward0>)\n",
            "Time 167.34537744522095 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 167.3948769569397 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 167.4400715827942 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 167.48672080039978 loss tensor(0.3504, grad_fn=<NegBackward0>)\n",
            "Time 167.51740288734436 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 167.55175876617432 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 167.5781283378601 loss tensor(0.3503, grad_fn=<NegBackward0>)\n",
            "Time 167.61050271987915 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 167.64032244682312 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 167.67276620864868 loss tensor(0.3502, grad_fn=<NegBackward0>)\n",
            "Time 167.70123672485352 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 167.73041200637817 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 167.7626416683197 loss tensor(0.3501, grad_fn=<NegBackward0>)\n",
            "Time 167.79604315757751 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 167.8331286907196 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 167.8599817752838 loss tensor(0.3500, grad_fn=<NegBackward0>)\n",
            "Time 167.89500498771667 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 167.92245936393738 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 167.94910264015198 loss tensor(0.3499, grad_fn=<NegBackward0>)\n",
            "Time 167.97682929039001 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 168.00635385513306 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 168.03915905952454 loss tensor(0.3498, grad_fn=<NegBackward0>)\n",
            "Time 168.0714259147644 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 168.09886050224304 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 168.12579703330994 loss tensor(0.3497, grad_fn=<NegBackward0>)\n",
            "Time 168.15331149101257 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 168.1872534751892 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 168.21564650535583 loss tensor(0.3496, grad_fn=<NegBackward0>)\n",
            "Time 168.24275946617126 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 168.28289246559143 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 168.31490993499756 loss tensor(0.3495, grad_fn=<NegBackward0>)\n",
            "Time 168.34413027763367 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 168.37189483642578 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 168.39862513542175 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 168.43450450897217 loss tensor(0.3494, grad_fn=<NegBackward0>)\n",
            "Time 168.46861219406128 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 168.50252556800842 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 168.53115344047546 loss tensor(0.3493, grad_fn=<NegBackward0>)\n",
            "Time 168.55878114700317 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 168.58711552619934 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 168.61501336097717 loss tensor(0.3492, grad_fn=<NegBackward0>)\n",
            "Time 168.64336156845093 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 168.67599201202393 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 168.70770502090454 loss tensor(0.3491, grad_fn=<NegBackward0>)\n",
            "Time 168.73401761054993 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 168.7612612247467 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 168.79009103775024 loss tensor(0.3490, grad_fn=<NegBackward0>)\n",
            "Time 168.82258892059326 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 168.8531904220581 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 168.88750839233398 loss tensor(0.3489, grad_fn=<NegBackward0>)\n",
            "Time 168.92034578323364 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 168.94882249832153 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 168.9771339893341 loss tensor(0.3488, grad_fn=<NegBackward0>)\n",
            "Time 169.00551223754883 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 169.0348391532898 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 169.06485438346863 loss tensor(0.3487, grad_fn=<NegBackward0>)\n",
            "Time 169.1016025543213 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 169.1312072277069 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 169.16024160385132 loss tensor(0.3486, grad_fn=<NegBackward0>)\n",
            "Time 169.18655490875244 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 169.21377658843994 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 169.24165296554565 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 169.27108883857727 loss tensor(0.3485, grad_fn=<NegBackward0>)\n",
            "Time 169.298686504364 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 169.3374421596527 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 169.3693618774414 loss tensor(0.3484, grad_fn=<NegBackward0>)\n",
            "Time 169.39793491363525 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 169.43540239334106 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 169.46455216407776 loss tensor(0.3483, grad_fn=<NegBackward0>)\n",
            "Time 169.49265217781067 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 169.52144241333008 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 169.55825114250183 loss tensor(0.3482, grad_fn=<NegBackward0>)\n",
            "Time 169.58610010147095 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 169.62011981010437 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 169.64785027503967 loss tensor(0.3481, grad_fn=<NegBackward0>)\n",
            "Time 169.67527866363525 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 169.70491933822632 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 169.73543310165405 loss tensor(0.3480, grad_fn=<NegBackward0>)\n",
            "Time 169.77123427391052 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 169.8017361164093 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 169.82858729362488 loss tensor(0.3479, grad_fn=<NegBackward0>)\n",
            "Time 169.8574721813202 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 169.88648581504822 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 169.91587376594543 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 169.9459834098816 loss tensor(0.3478, grad_fn=<NegBackward0>)\n",
            "Time 169.98107433319092 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 170.01571130752563 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 170.04275727272034 loss tensor(0.3477, grad_fn=<NegBackward0>)\n",
            "Time 170.07152557373047 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 170.0998764038086 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 170.1281509399414 loss tensor(0.3476, grad_fn=<NegBackward0>)\n",
            "Time 170.15637469291687 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 170.18713331222534 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 170.22001957893372 loss tensor(0.3475, grad_fn=<NegBackward0>)\n",
            "Time 170.24822545051575 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 170.27740478515625 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 170.3067922592163 loss tensor(0.3474, grad_fn=<NegBackward0>)\n",
            "Time 170.34218621253967 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 170.37344670295715 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 170.40999507904053 loss tensor(0.3473, grad_fn=<NegBackward0>)\n",
            "Time 170.44176650047302 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 170.47250413894653 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 170.5035262107849 loss tensor(0.3472, grad_fn=<NegBackward0>)\n",
            "Time 170.53154921531677 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 170.55880069732666 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 170.58658719062805 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 170.61975717544556 loss tensor(0.3471, grad_fn=<NegBackward0>)\n",
            "Time 170.65388989448547 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 170.68212246894836 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 170.70833277702332 loss tensor(0.3470, grad_fn=<NegBackward0>)\n",
            "Time 170.73930025100708 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 170.7711570262909 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 170.8013665676117 loss tensor(0.3469, grad_fn=<NegBackward0>)\n",
            "Time 170.83855199813843 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 170.86860513687134 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 170.90150022506714 loss tensor(0.3468, grad_fn=<NegBackward0>)\n",
            "Time 170.93030190467834 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 170.96256709098816 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 170.989825963974 loss tensor(0.3467, grad_fn=<NegBackward0>)\n",
            "Time 171.01979160308838 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 171.05957221984863 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 171.0962197780609 loss tensor(0.3466, grad_fn=<NegBackward0>)\n",
            "Time 171.1252567768097 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 171.15237164497375 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 171.1844630241394 loss tensor(0.3465, grad_fn=<NegBackward0>)\n",
            "Time 171.2147135734558 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 171.2459692955017 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 171.28347158432007 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 171.31385231018066 loss tensor(0.3464, grad_fn=<NegBackward0>)\n",
            "Time 171.34239149093628 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 171.3736174106598 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 171.40195155143738 loss tensor(0.3463, grad_fn=<NegBackward0>)\n",
            "Time 171.43118619918823 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 171.47082829475403 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 171.50587344169617 loss tensor(0.3462, grad_fn=<NegBackward0>)\n",
            "Time 171.53381776809692 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 171.5609428882599 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 171.59194016456604 loss tensor(0.3461, grad_fn=<NegBackward0>)\n",
            "Time 171.62091994285583 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 171.64899039268494 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 171.67761731147766 loss tensor(0.3460, grad_fn=<NegBackward0>)\n",
            "Time 171.7068920135498 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 171.74248123168945 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 171.7703309059143 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 171.79857969284058 loss tensor(0.3459, grad_fn=<NegBackward0>)\n",
            "Time 171.8275182247162 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 171.85703444480896 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 171.88629055023193 loss tensor(0.3458, grad_fn=<NegBackward0>)\n",
            "Time 171.9136860370636 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 171.94776844978333 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 171.97691655158997 loss tensor(0.3457, grad_fn=<NegBackward0>)\n",
            "Time 172.01525044441223 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 172.04200506210327 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 172.06949949264526 loss tensor(0.3456, grad_fn=<NegBackward0>)\n",
            "Time 172.09715294837952 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 172.12580728530884 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 172.16149950027466 loss tensor(0.3455, grad_fn=<NegBackward0>)\n",
            "Time 172.19004321098328 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 172.21808195114136 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 172.2451729774475 loss tensor(0.3454, grad_fn=<NegBackward0>)\n",
            "Time 172.2751979827881 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 172.3036298751831 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 172.3389070034027 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 172.37937879562378 loss tensor(0.3453, grad_fn=<NegBackward0>)\n",
            "Time 172.4095802307129 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 172.44055271148682 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 172.47092032432556 loss tensor(0.3452, grad_fn=<NegBackward0>)\n",
            "Time 172.50296640396118 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 172.53038144111633 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 172.56632804870605 loss tensor(0.3451, grad_fn=<NegBackward0>)\n",
            "Time 172.5946123600006 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 172.62275576591492 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 172.64922499656677 loss tensor(0.3450, grad_fn=<NegBackward0>)\n",
            "Time 172.6808533668518 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 172.70897459983826 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 172.73627352714539 loss tensor(0.3449, grad_fn=<NegBackward0>)\n",
            "Time 172.76671481132507 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 172.80544257164001 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 172.83540081977844 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 172.86735153198242 loss tensor(0.3448, grad_fn=<NegBackward0>)\n",
            "Time 172.89726996421814 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 172.92556643486023 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 172.9533088207245 loss tensor(0.3447, grad_fn=<NegBackward0>)\n",
            "Time 172.98796463012695 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 173.02892136573792 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 173.05621814727783 loss tensor(0.3446, grad_fn=<NegBackward0>)\n",
            "Time 173.0837905406952 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 173.1118049621582 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 173.13962984085083 loss tensor(0.3445, grad_fn=<NegBackward0>)\n",
            "Time 173.16746926307678 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 173.20184779167175 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 173.22935557365417 loss tensor(0.3444, grad_fn=<NegBackward0>)\n",
            "Time 173.2568657398224 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 173.28485536575317 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 173.31231045722961 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 173.34191226959229 loss tensor(0.3443, grad_fn=<NegBackward0>)\n",
            "Time 173.37318468093872 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 173.4025149345398 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 173.44650173187256 loss tensor(0.3442, grad_fn=<NegBackward0>)\n",
            "Time 173.4739260673523 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 173.51149225234985 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 173.53907251358032 loss tensor(0.3441, grad_fn=<NegBackward0>)\n",
            "Time 173.56661081314087 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 173.59410429000854 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 173.62887573242188 loss tensor(0.3440, grad_fn=<NegBackward0>)\n",
            "Time 173.6560878753662 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 173.68345999717712 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 173.71072053909302 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 173.73997163772583 loss tensor(0.3439, grad_fn=<NegBackward0>)\n",
            "Time 173.77342772483826 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 173.8025062084198 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 173.83770442008972 loss tensor(0.3438, grad_fn=<NegBackward0>)\n",
            "Time 173.87237858772278 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 173.91688537597656 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 173.94487118721008 loss tensor(0.3437, grad_fn=<NegBackward0>)\n",
            "Time 173.97400999069214 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 174.0021734237671 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 174.03954768180847 loss tensor(0.3436, grad_fn=<NegBackward0>)\n",
            "Time 174.07623052597046 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 174.10526657104492 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 174.13389134407043 loss tensor(0.3435, grad_fn=<NegBackward0>)\n",
            "Time 174.16219234466553 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 174.1905586719513 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 174.21897983551025 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 174.24690341949463 loss tensor(0.3434, grad_fn=<NegBackward0>)\n",
            "Time 174.27608180046082 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 174.3148548603058 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 174.34817624092102 loss tensor(0.3433, grad_fn=<NegBackward0>)\n",
            "Time 174.37824606895447 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 174.40846610069275 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 174.43991947174072 loss tensor(0.3432, grad_fn=<NegBackward0>)\n",
            "Time 174.4698085784912 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 174.5106816291809 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 174.5429446697235 loss tensor(0.3431, grad_fn=<NegBackward0>)\n",
            "Time 174.57128190994263 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 174.59839153289795 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 174.62623715400696 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 174.66017842292786 loss tensor(0.3430, grad_fn=<NegBackward0>)\n",
            "Time 174.69140219688416 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 174.7293357849121 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 174.75989532470703 loss tensor(0.3429, grad_fn=<NegBackward0>)\n",
            "Time 174.7880482673645 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 174.8155345916748 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 174.84292674064636 loss tensor(0.3428, grad_fn=<NegBackward0>)\n",
            "Time 174.8735227584839 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 174.90240859985352 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 174.9315004348755 loss tensor(0.3427, grad_fn=<NegBackward0>)\n",
            "Time 174.96281266212463 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 174.99028944969177 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 175.01922249794006 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 175.05082058906555 loss tensor(0.3426, grad_fn=<NegBackward0>)\n",
            "Time 175.07745742797852 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 175.10550713539124 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 175.1347439289093 loss tensor(0.3425, grad_fn=<NegBackward0>)\n",
            "Time 175.1706883907318 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 175.1982982158661 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 175.22695422172546 loss tensor(0.3424, grad_fn=<NegBackward0>)\n",
            "Time 175.2554633617401 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 175.28449010849 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 175.3112609386444 loss tensor(0.3423, grad_fn=<NegBackward0>)\n",
            "Time 175.33781933784485 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 175.37202763557434 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 175.4102704524994 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 175.43810725212097 loss tensor(0.3422, grad_fn=<NegBackward0>)\n",
            "Time 175.4647421836853 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 175.4925684928894 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 175.5272500514984 loss tensor(0.3421, grad_fn=<NegBackward0>)\n",
            "Time 175.55463886260986 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 175.59079790115356 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 175.6201572418213 loss tensor(0.3420, grad_fn=<NegBackward0>)\n",
            "Time 175.646968126297 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 175.67395853996277 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 175.70113229751587 loss tensor(0.3419, grad_fn=<NegBackward0>)\n",
            "Time 175.72949838638306 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 175.75597047805786 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 175.78532791137695 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 175.82362031936646 loss tensor(0.3418, grad_fn=<NegBackward0>)\n",
            "Time 175.85049033164978 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 175.88316822052002 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 175.9092617034912 loss tensor(0.3417, grad_fn=<NegBackward0>)\n",
            "Time 175.93780374526978 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 175.96580910682678 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 175.99226260185242 loss tensor(0.3416, grad_fn=<NegBackward0>)\n",
            "Time 176.0217673778534 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 176.06246829032898 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 176.08918476104736 loss tensor(0.3415, grad_fn=<NegBackward0>)\n",
            "Time 176.11476254463196 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 176.1416642665863 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 176.16885447502136 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 176.1961386203766 loss tensor(0.3414, grad_fn=<NegBackward0>)\n",
            "Time 176.22331953048706 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 176.2542929649353 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 176.29496121406555 loss tensor(0.3413, grad_fn=<NegBackward0>)\n",
            "Time 176.32323598861694 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 176.35167264938354 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 176.38200163841248 loss tensor(0.3412, grad_fn=<NegBackward0>)\n",
            "Time 176.41527104377747 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 176.44550848007202 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 176.47402238845825 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 176.5086965560913 loss tensor(0.3411, grad_fn=<NegBackward0>)\n",
            "Time 176.54438495635986 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 176.57560062408447 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 176.60567665100098 loss tensor(0.3410, grad_fn=<NegBackward0>)\n",
            "Time 176.63427734375 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 176.66256976127625 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 176.69479823112488 loss tensor(0.3409, grad_fn=<NegBackward0>)\n",
            "Time 176.7313961982727 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 176.760835647583 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 176.79089665412903 loss tensor(0.3408, grad_fn=<NegBackward0>)\n",
            "Time 176.82194018363953 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 176.85476922988892 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 176.89127779006958 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 176.92885446548462 loss tensor(0.3407, grad_fn=<NegBackward0>)\n",
            "Time 176.9696922302246 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 177.00135135650635 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 177.03643822669983 loss tensor(0.3406, grad_fn=<NegBackward0>)\n",
            "Time 177.06471824645996 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 177.09281587600708 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 177.12488460540771 loss tensor(0.3405, grad_fn=<NegBackward0>)\n",
            "Time 177.15367460250854 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 177.1909294128418 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 177.21923995018005 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 177.2471845149994 loss tensor(0.3404, grad_fn=<NegBackward0>)\n",
            "Time 177.2754385471344 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 177.30430507659912 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 177.33850026130676 loss tensor(0.3403, grad_fn=<NegBackward0>)\n",
            "Time 177.36719155311584 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 177.40619230270386 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 177.43506693840027 loss tensor(0.3402, grad_fn=<NegBackward0>)\n",
            "Time 177.46116662025452 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 177.49479007720947 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 177.54084587097168 loss tensor(0.3401, grad_fn=<NegBackward0>)\n",
            "Time 177.59604001045227 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 177.6540915966034 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 177.6960253715515 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 177.73761653900146 loss tensor(0.3400, grad_fn=<NegBackward0>)\n",
            "Time 177.7827136516571 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 177.82089757919312 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 177.86737990379333 loss tensor(0.3399, grad_fn=<NegBackward0>)\n",
            "Time 177.9088695049286 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 177.94658637046814 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 177.98527264595032 loss tensor(0.3398, grad_fn=<NegBackward0>)\n",
            "Time 178.02556490898132 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 178.06414103507996 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 178.1098620891571 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 178.14813137054443 loss tensor(0.3397, grad_fn=<NegBackward0>)\n",
            "Time 178.1884639263153 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 178.22684383392334 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 178.2715437412262 loss tensor(0.3396, grad_fn=<NegBackward0>)\n",
            "Time 178.3207552433014 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 178.36573028564453 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 178.40625882148743 loss tensor(0.3395, grad_fn=<NegBackward0>)\n",
            "Time 178.44653487205505 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 178.48416566848755 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 178.52128505706787 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 178.5871171951294 loss tensor(0.3394, grad_fn=<NegBackward0>)\n",
            "Time 178.63925957679749 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 178.68090558052063 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 178.72166275978088 loss tensor(0.3393, grad_fn=<NegBackward0>)\n",
            "Time 178.76437067985535 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 178.81159019470215 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 178.8576467037201 loss tensor(0.3392, grad_fn=<NegBackward0>)\n",
            "Time 178.90334486961365 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 178.9458613395691 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 178.99444723129272 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 179.0365126132965 loss tensor(0.3391, grad_fn=<NegBackward0>)\n",
            "Time 179.0759675502777 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 179.12371802330017 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 179.15204620361328 loss tensor(0.3390, grad_fn=<NegBackward0>)\n",
            "Time 179.17991971969604 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 179.2137689590454 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 179.24233555793762 loss tensor(0.3389, grad_fn=<NegBackward0>)\n",
            "Time 179.27299523353577 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 179.3003261089325 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 179.32784748077393 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 179.3562605381012 loss tensor(0.3388, grad_fn=<NegBackward0>)\n",
            "Time 179.3873405456543 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 179.41644978523254 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 179.44912719726562 loss tensor(0.3387, grad_fn=<NegBackward0>)\n",
            "Time 179.47856783866882 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 179.50597143173218 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 179.5334894657135 loss tensor(0.3386, grad_fn=<NegBackward0>)\n",
            "Time 179.5627737045288 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 179.5950047969818 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 179.63184118270874 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 179.66782975196838 loss tensor(0.3385, grad_fn=<NegBackward0>)\n",
            "Time 179.69524812698364 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 179.72823786735535 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 179.7574532032013 loss tensor(0.3384, grad_fn=<NegBackward0>)\n",
            "Time 179.7879638671875 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 179.81669807434082 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 179.85213160514832 loss tensor(0.3383, grad_fn=<NegBackward0>)\n",
            "Time 179.88584399223328 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 179.91630601882935 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 179.944810628891 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 179.97511339187622 loss tensor(0.3382, grad_fn=<NegBackward0>)\n",
            "Time 180.0030837059021 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 180.0352394580841 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 180.07081365585327 loss tensor(0.3381, grad_fn=<NegBackward0>)\n",
            "Time 180.099693775177 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 180.12724614143372 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 180.1547145843506 loss tensor(0.3380, grad_fn=<NegBackward0>)\n",
            "Time 180.18213605880737 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 180.209459066391 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 180.2367968559265 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 180.26488995552063 loss tensor(0.3379, grad_fn=<NegBackward0>)\n",
            "Time 180.29939723014832 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 180.32858180999756 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 180.35624623298645 loss tensor(0.3378, grad_fn=<NegBackward0>)\n",
            "Time 180.38594460487366 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 180.41333961486816 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 180.44116353988647 loss tensor(0.3377, grad_fn=<NegBackward0>)\n",
            "Time 180.46795797348022 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 180.49531650543213 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 180.53732323646545 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 180.5648593902588 loss tensor(0.3376, grad_fn=<NegBackward0>)\n",
            "Time 180.5927505493164 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 180.6208691596985 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 180.65020084381104 loss tensor(0.3375, grad_fn=<NegBackward0>)\n",
            "Time 180.68401074409485 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 180.713214635849 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 180.74736309051514 loss tensor(0.3374, grad_fn=<NegBackward0>)\n",
            "Time 180.78346943855286 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 180.81290316581726 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 180.84241843223572 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 180.8813898563385 loss tensor(0.3373, grad_fn=<NegBackward0>)\n",
            "Time 180.91256499290466 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 180.94019269943237 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 180.97424006462097 loss tensor(0.3372, grad_fn=<NegBackward0>)\n",
            "Time 181.0011670589447 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 181.0287733078003 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 181.05442023277283 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 181.08516597747803 loss tensor(0.3371, grad_fn=<NegBackward0>)\n",
            "Time 181.11507201194763 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 181.1417579650879 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 181.16903710365295 loss tensor(0.3370, grad_fn=<NegBackward0>)\n",
            "Time 181.212575674057 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 181.24034762382507 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 181.26833868026733 loss tensor(0.3369, grad_fn=<NegBackward0>)\n",
            "Time 181.2966651916504 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 181.32448077201843 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 181.3521134853363 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 181.38209700584412 loss tensor(0.3368, grad_fn=<NegBackward0>)\n",
            "Time 181.40992712974548 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 181.44599437713623 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 181.47348403930664 loss tensor(0.3367, grad_fn=<NegBackward0>)\n",
            "Time 181.50651478767395 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 181.53600811958313 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 181.56339502334595 loss tensor(0.3366, grad_fn=<NegBackward0>)\n",
            "Time 181.5937523841858 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 181.6215798854828 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 181.65774607658386 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 181.6961498260498 loss tensor(0.3365, grad_fn=<NegBackward0>)\n",
            "Time 181.7242374420166 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 181.75356340408325 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 181.78254342079163 loss tensor(0.3364, grad_fn=<NegBackward0>)\n",
            "Time 181.81084966659546 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 181.83816719055176 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 181.87283611297607 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 181.90248560905457 loss tensor(0.3363, grad_fn=<NegBackward0>)\n",
            "Time 181.93845462799072 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 181.96629357337952 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 181.99386954307556 loss tensor(0.3362, grad_fn=<NegBackward0>)\n",
            "Time 182.02325749397278 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 182.05060124397278 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 182.08286881446838 loss tensor(0.3361, grad_fn=<NegBackward0>)\n",
            "Time 182.11088728904724 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 182.13818836212158 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 182.16526126861572 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 182.1928207874298 loss tensor(0.3360, grad_fn=<NegBackward0>)\n",
            "Time 182.22023749351501 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 182.24823832511902 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 182.27593231201172 loss tensor(0.3359, grad_fn=<NegBackward0>)\n",
            "Time 182.31272077560425 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 182.34082198143005 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 182.3688805103302 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 182.39814925193787 loss tensor(0.3358, grad_fn=<NegBackward0>)\n",
            "Time 182.4255018234253 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 182.45301938056946 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 182.480788230896 loss tensor(0.3357, grad_fn=<NegBackward0>)\n",
            "Time 182.5086431503296 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 182.54544878005981 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 182.5733983516693 loss tensor(0.3356, grad_fn=<NegBackward0>)\n",
            "Time 182.6008870601654 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 182.62798070907593 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 182.66230988502502 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 182.70068907737732 loss tensor(0.3355, grad_fn=<NegBackward0>)\n",
            "Time 182.73236513137817 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 182.76670336723328 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 182.80131840705872 loss tensor(0.3354, grad_fn=<NegBackward0>)\n",
            "Time 182.83106589317322 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 182.85937094688416 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 182.88855075836182 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 182.92056894302368 loss tensor(0.3353, grad_fn=<NegBackward0>)\n",
            "Time 182.94883561134338 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 182.9907248020172 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 183.02109789848328 loss tensor(0.3352, grad_fn=<NegBackward0>)\n",
            "Time 183.0480887889862 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 183.07893013954163 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 183.109548330307 loss tensor(0.3351, grad_fn=<NegBackward0>)\n",
            "Time 183.13949608802795 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 183.16874480247498 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 183.20564556121826 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 183.23743104934692 loss tensor(0.3350, grad_fn=<NegBackward0>)\n",
            "Time 183.26919794082642 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 183.29875946044922 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 183.32653617858887 loss tensor(0.3349, grad_fn=<NegBackward0>)\n",
            "Time 183.35526943206787 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 183.38770532608032 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 183.42335510253906 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 183.45030784606934 loss tensor(0.3348, grad_fn=<NegBackward0>)\n",
            "Time 183.47760128974915 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 183.50566339492798 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 183.53349328041077 loss tensor(0.3347, grad_fn=<NegBackward0>)\n",
            "Time 183.5615839958191 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 183.58953881263733 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 183.61959743499756 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 183.66507387161255 loss tensor(0.3346, grad_fn=<NegBackward0>)\n",
            "Time 183.69686079025269 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 183.73664355278015 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 183.76345086097717 loss tensor(0.3345, grad_fn=<NegBackward0>)\n",
            "Time 183.7929346561432 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 183.8195400238037 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 183.847021818161 loss tensor(0.3344, grad_fn=<NegBackward0>)\n",
            "Time 183.88714861869812 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 183.91936230659485 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 183.9455051422119 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 183.97811818122864 loss tensor(0.3343, grad_fn=<NegBackward0>)\n",
            "Time 184.00535368919373 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 184.03361225128174 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 184.06036734580994 loss tensor(0.3342, grad_fn=<NegBackward0>)\n",
            "Time 184.08744025230408 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 184.12116289138794 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 184.14663076400757 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 184.17271900177002 loss tensor(0.3341, grad_fn=<NegBackward0>)\n",
            "Time 184.20196843147278 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 184.23013925552368 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 184.25955843925476 loss tensor(0.3340, grad_fn=<NegBackward0>)\n",
            "Time 184.2878839969635 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 184.32707333564758 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 184.36880350112915 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 184.40097761154175 loss tensor(0.3339, grad_fn=<NegBackward0>)\n",
            "Time 184.42759943008423 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 184.45533442497253 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 184.48327898979187 loss tensor(0.3338, grad_fn=<NegBackward0>)\n",
            "Time 184.51067209243774 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 184.54585027694702 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 184.57341742515564 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 184.60430526733398 loss tensor(0.3337, grad_fn=<NegBackward0>)\n",
            "Time 184.6305639743805 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 184.65944623947144 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 184.69471955299377 loss tensor(0.3336, grad_fn=<NegBackward0>)\n",
            "Time 184.73115301132202 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 184.76708221435547 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 184.79588294029236 loss tensor(0.3335, grad_fn=<NegBackward0>)\n",
            "Time 184.82294249534607 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 184.85069870948792 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 184.88054728507996 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 184.9083433151245 loss tensor(0.3334, grad_fn=<NegBackward0>)\n",
            "Time 184.9381399154663 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 184.96601676940918 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 185.0029799938202 loss tensor(0.3333, grad_fn=<NegBackward0>)\n",
            "Time 185.03447127342224 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 185.062397480011 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 185.09070301055908 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 185.11876249313354 loss tensor(0.3332, grad_fn=<NegBackward0>)\n",
            "Time 185.14656710624695 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 185.17465472221375 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 185.20279383659363 loss tensor(0.3331, grad_fn=<NegBackward0>)\n",
            "Time 185.23842597007751 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 185.2655692100525 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 185.29441785812378 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 185.32128500938416 loss tensor(0.3330, grad_fn=<NegBackward0>)\n",
            "Time 185.35070061683655 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 185.37892961502075 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 185.41650795936584 loss tensor(0.3329, grad_fn=<NegBackward0>)\n",
            "Time 185.45190811157227 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 185.48329544067383 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 185.51286625862122 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 185.54119062423706 loss tensor(0.3328, grad_fn=<NegBackward0>)\n",
            "Time 185.5695300102234 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 185.59834599494934 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 185.62560057640076 loss tensor(0.3327, grad_fn=<NegBackward0>)\n",
            "Time 185.6525363922119 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 185.68661618232727 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 185.71403121948242 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 185.74985647201538 loss tensor(0.3326, grad_fn=<NegBackward0>)\n",
            "Time 185.7784972190857 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 185.81222939491272 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 185.8416748046875 loss tensor(0.3325, grad_fn=<NegBackward0>)\n",
            "Time 185.87610793113708 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 185.9038815498352 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 185.9340784549713 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 185.95995450019836 loss tensor(0.3324, grad_fn=<NegBackward0>)\n",
            "Time 185.98661637306213 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 186.01580715179443 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 186.04225492477417 loss tensor(0.3323, grad_fn=<NegBackward0>)\n",
            "Time 186.0684769153595 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 186.10400581359863 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 186.136328458786 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 186.16238570213318 loss tensor(0.3322, grad_fn=<NegBackward0>)\n",
            "Time 186.18957424163818 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 186.21611618995667 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 186.2436077594757 loss tensor(0.3321, grad_fn=<NegBackward0>)\n",
            "Time 186.27323961257935 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 186.30220103263855 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 186.3360719680786 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 186.36365127563477 loss tensor(0.3320, grad_fn=<NegBackward0>)\n",
            "Time 186.393394947052 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 186.4221019744873 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 186.4518814086914 loss tensor(0.3319, grad_fn=<NegBackward0>)\n",
            "Time 186.4802701473236 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 186.50818991661072 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 186.5361943244934 loss tensor(0.3318, grad_fn=<NegBackward0>)\n",
            "Time 186.5780324935913 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 186.60454750061035 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 186.63148832321167 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 186.6581678390503 loss tensor(0.3317, grad_fn=<NegBackward0>)\n",
            "Time 186.68519353866577 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 186.71431350708008 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 186.74940657615662 loss tensor(0.3316, grad_fn=<NegBackward0>)\n",
            "Time 186.7901644706726 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 186.81732177734375 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 186.8459599018097 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 186.87447047233582 loss tensor(0.3315, grad_fn=<NegBackward0>)\n",
            "Time 186.9033544063568 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 186.93353271484375 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 186.96803188323975 loss tensor(0.3314, grad_fn=<NegBackward0>)\n",
            "Time 186.9955334663391 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 187.02744936943054 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 187.05397963523865 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 187.08007335662842 loss tensor(0.3313, grad_fn=<NegBackward0>)\n",
            "Time 187.10663628578186 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 187.1420168876648 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 187.17140245437622 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 187.21064257621765 loss tensor(0.3312, grad_fn=<NegBackward0>)\n",
            "Time 187.23873233795166 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 187.26699352264404 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 187.29567432403564 loss tensor(0.3311, grad_fn=<NegBackward0>)\n",
            "Time 187.32526564598083 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 187.35286569595337 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 187.39286160469055 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 187.42140793800354 loss tensor(0.3310, grad_fn=<NegBackward0>)\n",
            "Time 187.44922494888306 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 187.47671031951904 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 187.50617146492004 loss tensor(0.3309, grad_fn=<NegBackward0>)\n",
            "Time 187.53468656539917 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 187.5611231327057 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 187.5953402519226 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 187.63161730766296 loss tensor(0.3308, grad_fn=<NegBackward0>)\n",
            "Time 187.66141510009766 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 187.69092559814453 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 187.72045016288757 loss tensor(0.3307, grad_fn=<NegBackward0>)\n",
            "Time 187.75263118743896 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 187.79101991653442 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 187.82997798919678 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 187.85949873924255 loss tensor(0.3306, grad_fn=<NegBackward0>)\n",
            "Time 187.88926315307617 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 187.9233045578003 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 187.95210194587708 loss tensor(0.3305, grad_fn=<NegBackward0>)\n",
            "Time 187.98041582107544 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 188.00971388816833 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 188.04466724395752 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 188.07444787025452 loss tensor(0.3304, grad_fn=<NegBackward0>)\n",
            "Time 188.1062572002411 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 188.13448071479797 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 188.16524386405945 loss tensor(0.3303, grad_fn=<NegBackward0>)\n",
            "Time 188.19525265693665 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 188.22835278511047 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 188.26392698287964 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 188.2918918132782 loss tensor(0.3302, grad_fn=<NegBackward0>)\n",
            "Time 188.3204951286316 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 188.3508369922638 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 188.3789083957672 loss tensor(0.3301, grad_fn=<NegBackward0>)\n",
            "Time 188.40679216384888 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 188.43319749832153 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 188.4599039554596 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 188.49518299102783 loss tensor(0.3300, grad_fn=<NegBackward0>)\n",
            "Time 188.52268481254578 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 188.55528473854065 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 188.58563351631165 loss tensor(0.3299, grad_fn=<NegBackward0>)\n",
            "Time 188.6142599582672 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 188.64140009880066 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 188.66897988319397 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 188.69865655899048 loss tensor(0.3298, grad_fn=<NegBackward0>)\n",
            "Time 188.73230004310608 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 188.7603244781494 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 188.7901246547699 loss tensor(0.3297, grad_fn=<NegBackward0>)\n",
            "Time 188.82815980911255 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 188.85759615898132 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 188.88651156425476 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 188.9229030609131 loss tensor(0.3296, grad_fn=<NegBackward0>)\n",
            "Time 188.95299863815308 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 188.98071599006653 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 189.00994539260864 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 189.03736758232117 loss tensor(0.3295, grad_fn=<NegBackward0>)\n",
            "Time 189.06481456756592 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 189.09261202812195 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 189.120441198349 loss tensor(0.3294, grad_fn=<NegBackward0>)\n",
            "Time 189.17694330215454 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 189.22260761260986 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 189.27353811264038 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 189.3186342716217 loss tensor(0.3293, grad_fn=<NegBackward0>)\n",
            "Time 189.35998249053955 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 189.40720963478088 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 189.44985270500183 loss tensor(0.3292, grad_fn=<NegBackward0>)\n",
            "Time 189.48761677742004 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 189.52547883987427 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 189.5623333454132 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 189.59952855110168 loss tensor(0.3291, grad_fn=<NegBackward0>)\n",
            "Time 189.6403501033783 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 189.6809914112091 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 189.72385120391846 loss tensor(0.3290, grad_fn=<NegBackward0>)\n",
            "Time 189.76611948013306 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 189.804869890213 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 189.85641884803772 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 189.8986439704895 loss tensor(0.3289, grad_fn=<NegBackward0>)\n",
            "Time 189.94129037857056 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 189.98646426200867 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 190.02771830558777 loss tensor(0.3288, grad_fn=<NegBackward0>)\n",
            "Time 190.0752468109131 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 190.11788415908813 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 190.1573212146759 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 190.19611406326294 loss tensor(0.3287, grad_fn=<NegBackward0>)\n",
            "Time 190.23682522773743 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 190.27572083473206 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 190.32428979873657 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 190.36222314834595 loss tensor(0.3286, grad_fn=<NegBackward0>)\n",
            "Time 190.40221977233887 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 190.44010853767395 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 190.49168229103088 loss tensor(0.3285, grad_fn=<NegBackward0>)\n",
            "Time 190.54127883911133 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 190.57972741127014 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 190.62892532348633 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 190.67742204666138 loss tensor(0.3284, grad_fn=<NegBackward0>)\n",
            "Time 190.72804760932922 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 190.76880073547363 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 190.81394839286804 loss tensor(0.3283, grad_fn=<NegBackward0>)\n",
            "Time 190.84233140945435 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 190.8801622390747 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 190.91282963752747 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 190.95528197288513 loss tensor(0.3282, grad_fn=<NegBackward0>)\n",
            "Time 190.98962879180908 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 191.02023601531982 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 191.04927015304565 loss tensor(0.3281, grad_fn=<NegBackward0>)\n",
            "Time 191.07840275764465 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 191.10795283317566 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 191.1366662979126 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 191.17232990264893 loss tensor(0.3280, grad_fn=<NegBackward0>)\n",
            "Time 191.20239973068237 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 191.23233270645142 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 191.2642092704773 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 191.2923789024353 loss tensor(0.3279, grad_fn=<NegBackward0>)\n",
            "Time 191.32148480415344 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 191.35215830802917 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 191.38657760620117 loss tensor(0.3278, grad_fn=<NegBackward0>)\n",
            "Time 191.41754388809204 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 191.44559907913208 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 191.47384786605835 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 191.50221252441406 loss tensor(0.3277, grad_fn=<NegBackward0>)\n",
            "Time 191.5323588848114 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 191.56195735931396 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 191.60247349739075 loss tensor(0.3276, grad_fn=<NegBackward0>)\n",
            "Time 191.63009452819824 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 191.65925216674805 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 191.68959140777588 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 191.7196695804596 loss tensor(0.3275, grad_fn=<NegBackward0>)\n",
            "Time 191.75078773498535 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 191.78167748451233 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 191.81964588165283 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 191.8475399017334 loss tensor(0.3274, grad_fn=<NegBackward0>)\n",
            "Time 191.88577127456665 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 191.9145472049713 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 191.94268345832825 loss tensor(0.3273, grad_fn=<NegBackward0>)\n",
            "Time 191.97807717323303 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 192.0063784122467 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 192.04267263412476 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 192.07179760932922 loss tensor(0.3272, grad_fn=<NegBackward0>)\n",
            "Time 192.10047960281372 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 192.13264346122742 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 192.16175413131714 loss tensor(0.3271, grad_fn=<NegBackward0>)\n",
            "Time 192.18971991539001 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 192.2173092365265 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 192.25797581672668 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 192.2868950366974 loss tensor(0.3270, grad_fn=<NegBackward0>)\n",
            "Time 192.31563305854797 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 192.3448348045349 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 192.37313961982727 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 192.40263199806213 loss tensor(0.3269, grad_fn=<NegBackward0>)\n",
            "Time 192.43186283111572 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 192.4611828327179 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 192.49724054336548 loss tensor(0.3268, grad_fn=<NegBackward0>)\n",
            "Time 192.52488565444946 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 192.55919551849365 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 192.58840370178223 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 192.61667370796204 loss tensor(0.3267, grad_fn=<NegBackward0>)\n",
            "Time 192.64712381362915 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 192.68229174613953 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 192.70912504196167 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 192.74024987220764 loss tensor(0.3266, grad_fn=<NegBackward0>)\n",
            "Time 192.7702076435089 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 192.79808807373047 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 192.82502102851868 loss tensor(0.3265, grad_fn=<NegBackward0>)\n",
            "Time 192.85149836540222 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 192.88766407966614 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 192.930837392807 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 192.96017909049988 loss tensor(0.3264, grad_fn=<NegBackward0>)\n",
            "Time 192.99290657043457 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 193.02601146697998 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 193.05326771736145 loss tensor(0.3263, grad_fn=<NegBackward0>)\n",
            "Time 193.08138751983643 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 193.11963891983032 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 193.14871072769165 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 193.18217825889587 loss tensor(0.3262, grad_fn=<NegBackward0>)\n",
            "Time 193.21189498901367 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 193.24070167541504 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 193.26880764961243 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 193.2966296672821 loss tensor(0.3261, grad_fn=<NegBackward0>)\n",
            "Time 193.3303303718567 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 193.35961294174194 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 193.3894739151001 loss tensor(0.3260, grad_fn=<NegBackward0>)\n",
            "Time 193.41769909858704 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 193.44710659980774 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 193.47455883026123 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 193.50226521492004 loss tensor(0.3259, grad_fn=<NegBackward0>)\n",
            "Time 193.52992057800293 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 193.56687021255493 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 193.59462976455688 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 193.62483048439026 loss tensor(0.3258, grad_fn=<NegBackward0>)\n",
            "Time 193.65240454673767 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 193.68126773834229 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 193.7090437412262 loss tensor(0.3257, grad_fn=<NegBackward0>)\n",
            "Time 193.73836421966553 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 193.7657172679901 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 193.80810952186584 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 193.8352336883545 loss tensor(0.3256, grad_fn=<NegBackward0>)\n",
            "Time 193.8678936958313 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 193.8989658355713 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 193.93584656715393 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 193.96443891525269 loss tensor(0.3255, grad_fn=<NegBackward0>)\n",
            "Time 193.9938018321991 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 194.03090953826904 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 194.0598976612091 loss tensor(0.3254, grad_fn=<NegBackward0>)\n",
            "Time 194.08786392211914 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 194.12232971191406 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 194.14901447296143 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 194.1779601573944 loss tensor(0.3253, grad_fn=<NegBackward0>)\n",
            "Time 194.20922231674194 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 194.24569725990295 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 194.2742784023285 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 194.3069429397583 loss tensor(0.3252, grad_fn=<NegBackward0>)\n",
            "Time 194.33650422096252 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 194.36469745635986 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 194.39311861991882 loss tensor(0.3251, grad_fn=<NegBackward0>)\n",
            "Time 194.42023849487305 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 194.44893383979797 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 194.4820384979248 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 194.50822591781616 loss tensor(0.3250, grad_fn=<NegBackward0>)\n",
            "Time 194.54385995864868 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 194.5700170993805 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 194.60135769844055 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 194.62898445129395 loss tensor(0.3249, grad_fn=<NegBackward0>)\n",
            "Time 194.6576066017151 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 194.6928071975708 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 194.7193319797516 loss tensor(0.3248, grad_fn=<NegBackward0>)\n",
            "Time 194.7464542388916 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 194.77434754371643 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 194.80587005615234 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 194.83484625816345 loss tensor(0.3247, grad_fn=<NegBackward0>)\n",
            "Time 194.86403799057007 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 194.899822473526 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 194.92835402488708 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 194.98165488243103 loss tensor(0.3246, grad_fn=<NegBackward0>)\n",
            "Time 195.00979828834534 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 195.03725266456604 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 195.0689733028412 loss tensor(0.3245, grad_fn=<NegBackward0>)\n",
            "Time 195.10048937797546 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 195.13598036766052 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 195.16317009925842 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 195.19265794754028 loss tensor(0.3244, grad_fn=<NegBackward0>)\n",
            "Time 195.2206175327301 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 195.24834513664246 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 195.27671313285828 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 195.30403876304626 loss tensor(0.3243, grad_fn=<NegBackward0>)\n",
            "Time 195.34016513824463 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 195.36796712875366 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 195.39698910713196 loss tensor(0.3242, grad_fn=<NegBackward0>)\n",
            "Time 195.42533659934998 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 195.45346546173096 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 195.48118233680725 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 195.5085039138794 loss tensor(0.3241, grad_fn=<NegBackward0>)\n",
            "Time 195.53633785247803 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 195.57278490066528 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 195.6008677482605 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 195.62879371643066 loss tensor(0.3240, grad_fn=<NegBackward0>)\n",
            "Time 195.6562910079956 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 195.68445897102356 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 195.71282839775085 loss tensor(0.3239, grad_fn=<NegBackward0>)\n",
            "Time 195.74464678764343 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 195.77316665649414 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 195.8107409477234 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 195.84108591079712 loss tensor(0.3238, grad_fn=<NegBackward0>)\n",
            "Time 195.8718559741974 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 195.90010690689087 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 195.92758321762085 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 195.95653533935547 loss tensor(0.3237, grad_fn=<NegBackward0>)\n",
            "Time 195.99585390090942 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 196.03722405433655 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 196.06697058677673 loss tensor(0.3236, grad_fn=<NegBackward0>)\n",
            "Time 196.09453463554382 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 196.12195944786072 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 196.14826679229736 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 196.17491245269775 loss tensor(0.3235, grad_fn=<NegBackward0>)\n",
            "Time 196.20553064346313 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 196.23489665985107 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 196.27234864234924 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 196.30115747451782 loss tensor(0.3234, grad_fn=<NegBackward0>)\n",
            "Time 196.33358716964722 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 196.3639373779297 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 196.40022492408752 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 196.42861676216125 loss tensor(0.3233, grad_fn=<NegBackward0>)\n",
            "Time 196.4556794166565 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 196.48987531661987 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 196.51798701286316 loss tensor(0.3232, grad_fn=<NegBackward0>)\n",
            "Time 196.54593563079834 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 196.57368063926697 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 196.6025083065033 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 196.63008522987366 loss tensor(0.3231, grad_fn=<NegBackward0>)\n",
            "Time 196.66477870941162 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 196.7034854888916 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 196.73447275161743 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 196.76515197753906 loss tensor(0.3230, grad_fn=<NegBackward0>)\n",
            "Time 196.7947292327881 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 196.8213279247284 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 196.8480303287506 loss tensor(0.3229, grad_fn=<NegBackward0>)\n",
            "Time 196.87750506401062 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 196.9109878540039 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 196.94146275520325 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 196.96842861175537 loss tensor(0.3228, grad_fn=<NegBackward0>)\n",
            "Time 197.0065815448761 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 197.03431582450867 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 197.06285214424133 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 197.0909125804901 loss tensor(0.3227, grad_fn=<NegBackward0>)\n",
            "Time 197.1237497329712 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 197.1700439453125 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 197.20176911354065 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 197.23501062393188 loss tensor(0.3226, grad_fn=<NegBackward0>)\n",
            "Time 197.2656192779541 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 197.2985646724701 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 197.32844257354736 loss tensor(0.3225, grad_fn=<NegBackward0>)\n",
            "Time 197.35849905014038 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 197.38607025146484 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 197.4148871898651 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 197.44179892539978 loss tensor(0.3224, grad_fn=<NegBackward0>)\n",
            "Time 197.46782755851746 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 197.50053644180298 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 197.52920007705688 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 197.5661108493805 loss tensor(0.3223, grad_fn=<NegBackward0>)\n",
            "Time 197.59661507606506 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 197.6258385181427 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 197.653799533844 loss tensor(0.3222, grad_fn=<NegBackward0>)\n",
            "Time 197.68396925926208 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 197.71494841575623 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 197.74417304992676 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 197.77780413627625 loss tensor(0.3221, grad_fn=<NegBackward0>)\n",
            "Time 197.8081934452057 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 197.843195438385 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 197.87197303771973 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 197.9025650024414 loss tensor(0.3220, grad_fn=<NegBackward0>)\n",
            "Time 197.9327437877655 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 197.96220636367798 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 198.00773525238037 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 198.03788256645203 loss tensor(0.3219, grad_fn=<NegBackward0>)\n",
            "Time 198.0656135082245 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 198.09354281425476 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 198.12229824066162 loss tensor(0.3218, grad_fn=<NegBackward0>)\n",
            "Time 198.15064024925232 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 198.17861580848694 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 198.20725297927856 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 198.2445888519287 loss tensor(0.3217, grad_fn=<NegBackward0>)\n",
            "Time 198.27309155464172 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 198.3022711277008 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 198.33367943763733 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 198.36161088943481 loss tensor(0.3216, grad_fn=<NegBackward0>)\n",
            "Time 198.3885452747345 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 198.41935348510742 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 198.45230746269226 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 198.47851467132568 loss tensor(0.3215, grad_fn=<NegBackward0>)\n",
            "Time 198.50860810279846 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 198.5387578010559 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 198.5640676021576 loss tensor(0.3214, grad_fn=<NegBackward0>)\n",
            "Time 198.59022903442383 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 198.61689591407776 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 198.65421962738037 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 198.68559765815735 loss tensor(0.3213, grad_fn=<NegBackward0>)\n",
            "Time 198.7173764705658 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 198.7509570121765 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 198.7788746356964 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 198.8097472190857 loss tensor(0.3212, grad_fn=<NegBackward0>)\n",
            "Time 198.83857369422913 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 198.87531161308289 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 198.90187692642212 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 198.93285632133484 loss tensor(0.3211, grad_fn=<NegBackward0>)\n",
            "Time 198.9661886692047 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 198.99313116073608 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 199.03213453292847 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 199.05860304832458 loss tensor(0.3210, grad_fn=<NegBackward0>)\n",
            "Time 199.0930461883545 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 199.1238775253296 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 199.151691198349 loss tensor(0.3209, grad_fn=<NegBackward0>)\n",
            "Time 199.17988777160645 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 199.20822143554688 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 199.23650074005127 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 199.26617622375488 loss tensor(0.3208, grad_fn=<NegBackward0>)\n",
            "Time 199.29360365867615 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 199.33527088165283 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 199.36656498908997 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 199.3973672389984 loss tensor(0.3207, grad_fn=<NegBackward0>)\n",
            "Time 199.4270167350769 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 199.4551784992218 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 199.48240399360657 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 199.51920175552368 loss tensor(0.3206, grad_fn=<NegBackward0>)\n",
            "Time 199.547283411026 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 199.5739243030548 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 199.60125637054443 loss tensor(0.3205, grad_fn=<NegBackward0>)\n",
            "Time 199.628333568573 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 199.65740036964417 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 199.68452405929565 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 199.71449613571167 loss tensor(0.3204, grad_fn=<NegBackward0>)\n",
            "Time 199.75394916534424 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 199.7842252254486 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 199.81241965293884 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 199.83956694602966 loss tensor(0.3203, grad_fn=<NegBackward0>)\n",
            "Time 199.86799097061157 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 199.89696073532104 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 199.92497658729553 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 199.9530668258667 loss tensor(0.3202, grad_fn=<NegBackward0>)\n",
            "Time 199.98564052581787 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 200.0167851448059 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 200.0534965991974 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 200.08027982711792 loss tensor(0.3201, grad_fn=<NegBackward0>)\n",
            "Time 200.10720205307007 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 200.13441157341003 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 200.16259384155273 loss tensor(0.3200, grad_fn=<NegBackward0>)\n",
            "Time 200.19706392288208 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 200.22416591644287 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 200.25173354148865 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 200.28048038482666 loss tensor(0.3199, grad_fn=<NegBackward0>)\n",
            "Time 200.31142663955688 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 200.3404896259308 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 200.36879301071167 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 200.40718388557434 loss tensor(0.3198, grad_fn=<NegBackward0>)\n",
            "Time 200.43521857261658 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 200.462637424469 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 200.4899604320526 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 200.52481818199158 loss tensor(0.3197, grad_fn=<NegBackward0>)\n",
            "Time 200.55555987358093 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 200.59093713760376 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 200.62029695510864 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 200.6485240459442 loss tensor(0.3196, grad_fn=<NegBackward0>)\n",
            "Time 200.67657017707825 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 200.70454335212708 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 200.7329318523407 loss tensor(0.3195, grad_fn=<NegBackward0>)\n",
            "Time 200.76379561424255 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 200.80812668800354 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 200.86136722564697 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 200.91077661514282 loss tensor(0.3194, grad_fn=<NegBackward0>)\n",
            "Time 200.96124577522278 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 201.00283670425415 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 201.06163620948792 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 201.10437440872192 loss tensor(0.3193, grad_fn=<NegBackward0>)\n",
            "Time 201.14631271362305 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 201.1875810623169 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 201.22663068771362 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 201.27013731002808 loss tensor(0.3192, grad_fn=<NegBackward0>)\n",
            "Time 201.31209707260132 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 201.35113501548767 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 201.39619088172913 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 201.4344048500061 loss tensor(0.3191, grad_fn=<NegBackward0>)\n",
            "Time 201.47487115859985 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 201.51724767684937 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 201.55440473556519 loss tensor(0.3190, grad_fn=<NegBackward0>)\n",
            "Time 201.59849572181702 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 201.64132618904114 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 201.691091299057 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 201.73252630233765 loss tensor(0.3189, grad_fn=<NegBackward0>)\n",
            "Time 201.77404499053955 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 201.8149950504303 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 201.85268592834473 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 201.9012496471405 loss tensor(0.3188, grad_fn=<NegBackward0>)\n",
            "Time 201.94184017181396 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 201.9846532344818 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 202.02958297729492 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 202.06811237335205 loss tensor(0.3187, grad_fn=<NegBackward0>)\n",
            "Time 202.120215177536 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 202.16288018226624 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 202.20958971977234 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 202.2570674419403 loss tensor(0.3186, grad_fn=<NegBackward0>)\n",
            "Time 202.29563999176025 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 202.3454189300537 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 202.38932609558105 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 202.43253588676453 loss tensor(0.3185, grad_fn=<NegBackward0>)\n",
            "Time 202.4711253643036 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 202.51769852638245 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 202.54653882980347 loss tensor(0.3184, grad_fn=<NegBackward0>)\n",
            "Time 202.58146214485168 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 202.6089732646942 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 202.63574147224426 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 202.6695158481598 loss tensor(0.3183, grad_fn=<NegBackward0>)\n",
            "Time 202.69653415679932 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 202.7285144329071 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 202.75566291809082 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 202.79413557052612 loss tensor(0.3182, grad_fn=<NegBackward0>)\n",
            "Time 202.82535886764526 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 202.8527307510376 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 202.88216853141785 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 202.9093577861786 loss tensor(0.3181, grad_fn=<NegBackward0>)\n",
            "Time 202.93888688087463 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 202.9665584564209 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 202.99774622917175 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 203.03970336914062 loss tensor(0.3180, grad_fn=<NegBackward0>)\n",
            "Time 203.07327961921692 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 203.10085797309875 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 203.13656997680664 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 203.16367959976196 loss tensor(0.3179, grad_fn=<NegBackward0>)\n",
            "Time 203.19052815437317 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 203.21759390830994 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 203.24822902679443 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 203.28142499923706 loss tensor(0.3178, grad_fn=<NegBackward0>)\n",
            "Time 203.3108673095703 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 203.3381597995758 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 203.36788249015808 loss tensor(0.3177, grad_fn=<NegBackward0>)\n",
            "Time 203.3972566127777 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 203.42686486244202 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 203.45829558372498 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 203.48643565177917 loss tensor(0.3176, grad_fn=<NegBackward0>)\n",
            "Time 203.51537895202637 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 203.54331064224243 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 203.58206224441528 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 203.6119406223297 loss tensor(0.3175, grad_fn=<NegBackward0>)\n",
            "Time 203.63868618011475 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 203.6753363609314 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 203.70670199394226 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 203.73417258262634 loss tensor(0.3174, grad_fn=<NegBackward0>)\n",
            "Time 203.76490545272827 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 203.79250144958496 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 203.81975197792053 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 203.85131406784058 loss tensor(0.3173, grad_fn=<NegBackward0>)\n",
            "Time 203.88709998130798 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 203.923104763031 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 203.9518313407898 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 203.97980642318726 loss tensor(0.3172, grad_fn=<NegBackward0>)\n",
            "Time 204.0131058692932 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 204.04515504837036 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 204.07520461082458 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 204.11143827438354 loss tensor(0.3171, grad_fn=<NegBackward0>)\n",
            "Time 204.1495475769043 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 204.17879343032837 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 204.20849347114563 loss tensor(0.3170, grad_fn=<NegBackward0>)\n",
            "Time 204.23859453201294 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 204.26783847808838 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 204.29588055610657 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 204.332932472229 loss tensor(0.3169, grad_fn=<NegBackward0>)\n",
            "Time 204.36416220664978 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 204.39279890060425 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 204.42238855361938 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 204.4519920349121 loss tensor(0.3168, grad_fn=<NegBackward0>)\n",
            "Time 204.48035979270935 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 204.50751614570618 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 204.53804397583008 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 204.5720031261444 loss tensor(0.3167, grad_fn=<NegBackward0>)\n",
            "Time 204.59990000724792 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 204.62773275375366 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 204.65514421463013 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 204.68341517448425 loss tensor(0.3166, grad_fn=<NegBackward0>)\n",
            "Time 204.7128655910492 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 204.7455072402954 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 204.77912664413452 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 204.8092155456543 loss tensor(0.3165, grad_fn=<NegBackward0>)\n",
            "Time 204.8362352848053 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 204.86563682556152 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 204.89492630958557 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 204.9240002632141 loss tensor(0.3164, grad_fn=<NegBackward0>)\n",
            "Time 204.9635374546051 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 204.9942524433136 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 205.02590203285217 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 205.05706429481506 loss tensor(0.3163, grad_fn=<NegBackward0>)\n",
            "Time 205.0854251384735 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 205.1132504940033 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 205.14132356643677 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 205.18948459625244 loss tensor(0.3162, grad_fn=<NegBackward0>)\n",
            "Time 205.21796202659607 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 205.24501824378967 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 205.27630281448364 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 205.30418515205383 loss tensor(0.3161, grad_fn=<NegBackward0>)\n",
            "Time 205.3392791748047 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 205.36870074272156 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 205.4109082221985 loss tensor(0.3160, grad_fn=<NegBackward0>)\n",
            "Time 205.44823002815247 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 205.47576522827148 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 205.50487351417542 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 205.53247904777527 loss tensor(0.3159, grad_fn=<NegBackward0>)\n",
            "Time 205.5596170425415 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 205.58652877807617 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 205.6170334815979 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 205.65043139457703 loss tensor(0.3158, grad_fn=<NegBackward0>)\n",
            "Time 205.6856963634491 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 205.7139172554016 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 205.74107718467712 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 205.77327632904053 loss tensor(0.3157, grad_fn=<NegBackward0>)\n",
            "Time 205.80044078826904 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 205.83707284927368 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 205.8657307624817 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 205.89372396469116 loss tensor(0.3156, grad_fn=<NegBackward0>)\n",
            "Time 205.92200684547424 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 205.95011591911316 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 205.97910952568054 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 206.01552987098694 loss tensor(0.3155, grad_fn=<NegBackward0>)\n",
            "Time 206.05278038978577 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 206.0812041759491 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 206.10895252227783 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 206.13627099990845 loss tensor(0.3154, grad_fn=<NegBackward0>)\n",
            "Time 206.1677484512329 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 206.19886231422424 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 206.2274875640869 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 206.25621891021729 loss tensor(0.3153, grad_fn=<NegBackward0>)\n",
            "Time 206.28978967666626 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 206.31811046600342 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 206.3486979007721 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 206.38632893562317 loss tensor(0.3152, grad_fn=<NegBackward0>)\n",
            "Time 206.417329788208 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 206.4475371837616 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 206.48607397079468 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 206.51571893692017 loss tensor(0.3151, grad_fn=<NegBackward0>)\n",
            "Time 206.5456349849701 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 206.57848238945007 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 206.61346673965454 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 206.64544486999512 loss tensor(0.3150, grad_fn=<NegBackward0>)\n",
            "Time 206.67520380020142 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 206.71379828453064 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 206.74528527259827 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 206.77543592453003 loss tensor(0.3149, grad_fn=<NegBackward0>)\n",
            "Time 206.80325031280518 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 206.83279252052307 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 206.86259722709656 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 206.8902986049652 loss tensor(0.3148, grad_fn=<NegBackward0>)\n",
            "Time 206.92818474769592 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 206.96054553985596 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 206.9886634349823 loss tensor(0.3147, grad_fn=<NegBackward0>)\n",
            "Time 207.0213611125946 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 207.05171918869019 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 207.0854811668396 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 207.11354112625122 loss tensor(0.3146, grad_fn=<NegBackward0>)\n",
            "Time 207.14953422546387 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 207.18423628807068 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 207.21617889404297 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 207.24636816978455 loss tensor(0.3145, grad_fn=<NegBackward0>)\n",
            "Time 207.27723026275635 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 207.3080108165741 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 207.33589911460876 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 207.37236380577087 loss tensor(0.3144, grad_fn=<NegBackward0>)\n",
            "Time 207.40061950683594 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 207.42947578430176 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 207.45632004737854 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 207.483562707901 loss tensor(0.3143, grad_fn=<NegBackward0>)\n",
            "Time 207.5114152431488 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 207.5442419052124 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 207.5709352493286 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 207.60741758346558 loss tensor(0.3142, grad_fn=<NegBackward0>)\n",
            "Time 207.6361014842987 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 207.66434049606323 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 207.69449830055237 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 207.7225308418274 loss tensor(0.3141, grad_fn=<NegBackward0>)\n",
            "Time 207.75340723991394 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 207.78368878364563 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 207.8155858516693 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 207.8537735939026 loss tensor(0.3140, grad_fn=<NegBackward0>)\n",
            "Time 207.88688588142395 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 207.9153597354889 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 207.95101046562195 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 207.9795732498169 loss tensor(0.3139, grad_fn=<NegBackward0>)\n",
            "Time 208.00840163230896 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 208.04794907569885 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 208.07979464530945 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 208.1080334186554 loss tensor(0.3138, grad_fn=<NegBackward0>)\n",
            "Time 208.13542079925537 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 208.16320323944092 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 208.19232368469238 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 208.22695994377136 loss tensor(0.3137, grad_fn=<NegBackward0>)\n",
            "Time 208.2687864303589 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 208.29713678359985 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 208.3254475593567 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 208.35341024398804 loss tensor(0.3136, grad_fn=<NegBackward0>)\n",
            "Time 208.3802626132965 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 208.40867471694946 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 208.43674516677856 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 208.46376085281372 loss tensor(0.3135, grad_fn=<NegBackward0>)\n",
            "Time 208.49861812591553 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 208.52936553955078 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 208.55861258506775 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 208.58770203590393 loss tensor(0.3134, grad_fn=<NegBackward0>)\n",
            "Time 208.61810278892517 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 208.64859628677368 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 208.6826171875 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 208.72196245193481 loss tensor(0.3133, grad_fn=<NegBackward0>)\n",
            "Time 208.752117395401 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 208.77990198135376 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 208.80703163146973 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 208.83435153961182 loss tensor(0.3132, grad_fn=<NegBackward0>)\n",
            "Time 208.86291670799255 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 208.8962585926056 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 208.92713117599487 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 208.96497654914856 loss tensor(0.3131, grad_fn=<NegBackward0>)\n",
            "Time 208.99387192726135 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 209.02511525154114 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 209.0557930469513 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 209.08391952514648 loss tensor(0.3130, grad_fn=<NegBackward0>)\n",
            "Time 209.11179208755493 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 209.1460359096527 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 209.17585253715515 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 209.20780277252197 loss tensor(0.3129, grad_fn=<NegBackward0>)\n",
            "Time 209.24129605293274 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 209.26775574684143 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 209.294842004776 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 209.3224744796753 loss tensor(0.3128, grad_fn=<NegBackward0>)\n",
            "Time 209.3529372215271 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 209.38285160064697 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 209.41095066070557 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 209.43810939788818 loss tensor(0.3127, grad_fn=<NegBackward0>)\n",
            "Time 209.4700300693512 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 209.49648332595825 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 209.52359580993652 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 209.55456399917603 loss tensor(0.3126, grad_fn=<NegBackward0>)\n",
            "Time 209.59296011924744 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 209.62568640708923 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 209.65482664108276 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 209.68374705314636 loss tensor(0.3125, grad_fn=<NegBackward0>)\n",
            "Time 209.7114782333374 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 209.7431604862213 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 209.78487968444824 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 209.81261801719666 loss tensor(0.3124, grad_fn=<NegBackward0>)\n",
            "Time 209.84632086753845 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 209.874685049057 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 209.90289616584778 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 209.93139266967773 loss tensor(0.3123, grad_fn=<NegBackward0>)\n",
            "Time 209.9577784538269 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 209.98556804656982 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 210.02083492279053 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 210.04987597465515 loss tensor(0.3122, grad_fn=<NegBackward0>)\n",
            "Time 210.07684087753296 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 210.10359263420105 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 210.13086915016174 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 210.15769863128662 loss tensor(0.3121, grad_fn=<NegBackward0>)\n",
            "Time 210.18969416618347 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 210.2248513698578 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 210.25755620002747 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 210.28659558296204 loss tensor(0.3120, grad_fn=<NegBackward0>)\n",
            "Time 210.31718182563782 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 210.3454613685608 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 210.3745493888855 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 210.40976858139038 loss tensor(0.3119, grad_fn=<NegBackward0>)\n",
            "Time 210.4403100013733 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 210.46865606307983 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 210.4964084625244 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 210.52481317520142 loss tensor(0.3118, grad_fn=<NegBackward0>)\n",
            "Time 210.55166792869568 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 210.58775901794434 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 210.62248849868774 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 210.6532599925995 loss tensor(0.3117, grad_fn=<NegBackward0>)\n",
            "Time 210.6836142539978 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 210.71362590789795 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 210.7419970035553 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 210.7716519832611 loss tensor(0.3116, grad_fn=<NegBackward0>)\n",
            "Time 210.8046271800995 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 210.8415277004242 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 210.86956429481506 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 210.90499687194824 loss tensor(0.3115, grad_fn=<NegBackward0>)\n",
            "Time 210.9317066669464 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 210.9577395915985 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 210.98408961296082 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 211.0132966041565 loss tensor(0.3114, grad_fn=<NegBackward0>)\n",
            "Time 211.039790391922 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 211.07765674591064 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 211.1058328151703 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 211.13339638710022 loss tensor(0.3113, grad_fn=<NegBackward0>)\n",
            "Time 211.16007328033447 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 211.1904170513153 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 211.22068762779236 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 211.25963687896729 loss tensor(0.3112, grad_fn=<NegBackward0>)\n",
            "Time 211.297509431839 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 211.32558226585388 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 211.35281586647034 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 211.38001537322998 loss tensor(0.3111, grad_fn=<NegBackward0>)\n",
            "Time 211.40695190429688 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 211.43583011627197 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 211.46311783790588 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 211.4909737110138 loss tensor(0.3110, grad_fn=<NegBackward0>)\n",
            "Time 211.52398419380188 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 211.55102252960205 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 211.5782754421234 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 211.60517859458923 loss tensor(0.3109, grad_fn=<NegBackward0>)\n",
            "Time 211.63213324546814 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 211.66712141036987 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 211.70049405097961 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 211.73082852363586 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 211.76530194282532 loss tensor(0.3108, grad_fn=<NegBackward0>)\n",
            "Time 211.79368495941162 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 211.8221788406372 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 211.85043001174927 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 211.8802454471588 loss tensor(0.3107, grad_fn=<NegBackward0>)\n",
            "Time 211.91009044647217 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 211.93997311592102 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 211.97267293930054 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 212.00042629241943 loss tensor(0.3106, grad_fn=<NegBackward0>)\n",
            "Time 212.0306580066681 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 212.06280708312988 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 212.0904290676117 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 212.1178421974182 loss tensor(0.3105, grad_fn=<NegBackward0>)\n",
            "Time 212.1457118988037 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 212.1803798675537 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 212.20755863189697 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 212.23408770561218 loss tensor(0.3104, grad_fn=<NegBackward0>)\n",
            "Time 212.26861929893494 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 212.30011796951294 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 212.3284468650818 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 212.35880780220032 loss tensor(0.3103, grad_fn=<NegBackward0>)\n",
            "Time 212.3963165283203 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 212.42697620391846 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 212.45378160476685 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 212.48124146461487 loss tensor(0.3102, grad_fn=<NegBackward0>)\n",
            "Time 212.50916957855225 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 212.5567922592163 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 212.61161518096924 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 212.65984749794006 loss tensor(0.3101, grad_fn=<NegBackward0>)\n",
            "Time 212.70787405967712 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 212.75153970718384 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 212.79659700393677 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 212.84495520591736 loss tensor(0.3100, grad_fn=<NegBackward0>)\n",
            "Time 212.88364791870117 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 212.92119526863098 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 212.9586100578308 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 212.9966583251953 loss tensor(0.3099, grad_fn=<NegBackward0>)\n",
            "Time 213.03702402114868 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 213.08277082443237 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 213.1227035522461 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 213.16154527664185 loss tensor(0.3098, grad_fn=<NegBackward0>)\n",
            "Time 213.20294976234436 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 213.24111914634705 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 213.28854513168335 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 213.33485460281372 loss tensor(0.3097, grad_fn=<NegBackward0>)\n",
            "Time 213.3785252571106 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 213.41586542129517 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 213.4542350769043 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 213.49787831306458 loss tensor(0.3096, grad_fn=<NegBackward0>)\n",
            "Time 213.54116415977478 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 213.57974576950073 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 213.61788487434387 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 213.65875792503357 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 213.7041790485382 loss tensor(0.3095, grad_fn=<NegBackward0>)\n",
            "Time 213.7470681667328 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 213.78706860542297 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 213.82962584495544 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 213.87417888641357 loss tensor(0.3094, grad_fn=<NegBackward0>)\n",
            "Time 213.92811584472656 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 213.96961045265198 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 214.01399898529053 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 214.05560493469238 loss tensor(0.3093, grad_fn=<NegBackward0>)\n",
            "Time 214.1002175807953 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 214.15122151374817 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 214.19459652900696 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 214.23119688034058 loss tensor(0.3092, grad_fn=<NegBackward0>)\n",
            "Time 214.25842094421387 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 214.28579115867615 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 214.31289553642273 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 214.35003900527954 loss tensor(0.3091, grad_fn=<NegBackward0>)\n",
            "Time 214.3907196521759 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 214.42184948921204 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 214.45040774345398 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 214.48360514640808 loss tensor(0.3090, grad_fn=<NegBackward0>)\n",
            "Time 214.51095581054688 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 214.53810143470764 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 214.5658073425293 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 214.5953824520111 loss tensor(0.3089, grad_fn=<NegBackward0>)\n",
            "Time 214.62513399124146 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 214.6523118019104 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 214.6796567440033 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 214.71430349349976 loss tensor(0.3088, grad_fn=<NegBackward0>)\n",
            "Time 214.74333810806274 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 214.773850440979 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 214.81536984443665 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 214.84189176559448 loss tensor(0.3087, grad_fn=<NegBackward0>)\n",
            "Time 214.87141513824463 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 214.8995087146759 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 214.92675805091858 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 214.95414328575134 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 214.9830358028412 loss tensor(0.3086, grad_fn=<NegBackward0>)\n",
            "Time 215.01204228401184 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 215.04502391815186 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 215.07036471366882 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 215.09895658493042 loss tensor(0.3085, grad_fn=<NegBackward0>)\n",
            "Time 215.12563800811768 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 215.15237975120544 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 215.1826934814453 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 215.21215081214905 loss tensor(0.3084, grad_fn=<NegBackward0>)\n",
            "Time 215.24058628082275 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 215.27722716331482 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 215.30654883384705 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 215.3344542980194 loss tensor(0.3083, grad_fn=<NegBackward0>)\n",
            "Time 215.36676907539368 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 215.39667654037476 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 215.43030285835266 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 215.457585811615 loss tensor(0.3082, grad_fn=<NegBackward0>)\n",
            "Time 215.4950819015503 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 215.52247214317322 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 215.54962801933289 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 215.5793788433075 loss tensor(0.3081, grad_fn=<NegBackward0>)\n",
            "Time 215.60964179039001 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 215.63664984703064 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 215.6646637916565 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 215.69221091270447 loss tensor(0.3080, grad_fn=<NegBackward0>)\n",
            "Time 215.7303168773651 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 215.75911378860474 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 215.78833842277527 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 215.81812262535095 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 215.84536695480347 loss tensor(0.3079, grad_fn=<NegBackward0>)\n",
            "Time 215.87642979621887 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 215.90629863739014 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 215.94286584854126 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 215.97163081169128 loss tensor(0.3078, grad_fn=<NegBackward0>)\n",
            "Time 216.00117373466492 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 216.04951357841492 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 216.08129286766052 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 216.1115562915802 loss tensor(0.3077, grad_fn=<NegBackward0>)\n",
            "Time 216.1400899887085 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 216.17912650108337 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 216.2088761329651 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 216.23639607429504 loss tensor(0.3076, grad_fn=<NegBackward0>)\n",
            "Time 216.26441931724548 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 216.29267716407776 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 216.32149863243103 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 216.35478734970093 loss tensor(0.3075, grad_fn=<NegBackward0>)\n",
            "Time 216.39354538917542 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 216.42218661308289 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 216.45182299613953 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 216.47932028770447 loss tensor(0.3074, grad_fn=<NegBackward0>)\n",
            "Time 216.50707483291626 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 216.53732323646545 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 216.56629610061646 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 216.59788608551025 loss tensor(0.3073, grad_fn=<NegBackward0>)\n",
            "Time 216.6303746700287 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 216.657217502594 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 216.6890413761139 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 216.71603798866272 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 216.74542260169983 loss tensor(0.3072, grad_fn=<NegBackward0>)\n",
            "Time 216.77290415763855 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 216.81076192855835 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 216.84797978401184 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 216.87667846679688 loss tensor(0.3071, grad_fn=<NegBackward0>)\n",
            "Time 216.90467596054077 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 216.93219137191772 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 216.9589819908142 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 216.9858078956604 loss tensor(0.3070, grad_fn=<NegBackward0>)\n",
            "Time 217.01911544799805 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 217.04913568496704 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 217.07698583602905 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 217.10528230667114 loss tensor(0.3069, grad_fn=<NegBackward0>)\n",
            "Time 217.13283371925354 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 217.15975904464722 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 217.19208908081055 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 217.22014665603638 loss tensor(0.3068, grad_fn=<NegBackward0>)\n",
            "Time 217.25774788856506 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 217.2860655784607 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 217.31497430801392 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 217.34360265731812 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 217.3796830177307 loss tensor(0.3067, grad_fn=<NegBackward0>)\n",
            "Time 217.40844893455505 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 217.43765830993652 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 217.47342896461487 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 217.50339484214783 loss tensor(0.3066, grad_fn=<NegBackward0>)\n",
            "Time 217.53671383857727 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 217.56403040885925 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 217.59210419654846 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 217.61998200416565 loss tensor(0.3065, grad_fn=<NegBackward0>)\n",
            "Time 217.64751958847046 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 217.67610359191895 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 217.71327662467957 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 217.74186825752258 loss tensor(0.3064, grad_fn=<NegBackward0>)\n",
            "Time 217.77367115020752 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 217.80176091194153 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 217.82948303222656 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 217.856103181839 loss tensor(0.3063, grad_fn=<NegBackward0>)\n",
            "Time 217.89716696739197 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 217.92651510238647 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 217.95342469215393 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 217.98145937919617 loss tensor(0.3062, grad_fn=<NegBackward0>)\n",
            "Time 218.01198434829712 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 218.03853011131287 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 218.0661654472351 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 218.09361696243286 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 218.12891674041748 loss tensor(0.3061, grad_fn=<NegBackward0>)\n",
            "Time 218.15699243545532 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 218.1839039325714 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 218.21130800247192 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 218.2384946346283 loss tensor(0.3060, grad_fn=<NegBackward0>)\n",
            "Time 218.26573777198792 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 218.29371547698975 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 218.3216679096222 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 218.36387038230896 loss tensor(0.3059, grad_fn=<NegBackward0>)\n",
            "Time 218.4011733531952 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 218.42936182022095 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 218.45722103118896 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 218.4852638244629 loss tensor(0.3058, grad_fn=<NegBackward0>)\n",
            "Time 218.51353907585144 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 218.54060339927673 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 218.57369780540466 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 218.6021683216095 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 218.6309735774994 loss tensor(0.3057, grad_fn=<NegBackward0>)\n",
            "Time 218.66029286384583 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 218.68873357772827 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 218.72643113136292 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 218.7542335987091 loss tensor(0.3056, grad_fn=<NegBackward0>)\n",
            "Time 218.7881371974945 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 218.81969213485718 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 218.84971690177917 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 218.87878274917603 loss tensor(0.3055, grad_fn=<NegBackward0>)\n",
            "Time 218.90625929832458 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 218.93392944335938 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 218.96098160743713 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 218.99000477790833 loss tensor(0.3054, grad_fn=<NegBackward0>)\n",
            "Time 219.02528524398804 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 219.05333638191223 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 219.0818247795105 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 219.11670303344727 loss tensor(0.3053, grad_fn=<NegBackward0>)\n",
            "Time 219.14507007598877 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 219.1728217601776 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 219.20476865768433 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 219.2378032207489 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 219.2658290863037 loss tensor(0.3052, grad_fn=<NegBackward0>)\n",
            "Time 219.29373025894165 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 219.32239985466003 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 219.3516047000885 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 219.37984538078308 loss tensor(0.3051, grad_fn=<NegBackward0>)\n",
            "Time 219.42049932479858 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 219.45160055160522 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 219.47912573814392 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 219.51194739341736 loss tensor(0.3050, grad_fn=<NegBackward0>)\n",
            "Time 219.53885197639465 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 219.56594061851501 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 219.59373426437378 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 219.62136793136597 loss tensor(0.3049, grad_fn=<NegBackward0>)\n",
            "Time 219.6589379310608 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 219.68750476837158 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 219.71501421928406 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 219.7436113357544 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 219.77213740348816 loss tensor(0.3048, grad_fn=<NegBackward0>)\n",
            "Time 219.80175185203552 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 219.8318157196045 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 219.86314153671265 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 219.89604663848877 loss tensor(0.3047, grad_fn=<NegBackward0>)\n",
            "Time 219.92741990089417 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 219.95667672157288 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 219.9849944114685 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 220.01547074317932 loss tensor(0.3046, grad_fn=<NegBackward0>)\n",
            "Time 220.04372787475586 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 220.072918176651 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 220.11385202407837 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 220.152419090271 loss tensor(0.3045, grad_fn=<NegBackward0>)\n",
            "Time 220.18125534057617 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 220.20961689949036 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 220.23787450790405 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 220.26560854911804 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 220.30190134048462 loss tensor(0.3044, grad_fn=<NegBackward0>)\n",
            "Time 220.3303039073944 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 220.35838508605957 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 220.38703846931458 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 220.41656804084778 loss tensor(0.3043, grad_fn=<NegBackward0>)\n",
            "Time 220.4512586593628 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 220.47873044013977 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 220.52050137519836 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 220.54859137535095 loss tensor(0.3042, grad_fn=<NegBackward0>)\n",
            "Time 220.57700300216675 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 220.60457396507263 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 220.63264989852905 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 220.6608726978302 loss tensor(0.3041, grad_fn=<NegBackward0>)\n",
            "Time 220.68964457511902 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 220.7196078300476 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 220.75660800933838 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 220.78721475601196 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 220.81785464286804 loss tensor(0.3040, grad_fn=<NegBackward0>)\n",
            "Time 220.85041403770447 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 220.8798565864563 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 220.9114110469818 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 220.94729208946228 loss tensor(0.3039, grad_fn=<NegBackward0>)\n",
            "Time 220.9788019657135 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 221.007000207901 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 221.03665900230408 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 221.06463646888733 loss tensor(0.3038, grad_fn=<NegBackward0>)\n",
            "Time 221.09233355522156 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 221.12031412124634 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 221.14948153495789 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 221.1821711063385 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 221.21010756492615 loss tensor(0.3037, grad_fn=<NegBackward0>)\n",
            "Time 221.23861074447632 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 221.26624274253845 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 221.2945430278778 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 221.3230004310608 loss tensor(0.3036, grad_fn=<NegBackward0>)\n",
            "Time 221.3510618209839 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 221.3922758102417 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 221.4210832118988 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 221.4572513103485 loss tensor(0.3035, grad_fn=<NegBackward0>)\n",
            "Time 221.48650407791138 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 221.5145959854126 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 221.54239296913147 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 221.57009649276733 loss tensor(0.3034, grad_fn=<NegBackward0>)\n",
            "Time 221.60425639152527 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 221.6386640071869 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 221.6681785583496 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 221.69761872291565 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 221.7253839969635 loss tensor(0.3033, grad_fn=<NegBackward0>)\n",
            "Time 221.75284099578857 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 221.78723526000977 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 221.82398104667664 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 221.852201461792 loss tensor(0.3032, grad_fn=<NegBackward0>)\n",
            "Time 221.88092160224915 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 221.9091637134552 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 221.93738055229187 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 221.96723914146423 loss tensor(0.3031, grad_fn=<NegBackward0>)\n",
            "Time 221.99713778495789 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 222.0343577861786 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 222.06517457962036 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 222.0937807559967 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 222.12350511550903 loss tensor(0.3030, grad_fn=<NegBackward0>)\n",
            "Time 222.15230584144592 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 222.18386697769165 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 222.21348667144775 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 222.24708318710327 loss tensor(0.3029, grad_fn=<NegBackward0>)\n",
            "Time 222.2779483795166 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 222.30694723129272 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 222.33553266525269 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 222.36383438110352 loss tensor(0.3028, grad_fn=<NegBackward0>)\n",
            "Time 222.39629697799683 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 222.42412185668945 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 222.46931743621826 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 222.49863839149475 loss tensor(0.3027, grad_fn=<NegBackward0>)\n",
            "Time 222.52873921394348 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 222.5557119846344 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 222.5838222503662 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 222.6107883453369 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 222.6392045021057 loss tensor(0.3026, grad_fn=<NegBackward0>)\n",
            "Time 222.66988563537598 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 222.70565176010132 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 222.73616409301758 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 222.76371908187866 loss tensor(0.3025, grad_fn=<NegBackward0>)\n",
            "Time 222.79750728607178 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 222.82625794410706 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 222.85437154769897 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 222.888099193573 loss tensor(0.3024, grad_fn=<NegBackward0>)\n",
            "Time 222.92194843292236 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 222.94970059394836 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 222.97744178771973 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 223.00953817367554 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 223.04756474494934 loss tensor(0.3023, grad_fn=<NegBackward0>)\n",
            "Time 223.07897281646729 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 223.11357951164246 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 223.14657163619995 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 223.1755301952362 loss tensor(0.3022, grad_fn=<NegBackward0>)\n",
            "Time 223.2039270401001 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 223.23242092132568 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 223.26129055023193 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 223.2906458377838 loss tensor(0.3021, grad_fn=<NegBackward0>)\n",
            "Time 223.33089566230774 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 223.35974526405334 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 223.38819932937622 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 223.41573071479797 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 223.44517469406128 loss tensor(0.3020, grad_fn=<NegBackward0>)\n",
            "Time 223.4821412563324 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 223.5102994441986 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 223.54377031326294 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 223.57169461250305 loss tensor(0.3019, grad_fn=<NegBackward0>)\n",
            "Time 223.60001254081726 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 223.62709259986877 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 223.65437841415405 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 223.68225860595703 loss tensor(0.3018, grad_fn=<NegBackward0>)\n",
            "Time 223.71187257766724 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 223.76369380950928 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 223.79555296897888 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 223.82461214065552 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 223.85090923309326 loss tensor(0.3017, grad_fn=<NegBackward0>)\n",
            "Time 223.87985038757324 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 223.90713357925415 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 223.93475604057312 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 223.96484518051147 loss tensor(0.3016, grad_fn=<NegBackward0>)\n",
            "Time 223.998694896698 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 224.0299196243286 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 224.05656623840332 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 224.0842559337616 loss tensor(0.3015, grad_fn=<NegBackward0>)\n",
            "Time 224.1112494468689 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 224.14125537872314 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 224.168475151062 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 224.20617485046387 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 224.2559630870819 loss tensor(0.3014, grad_fn=<NegBackward0>)\n",
            "Time 224.30741548538208 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 224.35315608978271 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 224.40234231948853 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 224.4477038383484 loss tensor(0.3013, grad_fn=<NegBackward0>)\n",
            "Time 224.49917316436768 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 224.54418206214905 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 224.58260869979858 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 224.62286686897278 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 224.66861367225647 loss tensor(0.3012, grad_fn=<NegBackward0>)\n",
            "Time 224.70748782157898 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 224.75031352043152 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 224.79044032096863 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 224.83144545555115 loss tensor(0.3011, grad_fn=<NegBackward0>)\n",
            "Time 224.8700110912323 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 224.912584066391 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 224.9520080089569 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 224.9903769493103 loss tensor(0.3010, grad_fn=<NegBackward0>)\n",
            "Time 225.03570318222046 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 225.08041787147522 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 225.12054586410522 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 225.1600878238678 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 225.19780230522156 loss tensor(0.3009, grad_fn=<NegBackward0>)\n",
            "Time 225.23882627487183 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 225.2768485546112 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 225.32018041610718 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 225.35889959335327 loss tensor(0.3008, grad_fn=<NegBackward0>)\n",
            "Time 225.39693355560303 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 225.43498396873474 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 225.4730372428894 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 225.51347374916077 loss tensor(0.3007, grad_fn=<NegBackward0>)\n",
            "Time 225.57184386253357 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 225.62203335762024 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 225.6637625694275 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 225.7075653076172 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 225.7483868598938 loss tensor(0.3006, grad_fn=<NegBackward0>)\n",
            "Time 225.7976212501526 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 225.8408031463623 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 225.88328289985657 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 225.92243671417236 loss tensor(0.3005, grad_fn=<NegBackward0>)\n",
            "Time 225.95069074630737 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 225.97798705101013 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 226.01496505737305 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 226.04182958602905 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 226.06893301010132 loss tensor(0.3004, grad_fn=<NegBackward0>)\n",
            "Time 226.09641790390015 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 226.12354922294617 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 226.1537630558014 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 226.18070125579834 loss tensor(0.3003, grad_fn=<NegBackward0>)\n",
            "Time 226.2079713344574 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 226.24351239204407 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 226.27143812179565 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 226.29963874816895 loss tensor(0.3002, grad_fn=<NegBackward0>)\n",
            "Time 226.3279926776886 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 226.3555121421814 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 226.38309788703918 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 226.42333030700684 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 226.45989894866943 loss tensor(0.3001, grad_fn=<NegBackward0>)\n",
            "Time 226.48933815956116 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 226.5180082321167 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Time 226.55013060569763 loss tensor(0.3000, grad_fn=<NegBackward0>)\n",
            "Final execution time 226.55013060569763\n",
            "Number of iterations 7082\n",
            "Mean execution time of an iteration 0.0319895694162239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "XNQaGo06Ta49",
        "outputId": "faf41fe1-dcfe-4159-b8fc-802e871a15b4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc9c0f6a220>]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6G3P5f8LTdAY",
        "outputId": "19783785-08d1-4f8a-faf7-a903fcb1e662"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc9c0a442e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "l0LtcyhPTeh8",
        "outputId": "774fbff1-ee02-42e5-f49b-13ac15d2f882"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc9c0a1f100>]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}