{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/LogisticRegression_fwd_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Oyi7eax2JnEO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm\n",
        "import torch.distributions as distr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "GVuIq3iFKJ9l"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "from torchvision import transforms as T"
      ],
      "metadata": {
        "id": "E7LCz1JiKMSj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the data"
      ],
      "metadata": {
        "id": "uclnxVteKfnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "penguins = tfds.load('penguins', as_supervised=True, split='train')"
      ],
      "metadata": {
        "id": "fZMg1kYeKS4U"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By default, the Dataset object is an iterator over the elements.\n",
        "# The instructions below extract the underlying tensors.\n",
        "X, y = penguins.batch(500).get_single_element()\n",
        "X, y = X.numpy(), y.numpy()"
      ],
      "metadata": {
        "id": "iYKcjgnqzm9C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "metadata": {
        "id": "ISJ8BgIMLPWX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "Xtest = torch.from_numpy(Xtest).float()"
      ],
      "metadata": {
        "id": "S3Y0sR080VHJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "lBkpViok0YZ4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Logistic Regression"
      ],
      "metadata": {
        "id": "KJO3tb6HLkD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "SbAXbIFTLjW-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, w, b):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(w)\n",
        "    self.bias = nn.Parameter(b)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(1, -1)\n",
        "    return torch.softmax(x@self.weight + self.bias, 1)"
      ],
      "metadata": {
        "id": "F_qTD2ovLn2Z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9O-8lwQM3IK",
        "outputId": "94d39630-b098-4a1e-e2c9-6410db102f20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the parameters"
      ],
      "metadata": {
        "id": "xANyM4TzM7YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the parameters randomly and the model with an input size\n",
        "w = torch.randn((4, 3), requires_grad=False)\n",
        "b = torch.randn((3, ), requires_grad=False)\n",
        "LG = SimpleLogisticRegression(4, w, b).to(device)"
      ],
      "metadata": {
        "id": "Au-0g48hM47D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we also need to move data when asking for a prediction\n",
        "print(LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc8fw23PNqUQ",
        "outputId": "66eedabd-4b05-4b0a-e3b9-3c5bc5825924"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1518, 0.0547, 0.7934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate the network with forward gradient"
      ],
      "metadata": {
        "id": "VnUzjP_aWCdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(ytrue, ypred):\n",
        "  return (ypred.argmax(1) == ytrue).float().mean()"
      ],
      "metadata": {
        "id": "WtYvEF9VNqqZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 10% (random guessing).\n",
        "accuracy(ytrain[0].to(device), LG(Xtrain[0].to(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bw1HBA6WGES",
        "outputId": "79adf183-d608-4991-c270-3ee5578e2d3e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Cross Entropy"
      ],
      "metadata": {
        "id": "nZ0xyQDVWli6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(ytrue, ypred):\n",
        "  \"\"\" Cross-entropy loss.\n",
        "  Inputs:\n",
        "  - ytrue (n,): vector of indices for the correct class.\n",
        "  - ypred (n, 3): predictions of the model.\n",
        "  Returns the average cross-entropy.\n",
        "  \"\"\"\n",
        "  # This is called integer array indexing in NumPy:\n",
        "  # https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
        "  return - ypred[torch.arange(0, ypred.shape[0]), ytrue].log().mean()"
      ],
      "metadata": {
        "id": "et6ncKfAWPqW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beale_function(x):\n",
        "  return (torch.pow(torch.tensor([1.5])-x[0]+x[0]*x[1],2) + torch.pow(torch.tensor([2.25])-x[0]+x[0]*torch.pow(x[1],2),2)+torch.pow(torch.tensor([2.625])-x[0]+x[0]*torch.pow(x[1],3),2))"
      ],
      "metadata": {
        "id": "fW7DIT_bWrAv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock_function(x):\n",
        "  sum=0\n",
        "  for i in range (x.size(0) -1):\n",
        "    sum += (100*torch.pow(x[i+1] - torch.pow(x[i], 2), 2) + torch.pow(1-x[i], 2))\n",
        "  return sum"
      ],
      "metadata": {
        "id": "UWDzjXptWuAH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sphere_function(x):\n",
        "  sum=0\n",
        "  for i in range(x.size(0)):\n",
        "    sum += torch.pow(x[i], 2)\n",
        "  return sum"
      ],
      "metadata": {
        "id": "aq5uL94Z56hk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functorch import jvp"
      ],
      "metadata": {
        "id": "bJeasqVYjFZ0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fwd_gradient(x, y):\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  l_rate0 = 0.0001\n",
        "  f = sphere_function\n",
        "\n",
        "  #Parameters\n",
        "  w = torch.FloatTensor(4, 3)\n",
        "  #w = torch.div(w, torch.norm(w, 2))\n",
        "\n",
        "  b = torch.FloatTensor(3, )\n",
        "  #b = torch.div(b, torch.norm(b, 2))\n",
        "\n",
        "  LG = SimpleLogisticRegression(4, w, b).to(device)\n",
        "  w1 = w.reshape(-1)\n",
        "  #w1 = torch.cat((w1, b), 0)\n",
        "  error=0\n",
        "  for i in range (x.size(0)):\n",
        "    if (LG(x[i]).argmax(1)- y[i])!=0:\n",
        "        error = error+ 1\n",
        "  error= error / x.size(0)\n",
        "  print(error)\n",
        "  t=torch.tensor([0])\n",
        "\n",
        "  while (error>0.1) :\n",
        "\n",
        "    t=t+1\n",
        "    vw1=torch.randn(w1.shape)\n",
        "    vw1 = (vw1 - torch.mean(vw1))/torch.std(vw1)\n",
        "    vb=torch.randn(b.shape)\n",
        "    vb=(vb - torch.mean(vb))/torch.std(vb)\n",
        "\n",
        "    ftw1, dtw1 = torch.tensor(jvp(f,(w1, ), (vw1, )))\n",
        "    print(ftw1)\n",
        "    ftb, dtb = torch.tensor(jvp(f,(b, ), (vb, )))\n",
        "    gtw1=vw1*dtw1\n",
        "    gtb = vb*dtb\n",
        "    w1 = w1 - l_rate0*gtw1\n",
        "    b = b - l_rate0*gtb\n",
        "\n",
        "\n",
        "    w = w1.reshape(-1, 3)\n",
        "    LG = SimpleLogisticRegression(4, w, b).to(device)\n",
        "    error=0\n",
        "    for i in range (x.size(0)):\n",
        "      if (LG(x[i]).argmax(1)- y[i])!=0:\n",
        "        error = error+ 1\n",
        "    error= error / x.size(0)\n",
        "    print (error)\n",
        "  return w, b"
      ],
      "metadata": {
        "id": "1wUCVnwXWzQF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b = train_fwd_gradient(Xtrain, ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sEXUvtqnMsbD",
        "outputId": "48b2de6f-e49e-4eb7-e492-e48dc432a824"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.796\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n",
            "0.8\n",
            "tensor(inf)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-03b6e6e2d293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fwd_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-b32332963ae7>\u001b[0m in \u001b[0;36mtrain_fwd_gradient\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "\n",
        "  LG.train()\n",
        "  for i in range(1):\n",
        "    xb, yb = next(iter(train_loader))\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "\n",
        "    w, b = train_fwd_gradient(xb, yb)\n",
        "    LG = SimpleLogisticRegression(1, w, b)"
      ],
      "metadata": {
        "id": "aDYtH6ud1Dwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}