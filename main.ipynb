{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidraamirez/GradientWithoutBackpropagation/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Without Backpropagation"
      ],
      "metadata": {
        "id": "qkzEBdcD3BRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm\n",
        "import torch.distributions as distr"
      ],
      "metadata": {
        "id": "dM-jay923zDH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "2DoBHL2Tz2s3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "from torchvision import transforms as T"
      ],
      "metadata": {
        "id": "h5aLBvC5z3kK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the dataset"
      ],
      "metadata": {
        "id": "w_w7gA2P5bQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "YNmPBpfS3FYq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative way to get the first element: image, label = next(iter(train_data))\n",
        "for image, label in train_data:\n",
        "  break"
      ],
      "metadata": {
        "id": "sYhWDEh30dsR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple transformation that converts the PIL image to a PyTorch array\n",
        "T.ToTensor()(image).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbtDnt1-0Awz",
        "outputId": "fc235ae3-b6f0-42bc-b676-3cd61b97f52e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T.Compose allows to chain together multiple transformations\n",
        "train_transforms = T.Compose([\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "EziYaTkO05Qt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This loads data with both data conversion.\n",
        "train_data = torchvision.datasets.KMNIST('./data', train=True, transform=train_transforms)"
      ],
      "metadata": {
        "id": "SLtrWriJ07-S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaders are used to shuffle, batch, and possibly sample the elements of the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "L9a4PEGN0SUD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "print(xb.shape)\n",
        "print(yb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkrrE4f0f7K",
        "outputId": "2d09b48f-6b92-428e-eb2b-db53ef49aaea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data is similar, but (a) we do not apply data augmentation,\n",
        "# and (b) we do not shuffle when building the mini-batches.\n",
        "test_data = torchvision.datasets.KMNIST('./data', train=False, transform=T.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "-acBNiYh1KxY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize parameters ????!!!!!"
      ],
      "metadata": {
        "id": "6p96IE1V5prD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize parameters\n",
        "\n",
        "def init():\n",
        "  theta = torch.randn(X.shape, requires_grad=False)\n",
        "  v = torch.randn(X.shape, requires_grad=False)\n",
        "  return theta, v"
      ],
      "metadata": {
        "id": "__I7-hrK77JY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Convolutional Neural Network Class"
      ],
      "metadata": {
        "id": "T55GS3b95kKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "M0UQB1abkxvi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        input_size = 1\n",
        "        self.conv1 = nn.Conv2d(input_size, 8, 3, padding=1)\n",
        "        print(self.conv1.weight)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.reshape((-1, 64*7*7))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "ssgUZF_S8gmM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check if CUDA is available. If you do not see it,\n",
        "# activate a GPU from Runtime >> Change runtime type and \n",
        "# restart the notebook.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ9BguV01cPi",
        "outputId": "561e25cf-3f75-4a17-fa6d-fdebe9b6b2d2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to move the SimpleCNN model to the device immediately\n",
        "cnn = SimpleCNN(1).to(device)\n",
        "print(len(list(cnn.parameters())))"
      ],
      "metadata": {
        "id": "Exuz9TVC3ReH",
        "outputId": "e998e216-8c2d-437e-f9e8-673e91841361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0700, -0.0318, -0.3248],\n",
            "          [-0.2118, -0.3014,  0.2572],\n",
            "          [ 0.0616,  0.2601,  0.2349]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0264, -0.1425, -0.3194],\n",
            "          [ 0.2587,  0.1923, -0.0372],\n",
            "          [ 0.2086,  0.0800, -0.1155]]],\n",
            "\n",
            "\n",
            "        [[[-0.3106, -0.3326,  0.0613],\n",
            "          [ 0.3019,  0.0629,  0.1640],\n",
            "          [-0.2718, -0.3292,  0.3142]]],\n",
            "\n",
            "\n",
            "        [[[-0.0018,  0.1631,  0.3232],\n",
            "          [ 0.1476, -0.2349, -0.0070],\n",
            "          [-0.0350,  0.0577,  0.0889]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0672, -0.2210,  0.1980],\n",
            "          [-0.0196, -0.0907, -0.0714],\n",
            "          [-0.0437,  0.1285, -0.2404]]],\n",
            "\n",
            "\n",
            "        [[[-0.2319,  0.2314,  0.2135],\n",
            "          [ 0.0706, -0.3154, -0.0576],\n",
            "          [-0.0807,  0.2794, -0.2058]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1104, -0.1419,  0.2641],\n",
            "          [ 0.0340,  0.1222, -0.0401],\n",
            "          [-0.0549,  0.2739,  0.2505]]],\n",
            "\n",
            "\n",
            "        [[[-0.1748, -0.1398,  0.1064],\n",
            "          [-0.0299,  0.0014,  0.2878],\n",
            "          [-0.1388, -0.0686, -0.2917]]]], requires_grad=True)\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we also need to move data when asking for a prediction\n",
        "cnn(xb.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBOLO2Ee3ZwE",
        "outputId": "9a8ef556-59c7-48f7-abbd-2dd2eab7f623"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and evaluate the network with forward gradient"
      ],
      "metadata": {
        "id": "TIaVzpBW5th5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(net, loader, device):\n",
        "  # A function that aggregates the accuracy over all mini-batches in the loader.\n",
        "  # See here for a quick-start on torchmetrics: https://torchmetrics.readthedocs.io/en/stable/pages/quickstart.html.\n",
        "  #acc = torchmetrics.Accuracy().to(device)\n",
        "  acc = torchmetrics.Accuracy('multiclass', num_classes=10).to(device)\n",
        "  for xb, yb in loader:\n",
        "      xb, yb = xb.to(device), yb.to(device)\n",
        "      ypred = cnn(xb)\n",
        "      _ = acc(ypred, yb)\n",
        "  return acc.compute()"
      ],
      "metadata": {
        "id": "oY45ByC93hg7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average accuracy at initialization is 10% (random guessing).\n",
        "accuracy(cnn, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNh5yF2Q53Tv",
        "outputId": "c11b9982-6d96-4551-bfb0-76c5886df2d5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0969, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CROSS_ENTROPY"
      ],
      "metadata": {
        "id": "fxOipAfLLhd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: it is important to move the CNN to the device before initializing the optimizer,\n",
        "# since the optimizer also has a state that must be moved to the GPU.\n",
        "loss = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "17Sb5kRR550I"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beale_function(x):\n",
        "  return (torch.pow(torch.tensor([1.5])-x[0]+x[0]*x[1],2) + torch.pow(torch.tensor([2.25])-x[0]+x[0]*torch.pow(x[1],2),2)+torch.pow(torch.tensor([2.625])-x[0]+x[0]*torch.pow(x[1],3),2))"
      ],
      "metadata": {
        "id": "1WtQ6zyjX6wD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fp(x, y):\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  l_rate0 = 0.025\n",
        "  f = beale_function\n",
        "  theta1 = torch.rand(2)\n",
        "  theta0 = theta1 + torch.tensor([1,1])\n",
        "  t=torch.tensor([0])\n",
        "  while (torch.norm(theta1 - theta0)>1e-10) :\n",
        "    l_rate=l_rate0*torch.exp(-t*1e-4)\n",
        "    t=t+1\n",
        "    v=torch.normal(torch.tensor([0.0, 0.0]),torch.tensor([1.0, 1.0]))\n",
        "    ft=f(theta1)\n",
        "    dt=torch.tensor(torch.autograd.functional.jvp(f,theta1,v)[1])\n",
        "    gt=v*dt\n",
        "    theta0 = theta1\n",
        "    theta1 = theta1 - l_rate*gt\n",
        "\n",
        "  return theta1  "
      ],
      "metadata": {
        "id": "1xtc8O-2D8YJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.tensor([2, 4, 8, 16])\n",
        "y=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
        "theta=train_fp(x,y)\n",
        "print(theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24QRQ6Hhaf4i",
        "outputId": "4c1239b5-d960-415d-92c8-68fe2587c4ab"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-08ee1067b7d1>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dt=torch.tensor(torch.autograd.functional.jvp(f,theta1,v)[1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.0004, 0.5001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "  cnn.train()\n",
        "  for i in range(10):\n",
        "    xb, yb = next(iter(train_loader))\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    ypred = cnn(xb)\n",
        "    l = loss(ypred, yb)\n",
        "\n",
        "    #Update cnn parameters\n",
        "    #Recalculate ypred and loss\n",
        "    #MIRAR NN_LAB_LOGISITC_REGRESSION\n",
        "    #CALCULAR G(THETA) QUE ES EL GRADIENTE Y APLICARLO A LOS PARAMETROS DEL CNN, LOS WEIGHTS\n",
        "\n",
        "  cnn.eval()\n",
        "  print(f'Accuracy at epoch {epoch}: {accuracy(cnn, test_loader, device)}')"
      ],
      "metadata": {
        "id": "V3k3eeKL_TPX",
        "outputId": "b7d9eb87-4719-48ad-d9ab-8913076be6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5cd81cbd360d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Update cnn parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[1;32m   1168\u001b[0m                  reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ]
    }
  ]
}